<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Mark  Crowley | Reinforcement Learning</title>
<meta name="description" content="">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/rlgradcourse/">

<!-- Theming-->


    
<!-- MathJax -->
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="/">
       <span class="font-weight-bold">Mark</span>   Crowley
      </a>
      
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/bio/">
                bio
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/contact/">
                contact
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/lab/">
                lab
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/news/">
                news
                
              </a>
          </li>
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/projects/">
                projects
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/showcase/">
                publications
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/teaching/">
                teaching
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/topics/">
                topics
                
              </a>
          </li>
          
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
      
          
            <h1 class="post-title">Reinforcement Learning</h1>
        
      
    <p class="post-description" style="border-bottom-style:dashed; border-bottom-color:lightgrey; border-bottom-width:1px; margin:1px; margin-bottom:10px;font-style: italic;">Fall 2024 - ECE 750 Topic 4</p>

      
      
      
      
      
      
        <p></p>
  </header>

  <article>
      
      <img src="/assets/img/teaching/ece493-logo.png" style="width: 300px; padding: 10px; float: right;">
      
    <h1 id="ece-750-topic-40---reinforcement-learning">ECE 750 Topic 40 - Reinforcement Learning</h1>

<p>Offered Fall 2024 by Prof. Mark Crowley</p>

<h3 id="course-description">Course Description</h3>

<p>This advanced topics graduate course will focus on the theories, methods and applications of Reinforcement Learning (RL). RL is an Artificial Intelligence/Machine Learning (AI/ML) approach for building systems that can  learn how to make decisions through their own experiences in an environment. The domain is more difficult than supervised ML since it involves uncertainty and limited information about how the world, and its dynamics, actually function. It can also be seen the AI analogy for the Optimal Control problem, where there are no dynamics models available and the objective is not globally known.</p>

<h4 id="foundations-first">Foundations First…</h4>
<p>This course should follow after learning about foundational theory and methods from Artificial Intelligence and Machine Learning, including Deep Learning methods. The foundations of RL theory will be covered in detail as needed to support understanding the recent explosion of interest and progress on Deep Reinforcement Learning methods over the past decade.</p>

<h4 id="reading-papers-on-the-latest-in-deep-rl">Reading Papers on the Latest in Deep RL</h4>
<p>After the foundations are covered, a series of papers from recent years will be <em>presented by students</em> and discussed in class to see the relationships between concepts and to gain practice viewing advanced AI/ML publications critically and analytically.</p>

<p>See the <a href="/rdgrp-ece750T4-f24">course reading list</a> <strong>[in progress]</strong> for an idea of the papers we will cover and how to sign up for pressentations.</p>

<h4 id="expected-background">Expected Background</h4>
<p>No background in Reinforcement Learning is required for this course, although we will move quite quickly through the classic concepts and background.  A background in control or decision making theory would be beneficial but not required.</p>

<p>The course will use standard concepts from probability and statistics, which will be assumed. It is assumed students are already have a background in standard Machine Learning concepts and practices, especially core Deep Learning concepts for fully connected networks and CNNs. We will go into depth on the various approaches for utilizing Deep Learning for Reinforcement Learning, and sequential machine learning more generally, but we will not spend much time looking at the definitions of neural networks, deep learning, CNNs, machine learning training methodology, etc. Thus, if you do not have this background, you should consider taking this course <em>after</em> a course such as ECE 657 or equivalent.</p>

<p>All other concepts needed for the course will be introduced directly. Examples and some assignments will depend on programming ability in Python.</p>

<h3 id="course-outline">Course Outline</h3>

<p>See the <a href="https://outline.uwaterloo.ca/view/nraur3"><strong>official course outline</strong></a> for course location, times, staff contact and other information .</p>

<h3 id="additional-resource-links">Additional Resource Links</h3>

<p>This page will have additional resources linking to previous courses, topic notes etc, which may also be duplicated on LEARN.</p>

<ul>
  <li><strong><a href="http://incompleteideas.net/book/the-book-2nd.html">Textbook</a></strong> (online, free)</li>
  <li>From my foundational undergraduate course on the same topic: <a href="https://www.youtube.com/channel/UC6p1AJ7jKNFp6OB2MmAoWvA">ECE 457C YouTube Channel</a></li>
</ul>

<hr />

<hr />

<h3 id="learning-objectives">Learning Objectives</h3>
<p>In this course we will build up the fundamental knowledge about these components and how they combine together to make such systems possible.</p>

<ol>
  <li>Identify and Explain the component theoretical concepts of Reinforcement Learning systems.</li>
  <li>Implement or instantiate any of the classic Reinforcement Learning algorithms on a variety of domains.</li>
  <li>Evaluate the performance of a particular RL system on a given domain through proper experimental design, statistical analysis and visualization.</li>
  <li>Be able to write mathematical notation electronically using <strong>LaTeX</strong> (also useful for Word/Google Docs/Markdown).</li>
  <li>Practice and feedback on reviewing, summarizing and utilizing theory and results from academic papers.</li>
</ol>

<h3 id="resourcesreferences">Resources/References</h3>
<p>The Foundations of RL will be taught from online sources and the seminal text by Sutton and Barto available freely on line.</p>
<ul>
  <li><strong>[SuttonBarto2018]</strong> - Reinforcement Learning: An Introduction. Book, free pdf of draft available. <a href="http://incompleteideas.net/book/the-book-2nd.html">http://incompleteideas.net/book/the-book-2nd.html</a>
Later advances in Deep RL and influence of RL concepts and methods in society will be covered through readings of academic papers, which students will present in class and discuss with everyone. This list will change and update over time.</li>
  <li><a href="https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf">Playing Atari with Deep Reinforcement Learning</a>, Mnih et al, 2013. </li>
  <li><a href="https://arxiv.org/abs/1511.05952">Prioritized Experience Replay</a>, Schaul et al, 2015. </li>
  <li><a href="https://arxiv.org/abs/1710.02298">Rainbow: Combining Improvements in Deep Reinforcement Learning</a>, Hessel et al, 2017. </li>
  <li><a href="https://arxiv.org/abs/1602.01783">Asynchronous Methods for Deep Reinforcement Learning</a>, Mnih et al, 2016. </li>
  <li><a href="https://arxiv.org/abs/1707.06347">Proximal Policy Optimization Algorithms</a>, Schulman et al, 2017. </li>
  <li><a href="https://arxiv.org/abs/1509.02971">Continuous Control With Deep Reinforcement Learning</a>, Lillicrap et al, 2015. </li>
  <li>and more from  “Key Papers in Deep RL” - <a href="https://spinningup.openai.com/en/latest/spinningup/keypapers.html">https://spinningup.openai.com/en/latest/spinningup/keypapers.html</a></li>
  <li>A Dual-Agent Scheduler for Distributed Deep Learning Jobs on Public Cloud via Reinforcement Learning. Xing, et. al, 2023. ACM SIGKDD Conference on Knowledge Discovery and Data Mining.</li>
  <li>Two Theories of Moral Cognition. [[JuliaHaas]], 2022. Chapter in <a href="https://link.springer.com/bookseries/7761">The International Library of Ethics, Law and Technology</a> book series (ELTE,volume 22).</li>
</ul>

<h3 id="assessment">Assessment</h3>

<p>Assessment in the course breaks down as follows:</p>
<ul>
  <li>20% Programming assignment on Fundaments of RL</li>
  <li>20% Programming assignment on Deep RL</li>
  <li>25% Midterm Exam on Fundamentals of RL and Deep RL</li>
  <li>35% Written report/paper/project on a topic covered in one or more paper  from the <a href="/rdgrp-ece750T4-f24/">reading list</a> (can be done alone or in pairs, research based students are encouraged to work alone on this)
    <ul>
      <li>10% Presentation of a paper from the required reading list that will be used in their project. Leading discussion with class about the paper. If working in pairs, both partners must present and discuss for roughly equal amounts of time.</li>
      <li>10% Related to at least one paper from the Reading List:
        <ul>
          <li>Coding: Implement and test the algorithm in use in that paper, or use some of it’s concepts to modify some other existing RL algorithm.</li>
          <li>Theory: Make some theoretical analysis, proof, or claim using one, or more, of the required papers.</li>
          <li>Could also challenge/examine the paper’s experiments, or combine of elements from multiple papers and carry out your own experiments.</li>
        </ul>
      </li>
      <li>15% Written report on what you did, summarizing the related paper(s), and explaining the work you did extending it, implementing it, combining it with another paper, or confirming it. The paper must be written in the style of a Machine Learning conference paper. A LaTeX template will be given.</li>
    </ul>
  </li>
</ul>

<h3 id="exam-reference-notes">Exam Reference Notes</h3>

<p>Note that the midterm exam and final exam will be entirely on paper in person, so any reliance you have on GenAI tools will not be available to you for the bulk of the course grades. For the midterm exam you will be permitted to bring in a couple pages of handwritten reference notes (a.k.a. “cheat sheets). These must be submitted with your exam and will returned afterwards if requested.</p>

<p>For more information also see the <a href="https://uwaterloo.ca/associate-vice-president-academic/artificial-intelligence-uw">UWaterloo Policy Page on Generative AI</a>.</p>

<h3 id="course-communication-processes">Course Communication Processes</h3>
<ul>
  <li>LEARN : Announcements will be sent out on LEARN, so you should set up your email notifications to forward any course announcements so you find out about them. All course lecture content, assignment materials, and grades will be hosted on LEARN as well.</li>
  <li>Microsoft Teams: We will also use Microsoft Teams for communication and discussion. Announcements about the course will be posted there in a main channel. There will be a setup for paper discussion and each student presentation and report should be posted there for others to read as well.</li>
  <li>We will try to use Teams for answering of questions on course material, but if it becomes too unwieldy let me know, we could use a more traditional discussion platform such as Piazza. However, since we have no Teaching Assistants for this course, I might not be as responsive to questions on Piazza as Teams.</li>
</ul>


  </article>


      

    
</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2025 Mark  Crowley.
    Based on [*folio](https://github.com/bogoli/-folio) design. Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
    Last updated: April 09, 2025.
    
  </div>
</footer>



  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  



<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

<!-- Load DarkMode JS -->
<script src="/assets/js/dark_mode.js"></script>


</html>

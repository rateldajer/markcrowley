---
layout: page
title: Artificial Intelligence (AI)
name: Artificial Intelligence (AI)
permalink: /artificial-intelligence/
bibkeyword: artificial-intelligence
description: AI is the study of how to build computer programs that can learn to detect patterns from data.
stage: topic
showtitle: true
showbib: false
showwebpage: false
publish: true
img: /assets/img/Marks-Unnessecarily-Big-Picture-of-AI-landscape.png
importance: 1
showsidbar: "true"
---
In the broadest terms my research spans the areas of ***Artificial Intelligence (AI)*** and ***[Machine Learning (ML)](/machine-learning/)*** which can be seen highly related, independent, or synonymous(?) research fields depending on who you are.

<!-- copied from AITopics/AI-Foundations page -->

## Going Back to the Beginning
When we ask the thorny question, what does Artificial Intelligence really *mean* though? We usually start, at the beginning, with our old friend, [the Turing Test](Going Back to the Beginning).

### So have we Passed the Turing Test?
Just a few years ago, there were popular Chatbot challenges to see if a chatbot could "pass the Turing test". Progress with structured rules for understanding and producing natural language in conversation had advanced significantly up to 2010. But the chatbots "winning" these competitions often relied a great deal on hardcoded tricks, or being rude in order to convince human judges that the agent on the other end of the chat stream was a fallible human rather than a programming chatbot.

However, since the dawn of the powerful Large Language Model chatbots such as ChatGPT form OpenAI in 2022, it would seem that the Turing Test is passed, for Turing's original proposal of a test of language fluency being able to fool a human judge. Even with the many flaws and blindspots of these systems, researchers 20 years ago would have marvelled as how well they seem to "understand" language. 

So, in short, I'd say the answer is clearly **yes**.

### We're only getting started...
Most AI researchers would concur that the Turing Test was *never actually a great test*, it was just a thought experiment by one of the worlds most brilliant founding minds. 

The test was problematic because first, itâ€™s a very low bar! People are actually pretty easy to fool when presented with a systems that superficially matches behaviours they view as human.

Second, the test was not quantitative enough, it depends on the opinions of human beings to judge something, rather than some measurement that is well defined. 

There isn't really a replacement that is completely non-subjective, but there are *many* new scoring functions and benchmarks which attempt to count and analyze how often the latest AI models get the "right answer" to particular questions. 
# A New Definition of Artificial Intelligence
At its core, I think Artificial Intelligence is about *making machines that can do the work of complex reasoning tasks that most human beings are able to do in their daily lives*.

Over the decades since Turing, many types of tasks have been put forward as what would demonstrate "intelligence" in a computer, such as :
- searching for optimal solutions to complex, logical systems (like games) 
- general mathematical and logical reasoning
- statistical prediction and inference given data
- planning and decision making given rules and preferences about outcomes
- recognizing objects in complex visual scenes, including face recognition 
- explanation, summarization and abstraction of natural language text
- communication with other people about our thoughts
- interpreting communications from others
- imagining new things based on experiences 
- so, what's next?... *that's the fun part*

Clearly, we don't know what all these words mean fully either, but we're closer than we were with "Intelligence" and "Thinking". 

An interesting aspect of the History of AI research is 
that many of the reasoning, or thinking, tasks above *used to be considered cutting-edge AI challenges*. Over the years, as people have found clever ways to make computers more clever, solving these reasoning tasks automatically has become common-place. So, many people *no longer consider them AI at all*. 

Has the definition of intelligence changed? (clearly not, since we never had one to begin with.) 

What happens is the *goalposts get moved*, and now AI has to be something *more impressive*. Which is why my informal definition is :

>  Artificial Intelligence research is about trying to get computers to do things that would seem impossible if not for the fact that we have proof it can be done, the proof being some human, animal, or other system in nature can perform the task perfectly well. -- Mark Crowley

This, of course, implies that the other system, usually a brain, is essentially a computer. If there's more going on than *computing* in the most general sense, then this argument wouldn't follow. But I've yet to encounter anything in crazy old universe that can't be thought of as computation, so I'll take that as a safe bet.

## An Unnecessarily Big Picture
One thing I like to do when thinking about these things is to draw concept graphs, my students have seen many of these. They aren't *always necessarily* enlightening, but they do force me to consider how to group together different ideas, and look for patterns that might help to explain what is it we're talking about when we say words like "intelligence", "reasoning", "thinking", "action", "observation".

Here's one of my favourites.
<a href="/assets/img/Marks-Unnessecarily-Big-Picture-of-AI-landscape.png" border=0><img src = "/assets/img/Marks-Unnessecarily-Big-Picture-of-AI-landscape.png" width="90%"></a>

## Publications
All my [publications](/pub-by-topic/) are, in one way or another, related to the pursuit of **artificial intelligence**. So, for this topic, I'd simply direct you the full list by subtopics. :)
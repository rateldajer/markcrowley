<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Mark  Crowley | publications</title>
<meta name="description" content="">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/showcase/">

<!-- Theming-->


    
<!-- MathJax -->
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="/">
       <span class="font-weight-bold">Mark</span>   Crowley
      </a>
      
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/bio/">
                bio
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/contact/">
                contact
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/lab/">
                lab
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/news/">
                news
                
              </a>
          </li>
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/projects/">
                projects
                
              </a>
          </li>
          
          
          
          <li class="nav-item active">
              <a class="nav-link" href="/showcase/">
                publications
                
                <span class="sr-only">(current)</span>
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/teaching/">
                teaching
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/topics/">
                topics
                
              </a>
          </li>
          
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
      
          
            <h1 class="post-title">showcased publications</h1>
          
      
    <p class="post-description" style="border-bottom-style:dashed; border-bottom-color:lightgrey; border-bottom-width:1px; margin:1px; margin-bottom:10px;font-style: italic;">A selection of highlighted papers by year</p>

      
      
      
      
      
      
        <p></p>
  </header>

  <article>
      
    <p>Also see:</p>
<ul>
  <li><strong><a href="/publications">All Published Works</a></strong></li>
  <li><a href="/pub-by-topic/">Publications Grouped by Research Topics</a></li>
  <li><a href="/theses">Defended Theses from the Lab</a></li>
  <li><a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Crowley%2C+M">My Arxiv Preprint Page</a></li>
  <li><a href="https://scholar.google.ca/citations?user=eL_y80EAAAAJ">Google Scholar</a></li>
</ul>

<!-- <h2>selected publications</h2> -->
<div class="publications by year">

  <h2 class="year">2024</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">Causal2</abbr>
    
  
  </div>

  <div id="bagi2024arxiv" class="col-sm-8">
      <div class="title">
          
          [preprint] Implicit Causal Representation Learning via Switchable Mechanisms
      </div>
      <div class="author">
        
            
            
              
                
                  
                    
                      <a href="https://uwaterloo.ca/scholar/sshirahm/home" target="_blank">Shayan Shirahmad Gale Bagi</a>,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      <a href="https://scholar.google.se/citations?user=nWe8d1MAAAAJ&amp;hl=sv" target="_blank">Zahra Gharaee</a>,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      <a href="https://www.cs.sfu.ca/~oschulte/" target="_blank">Oliver Schulte</a>,
                    
                  
                
              
        
            
            
              
                
                  
                    and <em>Mark Crowley</em>
                  
                
              
        
      </div>

      <div class="periodical">
      
          In <em>Arxiv Preprint</em>. 

      

      
      
      
      
        2024.
      

       
      
        
      <div class="periodical">
          
      </div>
      </div>

    <div class="links">
    
    
      <a href="http://arxiv.org/abs/2402.11124" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
      
      <a href="/assets/pdf/2024-arxiv-bagi-disentanglement.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
    
    

    
        
        
          <a class="abstract btn btn-sm z-depth-0" role="button">Notes</a>
        
    
    </div>

    <!-- Hidden notes block - pick note or annote and stick to it -->
    
        
        
        <div class="abstract hidden">
            <p><b>Note:</b> This is being reworked for a journal submission soon. </p>
          </div>
        
    

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ChemGymRL</abbr>
    
  
  </div>

  <div id="beeler2023digidiscjourn" class="col-sm-8">
      <div class="title">
          
          ChemGymRL: An Interactive Framework for Reinforcement Learning for Digital Chemistry
      </div>
      <div class="author">
        
            
            
              
                
                  
                    
                      Chris Beeler,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      <a href="https://sriramsubramanian.com/" target="_blank">Sriram Ganapathi Subramanian</a>,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      Kyle Sprague,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      Nouha Chatti,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      <a href="https://web.cs.dal.ca/~bellinger/" target="_blank">Colin Bellinger</a>,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      Mitchell Shahen,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      Nicholas Paquin,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      Mark Baula,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      Amanuel Dawit,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      Zihan Yang,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      Xinkai Li,
                    
                  
                
              
        
            
            
              
                
                  
                    <em>Mark Crowley</em>,
                  
                
              
        
            
            
              
                
                  
                    
                      and Isaac Tamblyn.
                    
                  
                
              
        
      </div>

      <div class="periodical">
      
        <em>Digital Discovery</em>.

          
              3,
          
          

      

      
      
      
          Feb,
      
      
        2024.
      

       
      
        
      <div class="periodical">
          
      </div>
      </div>

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      
      <a href="/assets/pdf/2024-digidiscjourn-beeler-chemgymrl-an.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/chemgymrl/chemgymrl" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    
    
    

    
        
        
    
    </div>

    <!-- Hidden notes block - pick note or annote and stick to it -->
    
        
        
    

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
        <p><b>Abstract:</b>
         This paper provides a simulated laboratory for making use of reinforcement learning (RL) for material design, synthesis, and discovery. Since RL is fairly data intensive, training agents ‘on-the-fly’ by taking actions in the real world is infeasible and possibly dangerous. Moreover, chemical processing and discovery involves challenges which are not commonly found in RL benchmarks and therefore offer a rich space to work in. We introduce a set of highly customizable and open-source RL environments, ChemGymRL, implementing the standard gymnasium API. ChemGymRL supports a series of interconnected virtual chemical benches where RL agents can operate and train. The paper introduces and details each of these benches using well-known chemical reactions as illustrative examples, and trains a set of standard RL algorithms in each of these benches. Finally, discussion and comparison of the performances of several standard RL methods are provided in addition to a list of directions for future work as a vision for the further development and usage of ChemGymRL.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2023</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ECML</abbr>
    
  
  </div>

  <div id="bellinger2023ecml" class="col-sm-8">
      <div class="title">
          
          Learning when to observe: A frugal reinforcement learning framework for a high-cost world
      </div>
      <div class="author">
        
            
            
              
                
                  
                    
                      <a href="https://web.cs.dal.ca/~bellinger/" target="_blank">Colin Bellinger</a>,
                    
                  
                
              
        
            
            
              
                
                  
                    <em>Mark Crowley</em>,
                  
                
              
        
            
            
              
                
                  
                    
                      and Isaac Tamblyn.
                    
                  
                
              
        
      </div>

      <div class="periodical">
      
          In <em>Workshop on Simplification, Compression, Efficiency and Frugality for Artificial intelligence at the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML-PKDD)</em>. 

      

      
      
          Turin, Italy.
      
      
          Sep,
      
      
        2023.
      

       
      
        
      <div class="periodical">
          
      </div>
      </div>

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/2307.02620" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
      
      <a href="https://www.dropbox.com/scl/fi/9w1llofc1hdtlxzcwscqj/2023-ecml-bellinger-learning.pdf?rlkey=0ub9s7lms2v1n8xrjybx2w1ro&amp;raw=1" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
      <a href="https://scefa.wp.imt.fr/articles-accepted/" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
    

    
        
        
    
    </div>

    <!-- Hidden notes block - pick note or annote and stick to it -->
    
        
        
    

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
        <p><b>Abstract:</b>
         Reinforcement learning (RL) has been shown to learn so- phisticated control policies for complex tasks including games, robotics, heating and cooling systems and text generation. The action-perception
cycle in RL, however, generally assumes that a measurement of the state of the environment is available at each time step without a cost. In applications such as materials design, deep-sea and planetary robot exploration and medicine, however, there can be a high cost associated with measuring, or even approximating, the state of the environment. In this paper, we survey the recently growing literature that adopts the perspective that an RL agent might not need, or even want, a costly mea- surement at each time step. Within this context, we propose the Deep Dynamic Multi-Step Observationless Agent (DMSOA), contrast it with the literature and empirically evaluate it on OpenAI gym and Atari Pong environments. Our results, show that DMSOA learns a better policy with fewer decision steps and measurements than the considered alternative from the literature. The corresponding code is available at: https: //github.com/cbellinger27/Learning-when-to-observe-in-RL</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">Multi-Advisor-QL</abbr>
    
  
  </div>

  <div id="ganapathisubramanian2023ijcai" class="col-sm-8">
      <div class="title">
          
          Multi-Agent Advisor Q-Learning
      </div>
      <div class="author">
        
            
            
              
                
                  
                    
                      <a href="https://sriramsubramanian.com/" target="_blank">Sriram Ganapathi Subramanian</a>,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      <a href="https://cs.uwaterloo.ca/~klarson/" target="_blank">Kate Larson</a>,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      <a href="https://irll.ca" target="_blank">Matthew Taylor</a>,
                    
                  
                
              
        
            
            
              
                
                  
                    and <em>Mark Crowley</em>
                  
                
              
        
      </div>

      <div class="periodical">
      
          In <em>International Joint Conference on Artificial Intelligence (IJCAI) : Journal Track</em>. 

      

      
      
          Macao, China.
      
      
          Aug,
      
      
        2023.
      

       
      
        
      <div class="periodical">
          
      </div>
      </div>

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      
      <a href="/assets/pdf/2022-jair-ganapathi%20subramanian-multi-agent.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/Sriram94/multiagentadvisorqlearning" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    
      <a href="https://doi.org/10.1613/jair.1.13445" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
      <a href="https://recorder-v3.slideslive.com/?share=82208&amp;s=5fe77823-b4c3-4f27-99ba-b59e71f4a7c4" class="btn btn-sm z-depth-0" role="button" target="_blank">Video</a>
    
    

    
        
        
          <a class="abstract btn btn-sm z-depth-0" role="button">Notes</a>
        
    
    </div>

    <!-- Hidden notes block - pick note or annote and stick to it -->
    
        
        
        <div class="abstract hidden">
            <p><b>Note:</b> This paper uses forest widlfire as one of its motivational examples to demonstrate the difficulty of multi-agent planning in real-world domains with many agents acting at once. This was a journal track paper and presentation of our 2022 JAIR paper of the same name. </p>
          </div>
        
    

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
        <p><b>Abstract:</b>
         In the last decade, there have been significant advances in multi-agent reinforcement learn- ing (MARL) but there are still numerous challenges, such as high sample complexity and slow convergence to stable policies, that need to be overcome before wide-spread deployment is possi- ble. However, many real-world environments already, in practice, deploy sub-optimal or heuristic approaches for generating policies. An interesting question that arises is how to best use such approaches as advisors to help improve reinforcement learning in multi-agent domains. In this paper, we provide a principled framework for incorporating action recommendations from online sub- optimal advisors in multi-agent settings. We describe the problem of ADvising Multiple Intelligent Reinforcement Agents (ADMIRAL) in nonrestrictive general-sum stochastic game environments and present two novel Q-learning based algorithms: ADMIRAL - Decision Making (ADMIRAL-DM) and ADMIRAL - Advisor Evaluation (ADMIRAL-AE), which allow us to improve learning by appropriately incorporating advice from an advisor (ADMIRAL-DM), and evaluate the effectiveness of an advisor (ADMIRAL-AE). We analyze the algorithms theoretically and provide fixed point guarantees regarding their learning in general-sum stochastic games. Furthermore, extensive experi- ments illustrate that these algorithms: can be used in a variety of environments, have performances that compare favourably to other related baselines, can scale to large state-action spaces, and are robust to poor advice from advisors.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">GCRL</abbr>
    
  
  </div>

  <div id="bagi2023icml" class="col-sm-8">
      <div class="title">
          
          Generative Causal Representation Learning for Out-of-Distribution Motion Forecasting
      </div>
      <div class="author">
        
            
            
              
                
                  
                    
                      <a href="https://uwaterloo.ca/scholar/sshirahm/home" target="_blank">Shayan Shirahmad Gale Bagi</a>,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      <a href="https://scholar.google.se/citations?user=nWe8d1MAAAAJ&amp;hl=sv" target="_blank">Zahra Gharaee</a>,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      <a href="https://www.cs.sfu.ca/~oschulte/" target="_blank">Oliver Schulte</a>,
                    
                  
                
              
        
            
            
              
                
                  
                    and <em>Mark Crowley</em>
                  
                
              
        
      </div>

      <div class="periodical">
      
          In <em>Proceedings of the 40th International Conference on Machine Learning (ICML)</em>. 

      

      
          PMLR,
      
      
          Honolulu, Hawaii, USA.
      
      
          Jul,
      
      
        2023.
      

       
      
        <i>[13 citations]</i>
      
        
      <div class="periodical">
          
      </div>
      </div>

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/2302.08635" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
      
      <a href="https://proceedings.mlr.press/v202/shirahmad-gale-bagi23a/shirahmad-gale-bagi23a.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/sshirahmad/GCRL" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
      
      <a href="/assets/pdf/2023-icml-bagi-generative-poster.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
      
    
    
    
    
      <a href="https://proceedings.mlr.press/v202/shirahmad-gale-bagi23a.html" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
    
      <a href="https://hyp.is/go?url=https%3A%2F%2Fopenreview.net%2Fpdf%3Fid%3DKw90j2pNSt&amp;group=__world__" class="btn btn-sm z-depth-0" role="button" target="_blank">Hypoth</a>
    

    
        
        
          <a class="abstract btn btn-sm z-depth-0" role="button">Notes</a>
        
    
    </div>

    <!-- Hidden notes block - pick note or annote and stick to it -->
    
        
        
        <div class="abstract hidden">
            <p><b>Note:</b> In this paper we propose a new framework for leveraging causal information to improve robustness of learning in the presence of distribution shift. Empirical results on the motion forecasting domain support the theoretical findings. </p>
          </div>
        
    

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
        <p><b>Abstract:</b>
         Conventional supervised learning methods typically assume i.i.d samples and are found to be sensitive to out-of-distribution (OOD) data. We propose Generative Causal Representation Learning (GCRL) which leverages causality to facilitate knowledge transfer under distribution shifts. While we evaluate the effectiveness of our proposed method in human trajectory prediction models, GCRL can be applied to other domains as well. First, we propose a novel causal model that explains the generative factors in motion forecasting datasets using features that are common across all environments and with features that are specific to each environment. Selection variables are used to determine which parts of the model can be directly transferred to a new environment without fine-tuning. Second, we propose an end-to-end variational learning paradigm to learn the causal mechanisms that generate observations from features. GCRL is supported by strong theoretical results that imply identifiability of the causal model under certain assumptions. Experimental results on synthetic and real-world motion forecasting datasets show the robustness and effectiveness of our proposed method for knowledge transfer under zero-shot and low-shot settings by substantially outperforming the prior motion forecasting models on out-of-distribution prediction.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">Textbook</abbr>
    
  
  </div>

  <div id="ghojogh2022springerbook" class="col-sm-8">
      <div class="title">
          
          Elements of Dimensionality Reduction and Manifold Learning
      </div>
      <div class="author">
        
            
            
              
                
                  
                    
                      <a href="https://www.researchgate.net/profile/Benyamin-Ghojogh" target="_blank">Benyamin Ghojogh</a>,
                    
                  
                
              
        
            
            
              
                
                  
                    <em>Mark Crowley</em>,
                  
                
              
        
            
            
              
                
                  
                    
                      <a href="https://uwaterloo.ca/scholar/karray" target="_blank">Fakhri Karray</a>,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      and <a href="https://uwaterloo.ca/data-analytics/" target="_blank">Ali Ghodsi</a>.
                    
                  
                
              
        
      </div>

      <div class="periodical">
      

      
          Springer Nature,
      
      
      
          Feb,
      
      
        2023.
      

       
      
        <i>[63 citations]</i>
      
        
      <div class="periodical">
          
      </div>
      </div>

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
      <a href="https://link.springer.com/book/10.1007/978-3-031-10602-6" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
    

    
        
        
          <a class="abstract btn btn-sm z-depth-0" role="button">Notes</a>
        
    
    </div>

    <!-- Hidden notes block - pick note or annote and stick to it -->
    
        
        
        <div class="abstract hidden">
            <p><b>Note:</b> Thanks mostly to the enourmous efforts of former PhD student Dr. Benyamin Ghojogh on this text based on the research and background reviews for his thesis. </p>
          </div>
        
    

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
        <p><b>Abstract:</b>
         Dimensionality reduction, also known as manifold learning, is an area of machine learning used for extracting informative features from data, for better representation of data or separation between classes. This book presents a cohesive review of linear and nonlinear dimensionality reduction and manifold learning. Three main aspects of dimensionality reduction are covered – spectral dimensionality reduction, probabilistic dimensionality reduction, and neural network-based dimensionality reduction, which have geometric, probabilistic, and information-theoretic points of view to dimensionality reduction, respectively. This book delves into basic concepts and recent developments in the field of dimensionality reduction and manifold learning, providing the reader with a comprehensive understanding. The necessary background and preliminaries, on linear algebra, optimization, and kernels, are also explained in the book to ensure a comprehensive understanding of the algorithms.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">Multi-Advisor-MARL</abbr>
    
  
  </div>

  <div id="ganapathi-subramanian2023aamas" class="col-sm-8">
      <div class="title">
          
          Learning from Multiple Independent Advisors in Multi-agent Reinforcement Learning
      </div>
      <div class="author">
        
            
            
              
                
                  
                    
                      <a href="https://sriramsubramanian.com/" target="_blank">Sriram Ganapathi Subramanian</a>,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      <a href="https://irll.ca" target="_blank">Matthew Taylor</a>,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      <a href="https://cs.uwaterloo.ca/~klarson/" target="_blank">Kate Larson</a>,
                    
                  
                
              
        
            
            
              
                
                  
                    and <em>Mark Crowley</em>
                  
                
              
        
      </div>

      <div class="periodical">
      
          In <em>Proceedings of the 22nd International Conference on Autonomous Agents and MultiAgent Systems (AAMAS)</em>. 

      

      
          International Foundation for Autonomous Agents and Multiagent Systems (IFAAMAS),
      
      
          London, United Kingdom.
      
      
          Sep,
      
      
        2023.
      

       
      
        
      <div class="periodical">
          
      </div>
      </div>

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      
      <a href="/assets/pdf/2023-aamas-ganapathi%20subramanian-learning%20from%20multiple%20independent%20advisors%20in%20multi-agent%20reinforcement%20learning.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
    
    

    
        
        
    
    </div>

    <!-- Hidden notes block - pick note or annote and stick to it -->
    
        
        
    

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
        <p><b>Abstract:</b>
         Multi-agent reinforcement learning typically suffers from the problem of sample inefficiency, where learning suitable policies involves the use of many data samples. Learning from external demonstrators is a possible solution that mitigates this problem. However, most prior approaches in this area assume the presence of a single demonstrator. Leveraging multiple knowledge sources (i.e., advisors) with expertise in distinct aspects of the environment could substantially speed up learning in complex environments. This paper considers the problem of simultaneously learning from multiple independent advisors in multi-agent reinforcement learning. The approach leverages a two-level Q-learning architecture, and extends this framework from single-agent to multi-agent settings. We provide principled algorithms that incorporate a set of advisors by both evaluating the advisors at each state and subsequently using the advisors to guide action selection. Also, we provide theoretical convergence and sample complexity guarantees. Experimentally, we validate our approach in three different test-beds and show that our algorithms give better performances than baselines, can effectively integrate the combined expertise of different advisors, and learn to ignore bad advice.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2022</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">IOTSMS</abbr>
    
  
  </div>

  <div id="camlica2022iotsms" class="col-sm-8">
      <div class="title">
          
          Aggressive Driver Behavior Detection using Parallel Convolutional Neural Networks on Simulated and Real Driving Data
      </div>
      <div class="author">
        
            
            
              
                
                  
                    
                      Zehra Camlica,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      Jim Quesenberry,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      Daniel Carballo,
                    
                  
                
              
        
            
            
              
                
                  
                    and <em>Mark Crowley</em>
                  
                
              
        
      </div>

      <div class="periodical">
      
          In <em>9th International Conference on Internet of Things: Systems, Management and Security (IOTSMS)</em>. 

      

      
          IEEE,
      
      
          Milan, Italy.
      
      
          Nov,
      
      
        2022.
      

       
      
        
      <div class="periodical">
          
      </div>
      </div>

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      
      <a href="/assets/pdf/2022-iotsms-camlica-aggressive.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
      
      <a href="https://www.dropbox.com/scl/fi/17fsz27m5rkgsmwr5fmj9/2022-iotsms-camlica-aggressive1.pdf?rlkey=63r495t23bah6kvqopk4ifqug&amp;raw=1" class="btn btn-sm z-depth-0" role="button" target="_blank">Slides</a>
      
    
    
    
      <a href="https://youtu.be/ORSPRSEJ5NQ" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
    

    
        
        
          <a class="abstract btn btn-sm z-depth-0" role="button">Notes</a>
        
    
    </div>

    <!-- Hidden notes block - pick note or annote and stick to it -->
    
        
        
        <div class="abstract hidden">
            <p><b>Note:</b> This paper at a workshop as part of an international IOT conference, presented new results from my PhD student Zehra Camlica on her work modelling aggressive/passive human driver behaviour styles using deep learning. We used simulated and real collected driver user data from the DBL project to validate the models. </p>
          </div>
        
    

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
        <p><b>Abstract:</b>
         The novel method proposed in this paper is com- promised of application of two Convolutional Neural Networks (CNN) working in parallel to simultaneously classify driver be- haviors while classifying maneuvers by using time series data. We claim that the Parallel Convolutional Neural Network (PCNN) not only speeds-up training time but also increases performance since having information about the maneuver helps to improve behavior classification performance and vice versa. In this study, both simulation and real-world driving datasets are utilized for driver behavior analysis. As simulation data, mobile phone sensor data are simulated as a time series using a combination of a traffic simulator (SUMO) and a car simulation system (Webots). The same type of data is collected with a specially designed vehicle traveled on a defined route around a predefined region. The collected data are then separately utilized as training and testing data for classification of both maneuvers (e.g turns and lane changes) and driver behaviors (e.g aggressive, non-aggressive) applying a novel method using deep learning on time series data. In addition, other methods which are commonly used for time series analysis, Hidden Markov Models(HMMs) and Recurrent Neural Networks (RNN), are applied to the same datasets to compare with PCNN. According to the results, the CNN classifiers perform efficiently for a single task and PCNN outperforms both single task-CNN and RNN with an average accuracy of 86%.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">Mean Field MARL</abbr>
    
  
  </div>

  <div id="ganapathisubramanian2022aaai" class="col-sm-8">
      <div class="title">
          
          Decentralized Mean Field Games
      </div>
      <div class="author">
        
            
            
              
                
                  
                    
                      <a href="https://sriramsubramanian.com/" target="_blank">Sriram Ganapathi Subramanian</a>,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      <a href="https://irll.ca" target="_blank">Matthew Taylor</a>,
                    
                  
                
              
        
            
            
              
                
                  
                    <em>Mark Crowley</em>,
                  
                
              
        
            
            
              
                
                  
                    
                      and Pascal Poupart.
                    
                  
                
              
        
      </div>

      <div class="periodical">
      
          In <em>Proceedings of the AAAI Conference on Artificial Intelligence (AAAI-2022)</em>. 

      

      
      
          Virtual.
      
      
          Feb,
      
      
        2022.
      

       
      
        <i>[11 citations]</i>
      
        
      <div class="periodical">
          
      </div>
      </div>

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/https://arxiv.org/abs/2112.09099" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
      
      <a href="/assets/pdf/2022-aaai-ganapathi%20subramanian-decentralized.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
      <a href="https://doi.org/10.1609/aaai.v36i9.21176" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
    
      <a href="https://hyp.is/go?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2112.09099.pdf&amp;group=__world__" class="btn btn-sm z-depth-0" role="button" target="_blank">Hypoth</a>
    

    
        
        
    
    </div>

    <!-- Hidden notes block - pick note or annote and stick to it -->
    
        
        
    

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
        <p><b>Abstract:</b>
         Multiagent reinforcement learning algorithms have not been widely adopted in large scale environments with many agents as they often scale poorly with the number of agents. Using mean field theory to aggregate agents has been proposed as a solution to this problem. However, almost all previous methods in this area make a strong assumption of a centralized system where all the agents in the environment learn the same policy and are effectively indistinguishable from each other. In this paper, we relax this assumption about indistinguishable agents and propose a new mean field system known as Decentralized Mean Field Games, where each agent can be quite different from others. All agents learn independent policies in a decentralized fashion, based on their local observations. We define a theoretical solution concept for this system and provide a fixed point guarantee for a Q-learning based algorithm in this system. A practical consequence of our approach is that we can address a ‘chicken-and-egg’ problem in empirical mean field reinforcement learning algorithms. Further, we provide Q-learning and actor-critic algorithms that use the decentralized mean field learning approach and give stronger performances compared to common baselines in this area. In our setting, agents do not need to be clones of each other and learn in a fully decentralized fashion. Hence, for the first time, we show the application of mean field learning methods in fully competitive environments, large-scale continuous action space environments, and other environments with heterogeneous agents. Importantly, we also apply the mean field method in a ride-sharing problem using a real-world dataset. We propose a decentralized solution to this problem, which is more practical than existing centralized training methods.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">Multi-Advisor-QL</abbr>
    
  
  </div>

  <div id="ganapathisubramanian2022jair" class="col-sm-8">
      <div class="title">
          
          Multi-Agent Advisor Q-Learning
      </div>
      <div class="author">
        
            
            
              
                
                  
                    
                      <a href="https://sriramsubramanian.com/" target="_blank">Sriram Ganapathi Subramanian</a>,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      <a href="https://cs.uwaterloo.ca/~klarson/" target="_blank">Kate Larson</a>,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      <a href="https://irll.ca" target="_blank">Matthew Taylor</a>,
                    
                  
                
              
        
            
            
              
                
                  
                    and <em>Mark Crowley</em>
                  
                
              
        
      </div>

      <div class="periodical">
      
        <em>Journal of Artificial Intelligence Research (JAIR)</em>.

          
              74,
          
          

      

      
      
      
          May,
      
      
        2022.
      

       
      
        <i>[12 citations]</i>
      
        
      <div class="periodical">
          
      </div>
      </div>

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      
      <a href="/assets/pdf/2022-jair-ganapathi%20subramanian-multi-agent.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/Sriram94/multiagentadvisorqlearning" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    
      <a href="https://doi.org/10.1613/jair.1.13445" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
    

    
        
        
          <a class="abstract btn btn-sm z-depth-0" role="button">Notes</a>
        
    
    </div>

    <!-- Hidden notes block - pick note or annote and stick to it -->
    
        
        
        <div class="abstract hidden">
            <p><b>Note:</b> This paper uses forest widlfire as one of its motivational examples to demonstrate the difficulty of multi-agent planning in real-world domains with many agents acting at once. </p>
          </div>
        
    

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
        <p><b>Abstract:</b>
         In the last decade, there have been significant advances in multi-agent reinforcement learning (MARL) but there are still numerous challenges, such as high sample complexity and slow convergence to stable policies, that need to be overcome before wide-spread deployment is possible. However, many real-world environments already, in practice, deploy sub-optimal or heuristic approaches for generating policies. An interesting question that arises is how to best use such approaches as advisors to help improve reinforcement learning in multi-agent domains. In this paper, we provide a principled framework for incorporating action recommendations from online sub-optimal advisors in multi-agent settings. We describe the problem of ADvising Multiple Intelligent Reinforcement Agents (ADMIRAL) in nonrestrictive general-sum stochastic game environments and present two novel Q-learning based algorithms: ADMIRAL - Decision Making (ADMIRAL-DM) and ADMIRAL - Advisor Evaluation (ADMIRAL-AE), which allow us to improve learning by appropriately incorporating advice from an advisor (ADMIRAL-DM), and evaluate the effectiveness of an advisor (ADMIRAL-AE). We analyze the algorithms theoretically and provide fixed point guarantees regarding their learning in general-sum stochastic games. Furthermore, extensive experi- ments illustrate that these algorithms: can be used in a variety of environments, have performances that compare favourably to other related baselines, can scale to large state-action spaces, and are robust to poor advice from advisors.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2021</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">MARLEmpircal</abbr>
    
  
  </div>

  <div id="lee2021neuripsdeeprl" class="col-sm-8">
      <div class="title">
          
          Investigation of Independent Reinforcement Learning Algorithms in Multi-Agent Environments
      </div>
      <div class="author">
        
            
            
              
                
                  
                    
                      <a href="https://www.linkedin.com/in/km-lee/" target="_blank">Ken Ming Lee</a>,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      <a href="https://sriramsubramanian.com/" target="_blank">Sriram Ganapathi Subramanian</a>,
                    
                  
                
              
        
            
            
              
                
                  
                    and <em>Mark Crowley</em>
                  
                
              
        
      </div>

      <div class="periodical">
      
          In <em>NeurIPS 2021 Deep Reinforcement Learning Workshop</em>. 

      

      
      
      
          Dec,
      
      
        2021.
      

       
      
        
      <div class="periodical">
          
      </div>
      </div>

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/2111.01100" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
    
    
    
    
    
    
    
    
    

    
        
        
    
    </div>

    <!-- Hidden notes block - pick note or annote and stick to it -->
    
        
        
    

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
        <p><b>Abstract:</b>
         Independent reinforcement learning algorithms have no theoretical guarantees for finding the best policy in multi-agent settings. However, in practice, prior works have reported good performance with independent algorithms in some domains and bad performance in others. Moreover, a comprehensive study of the strengths and weaknesses of independent algorithms is lacking in the literature. In this paper, we carry out an empirical comparison of the performance of independent algorithms on four PettingZoo environments that span the three main categories of multi-agent environments, i.e., cooperative, competitive, and mixed. We show that in fully-observable environments, independent algorithms can perform on par with multi-agent algorithms in cooperative and competitive settings. For the mixed environments, we show that agents trained via independent algorithms learn to perform well individually, but fail to learn to cooperate with allies and compete with enemies. We also show that adding recurrence improves the learning of independent algorithms in cooperative partially observable environments.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">NLP-DigiPath</abbr>
    
  
  </div>

  <div id="allada2021embc" class="col-sm-8">
      <div class="title">
          
          Analysis of Language Embeddings for Classification of Unstructured Pathology Reports
      </div>
      <div class="author">
        
            
            
              
                
                  
                    
                      Aishwarya Krishna Allada,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      Yuanxin Wang,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      Veni Jindal,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      <a href="https://uwaterloo.ca/systems-design-engineering/people-profiles/morteza-babaie" target="_blank">Morteza Babaie</a>,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      <a href="https://kimialab.uwaterloo.ca/kimia/index.php/h-r-tizhoosh/" target="_blank">H.R. Tizhoosh</a>,
                    
                  
                
              
        
            
            
              
                
                  
                    and <em>Mark Crowley</em>
                  
                
              
        
      </div>

      <div class="periodical">
      
          In <em>International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)</em>. 

      

      
          IEEE,
      
      
      
          Nov,
      
      
        2021.
      

       
      
        <i>[10 citations]</i>
      
        
      <div class="periodical">
          
      </div>
      </div>

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
    
    

    
        
        
          <a class="abstract btn btn-sm z-depth-0" role="button">Notes</a>
        
    
    </div>

    <!-- Hidden notes block - pick note or annote and stick to it -->
    
        
        
        <div class="abstract hidden">
            <p><b>Note:</b> This paper makes a comparative analysis of various natural language embedding models on the novel domain of digital pathology reports and attempts to determine the strengths and weaknesses of different wyas of dealing with these large and variable language datasets. </p>
          </div>
        
    

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
        <p><b>Abstract:</b>
         A pathology report is one of the most significant medical documents providing interpretive insights into the visual appearance of the patient’s biopsy sample. In digital pathology, high-resolution images of tissue samples are stored along with pathology reports. Despite the valuable information that pathology reports hold, they are not used in any systematic manner to promote computational pathology. In this work, we focus on analyzing the reports, which are generally unstructured documents written in English with sophisticated and highly specialized medical terminology. We provide a comparative analysis of various embedding models like BioBERT, Clinical BioBERT, BioMed-RoBERTa and Term Frequency-Inverse Document Frequency (TF-IDF), a traditional NLP technique, as well as the combination of embeddings from pre-trained models with TF-IDF. Our results demonstrate the effectiveness of various word embedding techniques for pathology reports.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">PO-MFRL</abbr>
    
  
  </div>

  <div id="ganapathisubramanian2021aamas" class="col-sm-8">
      <div class="title">
          
          Partially Observable Mean Field Reinforcement Learning
      </div>
      <div class="author">
        
            
            
              
                
                  
                    
                      <a href="https://sriramsubramanian.com/" target="_blank">Sriram Ganapathi Subramanian</a>,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      <a href="https://irll.ca" target="_blank">Matthew Taylor</a>,
                    
                  
                
              
        
            
            
              
                
                  
                    <em>Mark Crowley</em>,
                  
                
              
        
            
            
              
                
                  
                    
                      and Pascal Poupart.
                    
                  
                
              
        
      </div>

      <div class="periodical">
      
          In <em>Proceedings of the 20th International Conference on Autonomous Agents and MultiAgent Systems (AAMAS)</em>. 

      

      
          International Foundation for Autonomous Agents and Multiagent Systems,
      
      
          London, United Kingdom.
      
      
          May,
      
      
        2021.
      

       
      
        <i>[23 citations]</i>
      
        
      <div class="periodical">
          
      </div>
      </div>

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/2012.15791" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
      
      <a href="/assets/pdf/2021-aamas-ganapathi%20subramanian-partially.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
    
    

    
        
        
    
    </div>

    <!-- Hidden notes block - pick note or annote and stick to it -->
    
        
        
    

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
        <p><b>Abstract:</b>
         Traditional multi-agent reinforcement learning algorithms are not scalable to environments with more than a few agents, since these algorithms are exponential in the number of agents. Recent research has introduced successful methods to scale multi-agent reinforcement learning algorithms to many agent scenarios using mean field theory. Previous work in this field assumes that an agent has access to exact cumulative metrics regarding the mean field behaviour of the system, which it can then use to take its actions. In this paper, we relax this assumption and maintain a distribution to model the uncertainty regarding the mean field of the system. We consider two different settings for this problem. In the first setting, only agents in a fixed neighbourhood are visible, while in the second setting, the visibility of agents is determined at random based on distances. For each of these settings, we introduce a Q-learning based algorithm that can learn effectively. We prove that this Q-learning estimate stays very close to the Nash Q-value (under a common set of assumptions) for the first setting. We also empirically show our algorithms outperform multiple baselines in three different games in the MAgents framework, which supports large environments with many agents learning simultaneously to achieve possibly distinct goals.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">Amrl</abbr>
    
  
  </div>

  <div id="bellinger2021canai" class="col-sm-8">
      <div class="title">
          
          Active Measure Reinforcement Learning for Observation Cost Minimization: A framework for minimizing measurement costs in reinforcement learning
      </div>
      <div class="author">
        
            
            
              
                
                  
                    
                      <a href="https://web.cs.dal.ca/~bellinger/" target="_blank">Colin Bellinger</a>,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      Rory Coles,
                    
                  
                
              
        
            
            
              
                
                  
                    <em>Mark Crowley</em>,
                  
                
              
        
            
            
              
                
                  
                    
                      and Isaac Tamblyn.
                    
                  
                
              
        
      </div>

      <div class="periodical">
      
          In <em>Canadian Conference on Artificial Intelligence</em>. 

      

      
          Springer,
      
      
      
      
        2021.
      

       
      
        <i>[28 citations]</i>
      
        
      <div class="periodical">
          
      </div>
      </div>

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/2005.12697" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
      
      <a href="/assets/pdf/2021-canai-bellinger-active%20measure%20reinforcement.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
    
    

    
        
        
          <a class="abstract btn btn-sm z-depth-0" role="button">Notes</a>
        
    
    </div>

    <!-- Hidden notes block - pick note or annote and stick to it -->
    
        
        
        <div class="abstract hidden">
            <p><b>Note:</b> Neurips 2022 paper doing similar idea cited us https://hyp.is/go?url=https%3A%2F%2Fproceedings.neurips.cc%2Fpaper%2F2021%2Ffile%2F83e8fe6279ad25f15b23c6298c6a3584-Paper.pdf&amp;group=__world__ </p>
          </div>
        
    

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
        <p><b>Abstract:</b>
         Markov Decision Processes (MDP) with explicit measurement cost are a class of en- vironments in which the agent learns to maximize the costed return. Here, we define the costed return as the discounted sum of rewards minus the sum of the explicit cost of measuring the next state. The RL agent can freely explore the relationship between actions and rewards but is charged each time it measures the next state. Thus, an op- timal agent must learn a policy without making a large number of measurements. We propose the active measure RL framework (Amrl) as a solution to this novel class of problem, and contrast it with standard reinforcement learning under full observability and planning under partially observability. We demonstrate that Amrl-Q agents learn to shift from a reliance on costly measurements to exploiting a learned transition model in order to reduce the number of real-world measurements and achieve a higher costed return. Our results demonstrate the superiority of Amrl-Q over standard RL methods, Q-learning and Dyna-Q, and POMCP for planning under a POMDP in environments with explicit measurement costs.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2020</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">iMondrian</abbr>
    
  
  </div>

  <div id="ma2020smc" class="col-sm-8">
      <div class="title">
          
          Isolation Mondrian Forest for Batch and Online Anomaly Detection
      </div>
      <div class="author">
        
            
            
              
                
                  
                    
                      Haoran Ma,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      <a href="https://www.researchgate.net/profile/Benyamin-Ghojogh" target="_blank">Benyamin Ghojogh</a>,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      Maria N Samad,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      Dongyu Zheng,
                    
                  
                
              
        
            
            
              
                
                  
                    and <em>Mark Crowley</em>
                  
                
              
        
      </div>

      <div class="periodical">
      
          In <em>IEEE International Conference on Systems, Man, and Cybernetics (IEEE-SMC-2020)</em>. 

      

      
          IEEE SMC,
      
      
          Toronto, Canada (virtual).
      
      
          Oct,
      
      
        2020.
      

       
      
        <i>[38 citations]</i>
      
        
      <div class="periodical">
          
      </div>
      </div>

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/2003.03692" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
      
      <a href="/assets/pdf/2020-smc-ma-isolation.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/rateldajer/iMondrianForest-IMF" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    
    
    
      <a href="https://hyp.is/go?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2003.03692&amp;group=__world__" class="btn btn-sm z-depth-0" role="button" target="_blank">Hypoth</a>
    

    
        
        
          <a class="abstract btn btn-sm z-depth-0" role="button">Notes</a>
        
    
    </div>

    <!-- Hidden notes block - pick note or annote and stick to it -->
    
        
        
        <div class="abstract hidden">
            <p><b>Note:</b> The algorithm fuses two ideas, "isolation" from ensemble trees methods for anomaly detection and "Mondrian forests" which can learn flexible regression models from streaming data. </p>
          </div>
        
    

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
        <p><b>Abstract:</b>
         We propose a new method, named isolation Mondrian forest (iMondrian forest), for batch and online anomaly detection. The proposed method is a novel hybrid of isolation forest and Mondrian forest which are existing methods for batch anomaly detection and online random forest, respectively. iMondrian forest takes the idea of isolation, using the depth of a node in a tree, and implements it in the Mondrian forest structure. The result is a new data structure which can accept streaming data in an online manner while being used for anomaly detection. Our experiments show that iMondrian forest mostly performs better than isolation forest in batch settings and has better or comparable performance against other batch and online anomaly detection methods.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">WildfireMLRev</abbr>
    
  
  </div>

  <div id="jain2020review" class="col-sm-8">
      <div class="title">
          
          A review of machine learning applications in wildfire science and management
      </div>
      <div class="author">
        
            
            
              
                
                  
                    
                      Piyush Jain,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      Sean CP Coogan,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      <a href="https://sriramsubramanian.com/" target="_blank">Sriram Ganapathi Subramanian</a>,
                    
                  
                
              
        
            
            
              
                
                  
                    <em>Mark Crowley</em>,
                  
                
              
        
            
            
              
                
                  
                    
                      <a href="https://cfs.nrcan.gc.ca/employees/read/staylor" target="_blank">Steve Taylor</a>,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      and Mike D Flannigan.
                    
                  
                
              
        
      </div>

      <div class="periodical">
      
        <em>Environmental Reviews</em>.

          
              28,
          
          
              (3).
          

      

      
          Canadian Science Publishing,
      
      
      
          Jul,
      
      
        2020.
      

       
      
        <i>[631 citations]</i>
      
        
      <div class="periodical">
          
      </div>
      </div>

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/2003.00646" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
      
      <a href="/assets/pdf/2020-envrevjrnl-jain-review.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
      
      <a href="https://www.dropbox.com/scl/fi/5236qksp44pp96tll8egl/2020-envrevjrnl-jain-review1.pdf?rlkey=1ycxvh8tyfxi8cxlzcctxch2y&amp;raw=1" class="btn btn-sm z-depth-0" role="button" target="_blank">Slides</a>
      
    
    
    
      <a href="https://cdnsciencepub.com/doi/10.1139/er-2020-0019" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
    

    
        
        
    
    </div>

    <!-- Hidden notes block - pick note or annote and stick to it -->
    
        
        
    

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
        <p><b>Abstract:</b>
         
Artificial intelligence has been applied in wildfire science and management since the 1990s, with early applications including neural networks and expert systems. Since then the field has rapidly progressed congruently with the wide adoption of machine learning (ML) methods in the environmental sciences. Here, we present a scoping review of ML applications in wildfire science and management. Our overall objective is to improve awareness of ML methods among wildfire researchers and managers, as well as illustrate the diverse and challenging range of problems in wildfire science available to ML data scientists. To that end, we first present an overview of popular ML approaches used in wildfire science to date, and then review the use of ML in wildfire science as broadly categorized into six problem domains, including: 1) fuels characterization, fire detection, and mapping; 2) fire weather and climate change; 3) fire occurrence, susceptibility, and risk; 4) fire behavior prediction; 5) fire effects; and 6) fire management. Furthermore, we discuss the advantages and limitations of various ML approaches relating to data size, computational requirements, generalizability, and interpretability, as well as identify opportunities for future advances in the science and management of wildfires within a data science context. In total, we identified 298 relevant publications, where the most frequently used ML methods across problem domains included random forests, MaxEnt, artificial neural networks, decision trees, support vector machines, and genetic algorithms. As such, there exists opportunities to apply more current ML methods — including deep learning and agent based learning — in the wildfire sciences, especially in instances involving very large multivariate datasets. We must recognize, however, that despite the ability of ML models to learn on their own, expertise in wildfire science is necessary to ensure realistic modelling of fire processes across multiple scales, while the complexity of some ML methods, such as deep learning, requires a dedicated and sophisticated knowledge of their application. Finally, we stress that the wildfire research and management communities play an active role in providing relevant, high quality, and freely available wildfire data for use by practitioners of ML methods.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="bhalla2020deep" class="col-sm-8">
      <div class="title">
          
          Deep Multi Agent Reinforcement Learning for Autonomous Driving
      </div>
      <div class="author">
        
            
            
              
                
                  
                    
                      Sushrut Bhalla,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      <a href="https://sriramsubramanian.com/" target="_blank">Sriram Ganapathi Subramanian</a>,
                    
                  
                
              
        
            
            
              
                
                  
                    and <em>Mark Crowley</em>
                  
                
              
        
      </div>

      <div class="periodical">
      
          In <em>Canadian Conference on Artificial Intelligence</em>. 

      

      
      
      
          May,
      
      
        2020.
      

       
      
        <i>[68 citations]</i>
      
        
      <div class="periodical">
          
      </div>
      </div>

    <div class="links">
    
    
    
    
      
      <a href="/assets/pdf/2020-canai-bhalla-deep.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
      <a href="https://link.springer.com/chapter/10.1007/978-3-030-47358-7_7" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
    

    
        
        
    
    </div>

    <!-- Hidden notes block - pick note or annote and stick to it -->
    
        
        
    

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="basiri2020cdc" class="col-sm-8">
      <div class="title">
          
          Distributed Nonlinear Model Predictive Control and Metric Learning for Heterogeneous Vehicle Platooning with Cut-in/Cut-out Maneuvers
      </div>
      <div class="author">
        
            
            
              
                
                  
                    
                      Mohammad Hossein Basiri,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      <a href="https://www.researchgate.net/profile/Benyamin-Ghojogh" target="_blank">Benyamin Ghojogh</a>,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      Nasser L Azad,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      <a href="https://uwaterloo.ca/embedded-software-group/people-profiles/sebastian-fischmeister" target="_blank">Sebastian Fischmeister</a>,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      <a href="https://uwaterloo.ca/scholar/karray" target="_blank">Fakhri Karray</a>,
                    
                  
                
              
        
            
            
              
                
                  
                    and <em>Mark Crowley</em>
                  
                
              
        
      </div>

      <div class="periodical">
      
          In <em>Proceeding of the 59th IEEE Conference on Decision and Control (CDC-2020)</em>. 

      

      
      
          Jeju Island, Korea (virtual).
      
      
          Dec,
      
      
        2020.
      

       
      
        <i>[37 citations]</i>
      
        
      <div class="periodical">
          
      </div>
      </div>

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    
    
    

    
        
        
    
    </div>

    <!-- Hidden notes block - pick note or annote and stick to it -->
    
        
        
    

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2019</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">TAC-ITS</abbr>
    
  
  </div>

  <div id="carrillo2019tac" class="col-sm-8">
      <div class="title">
          
          Comparison of Deep Learning models for Determining Road Surface Condition from Roadside Camera Images and Weather Data
      </div>
      <div class="author">
        
            
            
              
                
                  
                    
                      J. Carrillo,
                    
                  
                
              
        
            
            
              
                
                  
                    <em>M. Crowley</em>,
                  
                
              
        
            
            
              
                
                  
                    
                      G. Pan,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      and L. Fu.
                    
                  
                
              
        
      </div>

      <div class="periodical">
      
          In <em>TAC-ITS Canada Joint Conference</em>. 

      

      
      
          Halifax, Canada.
      
      
      
        2019.
      

       
      
        <i>[29 citations]</i>
      
        
      <div class="periodical">
          
      </div>
      </div>

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
      <a href="https://tac-its.ca/conference-papers/comparison-deep-learning-models-determining-road-surface-condition-roadside-camera" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
    

    
        
        
    
    </div>

    <!-- Hidden notes block - pick note or annote and stick to it -->
    
        
        
    

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
        <p><b>Abstract:</b>
         Road maintenance during the Winter season is a safety critical and resource demanding operation. One of its key activities is determining road surface condition (RSC) in order to prioritize roads and allocate cleaning efforts such as plowing or salting. Two conventional approaches for determining RSC are: visual examination of roadside camera images by trained personnel and patrolling the roads to perform on-site inspections. However, with more than 500 cameras collecting images across Ontario, visual examination becomes a resource-intensive activity, difficult to scale especially during periods of snow storms. This paper presents the preliminary results of an ongoing study focused on improving the efficiency of road maintenance operations. We use multiple Deep Learning models to automatically determine RSC from roadside camera images and weather variables, extending previous research where similar methods have been used to deal with the problem. The dataset we use was collected during the 2017-2018 Winter season from 40 stations connected to the Ontario Road Weather Information System (RWIS), it includes 14.000 labelled images and 70.000 weather measurements. In particular, we train and evaluate the performance of seven state-of-the-art models from the Computer Vision literature, including the recent DenseNet, NASNet, and MobileNet. Also, by integrating observations from weather variables, the models are able to better ascertain RSC under poor visibility conditions.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="ghojogh2019ccai" class="col-sm-8">
      <div class="title">
          
          Instance Ranking and Numerosity Reduction Using Matrix Decompositionand Subspace Learning
      </div>
      <div class="author">
        
            
            
              
                
                  
                    
                      <a href="https://www.researchgate.net/profile/Benyamin-Ghojogh" target="_blank">Benyamin Ghojogh</a>,
                    
                  
                
              
        
            
            
              
                
                  
                    and <em>Mark Crowley</em>
                  
                
              
        
      </div>

      <div class="periodical">
      
          In <em>Canadian Conference on Artificial Intelligence</em>. 

      

      
          Springer’s Lecture Notes in Artificial Intelligence.,
      
      
          Kingston, ON, Canada.
      
      
      
        2019.
      

       
      
        <i>[10 citations]</i>
      
        
      <div class="periodical">
          
      </div>
      </div>

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
    
    

    
        
        
    
    </div>

    <!-- Hidden notes block - pick note or annote and stick to it -->
    
        
        
    

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
        <p><b>Abstract:</b>
         One way to deal with the ever increasing amount of available data for processing is to rank data instances by usefulness and reduce the dataset size. In this work, we introduce a framework to achieve this using matrix decomposition and subspace learning. Our central contribution is a novel similarity measure for data instances that uses the basis obtained from matrix decomposition of the dataset. Using this similarity measure, we propose several related algorithms for ranking data instances and performing numerosity reduction. We then validate the effectiveness of these algorithms for data reduction on several datasets for classification, regression, and clustering tasks.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ECML</abbr>
    
  
  </div>

  <div id="bhalla2019ecml" class="col-sm-8">
      <div class="title">
          
          Compact Representation of a Multi-dimensional Combustion Manifold Using Deep Neural Networks
      </div>
      <div class="author">
        
            
            
              
                
                  
                    
                      Sushrut Bhalla,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      Matthew Yao,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      Jean-Pierre Hickey,
                    
                  
                
              
        
            
            
              
                
                  
                    and <em>Mark Crowley</em>
                  
                
              
        
      </div>

      <div class="periodical">
      
          In <em>European Conference on Machine Learning (ECML-19)</em>. 

      

      
      
          Wurzburg, Germany.
      
      
      
        2019.
      

       
      
        <i>[22 citations]</i>
      
        
      <div class="periodical">
          
      </div>
      </div>

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      
      <a href="/assets/pdf/2019-ecml-bhalla-compact.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
      
      <a href="/assets/pdf/2019-ecml-bhalla-compact2.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
      
    
    
      
      <a href="/assets/pdf/2019-ecml-bhalla-compact1.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Slides</a>
      
    
    
    
    
    

    
        
        
    
    </div>

    <!-- Hidden notes block - pick note or annote and stick to it -->
    
        
        
    

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
        <p><b>Abstract:</b>
         The computational challenges in turbulent combustion simulations stem from the physical complexities and multi-scale nature of the problem which make it intractable to compute scaleesolving simulations. For most engineering applications, the large scale separation between the flame (typically submillimeter scale) and the characteristic turbulent flow (typically centimeter or meter scale) allows us to evoke simplifying assumptions–such as done for the flamelet model to precompute all the chemical reactions and map them to a low order manifold. The resulting manifold is then tabulated and looked up at runtime. As the physical complexity of combustion simulations increases (including radiation, soot formation, pressure variations etc.) the dimensionality of the resulting manifold grows which impedes an efficient tabulation and look up. In this paper we present a novel approach to model the multidimensional combustion manifold. We approximate the combustion manifold using a neural network function approximator and use it to predict the temperature and composition of the reaction. We present a novel training procedure which is developed to generate a smooth output curve for temperature over the course of a reaction. We then evaluate our work against the current approach of tabulation with linear interpolation in combustion simulations. We also provide an ablation study of our training procedure in the context of overfitting in our model. The combustion dataset used for the modeling of combustion of H2 and O2 in this work is released alongside this paper.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2018</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">MCTS+A3C</abbr>
    
  
  </div>

  <div id="Subramanian2018CCAI" class="col-sm-8">
      <div class="title">
          
          Combining MCTS and A3C for prediction of spatially spreading processes in forest wildfire settings
      </div>
      <div class="author">
        
            
            
              
                
                  
                    
                      <a href="https://sriramsubramanian.com/" target="_blank">Sriram Ganapathi Subramanian</a>,
                    
                  
                
              
        
            
            
              
                
                  
                    and <em>Mark Crowley</em>
                  
                
              
        
      </div>

      <div class="periodical">
      
          In <em>Canadian Conference on Artificial Intelligence</em>. 

      

      
      
          Toronto, Ontario, Canada.
      
      
      
        2018.
      

       
      
        <i>[15 citations]</i>
      
        
      <div class="periodical">
          
      </div>
      </div>

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      
      <a href="/assets/pdf/2018-canai-ganapathi%20subramanian-combining.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
      <a href="https://doi.org/10.1007/978-3-319-89656-4_28" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
    

    
        
        
    
    </div>

    <!-- Hidden notes block - pick note or annote and stick to it -->
    
        
        
    

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
        <p><b>Abstract:</b>
         In recent years, Deep Reinforcement Learning (RL) algorithms have shown super-human performance in a variety Atari and classic board games like chess and GO. Research into applications of RL in other domains with spatial considerations like environmental planning are still in their nascent stages. In this paper, we introduce a novel combination of Monte-Carlo Tree Search (MCTS) and A3C algorithms on an online simulator of a wildfire, on a pair of forest fires in Northern Alberta (Fort McMurray and Richardson fires) and on historical Saskatchewan fires previously compared by others to a physics-based simulator. We conduct several experiments to predict fire spread for several days before and after the given spatial information of fire spread and ignition points. Our results show that the advancements in Deep RL applications in the gaming world have advantages in spatially spreading real-world problems like forest fires. \textcopyright Springer International Publishing AG, part of Springer Nature 2018.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="Eaton2018" class="col-sm-8">
      <div class="title">
          
          Blue Sky Ideas in Artificial Intelligence Education from the EAAI 2017 New and Future AI Educator Program
      </div>
      <div class="author">
        
            
            
              
                
                  
                    
                      Eric Eaton,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      Sven Koenig,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      Claudia Schulz,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      Francesco Maurelli,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      John Lee,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      Joshua Eckroth,
                    
                  
                
              
        
            
            
              
                
                  
                    <em>Mark Crowley</em>,
                  
                
              
        
            
            
              
                
                  
                    
                      Richard G Freedman,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      Rogelio E Cardona-Rivera,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      Tiago Machado,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      and Tom Williams.
                    
                  
                
              
        
      </div>

      <div class="periodical">
      

      
          ACM,
      
      
          New York, NY, USA.
      
      
          Feb,
      
      
        2018.
      

       
      
        <i>[63 citations]</i>
      
        
      <div class="periodical">
          
      </div>
      </div>

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    
      <a href="http://doi.acm.org/10.1145/3175502.3175509" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
    

    
        
        
    
    </div>

    <!-- Hidden notes block - pick note or annote and stick to it -->
    
        
        
    

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="ganapathisubramanian2018frontict" class="col-sm-8">
      <div class="title">
          
          Using Spatial Reinforcement Learning to Build Forest Wildfire Dynamics Models From Satellite Images
      </div>
      <div class="author">
        
            
            
              
                
                  
                    
                      <a href="https://sriramsubramanian.com/" target="_blank">Sriram Ganapathi Subramanian</a>,
                    
                  
                
              
        
            
            
              
                
                  
                    and <em>Mark Crowley</em>
                  
                
              
        
      </div>

      <div class="periodical">
      
        <em>Frontiers in ICT</em>.

          
              5,
          
          
              (6).
          

      

      
          Frontiers,
      
      
      
          Apr,
      
      
        2018.
      

       
      
        <i>[63 citations]</i>
      
        
      <div class="periodical">
          
      </div>
      </div>

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      
      <a href="/assets/pdf/2018-frontict-ganapathi%20subramanian-using" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
      <a href="http://journal.frontiersin.org/article/10.3389/fict.2018.00006/full" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
    

    
        
        
    
    </div>

    <!-- Hidden notes block - pick note or annote and stick to it -->
    
        
        
    

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
        <p><b>Abstract:</b>
         Machine learning algorithms have increased tremendously in power in recent years but have yet to be fully utilized in many ecology and sustainable resource management domains such as wildlife reserve design, forest fire management and invasive species spread. One thing these domains have in common is that they contain dynamics that can be characterized as a Spatially Spreading Process (SSP) which requires many parameters to be set precisely to model the dynamics, spread rates and directional biases of the elements which are spreading. We present related work in Artificial Intelligence and Machine Learning for SSP sustainability domains including forest wildfire prediction. We then introduce a novel approach for learning in SSP domains using Reinforcement Learning (RL) where fire is the agent at any cell in the landscape and the set of actions the fire can take from a location at any point in time includes spreading North, South, East, West or not spreading. This approach inverts the usual RL setup since the dynamics of the corresponding Markov Decision Process (MDP) is a known function for immediate wildfire spread. Meanwhile, we learn an agent policy for a predictive model of the dynamics of a complex spatially-spreading process. Rewards are provided for correctly classifying which cells are on fire or not compared to satellite and other related data. We examine the behaviour of five RL algorithms on this problem: Value Iteration, Policy Iteration, Q-Learning, Monte Carlo Tree Search and Asynchronous Advantage Actor-Critic (A3C). We compare to a Gaussian process based supervised learning approach and discuss the relation of our approach to manually constructed, state-of-the-art methods from forest wildfire modelling. We also discuss the relation of our approach to manually constructed, state-of-the-art methods from forest wildfire modelling. We validate our approach with satellite image data of two massive wildfire events in Northern Alberta, Canada, the Fort McMurray fire of 2016 and the Richardson fire of 2011. The results show that we can learn predictive, agent-based policies as models of spatial dynamics using RL on readily available satellite images that other methods and have many additional advantages in terms of generalizability and interpretability.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2017</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="subramanian2017rldm" class="col-sm-8">
      <div class="title">
          
          Learning Forest Wildfire Dynamics from Satellite Images Using Reinforcement Learning
      </div>
      <div class="author">
        
            
            
              
                
                  
                    
                      <a href="https://sriramsubramanian.com/" target="_blank">Sriram Ganapathi Subramanian</a>,
                    
                  
                
              
        
            
            
              
                
                  
                    and <em>Mark Crowley</em>
                  
                
              
        
      </div>

      <div class="periodical">
      
          In <em>Conference on Reinforcement Learning and Decision Making</em>. 

      

      
      
          Ann Arbor, MI, USA..
      
      
      
        2017.
      

       
      
        <i>[24 citations]</i>
      
        
      <div class="periodical">
          
      </div>
      </div>

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    
    
    

    
        
        
    
    </div>

    <!-- Hidden notes block - pick note or annote and stick to it -->
    
        
        
    

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2016</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="salem2016ecrts" class="col-sm-8">
      <div class="title">
          
          Anomaly Detection Using Inter-Arrival Curves for Real-time Systems
      </div>
      <div class="author">
        
            
            
              
                
                  
                    
                      Mahmoud Salem,
                    
                  
                
              
        
            
            
              
                
                  
                    <em>Mark Crowley</em>,
                  
                
              
        
            
            
              
                
                  
                    
                      and <a href="https://uwaterloo.ca/embedded-software-group/people-profiles/sebastian-fischmeister" target="_blank">Sebastian Fischmeister</a>.
                    
                  
                
              
        
      </div>

      <div class="periodical">
      
          In <em>2016 28th Euromicro Conference on Real-Time Systems</em>. 

      

      
      
          Toulouse, France.
      
      
          Jul,
      
      
        2016.
      

       
      
        <i>[38 citations]</i>
      
        
      <div class="periodical">
          
      </div>
      </div>

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
      <a href="https://doi.org/10.1109/ECRTS.2016.22" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
    

    
        
        
    
    </div>

    <!-- Hidden notes block - pick note or annote and stick to it -->
    
        
        
    

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
        <p><b>Abstract:</b>
         —Real-time embedded systems are a significant class of applications, poised to grow even further as automated vehicles and the Internet of Things become a reality. An important problem for these systems is to detect anomalies during operation. Anomaly detection is a form of classification, which can be driven by data collected from the system at execution time. We propose inter-arrival curves as a novel analytic modelling technique for discrete event traces. Our approach relates to the existing technique of arrival curves and expands the technique to anomaly detection. Inter-arrival curves analyze the behaviour of events within a trace by providing upper and lower bounds to their inter-arrival occurrence. We exploit inter-arrival curves in a classification framework that detects deviations within these bounds for anomaly detection. Also, we show how inter-arrival curves act as good features to extract recurrent behaviour that these systems often exhibit. We demonstrate the feasibility and viability of the fully implemented approach with an industrial automotive case study (CAN traces) as well as a deployed aerospace case study (RTOS kernel traces).</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2015</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="taleghan2015jmlr" class="col-sm-8">
      <div class="title">
          
          PAC Optimal MDP Planning with Application to Invasive Species Management
      </div>
      <div class="author">
        
            
            
              
                
                  
                    
                      Majid Alkaee Taleghan,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      Thomas G. Dietterich,
                    
                  
                
              
        
            
            
              
                
                  
                    <em>Mark Crowley</em>,
                  
                
              
        
            
            
              
                
                  
                    
                      Kim Hall,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      and H. Jo Albers.
                    
                  
                
              
        
      </div>

      <div class="periodical">
      
        <em>Journal of Machine Learning Research</em>.

          
              16,
          
          

      

      
      
      
      
        2015.
      

       
      
        <i>[29 citations]</i>
      
        
      <div class="periodical">
          
      </div>
      </div>

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
      <a href="http://jmlr.org/papers/v16/taleghan15a.html" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
    

    
        
        
    
    </div>

    <!-- Hidden notes block - pick note or annote and stick to it -->
    
        
        
    

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
        <p><b>Abstract:</b>
         In a simulator-defined MDP, the Markovian dynamics and rewards are provided in the form of a simulator from which samples can be drawn. This paper studies MDP planning algorithms that attempt to minimize the number of simulator calls before terminating and outputting a policy that is approximately optimal with high probability. The paper introduces two heuristics for efficient exploration and an improved confidence interval that enables earlier termination with probabilis- tic guarantees. We prove that the heuristics and the confidence interval are sound and produce with high probability an approximately optimal policy in polynomial time. Experiments on two benchmark problems and two instances of an invasive species management problem show that the improved confidence intervals and the new search heuristics yield reductions of between 8% and 47% in the number of simulator calls required to reach near-optimal policies.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2014</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="crowley2014ieeetoc" class="col-sm-8">
      <div class="title">
          
          Using equilibrium policy gradients for spatiotemporal planning in forest ecosystem management
      </div>
      <div class="author">
        
            
            
              
                
                   <em>Mark Crowley</em>.
                
              
        
      </div>

      <div class="periodical">
      
        <em>IEEE Transactions on Computers</em>.

          
              63,
          
          
              (1).
          

      

      
          IEEE computer Society Digital Library. IEEE Computer Society.,
      
      
      
      
        2014.
      

       
      
        
      <div class="periodical">
          
      </div>
      </div>

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
      <a href="http://www.computer.org/csdl/trans/tc/preprint/06514032-abs.html" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
    

    
        
        
    
    </div>

    <!-- Hidden notes block - pick note or annote and stick to it -->
    
        
        
    

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
        <p><b>Abstract:</b>
         Spatiotemporal planning involves making choices at multiple locations in space over some planning horizon to maximize utility and satisfy various constraints. In Forest Ecosystem Management, the problem is to choose actions for thousands of locations each year including harvesting, treating trees for fire or pests, or doing nothing. The utility models could place value on sale of lumber, ecosystem sustainability or employment levels and incorporate legal and logistical constraints on actions such as avoiding large contiguous areas of clearcutting. Simulators developed by forestry researchers provide detailed dynamics but are generally inaccesible black boxes. We model spatiotemporal planning as a factored Markov decision process and present a policy gradient planning algorithm to optimize a stochastic spatial policy using simulated dynamics. It is common in environmental and resource planning to have actions at different locations be spatially interelated, this makes representation and planning challenging. We define a global spatial policy in terms of interacting local policies defining distributions over actions at each location conditioned on actions at nearby locations. Markov chain Monte Carlo simulation is used to sample landscape policies and estimate their gradients. Evaluation is carried out on a forestry planning problem with 1,880 locations using a variety of value models and constraints. Index</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2013</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="houtman2013ijwf" class="col-sm-8">
      <div class="title">
          
          Allowing a wildfire to burn: Estimating the effect on future fire suppression costs
      </div>
      <div class="author">
        
            
            
              
                
                  
                    
                      Rachel M. Houtman,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      Claire A. Montgomery,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      Aaron R. Gagnon,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      David E. Calkin,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      Thomas G. Dietterich,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      Sean McGregor,
                    
                  
                
              
        
            
            
              
                
                  
                    and <em>Mark Crowley</em>
                  
                
              
        
      </div>

      <div class="periodical">
      
        <em>International Journal of Wildland Fire</em>.

          
              22,
          
          
              (7).
          

      

      
      
      
      
        2013.
      

       
      
        <i>[116 citations]</i>
      
        
      <div class="periodical">
          
      </div>
      </div>

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      
      <a href="/assets/pdf/2013-ijwf-houtman-allowing.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
      <a href="https://www.publish.csiro.au/wf/WF12157" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
    

    
        
        
    
    </div>

    <!-- Hidden notes block - pick note or annote and stick to it -->
    
        
        
    

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
        <p><b>Abstract:</b>
         Where a legacy of aggressive wildland fire suppression has left forests in need of fuel reduction, allowing wildland fire to burn may provide fuel treatment benefits, thereby reducing suppression costs from subsequent fires. The least-cost-plus-net-value-change model of wildland fire economics includes benefits of wildfire in a framework for evaluating suppression options. In this study, we estimated one component of that benefit – the expected present value of the reduction in suppression costs for subsequent fires arising from the fuel treatment effect of a current fire. To that end, we employed Monte Carlo methods to generate a set of scenarios for subsequent fire ignition and weather events, which are referred to as sample paths, for a study area in central Oregon. We simulated fire on the landscape over a 100-year time horizon using existing models of fire behaviour, vegetation and fuels development, and suppression effectiveness, and we estimated suppression costs using an existing suppression cost model. Our estimates suggest that the potential cost savings may be substantial. Further research is needed to estimate the full least-cost-plus-net-value-change model. This line of research will extend the set of tools available for developing wildfire management plans for forested landscapes.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="dietterich2013aaai" class="col-sm-8">
      <div class="title">
          
          PAC Optimal Planning for Invasive Species Management: Improved Exploration for Reinforcement Learning from Simulator-Defined MDPs
      </div>
      <div class="author">
        
            
            
              
                
                  
                    
                      Thomas G Dietterich,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      Majid Alkaee Taleghan,
                    
                  
                
              
        
            
            
              
                
                  
                    and <em>Mark Crowley</em>
                  
                
              
        
      </div>

      <div class="periodical">
      
          In <em>Proceedings of the AAAI Conference on Artificial Intelligence (AAAI-2013)</em>. 

      

      
      
          Bellevue, WA, USA.
      
      
      
        2013.
      

       
      
        <i>[22 citations]</i>
      
        
      <div class="periodical">
          
      </div>
      </div>

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
      <a href="http://www.aaai.org/ocs/index.php/AAAI/AAAI13/paper/view/6478" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
    

    
        
        
    
    </div>

    <!-- Hidden notes block - pick note or annote and stick to it -->
    
        
        
    

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
        <p><b>Abstract:</b>
         Often the most practical way to define a Markov Decision Process (MDP) is as a simulator that, given a state and an action, produces a resulting state and immediate reward sampled from the corresponding distributions. Simulators in natural resource management can be very expensive to execute, so that the time required to solve such MDPs is dominated by the number of calls to the simulator. This paper presents an algorithm, DDV, that combines improved confidence intervals on the Q values (as in interval estimation) with a novel upper bound on the discounted state occupancy probabilities to intelligently choose state-action pairs to explore. We prove that this algorithm terminates with a policy whose value is within εof the optimal policy (with probability 1−δ) after making only polynomially-many calls to the simulator. Experiments on one benchmark MDP and on an MDP for invasive species management show very large reductions in the number of simulator calls required.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="poole2013ijcai" class="col-sm-8">
      <div class="title">
          
          Cyclic causal models with discrete variables: Markov chain equilibrium semantics and sample ordering
      </div>
      <div class="author">
        
            
            
              
                
                  
                    
                      <a href="https://www.cs.ubc.ca/~poole/" target="_blank">David Poole</a>,
                    
                  
                
              
        
            
            
              
                
                  
                    and <em>Mark Crowley</em>
                  
                
              
        
      </div>

      <div class="periodical">
      
          In <em>International Joint Conference on Artificial Intelligence (IJCAI)</em>. 

      

      
      
          Beijing, China.
      
      
      
        2013.
      

       
      
        <i>[18 citations]</i>
      
        
      <div class="periodical">
          
      </div>
      </div>

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
      <a href="http://dl.acm.org/citation.cfm?id=2540281" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
    

    
        
        
    
    </div>

    <!-- Hidden notes block - pick note or annote and stick to it -->
    
        
        
    

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
        <p><b>Abstract:</b>
         We analyze the foundations of cyclic causal models for discrete variables, and compare structural equation models (SEMs) to an alternative semantics as the equilibrium (stationary) distribution of a Markov chain. We show under general conditions, discrete cyclic SEMs cannot have independent noise, even in the simplest case, cyclic structural equation models imply constraints on the noise. We give a formalization of an alternative Markov chain equilibrium semantics which requires not only the causal graph, but also a sample order. We show how the resulting equilibrium is a function of the sample ordering, both theoretically and empirically.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2012</h2>
  <ol class="bibliography"></ol>

  <h2 class="year">2011</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="Crowley2011" class="col-sm-8">
      <div class="title">
          
          Policy gradient planning for environmental decision making with existing simulators
      </div>
      <div class="author">
        
            
            
              
                
                  
                    <em>Mark Crowley</em>,
                  
                
              
        
            
            
              
                
                  
                    
                      and <a href="https://www.cs.ubc.ca/~poole/" target="_blank">David Poole</a>.
                    
                  
                
              
        
      </div>

      <div class="periodical">
      
          In <em>Proceedings of the Twenty-Fifth Conference on Artificial Intelligence (AAAI)</em>. 

      

      
      
          San Francisco.
      
      
      
        2011.
      

       
      
        <i>[14 citations]</i>
      
        
      <div class="periodical">
          
      </div>
      </div>

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
      <a href="http://www.scopus.com/inward/record.url?eid=2-s2.0-80055051332&amp;partnerID=tZOtx3y1" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
    

    
        
        
    
    </div>

    <!-- Hidden notes block - pick note or annote and stick to it -->
    
        
        
    

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
        <p><b>Abstract:</b>
         In environmental and natural resource planning domains actions are taken at a large number of locations over multiple time periods. These problems have enormous state and action spaces, spatial correlation between actions, uncertainty and complex utility models. We present an approach for modeling these planning problems as factored Markov decision processes. The reward model can contain local and global components as well as spatial constraints between locations. The transition dynamics can be provided by existing simulators developed by domain experts. We propose a landscape policy defined as the equilibrium distribution of a Markov chain built from many locally-parameterized policies. This policy is optimized using a policy gradient algorithm. Experiments using a forestry simulator demonstrate the algorithm’s ability to devise policies for sustainable harvest planning of a forest. Copyright \textcopyright 2011, Association for the Advancement of Artificial Intelligence. All rights reserved.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2009</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="Crowley2009" class="col-sm-8">
      <div class="title">
          
          Seeing the Forest Despite the Trees : Large Scale Spatial-Temporal Decision Making
      </div>
      <div class="author">
        
            
            
              
                
                  
                    <em>Mark Crowley</em>,
                  
                
              
        
            
            
              
                
                  
                    
                      John Nelson,
                    
                  
                
              
        
            
            
              
                
                  
                    
                      and <a href="https://www.cs.ubc.ca/~poole/" target="_blank">David Poole</a>.
                    
                  
                
              
        
      </div>

      <div class="periodical">
      
          In <em>Conference on Uncertainty in Artificial Intelligence (UAI09)</em>. 

      

      
      
          Montreal, Canada.
      
      
      
        2009.
      

       
      
        
      <div class="periodical">
          
      </div>
      </div>

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
      <a href="http://www.cs.ubc.ca/ crowley/papers/uai09-mark-crowley.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
    

    
        
        
          <a class="abstract btn btn-sm z-depth-0" role="button">Notes</a>
        
    
    </div>

    <!-- Hidden notes block - pick note or annote and stick to it -->
    
        
        
        <div class="abstract hidden">
            <p><b>Note:</b> My first publication.	 </p>
          </div>
        
    

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
        <p><b>Abstract:</b>
         We introduce a challenging real world planning problem where actions must be taken at each location in a spatial area at each point in time. We use forestry planning as the motivating application. In Large Scale Spatial-Temporal (LSST) planning problems, the state and action spaces are defined as the cross-products of many local state and action spaces spread over a large spatial area such as a city or forest. These problems possess state uncertainty, have complex utility functions involving spatial constraints and we generally must rely on simulations rather than an explicit transition model. We define LSST problems as reinforcement learning prob- lems and present a solution using policy gradients. We compare two different policy formulations: an explicit policy that identifies each location in space and the action to take there, and an abstract policy that defines the proportion of actions to take across all locations in space. We show that the abstract policy is more robust and achieves higher rewards with far fewer parameters than the elementary policy. This abstract policy is also a better fit to the properties that practitioners in LSST problem domains require for such methods to be widely useful</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2007</h2>
  <ol class="bibliography"></ol>

</div>

  </article>


      

    
</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2025 Mark  Crowley.
    Based on [*folio](https://github.com/bogoli/-folio) design. Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
    Last updated: April 09, 2025.
    
  </div>
</footer>



  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  



<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

<!-- Load DarkMode JS -->
<script src="/assets/js/dark_mode.js"></script>


</html>

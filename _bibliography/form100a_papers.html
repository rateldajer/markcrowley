<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 TRANSITIONAL//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<head>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link rel="stylesheet" href="htmlExportStyleSheet.css" />

<title>papers.bib</title> 
</head>

<body>
<div class="content">
<h1>papers.bib</h1>
<dl>
<dt class="Key" id="beeler2024canai">beeler2024canai</dt>
<dd class="Pub">
	<span class="Title">Dynamic programming with incomplete information to overcomenavigational uncertainty in {POMDPs}</span><br />
	<span class="Author">Authors: C. Beeler, X. Li, C. Bellinger, M. Crowley, M. Fraser, and I. Tamblyn</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: Proceedings of the Canadian Conference on Artificial Intelligence</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 12</span><br />
	(<span class="Date">Date: 2024</span>)<br />
    <div class="Abstract">Abstract: Using a generalizable novel nautical navigation environment, we show how dynamic programming can be used when only incomplete information about a partially observed Markov decision process (POMDP) is known. By incorporating uncertainty into our model, we show that navigation policies can be constructed that maintain safety, outperforming the baseline performance of traditional dynamic programming for Markov decision processes (MDPs). Adding in controlled sensing methods, we show that these policies can also lower measurement costs at the same time.</div><br />
    <div class="Abstract">Short Description: This paper used a spatial submarine simulator as a thought experiment to show how to improve reliability and speed of optimal planning algorithms in the presence of state uncertainty about critical factors with a spatial distribution such as ocean currents.</div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: mdp, dynamic-programming, reinforcement-learning, subworld, spatiotemporal-planning, decision-making, uncertainty, pomdp; grant-form100a</span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2024-canai-beeler-dynamic-programming.pdf">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2024-canai-beeler-dynamic-programming.pdf</a></span><br />
</dd>
<dt class="Key" id="bagi2024arxiv">bagi2024arxiv</dt>
<dd class="Pub">
	<span class="Title">Disentanglement in Implicit Causal Models via Switch Variable</span><br />
	<span class="Author">Authors: S. S. G. Bagi, Z. Gharaee, O. Schulte, and M. Crowley</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: Arxiv Preprint</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 18</span><br />
	(<span class="Date">Date: 2024</span>)<br />
    <div class="Abstract">Abstract: </div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: causality; machine-learning; deep-learning</span><br />
	<span class="File"><a href=""></a></span><br />
</dd>
<dt class="Key" id="beeler2023digidiscjourn">beeler2023digidiscjourn</dt>
<dd class="Pub">
	<span class="Title">ChemGymRL: An Interactive Framework for Reinforcement Learning for Digital Chemistry</span><br />
	<span class="Author">Authors: C. Beeler, S. G. Subramanian, K. Sprague, N. Chatti, C. Bellinger, M. Shahen, N. Paquin, M. Baula, A. Dawit, Z. Yang, X. Li, M. Crowley, and I. Tamblyn</span><br />
    <span class="Journal">Journal: Digital Discovery</span><br />
    <span class="Journal">Conference: </span><br />
	<span class="Volume">Volume: 3</span><br />
	<span class="Pages">Pages: 742-758</span><br />
	(<span class="Date">Date: 2024</span>)<br />
    <div class="Abstract">Abstract: This paper provides a simulated laboratory for making use of reinforcement learning (RL) for material design, synthesis, and discovery. Since RL is fairly data intensive, training agents `on-the-fly' by taking actions in the real world is infeasible and possibly dangerous. Moreover, chemical processing and discovery involves challenges which are not commonly found in RL benchmarks and therefore offer a rich space to work in. We introduce a set of highly customizable and open-source RL environments, ChemGymRL, implementing the standard gymnasium API. ChemGymRL supports a series of interconnected virtual chemical benches where RL agents can operate and train. The paper introduces and details each of these benches using well-known chemical reactions as illustrative examples, and trains a set of standard RL algorithms in each of these benches. Finally, discussion and comparison of the performances of several standard RL methods are provided in addition to a list of directions for future work as a vision for the further development and usage of ChemGymRL.</div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: reinforcement-learning, proj-chemgymrl, digital-chemistry, machine-learning, ai-for-chemistry, ai-for-science, grant-form100a</span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2024-digidiscjourn-beeler-chemgymrl-an.pdf">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2024-digidiscjourn-beeler-chemgymrl-an.pdf</a></span><br />
</dd>
<dt class="Key" id="bellinger2023neuripswant">bellinger2023neuripswant</dt>
<dd class="Pub">
	<span class="Title">Dynamic Observation Policies in Observation Cost-Sensitive Reinforcement Learning</span><br />
	<span class="Author">Authors: C. Bellinger, M. Crowley, and I. Tamblyn</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: Workshop on Advancing Neural Network Training: Computational Efficiency, Scalability, and Resource Optimization (WANT@NeurIPS 2023)</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 13</span><br />
	(<span class="Date">Date: 2023</span>)<br />
    <div class="Abstract">Abstract: Reinforcement learning (RL) has been shown to learn sophisticated control policies for complex tasks including games, robotics, heating and cooling systems and text generation. The action-perception cycle in RL, however, generally assumes that a measurement of the state of the environment is available at each time step without a cost. In applications such as materials design, deep-sea and planetary robot exploration and medicine, however, there can be a high cost associated with measuring, or even approximating, the state of the environment. In this paper, we survey the recently growing literature that adopts the perspective that an RL agent might not need, or even want, a costly measurement at each time step. Within this context, we propose the Deep Dynamic Multi-Step Observationless Agent (DMSOA), contrast it with the literature and empirically evaluate it on OpenAI gym and Atari Pong environments. Our results, show that DMSOA learns a better policy with fewer decision steps and measurements than the considered alternative from the literature.</div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: reinforcement-learning, proj-chemgymrl, digital-chemistry, machine-learning, ai-for-chemistry, ai-for-science, showcase; grant-form100a</span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2023-neuripswan-bellinger-dynamic.pdf">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2023-neuripswan-bellinger-dynamic.pdf</a></span><br />
	<span class="URL"><a href="https://openreview.net/forum?id=3GL2GETaaL">https://openreview.net/forum?id=3GL2GETaaL</a></span><br />
</dd>
<dt class="Key" id="beeler2023ai4science">beeler2023ai4science</dt>
<dd class="Pub">
	<span class="Title">ChemGym{RL}: An Interactive Framework for Reinforcement Learning for Digital Chemistry</span><br />
	<span class="Author">Authors: C. Beeler, S. G. Subramanian, C. Bellinger, M. Crowley, and I. Tamblyn</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: {NeurIPS} 2023 {AI} for Science Workshop</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 16</span><br />
	(<span class="Date">Date: 2023</span>)<br />
    <div class="Abstract">Abstract: This paper provides a simulated laboratory for making use of Reinforcement Learning (RL) for chemical discovery. Since RL is fairly data intensive, training agents `on-the-fly' by taking actions in the real world is infeasible and possibly dangerous. Moreover, chemical processing and discovery involves challenges which are not commonly found in RL benchmarks and therefore offer a rich space to work in. We introduce a set of highly customizable and open-source RL environments, ChemGymRL, implementing the standard Gymnasium API. ChemGymRL supports a series of interconnected virtual chemical benches where RL agents can operate and train. The paper introduces and details each of these benches using well-known chemical reactions as illustrative examples, and trains a set of standard RL algorithms in each of these benches. Finally, discussion and comparison of the performances of several standard RL methods are provided in addition to a list of directions for future work as a vision for the further development and usage of ChemGymRL.</div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: 7</span><br />
	<span class="Journal">Keywords: reinforcement-learning, proj-chemgymrl, digital-chemistry, machine-learning, ai-for-chemistry, ai-for-science; grant-form100a</span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2023-ai4science-beeler-chemgymrl.pdf">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2023-ai4science-beeler-chemgymrl.pdf</a></span><br />
	<span class="URL"><a href="https://openreview.net/forum?id=ZUkrNwMz5J">https://openreview.net/forum?id=ZUkrNwMz5J</a></span><br />
</dd>
<dt class="Key" id="beeler2023ai4mat">beeler2023ai4mat</dt>
<dd class="Pub">
	<span class="Title">Demonstrating ChemGym{RL}: An Interactive Framework for Reinforcement Learning for Digital Chemistry</span><br />
	<span class="Author">Authors: C. Beeler, S. G. Subramanian, K. Sprague, M. Crowley, C. Bellinger, and I. Tamblyn</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: {NeurIPS} 2023 {AI} for Accelerated Materials Discovery {(AI4Mat)} Workshop</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 6</span><br />
	(<span class="Date">Date: 2023</span>)<br />
    <div class="Abstract">Abstract: This tutorial describes a simulated laboratory for making use of reinforcement learning (RL) for chemical discovery. A key advantage of the simulated environment is that it enables RL agents to be trained safely and efficiently. In addition, it offer an excellent test-bed for RL in general, with challenges which are uncommon in existing RL benchmarks. The simulated laboratory, denoted ChemGymRL, is open-source, implemented according to the standard Gymnasium API, and is highly customizable. It supports a series of interconnected virtual chemical \emph{benches} where RL agents can operate and train. Within this tutorial introduce the environment, demonstrate how to train off-the-shelf RL algorithms on the benches, and how to modify the benches by adding additional reactions and other capabilities. In addition, we discuss future directions for ChemGymRL benches and RL for laboratory automation and the discovery of novel synthesis pathways. The software, documentation and tutorials are available here: https://www.chemgymrl.com</div><br />
    <div class="Abstract">Short Description: This was a workshop at the prestigious ICML conference on Machine Learning that focussed on the synergy between scientific modelling and machine learning. It was the perfect venue to publish the definition of our material design chemistry simulator for Reinforcement Learning with initial results.</div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: reinforcement-learning, proj-chemgymrl, digital-chemistry, machine-learning, ai-for-chemistry, ai-for-science, showcase; grant-form100a</span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2023-ai4mat-beeler-demonstrating.pdf">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2023-ai4mat-beeler-demonstrating.pdf</a></span><br />
</dd>
<dt class="Key" id="ramisaab2023frontneuro">ramisaab2023frontneuro</dt>
<dd class="Pub">
	<span class="Title">Machine-learning Assisted Swallowing Assessment: a deep learning-based quality improvement tool to screen for post-stroke dysphagia</span><br />
	<span class="Author">Authors: R. Saab, A. Balachandar, H. Mahdi, E. Nashnoush, L. Perri, A. Waldron, A. Sadeghian, G. Rubenfeld, M. Crowley, M. I. Boulos, B. Murray, and H. Khosravani</span><br />
    <span class="Journal">Journal: Frontiers in Neuroscience</span><br />
    <span class="Journal">Conference: </span><br />
	<span class="Volume">Volume: 17</span><br />
	<span class="Pages">Pages: 11</span><br />
	(<span class="Date">Date: 2023</span>)<br />
    <div class="Abstract">Abstract: Post-stroke dysphagia is common and associated with significant morbidity and mortality, rendering bedside screening of significant clinical importance. Using voice as a biomarker coupled with deep learning has the potential to improve patient access to screening and mitigate the subjectivity associated with detecting voice change, a component of several validated screening protocols. In this single-center study, we developed a proof-of-concept model for automated dysphagia screening and evaluated the performance of this model on training and testing cohorts. Patients were admitted to a comprehensive stroke center, where primary English speakers could follow commands without significant aphasia and participated on a rolling basis. The primary outcome was classification either as a pass or fail equivalent using a dysphagia screening test as a label. Voice data was recorded from patients who spoke a standardized set of vowels, words, and sentences from the National Institute of Health Stroke Scale. Seventy patients were recruited and 68 were included in the analysis, with 40 in training and 28 in testing cohorts, respectively. Speech from patients was segmented into 1,579 audio clips, from which 6,655 Mel-spectrogram images were computed and used as inputs for deep-learning models (DenseNet and ConvNext, separately and together). Clip-level and participant-level swallowing status predictions were obtained through a voting method. Model performance on the individual clip-level demonstrated dysphagia screening sensitivity of 71% and specificity of 77% (F1=0.73, AUC=0.80 [95% CI: 0.78-0.82]. On the participant-level the sensitivity and specificity were 89% and 79% respectively (F1=0.81, AUC=0.91 [95% CI: 0.77--1.05]). Our study is the first to demonstrate the feasibility of applying deep learning to classify vocalizations to detect post-stroke dysphagia.</div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: machine-learning, medical, stroke-recovery, dysphagia, time-series, classification, deep-learning, convolutional-network, showcase; grant-form100a</span><br />
	<span class="File"><a href=""></a></span><br />
	<span class="URL"><a href="https://www.frontiersin.org/articles/10.3389/fnins.2023.1302132/abstract">https://www.frontiersin.org/articles/10.3389/fnins.2023.1302132/abstract</a></span><br />
	<span class="URL"><a href="https://doi.org/10.3389/fnins.2023.1302132">https://doi.org/10.3389/fnins.2023.1302132</a></span><br />
</dd>
<dt class="Key" id="bellinger2023ecml">bellinger2023ecml</dt>
<dd class="Pub">
	<span class="Title">{Learning when to observe: A frugal reinforcement learning framework for a high-cost world}</span><br />
	<span class="Author">Authors: C. Bellinger, M. Crowley, and I. Tamblyn</span><br />
    <span class="Journal">Journal: ECML-PKDD</span><br />
    <span class="Journal">Conference: Workshop on Simplification, Compression, Efficiency and Frugality for Artificial intelligence at the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML-PKDD)</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 16</span><br />
	(<span class="Date">Date: 2023</span>)<br />
    <div class="Abstract">Abstract: Reinforcement learning (RL) has been shown to learn so- phisticated control policies for complex tasks including games, robotics, heating and cooling systems and text generation. The action-perception
cycle in RL, however, generally assumes that a measurement of the state of the environment is available at each time step without a cost. In applications such as materials design, deep-sea and planetary robot exploration and medicine, however, there can be a high cost associated with measuring, or even approximating, the state of the environment. In this paper, we survey the recently growing literature that adopts the perspective that an RL agent might not need, or even want, a costly mea- surement at each time step. Within this context, we propose the Deep Dynamic Multi-Step Observationless Agent (DMSOA), contrast it with the literature and empirically evaluate it on OpenAI gym and Atari Pong environments. Our results, show that DMSOA learns a better policy with fewer decision steps and measurements than the considered alternative from the literature. The corresponding code is available at: https: //github.com/cbellinger27/Learning-when-to-observe-in-RL</div><br />
    <div class="Abstract">Short Description: This workshop paper is part of the larger Digital Chemistry project I have with the NRC. This paper was written primarily by Dr. Bellinger with input and revisions by me and Dr. Tamblyn.</div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: Computer Science - Machine Learning, Computer Science - Artificial Intelligence, 68T01, I.2.0; grant-form100a</span><br />
	<span class="File"><a href="file:///Users/mcrowley/Dropbox/website_assets/markcrowley-ca/pdfs/2023-ecml-bellinger-learning.pdf">/Users/mcrowley/Dropbox/website_assets/markcrowley-ca/pdfs/2023-ecml-bellinger-learning.pdf</a></span><br />
	<span class="URL"><a href="https://doi.org/10.48550/arXiv.2307.02620">https://doi.org/10.48550/arXiv.2307.02620</a></span><br />
</dd>
<dt class="Key" id="beeler2023synsandml">beeler2023synsandml</dt>
<dd class="Pub">
	<span class="Title">ChemGymRL: An Interactive Framework for Reinforcement Learning for Digital Chemistry</span><br />
	<span class="Author">Authors: C. Beeler, S. G. Subramanian, K. Sprague, N. Chatti, C. Bellinger, M. Shahen, N. Paquin, M. Baula, A. Dawit, Z. Yang, X. Li, M. Crowley, and I. Tamblyn</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: {ICML 2023 Synergy of Scientific and Machine Learning Modeling (SynS\&ML) Workshop}</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 19</span><br />
	(<span class="Date">Date: 2023</span>)<br />
    <div class="Abstract">Abstract: This paper provides a simulated laboratory for making use of Reinforcement Learning (RL) for chemical discovery. Since RL is fairly data intensive, training agents `on-the-fly' by taking actions in the real world is infeasible and possibly dangerous. Moreover, chemical processing and discovery involves challenges which are not commonly found in RL benchmarks and therefore offer a rich space to work in. We introduce a set of highly customizable and open-source RL environments, ChemGymRL, based on the standard Open AI Gym template. ChemGymRL supports a series of interconnected virtual chemical benches where RL agents can operate and train. The paper introduces and details each of these benches using well-known chemical reactions as illustrative examples, and trains a set of standard RL algorithms in each of these benches. Finally, discussion and comparison of the performances of several standard RL methods are provided in addition to a list of directions for future work as a vision for the further development and usage of ChemGymRL.</div><br />
    <div class="Abstract">Short Description: This was a workshop at the prestigious ICML conference on Machine Learning that focussed on the synergy between scientific modelling and machine learning. It was the perfect venue to publish the definition of our material design chemistry simulator for Reinforcement Learning with initial results.</div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: reinforcement-learning, proj-chemgymrl, digital-chemistry, machine-learning, ai-for-chemistry, ai-for-science, showcase; grant-form100a</span><br />
	<span class="File"><a href="file:///Users/mcrowley/Dropbox/website_assets/markcrowley-ca/pdfs/2023-synsandml-beeler-chemgymrl2.pdf">/Users/mcrowley/Dropbox/website_assets/markcrowley-ca/pdfs/2023-synsandml-beeler-chemgymrl2.pdf</a></span><br />
</dd>
<dt class="Key" id="ganapathisubramanian2023ijcai">ganapathisubramanian2023ijcai</dt>
<dd class="Pub">
	<span class="Title">Multi-{A}gent {A}dvisor {Q}-{L}earning</span><br />
	<span class="Author">Authors: S. Ganapathi Subramanian, K. Larson, M. Taylor, and M. Crowley</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: International Joint Conference on Artificial Intelligence (IJCAI) : Journal Track</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 74</span><br />
	(<span class="Date">Date: 2023</span>)<br />
    <div class="Abstract">Abstract: In the last decade, there have been significant advances in multi-agent reinforcement learn- ing (MARL) but there are still numerous challenges, such as high sample complexity and slow convergence to stable policies, that need to be overcome before wide-spread deployment is possi- ble. However, many real-world environments already, in practice, deploy sub-optimal or heuristic approaches for generating policies. An interesting question that arises is how to best use such approaches as advisors to help improve reinforcement learning in multi-agent domains. In this paper, we provide a principled framework for incorporating action recommendations from online sub- optimal advisors in multi-agent settings. We describe the problem of ADvising Multiple Intelligent Reinforcement Agents (ADMIRAL) in nonrestrictive general-sum stochastic game environments and present two novel Q-learning based algorithms: ADMIRAL - Decision Making (ADMIRAL-DM) and ADMIRAL - Advisor Evaluation (ADMIRAL-AE), which allow us to improve learning by appropriately incorporating advice from an advisor (ADMIRAL-DM), and evaluate the effectiveness of an advisor (ADMIRAL-AE). We analyze the algorithms theoretically and provide fixed point guarantees regarding their learning in general-sum stochastic games. Furthermore, extensive experi- ments illustrate that these algorithms: can be used in a variety of environments, have performances that compare favourably to other related baselines, can scale to large state-action spaces, and are robust to poor advice from advisors.</div><br />
    <div class="Abstract">Short Description: This is a journal track for abstracts and presentations of journal articles from the previous year for JAIR and AIJ journals. We published a paper of the same name in JAIR in 2022 and presented it at IJCAIR 2023.</div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: showcase, reinforcement-learning, multi-agent-systems, deep-learning; forest-wildfire; forest-management; game-playing; grant-form100a</span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2022-jair-ganapathi%20subramanian-multi-agent.pdf">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2022-jair-ganapathi subramanian-multi-agent.pdf</a></span><br />
</dd>
<dt class="Key" id="bagi2023icml">bagi2023icml</dt>
<dd class="Pub">
	<span class="Title">Generative Causal Representation Learning for Out-of-Distribution Motion Forecasting</span><br />
	<span class="Author">Authors: S. S. G. Bagi, Z. Gharaee, O. Schulte, and M. Crowley</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: International Conference on Machine Learning (ICML)</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 17</span><br />
	(<span class="Date">Date: 2023</span>)<br />
    <div class="Abstract">Abstract: Conventional supervised learning methods typically assume i.i.d samples and are found to be sensitive to out-of-distribution (OOD) data. We propose Generative Causal Representation Learning (GCRL) which leverages causality to facilitate knowledge transfer under distribution shifts. While we evaluate the effectiveness of our proposed method in human trajectory prediction models, GCRL can be applied to other domains as well. First, we propose a novel causal model that explains the generative factors in motion forecasting datasets using features that are common across all environments and with features that are specific to each environment. Selection variables are used to determine which parts of the model can be directly transferred to a new environment without fine-tuning. Second, we propose an end-to-end variational learning paradigm to learn the causal mechanisms that generate observations from features. GCRL is supported by strong theoretical results that imply identifiability of the causal model under certain assumptions. Experimental results on synthetic and real-world motion forecasting datasets show the robustness and effectiveness of our proposed method for knowledge transfer under zero-shot and low-shot settings by substantially outperforming the prior motion forecasting models on out-of-distribution prediction.</div><br />
    <div class="Abstract">Short Description: We propose a new framework for leveraging causal information to improve robustness of learning in the presence of distribution shift. Empirical results on the motion forecasting domain support the theoretical findings.</div><br />
	<span class="Pages">Citations: 1</span><br />
	<span class="Journal">Keywords: causality, machine-learning, probabilistic-inference, autonomous-driving, pedestrian-detection, motion-forecasting, showcase; probabilistic-graphical-models; grant-form100a</span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2023-icml-bagi-generative-poster.pdf">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2023-icml-bagi-generative-poster.pdf</a></span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2023-icml-bagi-generative.pdf">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2023-icml-bagi-generative.pdf</a></span><br />
</dd>
<dt class="Key" id="camlica2022iotsms">camlica2022iotsms</dt>
<dd class="Pub">
	<span class="Title">Aggressive Driver Behavior Detection using Parallel Convolutional Neural Networks on Simulated and Real Driving Data</span><br />
	<span class="Author">Authors: Z. Camlica, J. Quesenberry, D. Carballo, and M. Crowley</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: 9th International Conference on Internet of Things: Systems, Management and Security (IOTSMS)</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 8</span><br />
	(<span class="Date">Date: 2022</span>)<br />
    <div class="Abstract">Abstract: The novel method proposed in this paper is com- promised of application of two Convolutional Neural Networks (CNN) working in parallel to simultaneously classify driver be- haviors while classifying maneuvers by using time series data. We claim that the Parallel Convolutional Neural Network (PCNN) not only speeds-up training time but also increases performance since having information about the maneuver helps to improve behavior classification performance and vice versa. In this study, both simulation and real-world driving datasets are utilized for driver behavior analysis. As simulation data, mobile phone sensor data are simulated as a time series using a combination of a traffic simulator (SUMO) and a car simulation system (Webots). The same type of data is collected with a specially designed vehicle traveled on a defined route around a predefined region. The collected data are then separately utilized as training and testing data for classification of both maneuvers (e.g turns and lane changes) and driver behaviors (e.g aggressive, non-aggressive) applying a novel method using deep learning on time series data. In addition, other methods which are commonly used for time series analysis, Hidden Markov Models(HMMs) and Recurrent Neural Networks (RNN), are applied to the same datasets to compare with PCNN. According to the results, the CNN classifiers perform efficiently for a single task and PCNN outperforms both single task-CNN and RNN with an average accuracy of 86%.</div><br />
    <div class="Abstract">Short Description: This is part of the research of my PhD student Zehra Camlica and uses data from the longrunning Driver Behaviour Learning project with Magna International. I presented the results virutally at this workshop in November 2022. These are results that will be part of her final PhD thesis, the collacoration was entirely between myself and the student including design of experiemnts and writing of the paper.</div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: deep-learning; lstm; rnn; autonomous-driving; driver-behaviour-learning; proj-dbl; aggressive-driving-detection; showcase; grant-form100a</span><br />
	<span class="File"><a href=""></a></span><br />
	<span class="File"><a href=""></a></span><br />
</dd>
<dt class="Key" id="ganapathi-subramanian2020aamas">ganapathi-subramanian2020aamas</dt>
<dd class="Pub">
	<span class="Title">Multi Type Mean Field Reinforcement Learning</span><br />
	<span class="Author">Authors: S. Ganapathi Subramanian, P. Poupart, M. Taylor, and N. Hegde</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: Proceedings of the 19th International Conference on Autonomous Agents and MultiAgent Systems (AAMAS)</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: </span><br />
	(<span class="Date">Date: 2020</span>)<br />
    <div class="Abstract">Abstract: </div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: reinforcement-learning, multi-agent-reinforcement-learning, multi-agent-systems; grant-form100a</span><br />
	<span class="URL"><a href="https://www.ifaamas.org/Proceedings/aamas2020/pdfs/p411.pdf">https://www.ifaamas.org/Proceedings/aamas2020/pdfs/p411.pdf</a></span><br />
</dd>
<dt class="Key" id="lau:2001jj">lau:2001jj</dt>
<dd class="Pub">
	<span class="Title">Net.Data to JSP Helper</span><br />
	<span class="Author">Authors: T. Lau, J. Lu, J. Mylopoulos, E. Hedges, K. Kontogiannis, E. Xing, and M. Crowley</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: </span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: </span><br />
	(<span class="Date">Date: 2001</span>)<br />
    <div class="Abstract">Abstract: </div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: CiteULike</span><br />
	<span class="URL"><a href="http://www.alphaworks.ibm.com/tech/netdatatojsp">http://www.alphaworks.ibm.com/tech/netdatatojsp</a></span><br />
</dd>
<dt class="Key" id="lau:2001xi">lau:2001xi</dt>
<dd class="Pub">
	<span class="Title">Migrating E-commerce Database Applications to an Enterprise Java Environment</span><br />
	<span class="Author">Authors: T. Lau, J. Lu, E. Hedges, and E. Xing</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: Proceedings of the 2001 conference of the Centre for Advanced Studies on Collaborative research</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: </span><br />
	(<span class="Date">Date: 2001</span>)<br />
    <div class="Abstract">Abstract: </div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: Mark Crowley Database; CiteULike</span><br />
	<span class="File"><a href=""></a></span><br />
	<span class="URL"><a href="http://portal.acm.org/citation.cfm?id=782096.782105&dl=GUIDE&dl=ACM">http://portal.acm.org/citation.cfm?id=782096.782105&dl=GUIDE&dl=ACM</a></span><br />
</dd>
<dt class="Key" id="akgun2022toac">akgun2022toac</dt>
<dd class="Pub">
	<span class="Title">Using Affect as a Communication Modality to Improve Human-Robot Communication in Robot-Assisted Search and Rescue Scenarios</span><br />
	<span class="Author">Authors: S. A. Akgun, M. Ghafurian, M. Crowley, and K. Dautenhahn</span><br />
    <span class="Journal">Journal: IEEE Transactions on Affective Computing</span><br />
    <span class="Journal">Conference: </span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 18</span><br />
	(<span class="Date">Date: 2022</span>)<br />
    <div class="Abstract">Abstract: Emotions can provide a natural communication modality to complement the existing multi-modal capabilities of social robots, such as text and speech, in many domains. We conducted three online studies with 112, 223, and 151 participants to investigate the benefits of using emotions as a communication modality for Search And Rescue (SAR) robots. In the first experiment, we investigated the feasibility of conveying information related to SAR situations through robots' emotions, resulting in mappings from SAR situations to emotions. The second study used Affect Control Theory as an alternative method for deriving such mappings. This method is more flexible, e.g. allows for such mappings to be adjusted for different emotion sets and different robots. In the third experiment, we created affective expressions for an appearance-constrained outdoor field research robot using LEDs as an expressive channel. Using these affective expressions in a variety of simulated SAR situations, we evaluated the effect of these expressions on participants' (adopting the role of rescue workers) situational awareness. Our results and proposed methodologies provide (a) insights on how emotions could help conveying messages in the context of SAR, and (b) evidence on the effectiveness of adding emotions as a communication modality in a (simulated) SAR communication context.</div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: Robotics (cs.RO), Human-Computer Interaction (cs.HC), FOS: Computer and information sciences, FOS: Computer and information sciences; empircal-study; showcase; grant-form100a</span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2022-toac-akgun-using.pdf">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2022-toac-akgun-using.pdf</a></span><br />
	<span class="URL"><a href="https://arxiv.org/abs/2208.09580">https://arxiv.org/abs/2208.09580</a></span><br />
	<span class="URL"><a href="https://doi.org/10.48550/ARXIV.2208.09580">https://doi.org/10.48550/ARXIV.2208.09580</a></span><br />
</dd>
<dt class="Key" id="subramanian2022uwspace">subramanian2022uwspace</dt>
<dd class="Pub">
	<span class="Title">Multi-Agent Reinforcement Learning in Large Complex Environments</span><br />
	<span class="Author">Authors: S. G. Subramanian</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: </span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: </span><br />
	(<span class="Date">Date: 2022</span>)<br />
    <div class="Abstract">Abstract: Multi-agent reinforcement learning (MARL) has seen much success in the past decade. However, these methods are yet to find wide application in large-scale real world problems due to two important reasons. First, MARL algorithms have poor sample efficiency, where many data samples need to be obtained through interactions with the environment to learn meaningful policies, even in small environments. Second, MARL algorithms are not scalable to environments with many agents since, typically, these algorithms are exponential in the number of agents in the environment. This dissertation aims to address both of these challenges with the goal of making MARL applicable to a variety of real world environments. Towards improving sample efficiency, an important observation is that many real world environments already, in practice, deploy sub-optimal or heuristic approaches for generating policies. A useful possibility that arises is how to best use such approaches as advisors to help improve reinforcement learning in multi-agent domains. In this dissertation, we provide a principled framework for incorporating action recommendations from online sub-optimal advisors in multi-agent settings. To this end, we propose a general model for learning from external advisors in MARL and show that desirable theoretical properties such as convergence to a unique solution concept, and reasonable finite sample complexity bounds exist, under a set of common assumptions. Furthermore, extensive experiments illustrate that these algorithms: can be used in a variety of environments, have performances that compare favourably to other related baselines, can scale to large state-action spaces, and are robust to poor advice from advisors. Towards scaling MARL, we explore the use of mean field theory. Mean field theory provides an effective way of scaling multi-agent reinforcement learning algorithms to environments with many agents, where other agents can be abstracted by a virtual mean agent. Prior work has used mean field theory in MARL, however, they suffer from several stringent assumptions such as requiring fully homogeneous agents, full observability of the environment, and centralized learning settings, that prevent their wide application in practical environments. In this dissertation, we extend mean field methods to environments having heterogeneous agents, and partially observable settings. Further, we extend mean field methods to include decentralized approaches. We provide novel mean field based MARL algorithms that outperform previous methods on a set of large games with many agents. Theoretically, we provide bounds on the information loss experienced as a result of using the mean field and further provide fixed point guarantees for Q-learning-based algorithms in each of these environments. Subsequently, we combine our work in mean field learning and learning from advisors to show that we can achieve powerful MARL algorithms that are more suitable for real world environments as compared to prior approaches. This method uses the recently introduced attention mechanism to perform per-agent modelling of others in the locality, in addition to using the mean field for global responses. Notably, in this dissertation, we show applications in several real world multi-agent environments such as the Ising model, the ride-pool matching problem, and the massively multi-player online (MMO) game setting (which is currently a multi-billion dollar market).</div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: reinforcement-learning; multi-agent-reinforcement-learning; forest-management; game-theory; forest-wildfire; grant-form100a</span><br />
	<span class="File"><a href=""></a></span><br />
</dd>
<dt class="Key" id="ghojogh2021mlwajrnl">ghojogh2021mlwajrnl</dt>
<dd class="Pub">
	<span class="Title">Quantile--Quantile Embedding for distribution transformation and manifold embedding with ability to choose the embedding distribution</span><br />
	<span class="Author">Authors: B. Ghojogh, F. Karray, and M. Crowley</span><br />
    <span class="Journal">Journal: Machine Learning with Applications (MLWA)</span><br />
    <span class="Journal">Conference: </span><br />
	<span class="Volume">Volume: 6</span><br />
	<span class="Pages">Pages: </span><br />
	(<span class="Date">Date: 2021</span>)<br />
    <div class="Abstract">Abstract: We propose a new embedding method, named Quantile-Quantile Embedding (QQE), for distribution transformation and manifold embedding with the ability to choose the embedding distribution. QQE, which uses the concept of quantile-quantile plot from visual statistical tests, can transform the distribution of data to any theoretical desired distribution or empirical reference sample. Moreover, QQE gives the user a choice of embedding distribution in embedding the manifold of data into the low dimensional embedding space. It can also be used for modifying the embedding distribution of other dimensionality reduction methods, such as PCA, t-SNE, and deep metric learning, for better representation or visualization of data. We propose QQE in both unsupervised and supervised forms. QQE can also transform a distribution to either an exact reference distribution or its shape. We show that QQE allows for better discrimination of classes in some cases. Our experiments on different synthetic and image datasets show the effectiveness of the proposed embedding method. </div><br />
    <div class="Abstract">Short Description: This journal paper extends upon one of the major components of my recently graduate PhD student Benyamin Ghojogh. The topic arose primarily from discussions betwteen Ghojogh and myself about novel ways to use learned data manifold, in this case, for mimicking other desired distributions in order to compare them better or for align better for other reasons. Ghojogh worked out the theoretical details and we designed the experiments and wrote the paper collaboratively. Prof. Karray gave feedback on the final revisions before submission.</div><br />
	<span class="Pages">Citations: 2</span><br />
	<span class="Journal">Keywords: year-in-review-2021, manifold-learning, dimensionality-reduction, image-processing, medical-imaging, proj-digipath; grant-form100a</span><br />
	<span class="URL"><a href="https://doi.org/10.1016/j.mlwa.2021.100088">https://doi.org/10.1016/j.mlwa.2021.100088</a></span><br />
</dd>
<dt class="Key" id="ghojogh2022springerbook">ghojogh2022springerbook</dt>
<dd class="Pub">
	<span class="Title">Elements of Dimensionality Reduction and Manifold Learning</span><br />
	<span class="Author">Authors: B. Ghojogh, M. Crowley, F. Karray, and A. Ghodsi</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: </span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 363</span><br />
	(<span class="Date">Date: 2023</span>)<br />
    <div class="Abstract">Abstract: Dimensionality reduction, also known as manifold learning, is an area of machine learning used for extracting informative features from data, for better representation of data or separation between classes. This book presents a cohesive review of linear and nonlinear dimensionality reduction and manifold learning. Three main aspects of dimensionality reduction are covered -- spectral dimensionality reduction, probabilistic dimensionality reduction, and neural network-based dimensionality reduction, which have geometric, probabilistic, and information-theoretic points of view to dimensionality reduction, respectively. This book delves into basic concepts and recent developments in the field of dimensionality reduction and manifold learning, providing the reader with a comprehensive understanding. The necessary background and preliminaries, on linear algebra, optimization, and kernels, are also explained in the book to ensure a comprehensive understanding of the algorithms.

The tools this book introduces are applied to various applications involving feature extraction, image processing, computer vision, and signal processing. This book is applicable to a wide audience who would like to acquire a deep understanding of the various ways to extract, transform, and understand the structure of data. The intended audiences are academics, students, and industry professionals. Academic researchers and students can use this book as a textbook for machine learning and dimensionality reduction. Data scientists, machine learning scientists, computer vision scientists, computer scientists, statisticians, and mathematicians in the fields of applied mathematics, statistical learning, Riemannian manifolds, subspace analysis, linear algebra, and optimization can use this book as a reference book for both technical and applied concepts. Industry professionals, including applied engineers, data engineers, and engineers in various fields of science dealing with machine learning, can use this book as a guidebook for feature extraction from their data as the raw data in industry often requires pre-processing. Data feature extraction is useful in various fields of science including engineering, physics, chemistry, biometrics, biomedical signals and images, etc.

This book is structured as a reference textbook, so that it can be used for advanced courses, as an in-depth supplementary resource or for researchers or practitioners who want to learn about dimensionality reduction and manifold learning. The book is grounded in theory, but provides thorough explanations and diverse examples to improve the readers comprehension of the advanced topics. Advanced methods are explained in a step-by-step manner so that readers of all levels can follow the reasoning and come to a deep understanding of the concepts. This book does not assume the reader has an advanced theoretical background in machine learning and provides necessary background, though an undergraduate-level background in linear algebra and calculus is recommended.</div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: 37</span><br />
	<span class="Journal">Keywords: manifold-learning, dimensionality-reduction, machine-learning, metric-learning, showcase; grant-form100a</span><br />
	<span class="File"><a href="file:///Users/mcrowley/Dropbox/DocumentsWaterloo/Projects/old-done-hidden/ManfoldLearningBook/final%20published/Elements_of_Dimensionality_Reduction_and_Manifold_Learning_2023.pdf">/Users/mcrowley/Dropbox/DocumentsWaterloo/Projects/old-done-hidden/ManfoldLearningBook/final published/Elements_of_Dimensionality_Reduction_and_Manifold_Learning_2023.pdf</a></span><br />
	<span class="URL"><a href="https://www.amazon.ca/Elements-Dimensionality-Reduction-Manifold-Learning/dp/3031106016/ref=sr_1_1?keywords=9783031106019&linkCode=qs&qid=1659572815&returnFromLogin=1&s=books&sr=1-1">https://www.amazon.ca/Elements-Dimensionality-Reduction-Manifold-Learning/dp/3031106016/ref=sr_1_1?keywords=9783031106019&linkCode=qs&qid=1659572815&returnFromLogin=1&s=books&sr=1-1</a></span><br />
	<span class="URL"><a href="https://link.springer.com/book/10.1007/978-3-031-10602-6">https://link.springer.com/book/10.1007/978-3-031-10602-6</a></span><br />
</dd>
<dt class="Key" id="Bellinger2022Balancing">Bellinger2022Balancing</dt>
<dd class="Pub">
	<span class="Title">Balancing Information with Observation Costs in Deep Reinforcement Learning</span><br />
	<span class="Author">Authors: C. Bellinger, A. Drozdyuk, M. Crowley, and I. Tamblyn</span><br />
    <span class="Journal">Journal: Proceedings of the Canadian Conference on Artificial Intelligence</span><br />
    <span class="Journal">Conference: Canadian Conference on Artificial Intelligence</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 12</span><br />
	(<span class="Date">Date: 2022</span>)<br />
    <div class="Abstract">Abstract: 
The use of Reinforcement Learning (RL) in scientific applications, such
as materials design and automated chemistry, is increasing. A major
challenge, however, lies in fact that measuring the state of the system
is often costly and time consuming in scientific applications, whereas
policy learning with RL requires a measurement after each time step. In
this work, we make the measurement costs explicit in the form of a
costed reward and propose the active-measure with costs framework that
enables off-the-shelf deep RL algorithms to learn a policy for both
selecting actions and determining whether or not to measure the state of
the system at each time step. In this way, the agents learn to balance
the need for information with the cost of information. Our results show
that when trained under this regime, the Dueling DQN and PPO agents can
learn optimal action policies whilst making up to 50\% fewer state
measurements, and recurrent neural networks can produce a greater than
50\% reduction in measurements. We postulate the these reduction can
help to lower the barrier to applying RL to real-world scientific
applications.
</div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: 7</span><br />
	<span class="Journal">Keywords: reinforcement-learning; ai-for-science; proj-chemgymrl; machine-learning; ai-for-material-design; ai-for-chemistry; digital-chemistry; grant-form100a</span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2022-canai-bellinger-balancing.pdf">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2022-canai-bellinger-balancing.pdf</a></span><br />
	<span class="File"><a href=""></a></span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2022-canai-bellinger-balancing.png">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2022-canai-bellinger-balancing.png</a></span><br />
</dd>
<dt class="Key" id="ghojogh2022canai">ghojogh2022canai</dt>
<dd class="Pub">
	<span class="Title">Theoretical Connection between Locally Linear Embedding, Factor Analysis, and Probabilistic PCA</span><br />
	<span class="Author">Authors: B. Ghojogh, A. Ghodsi, F. Karray, and M. Crowley</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: Canadian Conference on Artificial Intelligence</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 6</span><br />
	(<span class="Date">Date: 2022</span>)<br />
    <div class="Abstract">Abstract: Locally Linear Embedding (LLE) is a nonlinear spectral dimensionality reduction and manifold learning method. It has two main steps which are linear reconstruction and linear embedding of points in the input space and embedding space, respectively. In this work, we look at the linear reconstruction step from a stochastic perspective where it is assumed that every data point is conditioned on its linear reconstruction weights as latent factors. The stochastic linear reconstruction of LLE is solved using expectation maximization. We show that there is a theoretical connection between three fundamental dimensionality reduction methods, i.e., LLE, factor analysis, and probabilistic Principal Component Analysis (PCA). The stochastic linear reconstruction of LLE is formulated similar to the factor analysis and probabilistic PCA. It is also explained why factor analysis and probabilistic PCA are linear and LLE is a nonlinear method. This work combines and makes a bridge between two broad approaches of dimensionality reduction, i.e., the spectral and probabilistic algorithms.	</div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: locally-linear-embedding, factor-analysis, manifold-learning, dimensionality-reduction, pca; grant-form100a</span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2022-canai-ghojogh-theoretical.pdf">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2022-canai-ghojogh-theoretical.pdf</a></span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2022-canai-ghojogh-theoretical1.pdf">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2022-canai-ghojogh-theoretical1.pdf</a></span><br />
</dd>
<dt class="Key" id="allada2021uw-masc-thesis">allada2021uw-masc-thesis</dt>
<dd class="Pub">
	<span class="Title">Histopathology Image Analysis and NLP for Digital Pathology.</span><br />
	<span class="Author">Authors: A. K. Allada</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: UWSpace. http://hdl.handle.net/10012/17305</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: </span><br />
	(<span class="Date">Date: 2021</span>)<br />
    <div class="Abstract">Abstract: </div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: proj-digipath, digital-pathology, machine-learning, image-processing, natural-language-processing, medical-imaging, deep-learning; grant-form100a</span><br />
	<span class="File"><a href=""></a></span><br />
</dd>
<dt class="Key" id="ganapathi-subramanian2023aamas">ganapathi-subramanian2023aamas</dt>
<dd class="Pub">
	<span class="Title">Learning from Multiple Independent Advisors in Multi-agent Reinforcement Learning</span><br />
	<span class="Author">Authors: S. Ganapathi Subramanian, M. Taylor, K. Larson, and M. Crowley</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: Proceedings of the 22nd International Conference on Autonomous Agents and MultiAgent Systems (AAMAS)</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 27</span><br />
	(<span class="Date">Date: 2023</span>)<br />
    <div class="Abstract">Abstract: Multi-agent reinforcement learning typically suffers from the problem of sample inefficiency, where learning suitable policies involves the use of many data samples. Learning from external demonstrators is a possible solution that mitigates this problem. However, most prior approaches in this area assume the presence of a single demonstrator. Leveraging multiple knowledge sources (i.e., advisors) with expertise in distinct aspects of the environment could substantially speed up learning in complex environments. This paper considers the problem of simultaneously learning from multiple independent advisors in multi-agent reinforcement learning. The approach leverages a two-level $Q$-learning architecture, and extends this framework from single-agent to multi-agent settings. We provide principled algorithms that incorporate a set of advisors by both evaluating the advisors at each state and subsequently using the advisors to guide action selection. Also, we provide theoretical convergence and sample complexity guarantees. Experimentally, we validate our approach in three different test-beds and show that our algorithms give better performances than baselines, can effectively integrate the combined expertise of different advisors, and learn to ignore bad advice.</div><br />
    <div class="Abstract">Short Description: This paper forms one of the final components of my PhD student Sriram's thesis work, who did the majority of the writing and all of the empirical work. The approach to theory, methodology and writing has been a regular and fully collaborative discussion amongst all the authors over several months.</div><br />
	<span class="Pages">Citations: 3</span><br />
	<span class="Journal">Keywords: machine-learning, reinforcement-learning, multi-agent-systems, Multi-agent Reinforcement Learning, {MARL}, showcase, forest-wildfire; forest-management; grant-form100a</span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2023-aamas-ganapathi%20subramanian-learning%20from%20multiple%20independent%20advisors%20in%20multi-agent%20reinforcement%20learning.pdf">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2023-aamas-ganapathi subramanian-learning from multiple independent advisors in multi-agent reinforcement learning.pdf</a></span><br />
	<span class="URL"><a href="https://openreview.net/forum?id=6UspkM-4uOw&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DNeurIPS.cc%2F2022%2FConference%2FAuthors%23your-submissions)">https://openreview.net/forum?id=6UspkM-4uOw&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DNeurIPS.cc%2F2022%2FConference%2FAuthors%23your-submissions)</a></span><br />
</dd>
<dt class="Key" id="beeler2022ieeeintsys">beeler2022ieeeintsys</dt>
<dd class="Pub">
	<span class="Title">Dynamic programming with partial information to overcome navigational uncertainty in a nautical environment</span><br />
	<span class="Author">Authors: C. Beeler, X. Li, M. Crowley, M. Fraser, and I. Tamblyn</span><br />
    <span class="Journal">Journal: IEEE Intelligent Systems</span><br />
    <span class="Journal">Conference: </span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: </span><br />
	(<span class="Date">Date: 2022</span>)<br />
    <div class="Abstract">Abstract: Using a toy nautical navigation environment, we show that dynamic
programming can be used when only partial information about a partially
observed Markov decision process (POMDP) is known. By incorporating
uncertainty into our model, we show that navigation policies can be
constructed that maintain safety. Adding controlled sensing methods, we
show that these policies can also lower measurement costs at the same
time.</div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: mdp, machine-learning, digital-chemistry, proj-chemgymrl, reinforcement-learning; ai-for-material-design; ai-for-chemistry; ai-for-science; grant-form100a</span><br />
</dd>
<dt class="Key" id="bellinger2022ai2ase">bellinger2022ai2ase</dt>
<dd class="Pub">
	<span class="Title">Scientific Discovery and the Cost of Measurement -- Balancing Information and Cost in Reinforcement Learning</span><br />
	<span class="Author">Authors: C. Bellinger, A. Drozdyuk, M. Crowley, and I. Tamblyn</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: 1st Annual AAAI Workshop on AI to Accelerate Science and Engineering (AI2ASE)</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: </span><br />
	(<span class="Date">Date: 2022</span>)<br />
    <div class="Abstract">Abstract: The use of reinforcement learning (RL) in scientific applications, such as materials design and automated chemistry, is increasing. A major challenge, however, lies in fact that measuring the state of the system is often costly and time consuming in scientific applications, whereas policy learning with RL requires a measurement after each time step. In this work, we make the measurement costs explicit in the form of a costed reward and propose a framework that enables off-the-shelf deep RL algorithms to learn a policy for both selecting actions and determining whether or not to measure the current state of the system at each time step. In this way, the agents learn to balance the need for information with the cost of information. Our results show that when trained under this regime, the Dueling DQN and PPO agents can learn optimal action policies whilst making up to 50\% fewer state measurements, and recurrent neural networks can produce a greater than 50\% reduction in measurements. We postulate the these reduction can help to lower the barrier to applying RL to real-world scientific applications.</div><br />
    <div class="Abstract">Short Description: This workshop paper follows up on from our paper at CanAI earlier in the year with additional modifications to the algorithm and experiments. This yielded some very promising empirical observations. TODO</div><br />
	<span class="Pages">Citations: 1</span><br />
	<span class="Journal">Keywords: reinforcement-learning; proj-chemgymrl; machine-learning; science; ai-for-science; ai-for-physics; ai-for-material-design; ai-for-chemistry; digital-chemistry; grant-form100a</span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2022-ai2ase-bellinger-scientific.pdf">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2022-ai2ase-bellinger-scientific.pdf</a></span><br />
</dd>
<dt class="Key" id="ganapathisubramanian2022aaai">ganapathisubramanian2022aaai</dt>
<dd class="Pub">
	<span class="Title">Decentralized Mean Field Games</span><br />
	<span class="Author">Authors: S. Ganapathi Subramanian, M. Taylor, M. Crowley, and P. Poupart</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: Proceedings of the AAAI Conference on Artificial Intelligence (AAAI-2022)</span><br />
	<span class="Volume">Volume: 36</span><br />
	<span class="Pages">Pages: 9439-9447</span><br />
	(<span class="Date">Date: 2022</span>)<br />
    <div class="Abstract">Abstract: Multiagent reinforcement learning algorithms have not been widely adopted in large scale environments with many agents as they often scale poorly with the number of agents. Using mean field theory to aggregate agents has been proposed as a solution to this problem. However, almost all previous methods in this area make a strong assumption of a centralized system where all the agents in the environment learn the same policy and are effectively indistinguishable from each other. In this paper, we relax this assumption about indistinguishable agents and propose a new mean field system known as Decentralized Mean Field Games, where each agent can be quite different from others. All agents learn independent policies in a decentralized fashion, based on their local observations. We define a theoretical solution concept for this system and provide a fixed point guarantee for a Q-learning based algorithm in this system. A practical consequence of our approach is that we can address a `chicken-and-egg' problem in empirical mean field reinforcement learning algorithms. Further, we provide Q-learning and actor-critic algorithms that use the decentralized mean field learning approach and give stronger performances compared to common baselines in this area. In our setting, agents do not need to be clones of each other and learn in a fully decentralized fashion. Hence, for the first time, we show the application of mean field learning methods in fully competitive environments, large-scale continuous action space environments, and other environments with heterogeneous agents. Importantly, we also apply the mean field method in a ride-sharing problem using a real-world dataset. We propose a decentralized solution to this problem, which is more practical than existing centralized training methods.</div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: 11</span><br />
	<span class="Journal">Keywords: mean-field-theory; reinforcement-learning; game-theory; multi-agent-reinforcement-learning; multi-agent-systems; showcase; grant-form100a</span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2022-aaai-ganapathi%20subramanian-decentralized.pdf">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2022-aaai-ganapathi subramanian-decentralized.pdf</a></span><br />
</dd>
<dt class="Key" id="lee2021frontai">lee2021frontai</dt>
<dd class="Pub">
	<span class="Title">Investigation of Independent Reinforcement Learning Algorithms in Multi-Agent Environments</span><br />
	<span class="Author">Authors: K. M. Lee, S. Ganapathi Subramanian, and M. Crowley</span><br />
    <span class="Journal">Journal: Frontiers in Artificial Intelligence</span><br />
    <span class="Journal">Conference: </span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 27</span><br />
	(<span class="Date">Date: 2022</span>)<br />
    <div class="Abstract">Abstract: Independent reinforcement learning algorithms have no theoretical guarantees for finding the best policy in multi-agent settings. However, in practice, prior works have reported good performance with independent algorithms in some domains and bad performance in others. Moreover, a comprehensive study of the strengths and weaknesses of independent algorithms is lacking in the literature. In this paper, we carry out an empirical comparison of the performance of independent algorithms on seven PettingZoo environments that span the three main categories of multi-agent environments, i.e., cooperative, competitive, and mixed. For the cooperative setting, we show that independent algorithms can perform on par with multi-agent algorithms in fully-observable environments, while adding recurrence improves the learning of independent algorithms in partially-observable environments. In the competitive setting, independent algorithms can perform on par or better than multi-agent algorithms, even in more challenging environments. We also show that agents trained via independent algorithms learn to perform well individually, but fail to learn to cooperate with allies and compete with enemies in mixed environments.

</div><br />
    <div class="Abstract">Short Description: This paper was part of a project for undergraduate student Lee, who has worked with me as a URA multiple terms on RL algorithms and software development. The original idea was mine and flowed out of results needed for Sriram's PhD work. It is an empirical comparison of many single and multi-agent algorithms on a range of multi-agent planning domains. A short version was presented at a NeurIPS workshop \citeleezbzneuripsdeeprl.</div><br />
	<span class="Pages">Citations: 6</span><br />
	<span class="Journal">Keywords: multi-agent-reinforcement-learning, reinforcement-learning, empircal-study, machine-learning; forest-wildfire; ai-for-games; forest-management; grant-form100a</span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2022-frontai-lee-investigation.pdf">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2022-frontai-lee-investigation.pdf</a></span><br />
</dd>
<dt class="Key" id="lee2021neuripsdeeprl">lee2021neuripsdeeprl</dt>
<dd class="Pub">
	<span class="Title">Investigation of Independent Reinforcement Learning Algorithms in Multi-Agent Environments</span><br />
	<span class="Author">Authors: K. M. Lee, S. Ganapathi Subramanian, and M. Crowley</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: NeurIPS 2021 Deep Reinforcement Learning Workshop</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 15</span><br />
	(<span class="Date">Date: 2021</span>)<br />
    <div class="Abstract">Abstract: Independent reinforcement learning algorithms have no theoretical guarantees for finding the best policy in multi-agent settings. However, in practice, prior works have reported good performance with independent algorithms in some domains and bad performance in others. Moreover, a comprehensive study of the strengths and weaknesses of independent algorithms is lacking in the literature. In this paper, we carry out an empirical comparison of the performance of independent algorithms on four PettingZoo environments that span the three main categories of multi-agent environments, i.e., cooperative, competitive, and mixed. We show that in fully-observable environments, independent algorithms can perform on par with multi-agent algorithms in cooperative and competitive settings. For the mixed environments, we show that agents trained via independent algorithms learn to perform well individually, but fail to learn to cooperate with allies and compete with enemies. We also show that adding recurrence improves the learning of independent algorithms in cooperative partially observable environments.</div><br />
    <div class="Abstract">Short Description: This workshop paper and presented was part of a project for undergraduate student Lee, who has worked with me as a URA multiple terms on RL algorithms and software development. The original idea was mine and flowed out of results needed for Sriram's PhD work. It is an empirical comparison of many single and multi-agent algorithms on a range of multi-agent planning domains. Based on the longer work submitted to the Frontiers in AI journal \citeleezbzfrontmlai.</div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: multi-agent-reinforcement-learning, reinforcement-learning,empircal-study, machine-learning; showcase; forest-wildfire; forest-management; grant-form100a</span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2021-neuripsdee-lee-investigation.pdf">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2021-neuripsdee-lee-investigation.pdf</a></span><br />
</dd>
<dt class="Key" id="ganapathisubramanian2022jair">ganapathisubramanian2022jair</dt>
<dd class="Pub">
	<span class="Title">Multi-{A}gent {A}dvisor {Q}-{L}earning</span><br />
	<span class="Author">Authors: S. Ganapathi Subramanian, K. Larson, M. Taylor, and M. Crowley</span><br />
    <span class="Journal">Journal: Journal of Artificial Intelligence Research (JAIR)</span><br />
    <span class="Journal">Conference: </span><br />
	<span class="Volume">Volume: 74</span><br />
	<span class="Pages">Pages: 1-74</span><br />
	(<span class="Date">Date: 2022</span>)<br />
    <div class="Abstract">Abstract: In the last decade, there have been significant advances in multi-agent reinforcement learning (MARL) but there are still numerous challenges, such as high sample complexity and slow convergence to stable policies, that need to be overcome before wide-spread deployment is possible. However, many real-world environments already, in practice, deploy sub-optimal or heuristic approaches for generating policies. An interesting question that arises is how to best use such approaches as advisors to help improve reinforcement learning in multi-agent domains. In this paper, we provide a principled framework for incorporating action recommendations from online sub-optimal advisors in multi-agent settings. We describe the problem of ADvising Multiple Intelligent Reinforcement Agents (ADMIRAL) in nonrestrictive general-sum stochastic game environments and present two novel Q-learning based algorithms: ADMIRAL - Decision Making (ADMIRAL-DM) and ADMIRAL - Advisor Evaluation (ADMIRAL-AE), which allow us to improve learning by appropriately incorporating advice from an advisor (ADMIRAL-DM), and evaluate the effectiveness of an advisor (ADMIRAL-AE). We analyze the algorithms theoretically and provide fixed point guarantees regarding their learning in general-sum stochastic games. Furthermore, extensive experi- ments illustrate that these algorithms: can be used in a variety of environments, have performances that compare favourably to other related baselines, can scale to large state-action spaces, and are robust to poor advice from advisors.</div><br />
    <div class="Abstract">Short Description: This paper is core work towards by PhD student Ganapathi Subramanian's PhD thesis on connecting RL with Game Theory for multiple agents. It is a theoretical paper and the writing and theory were a full collaboration between myself and the student, collorating on a joint document and working through proofs in detail. His co-supervisor, Prof. Larson, also provided significant input to some theoretical aspects and writing.</div><br />
	<span class="Pages">Citations: 11</span><br />
	<span class="Journal">Keywords: showcase, reinforcement-learning, multi-agent-systems, deep-learning; forest-wildfire; forest-management; game-playing; game-theory; grant-form100a</span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2022-jair-ganapathi%20subramanian-multi-agent.pdf">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2022-jair-ganapathi subramanian-multi-agent.pdf</a></span><br />
</dd>
<dt class="Key" id="ghojoghthesis2021">ghojoghthesis2021</dt>
<dd class="Pub">
	<span class="Title">Data Reduction Algorithms in Machine Learning and Data Science</span><br />
	<span class="Author">Authors: B. Ghojogh</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: </span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: </span><br />
	(<span class="Date">Date: 2021</span>)<br />
    <div class="Abstract">Abstract: Raw data are usually required to be pre-processed for better representation or discrimination of classes. This pre-processing can be done by data reduction, i.e., either reduction in dimensionality or numerosity (cardinality). Dimensionality reduction can be used for feature extraction or data visualization. Numerosity reduction is useful for ranking data points or finding the most and least important data points. This thesis proposes several algorithms for data reduction, known as dimensionality and numerosity reduction, in machine learning and data science. Dimensionality reduction tackles feature extraction and feature selection methods while numerosity reduction includes prototype selection and prototype generation approaches. This thesis focuses on feature extraction and prototype selection for data reduction. Dimensionality reduction methods can be divided into three categories, i.e., spectral, probabilistic, and neural network-based methods.</div><br />
    <div class="Abstract">Short Description: The PhD thesis of UWECEML student Benyamini Ghojogh.</div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: machine-learning, manifold-learning, dimensionality-reduction, thesis; grant-form100a</span><br />
	<span class="File"><a href=""></a></span><br />
</dd>
<dt class="Key" id="ghojogh2021softimp">ghojogh2021softimp</dt>
<dd class="Pub">
	<span class="Title">Generative locally linear embedding: A module for manifold unfolding and visualization</span><br />
	<span class="Author">Authors: B. Ghojogh, A. Ghodsi, F. Karray, and M. Crowley</span><br />
    <span class="Journal">Journal: Software Impacts</span><br />
    <span class="Journal">Conference: </span><br />
	<span class="Volume">Volume: 9</span><br />
	<span class="Pages">Pages: 3</span><br />
	(<span class="Date">Date: 2021</span>)<br />
    <div class="Abstract">Abstract: Data often have nonlinear patterns in machine learning. One can unfold the nonlinear manifold of a dataset for low-dimensional visualization and feature extraction. Locally Linear Embedding (LLE) is a nonlinear spectral method for dimensionality reduction and manifold unfolding. It embeds data using the same linear reconstruction weights as in the input space. In this paper, we propose an open source module which not only implements LLE, but also includes implementations of two generative LLE algorithms whose linear reconstruction phases are stochastic. Using this module, one can generate as many manifold unfoldings as desired for data visualization or feature extraction.</div><br />
    <div class="Abstract">Short Description: This is an new form of publication called an ``Original Software Publication'', in it we describe the software libraries and usage of the described algorithms, which are available as a preprint paper and will be submitted to a conference venue soon.</div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: software-development; manifold-learning; visualization; interpretability; representation-learning; tools; software; grant-form100a</span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2021-softimp-ghojogh-generative.pdf">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2021-softimp-ghojogh-generative.pdf</a></span><br />
</dd>
<dt class="Key" id="poorheravi2021cvis">poorheravi2021cvis</dt>
<dd class="Pub">
	<span class="Title">Acceleration of Large Margin Metric Learning for Nearest Neighbor Classification Using Triplet Mining and Stratified Sampling</span><br />
	<span class="Author">Authors: P. Poorheravi, B. Ghojogh, V. Gaudet, F. Karray, and M. Crowley</span><br />
    <span class="Journal">Journal: Journal of Computational Vision and Imaging Systems</span><br />
    <span class="Journal">Conference: </span><br />
	<span class="Volume">Volume: 6</span><br />
	<span class="Pages">Pages: 5</span><br />
	(<span class="Date">Date: 2021</span>)<br />
    <div class="Abstract">Abstract: Metric learning is a technique in manifold learning to find a projection subspace for increasing and decreasing the inter- and intra-class variances, respectively. Some metric learning methods are based on triplet learning with anchor-positive-negative triplets. Large margin metric learning for nearest neighbor classification is one of the fundamental methods to do this. Recently, Siamese networks have been introduced with the triplet loss. Many triplet mining methods have been developed for Siamese nets; however, these techniques have not been applied on the triplets of large margin metric learning. In this work, inspired by the mining methods for Siamese nets, we propose several triplet mining techniques for large margin metric learning. Moreover, a hierarchical approach is proposed, for acceleration and scalability of optimization, where triplets are selected by stratified sampling in hierarchical hyper-spheres. We analyze the proposed methods on three publicly available datasets.</div><br />
    <div class="Abstract">Short Description: This paper was a collaboration initiated by the student authors on a novel requirement for sampling to deal with unbalanced data using a stratefied approach. I worked with the students to clarify their problem focus and explanations in the paper in order to make it clearer and reproducable by other researchers.</div><br />
	<span class="Pages">Citations: 5</span><br />
	<span class="Journal">Keywords: manifold-learning, metric-learning, triplet-mining, siamese-networks, computer-vision, showcase; grant-form100a</span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2021-cvis-poorheravi-acceleration1.pdf">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2021-cvis-poorheravi-acceleration1.pdf</a></span><br />
	<span class="URL"><a href="https://openjournals.uwaterloo.ca/index.php/vsl/article/view/3534">https://openjournals.uwaterloo.ca/index.php/vsl/article/view/3534</a></span><br />
	<span class="URL"><a href="https://doi.org/10.15353/jcvis.v6i1.3534">https://doi.org/10.15353/jcvis.v6i1.3534</a></span><br />
</dd>
<dt class="Key" id="akgun2021hri">akgun2021hri</dt>
<dd class="Pub">
	<span class="Title">Integrating Affective Expressions into the Search and Rescue Context in order to Improve Non-Verbal Human-Robot Interaction</span><br />
	<span class="Author">Authors: S. A. Akgun, M. Ghafurian, M. Crowley, and K. Dautenhahn</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: Workshop on Exploring Applications for Autonomous Non-Verbal Human-Robot Interactions ({HRI})</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: </span><br />
	(<span class="Date">Date: 2021</span>)<br />
    <div class="Abstract">Abstract: Unexplained or ambiguous behaviours of rescue robots can lead to inefficient collaborations between humans and robots in robot-assisted search and rescue (SAR) teams. To date, rescue robots do not have the ability to interact with humans on a social level, which is believed to be an important ability that can improve the quality of interactions. In this project, we propose to bring affective robot expressions into search and rescue context to grant rescue robots with social capabilities. Affective expressions can be used as an additional complementary modality to convey information from rescue robots to field workers. We believe that supporting non-verbal communication in SAR teams with affective expressions will introduce a natural way to notify field workers about the rescue field and increase their situational awareness, as well as the effectiveness of interacting with the rescue robots. Additionally, affective search and rescue robots might be beneficial to keep victims calm until medical teams arrive and prevent/reduce shock.</div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: human-robot-interaction, affective-robot-communication, emotion-modeling, search-and-rescue; year-in-review-2021; empircal-study; grant-form100a</span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2021-hri-akgun-integrating.pdf">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2021-hri-akgun-integrating.pdf</a></span><br />
	<span class="URL"><a href="https://sites.google.com/view/non-verbal-hri-2021/home">https://sites.google.com/view/non-verbal-hri-2021/home</a></span><br />
</dd>
<dt class="Key" id="crowley2020coviddata">crowley2020coviddata</dt>
<dd class="Pub">
	<span class="Title">Prediction and Causality: How Can Machine Learning be Used for COVID-19?</span><br />
	<span class="Author">Authors: M. Crowley</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: "What Needs to be done in order to Curb the Spread of Covid-19: Exposure Notification, Legal Considerations, and Statistical Modeling", a Conference on Data and Privacy during a Global Pandemic</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 6</span><br />
	(<span class="Date">Date: 2021</span>)<br />
    <div class="Abstract">Abstract: </div><br />
    <div class="Abstract">Short Description: This paper is an expanded version of the talk I gave for the invited talk I gave for this conference, hosted virutally at the University of Waterloo in December 2020.</div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: causality, reinforcement-learning, machine-learning, graphical-models, covid-19, epidemiology, health, year-in-review-2021, infectious-disease; probabilistic-graphical-models</span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2021-coviddata-crowley-prediction.pdf">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2021-coviddata-crowley-prediction.pdf</a></span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2021-coviddata-crowley-prediction1.pdf">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2021-coviddata-crowley-prediction1.pdf</a></span><br />
	<span class="URL"><a href="https://uwaterloo.ca/master-of-public-service/events/data-and-privacy-during-global-pandemic-conference">https://uwaterloo.ca/master-of-public-service/events/data-and-privacy-during-global-pandemic-conference</a></span><br />
</dd>
<dt class="Key" id="allada2021embc">allada2021embc</dt>
<dd class="Pub">
	<span class="Title">Analysis of Language Embeddings for Classification of Unstructured Pathology Reports</span><br />
	<span class="Author">Authors: A. K. Allada, Y. Wang, V. Jindal, M. Babaie, H. R. Tizhoosh, and M. Crowley</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: International Conference of the IEEE Engineering in Medicine and Biology Society {(EMBC)}</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 2378-2381</span><br />
	(<span class="Date">Date: 2021</span>)<br />
    <div class="Abstract">Abstract: A pathology report is one of the most significant medical documents providing interpretive insights into the visual appearance of the patient's biopsy sample. In digital pathology, high-resolution images of tissue samples are stored along with pathology reports. Despite the valuable information that pathology reports hold, they are not used in any systematic manner to promote computational pathology. In this work, we focus on analyzing the reports, which are generally unstructured documents written in English with sophisticated and highly specialized medical terminology. We provide a comparative analysis of various embedding models like BioBERT, Clinical BioBERT, BioMed-RoBERTa and Term Frequency-Inverse Document Frequency (TF-IDF), a traditional NLP technique, as well as the combination of embeddings from pre-trained models with TF-IDF. Our results demonstrate the effectiveness of various word embedding techniques for pathology reports.</div><br />
    <div class="Abstract">Short Description: This work was carried out by a series of single-term undergraduate and graduate students as term projects under my direction tying the work together. Finally then Allada switched to a thesis based MASc degree to work full time on the work. She will defend her thesis before the end of Fall 2021.</div><br />
	<span class="Pages">Citations: 7</span><br />
	<span class="Journal">Keywords: proj-digipath, natural-language-processing, digital-pathology; year-in-review-2021; medical-imaging; deep-learning; showcase; image-processing; grant-form100a</span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2021-embc-allada-analysis1.pdf">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2021-embc-allada-analysis1.pdf</a></span><br />
</dd>
<dt class="Key" id="godaz2021acml">godaz2021acml</dt>
<dd class="Pub">
	<span class="Title">Vector Transport Free Riemannian {LBFGS} for Optimization on Symmetric Positive Definite Matrix Manifolds</span><br />
	<span class="Author">Authors: R. Godaz, B. Ghojogh, R. Hosseini, R. Monsefi, F. Karray, and M. Crowley</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: Asian Conference on Machine Learning {(ACML)}</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 8</span><br />
	(<span class="Date">Date: 2021</span>)<br />
    <div class="Abstract">Abstract: This work concentrates on optimization on Riemannian manifolds. The Limited-memory Broyden--Fletcher--Goldfarb--Shanno (LBFGS) algorithm is a commonly used quasi-Newton method for numerical optimization in Euclidean spaces. Riemannian LBFGS (RLBFGS) is an extension of this method to Riemannian manifolds. RLBFGS involves computationally expensive vector transports as well as unfolding recursions using adjoint vector transports. In this article, we propose two mappings in the tangent space using the inverse second root and Cholesky decomposition. These mappings make both vector transport and adjoint vector transport identity and therefore isometric. Identity vector transport makes RLBFGS less computationally expensive and its isometry is also very useful in convergence analysis of RLBFGS. Moreover, under the proposed mappings, the Riemannian metric reduces to Euclidean inner product, which is much less computationally expensive. We focus on the Symmetric Positive Definite (SPD) manifolds which are beneficial in various fields such as data science and statistics. This work opens a research opportunity for extension of the proposed mappings to other well-known manifolds.</div><br />
    <div class="Abstract">Short Description: This is a new collaboration between by postdoc Ghojogh, myself and the other authors. The idea arose from those other author's discussions on how to make the gneeral LBFGS methods more efficient computationally and compact theoretically. I was deeply involved in revision and writing of the final paper.</div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: year-in-review-2021, machine-learning, optimization; grant-form100a</span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2021-acml-godaz-vector1.pdf">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2021-acml-godaz-vector1.pdf</a></span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2021-acml-godaz-vector2.pdf">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2021-acml-godaz-vector2.pdf</a></span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2021-acml-godaz-vector3.pdf">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2021-acml-godaz-vector3.pdf</a></span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2021-acml-godaz-vector.png">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2021-acml-godaz-vector.png</a></span><br />
</dd>
<dt class="Key" id="sikaroudi2021isbi">sikaroudi2021isbi</dt>
<dd class="Pub">
	<span class="Title">Magnification Generalization for Histopathology Image Embedding</span><br />
	<span class="Author">Authors: M. Sikaroudi, B. Ghojogh, F. Karray, M. Crowley, and H. R. Tizhoosh</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: IEEE International Symposium on Biomedical Imaging (ISBI)</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 5</span><br />
	(<span class="Date">Date: 2021</span>)<br />
    <div class="Abstract">Abstract: Histopathology image embedding is an active research area in computer vision. Most of the embedding models exclusively concentrate on a specific magnification level. However, a useful task in histopathology embedding is to train an embedding space regardless of the magnification level. Two main approaches for tackling this goal are domain adaptation and domain generalization, where the target magnification levels may or may not be introduced to the model in training, respectively. Although magnification adaptation is a well-studied topic in the literature, this paper, to the best of our knowledge, is the first work on magnification generalization for histopathology image embedding. We use an episodic trainable domain generalization technique for magnification generalization, namely Model Agnostic Learning of Semantic Features (MASF), which works based on the Model Agnostic Meta-Learning (MAML) concept. Our experimental results on a breast cancer histopathology dataset with four different magnification levels show the proposed method's effectiveness for magnification generalization.</div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: 9</span><br />
	<span class="Journal">Keywords: year-in-review-2021; proj-digipath; medical-imaging; grant-form100a; digital-pathology</span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2021-isbi-sikaroudi-magnification.pdf">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2021-isbi-sikaroudi-magnification.pdf</a></span><br />
</dd>
<dt class="Key" id="akgun2020icmi">akgun2020icmi</dt>
<dd class="Pub">
	<span class="Title">Using Emotions to Complement Multi-Modal Human-Robot Interaction in Urban Search and Rescue Scenarios</span><br />
	<span class="Author">Authors: S. A. Akgun, M. Ghafurian, M. Crowley, and K. Dautenhahn</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: Proceedings of the 2020 International Conference on Multimodal Interaction (ICMI)</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 575--584</span><br />
	(<span class="Date">Date: 2020</span>)<br />
    <div class="Abstract">Abstract: An experiment is presented to investigate whether there is consensus in mapping emotions to messages/situations in urban search and rescue scenarios, where efficiency and effectiveness of interactions are key to success. We studied mappings between 10 specific messages, presented in two different communication styles, reflecting common situations that might happen during search and rescue missions, and the emotions exhibited by robots in those situations. The data was obtained through a Mechanical Turk study with 78 participants. Our findings support the feasibility of using emotions as an additional communication channel to improve multi-modal human-robot interaction for urban search and rescue robots, and suggests that these mappings are robust, i.e. are not affected by the robot's communication style.</div><br />
    <div class="Abstract">Short Description: This is a highly competitive conference in the field of complex, multi-model robotic systems and human interaction. Our paper is a study of human interpretation of robot actions intended to mimic emotions and how they can be used to increase human understanding of robot responses in the presence of visual distractions as would occur during disaster recovery operations. I consulted heavily on the analysis approaches being used and connections to future RL use cases.</div><br />
	<span class="Pages">Citations: 3</span><br />
	<span class="Journal">Keywords: search-and-rescue, search-and-rescue, multi-modal-communication, affective-robot-communication, emotion-modeling, human-robot-interaction; year-in-review-2021; empircal-study; grant-form100a</span><br />
	<span class="URL"><a href="https://doi.org/10.1145/3382507.3418871">https://doi.org/10.1145/3382507.3418871</a></span><br />
</dd>
<dt class="Key" id="subramanian2018neurips-ai4sg">subramanian2018neurips-ai4sg</dt>
<dd class="Pub">
	<span class="Title">A Complementary Approach to Improve WildFire Prediction Systems.</span><br />
	<span class="Author">Authors: S. G. Subramanian and M. Crowley</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: Neural Information Processing Systems (AI for social good workshop)</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: </span><br />
	(<span class="Date">Date: 2018</span>)<br />
    <div class="Abstract">Abstract: </div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: reinforcement-learning; machine-learning; mcts; forest-wildfire; forest-management; computational-sustainability; grant-form100a</span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2018-neurips-ai-subramanian-a%20complementary.pdf">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2018-neurips-ai-subramanian-a complementary.pdf</a></span><br />
	<span class="URL"><a href="https://aiforsocialgood.github.io/2018/acceptedpapers.htm">https://aiforsocialgood.github.io/2018/acceptedpapers.htm</a></span><br />
</dd>
<dt class="Key" id="ganapathisubramanian2021aamas">ganapathisubramanian2021aamas</dt>
<dd class="Pub">
	<span class="Title">Partially Observable Mean Field Reinforcement Learning</span><br />
	<span class="Author">Authors: S. Ganapathi Subramanian, M. Taylor, M. Crowley, and P. Poupart</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: Proceedings of the 20th International Conference on Autonomous Agents and MultiAgent Systems (AAMAS)</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 537-545</span><br />
	(<span class="Date">Date: 2021</span>)<br />
    <div class="Abstract">Abstract: Traditional multi-agent reinforcement learning algorithms are not scalable to environments with more than a few agents, since these algorithms are exponential in the number of agents. Recent research has introduced successful methods to scale multi-agent reinforcement learning algorithms to many agent scenarios using mean field theory. Previous work in this field assumes that an agent has access to exact cumulative metrics regarding the mean field behaviour of the system, which it can then use to take its actions. In this paper, we relax this assumption and maintain a distribution to model the uncertainty regarding the mean field of the system. We consider two different settings for this problem. In the first setting, only agents in a fixed neighbourhood are visible, while in the second setting, the visibility of agents is determined at random based on distances. For each of these settings, we introduce a Q-learning based algorithm that can learn effectively. We prove that this Q-learning estimate stays very close to the Nash Q-value (under a common set of assumptions) for the first setting. We also empirically show our algorithms outperform multiple baselines in three different games in the MAgents framework, which supports large environments with many agents learning simultaneously to achieve possibly distinct goals.</div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: 23</span><br />
	<span class="Journal">Keywords: game-theory, multi-agent-reinforcement-learning, reinforcement-learning, mean-field-theory, incomplete-information, partially-observable-problems, showcase; year-in-review-2021; forest-wildfire; forest-management; grant-form100a</span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2021-aamas-ganapathi%20subramanian-partially.pdf">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2021-aamas-ganapathi subramanian-partially.pdf</a></span><br />
</dd>
<dt class="Key" id="akgun2021ieeetoac">akgun2021ieeetoac</dt>
<dd class="Pub">
	<span class="Title">Emotion Modelling for Robot to Human Communication in Search and Rescue Contexts</span><br />
	<span class="Author">Authors: M. Crowley and K. Dautenhahn</span><br />
    <span class="Journal">Journal: IEEE Transactions on Affective Computing (IEEE TAC)</span><br />
    <span class="Journal">Conference: </span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: </span><br />
	(<span class="Date">Date: 2021</span>)<br />
    <div class="Abstract">Abstract: </div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: human-robot-interaction, affective-robot-communication, emotion-modeling, search-and-rescue; year-in-review-2021; empircal-study; grant-form100a</span><br />
</dd>
<dt class="Key" id="sikaroudi2021icpr">sikaroudi2021icpr</dt>
<dd class="Pub">
	<span class="Title">Batch-Incremental Triplet Sampling for Training Triplet Networks Using Bayesian Updating Theorem</span><br />
	<span class="Author">Authors: M. Sikaroudi, B. Ghojogh, F. Karray, M. Crowley, and H. R. Tizhoosh</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: 25th International Conference on Pattern Recognition (ICPR)</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 7</span><br />
	(<span class="Date">Date: 2021</span>)<br />
    <div class="Abstract">Abstract: Variants of Triplet networks are robust entities for learning a discriminative embedding subspace. There exist different triplet mining approaches for selecting the most suitable training triplets. Some of these mining methods rely on the extreme distances between instances, and some others make use of sampling. However, sampling from stochastic distributions of data rather than sampling merely from the existing embedding instances can provide more discriminative information. In this work, we sample triplets from distributions of data rather than from existing instances. We consider a multivariate normal distribution for the embedding of each class. Using Bayesian updating and conjugate priors, we update the distributions of classes dynamically by receiving the new mini-batches of training data. The proposed triplet mining with Bayesian updating can be used with any triplet-based loss function, e.g., triplet-loss or Neighborhood Component Analysis (NCA) loss. Accordingly, Our triplet mining approaches are called Bayesian Updating Triplet (BUT) and Bayesian Updating NCA (BUNCA), depending on which loss function is being used. Experimental results on two public datasets, namely MNIST and histopathology colorectal cancer (CRC), substantiate the effectiveness of the proposed triplet mining method.</div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: 7</span><br />
	<span class="Journal">Keywords: year-in-review-2021; digital-pathology, triplet-mining, manifold-learning; proj-digipath; medical-imaging; image-processing; grant-form100a</span><br />
	<span class="File"><a href=""></a></span><br />
</dd>
<dt class="Key" id="bellinger2021canai">bellinger2021canai</dt>
<dd class="Pub">
	<span class="Title">Active Measure Reinforcement Learning for Observation Cost Minimization: A framework for minimizing measurement costs in reinforcement learning</span><br />
	<span class="Author">Authors: C. Bellinger, R. Coles, M. Crowley, and I. Tamblyn</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: Canadian Conference on Artificial Intelligence</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 12</span><br />
	(<span class="Date">Date: 2021</span>)<br />
    <div class="Abstract">Abstract: Markov Decision Processes (MDP) with explicit measurement cost are a class of en- vironments in which the agent learns to maximize the costed return. Here, we define the costed return as the discounted sum of rewards minus the sum of the explicit cost of measuring the next state. The RL agent can freely explore the relationship between actions and rewards but is charged each time it measures the next state. Thus, an op- timal agent must learn a policy without making a large number of measurements. We propose the active measure RL framework (Amrl) as a solution to this novel class of problem, and contrast it with standard reinforcement learning under full observability and planning under partially observability. We demonstrate that Amrl-Q agents learn to shift from a reliance on costly measurements to exploiting a learned transition model in order to reduce the number of real-world measurements and achieve a higher costed return. Our results demonstrate the superiority of Amrl-Q over standard RL methods, Q-learning and Dyna-Q, and POMCP for planning under a POMDP in environments with explicit measurement costs.</div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: 20</span><br />
	<span class="Journal">Keywords: reinforcement-learning, machine-learning, digital-chemistry, proj-chemgymrl, showcase, year-in-review-2021; deep-learning; ai-for-material-design; ai-for-science; ai-for-physics; ai-for-chemistry; grant-form100a</span><br />
	<span class="File"><a href=""></a></span><br />
</dd>
<dt class="Key" id="ghafurian2020interact">ghafurian2020interact</dt>
<dd class="Pub">
	<span class="Title">Recognition of a Robot's Affective Expressions under Conditions with Limited Visibility</span><br />
	<span class="Author">Authors: M. Ghafurian, S. A. Akgun, M. Crowley, and K. Dautenhahn</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: 18th International Conference promoted by the IFIP Technical Committee 13 on Human--Computer Interaction ({INTERACT} 2021)</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 22</span><br />
	(<span class="Date">Date: 2021</span>)<br />
    <div class="Abstract">Abstract: The capability of showing affective expressions is important for the design of social robots in many contexts, especially where the robot is designed to communicate with humans. It is reasonable to expect that, similar to all other interaction modalities, communicating with affective expressions is not without limitations. In this paper, we present two online video studies (N=72 and N=50) and investigate if/how much the recognition of affective displays of a zoomorphic robot is affected under situations with different levels of visibility. Five affective expressions combined with five visibility effects were studied. The intensity of the effects was more pronounced in the second experiment. While visual constraints affected recognition of expressions, our results showed that affective displays of the robot conveyed through its head and body gestures can be robust and recognition rates can still be high even under severe constraints. This study supported the effectiveness of using affective displays as a complementary communication modality in human-robot interaction in situations with low visibility.</div><br />
    <div class="Abstract">Short Description: This paper was primarily led by Ghafurian, a postdoc in Prof. Dautenhahn's lab. I provided supportive ideas about modelling and prediction methods as well as feedback on the paper writing.</div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: human-robot-interaction; year-in-review-2021; empircal-study; grant-form100a</span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2021-interact-ghafurian-recognition.pdf">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2021-interact-ghafurian-recognition.pdf</a></span><br />
</dd>
<dt class="Key" id="sikaroudi2020iscv">sikaroudi2020iscv</dt>
<dd class="Pub">
	<span class="Title">Offline versus Online Triplet Mining based on Extreme Distances of Histopathology Patches</span><br />
	<span class="Author">Authors: M. Sikaroudi, B. Ghojogh, A. Safarpoor, F. Karray, M. Crowley, and H. R. Tizhoosh</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: 15th International Symposium on Visual Computing (ISCV 2020)</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 333--345</span><br />
	(<span class="Date">Date: 2020</span>)<br />
    <div class="Abstract">Abstract: We analyze the effect of offline and online triplet mining for colorectal cancer (CRC) histopathology dataset containing 100,000 patches. We consider the extreme, i.e., farthest and nearest patches with respect to a given anchor, both in online and offline mining. While many works focus solely on how to select the triplets online (batch-wise), we also study the effect of extreme distances and neighbor patches before training in an offline fashion. We analyze the impacts of extreme cases for offline versus online mining, including easy positive, batch semi-hard, and batch hard triplet mining as well as the neighborhood component analysis loss, its proxy version, and distance weighted sampling. We also investigate online approaches based on extreme distance and comprehensively compare the performance of offline and online mining based on the data patterns and explain offline mining as a tractable generalization of the online mining with large mini-batch size. As well, we discuss the relations of different colorectal tissue types in terms of extreme distances. We found that offline mining can generate a better statistical representation of the population by working on the whole dataset.</div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: 25</span><br />
	<span class="Journal">Keywords: proj-digipath, triplet-mining, machine-learning, proj-digipath; year-in-review-2021; medical-imaging; digital-pathology; grant-form100a</span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2020-iscv-sikaroudi-offline.pdf">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2020-iscv-sikaroudi-offline.pdf</a></span><br />
</dd>
<dt class="Key" id="ma2020smc">ma2020smc</dt>
<dd class="Pub">
	<span class="Title">Isolation Mondrian Forest for Batch and Online Anomaly Detection</span><br />
	<span class="Author">Authors: H. Ma, B. Ghojogh, M. N. Samad, D. Zheng, and M. Crowley</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: IEEE International Conference on Systems, Man, and Cybernetics (IEEE-SMC-2020)</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 7</span><br />
	(<span class="Date">Date: 2020</span>)<br />
    <div class="Abstract">Abstract: We propose a new method, named isolation Mon- drian forest (iMondrian forest), for batch and online anomaly detection. The proposed method is a novel hybrid of isolation forest and Mondrian forest which are existing methods for batch anomaly detection and online random forest, respectively. iMondrian forest takes the idea of isolation, using the depth of a node in a tree, and implements it in the Mondrian forest structure. The result is a new data structure which can accept streaming data in an online manner while being used for anomaly detection. Our experiments show that iMondrian forest mostly performs better than isolation forest in batch settings and has better or comparable performance against other batch and online anomaly detection methods.</div><br />
    <div class="Abstract">Short Description: The algorithm fuses two ideas, "isolation" from ensemble trees methods for anomaly detection and "Mondrian forests" which can learn flexible regression models from streaming data.</div><br />
	<span class="Pages">Citations: 31</span><br />
	<span class="Journal">Keywords: showcase; year-in-review-2021; anomaly-detection; machine-learning; decision-trees; random-forests; mondrian-forests; isolation-forests; tree-based-ensembles; grant-form100a</span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2020-smc-ma-isolation.pdf">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2020-smc-ma-isolation.pdf</a></span><br />
</dd>
<dt class="Key" id="densopatent">densopatent</dt>
<dd class="Pub">
	<span class="Title">Multi-Level Collaborative Control System With Dual Neural Network Planning For Autonomous Vehicle Control In A Noisy Environment</span><br />
	<span class="Author">Authors: Z. Du, J. Lull, R. Malhan, S. Ganapathi Subramanian, S. Bhalla, J. Sambee, M. Crowley, S. Fischmeister, D. Shin, W. Melek, B. Fidan, A. Woo, and B. Sahoo</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: </span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: </span><br />
	(<span class="Date">Date: 2021</span>)<br />
    <div class="Abstract">Abstract: A RLP system for a host vehicle includes a memory and levels. The memory stores a RLP algorithm, which is a multi-agent collaborative DQN with PER algorithm. A first level includes a data processing module that provides sensor data, object location data, and state information of the host vehicle and other vehicles. A second level includes a coordinate location module that, based on the sensor data, the object location data, the state information, and a refined policy provided by the third level, generates an updated policy and a set of future coordinate locations implemented via the first level. A third level includes evaluation and target neural networks and a processor that executes instructions of the RLP algorithm for collaborative action planning between the host and other vehicles based on outputs of the evaluation and target networks and to generate the refined policy based on reward values associated with events.</div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: 1</span><br />
	<span class="Journal">Keywords: patentpending, patentawarded, DENSO, autonomous-driving; year-in-review-2021; grant-form100a</span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2020-patent-du-multi-level.pdf">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2020-patent-du-multi-level.pdf</a></span><br />
	<span class="URL"><a href="https://patents.google.com/patent/US11131992B2/en">https://patents.google.com/patent/US11131992B2/en</a></span><br />
</dd>
<dt class="Key" id="jain2020review">jain2020review</dt>
<dd class="Pub">
	<span class="Title">A review of machine learning applications in wildfire science and management</span><br />
	<span class="Author">Authors: P. Jain, S. C. Coogan, S. Ganapathi Subramanian, M. Crowley, S. Taylor, and M. D. Flannigan</span><br />
    <span class="Journal">Journal: Environmental Reviews</span><br />
    <span class="Journal">Conference: </span><br />
	<span class="Volume">Volume: 28</span><br />
	<span class="Pages">Pages: </span><br />
	(<span class="Date">Date: 2020</span>)<br />
    <div class="Abstract">Abstract: 
Artificial intelligence has been applied in wildfire science and management since the 1990s, with early applications including neural networks and expert systems. Since then the field has rapidly progressed congruently with the wide adoption of machine learning (ML) methods in the environmental sciences. Here, we present a scoping review of ML applications in wildfire science and management. Our overall objective is to improve awareness of ML methods among wildfire researchers and managers, as well as illustrate the diverse and challenging range of problems in wildfire science available to ML data scientists. To that end, we first present an overview of popular ML approaches used in wildfire science to date, and then review the use of ML in wildfire science as broadly categorized into six problem domains, including: 1) fuels characterization, fire detection, and mapping; 2) fire weather and climate change; 3) fire occurrence, susceptibility, and risk; 4) fire behavior prediction; 5) fire effects; and 6) fire management. Furthermore, we discuss the advantages and limitations of various ML approaches relating to data size, computational requirements, generalizability, and interpretability, as well as identify opportunities for future advances in the science and management of wildfires within a data science context. In total, we identified 298 relevant publications, where the most frequently used ML methods across problem domains included random forests, MaxEnt, artificial neural networks, decision trees, support vector machines, and genetic algorithms. As such, there exists opportunities to apply more current ML methods --- including deep learning and agent based learning --- in the wildfire sciences, especially in instances involving very large multivariate datasets. We must recognize, however, that despite the ability of ML models to learn on their own, expertise in wildfire science is necessary to ensure realistic modelling of fire processes across multiple scales, while the complexity of some ML methods, such as deep learning, requires a dedicated and sophisticated knowledge of their application. Finally, we stress that the wildfire research and management communities play an active role in providing relevant, high quality, and freely available wildfire data for use by practitioners of ML methods.</div><br />
    <div class="Abstract">Short Description: This review paper arose from my visit to BC to speak on the use of AI for Forest Fire management and led to a collaboration amongst these senior researchers, myself and my PhD student Sriram. We collaborated on every part of the paper, I especially wrote the general AI/ML background and checked that each specific Forest Fire domain was connected correctly to the ML literature. It will serve as a much-needed resource for researches in my field as well as applied Forest Fire Management and Science fields. Note, that for the tutorials there is some self-citation included.</div><br />
	<span class="Pages">Citations: 485</span><br />
	<span class="Journal">Keywords: showcase; year-in-review-2021; forest-management; machine-learning; forest-wildfire; tree-based-ensembles; grant-form100a</span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2020-envrevjrnl-jain-review.pdf">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2020-envrevjrnl-jain-review.pdf</a></span><br />
	<span class="File"><a href=""></a></span><br />
</dd>
<dt class="Key" id="bhalla2020deep">bhalla2020deep</dt>
<dd class="Pub">
	<span class="Title">Deep Multi Agent Reinforcement Learning for Autonomous Driving</span><br />
	<span class="Author">Authors: S. Bhalla, S. Ganapathi Subramanian, and M. Crowley</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: Canadian Conference on Artificial Intelligence</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 67--78</span><br />
	(<span class="Date">Date: 2020</span>)<br />
    <div class="Abstract">Abstract: </div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: 60</span><br />
	<span class="Journal">Keywords: autonomous-driving,multi-agent-reinforcement-learning,Multi-Agent-Systems,reinforcement-learning; year-in-review-2021; vehicle-communication; grant-form100a</span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2020-canai-bhalla-deep.pdf">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2020-canai-bhalla-deep.pdf</a></span><br />
</dd>
<dt class="Key" id="sikaroudi2020embc">sikaroudi2020embc</dt>
<dd class="Pub">
	<span class="Title">Supervision and Source Domain Impact on Representation Learning: A Histopathology Case Study</span><br />
	<span class="Author">Authors: M. Sikaroudi, A. Safarpoor, B. Ghojogh, S. Shafiei, M. Crowley, and H. Tizhoosh</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC'20)</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 4</span><br />
	(<span class="Date">Date: 2020</span>)<br />
    <div class="Abstract">Abstract: As many algorithms depend on a suitable representation of data, learning
unique features is considered a crucial task. Although supervised techniques
using deep neural networks have boosted the performance of representation
learning, the need for a large set of labeled data limits the application of
such methods. As an example, high-quality delineations of regions of interest
in the field of pathology is a tedious and time-consuming task due to the large
image dimensions. In this work, we explored the performance of a deep neural
network and triplet loss in the area of representation learning. We
investigated the notion of similarity and dissimilarity in pathology
whole-slide images and compared different setups from unsupervised and
semi-supervised to supervised learning in our experiments. Additionally,
different approaches were tested, applying few-shot learning on two publicly
available pathology image datasets. We achieved high accuracy and
generalization when the learned representations were applied to two different
pathology datasets</div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: 15</span><br />
	<span class="Journal">Keywords: representation-learning, proj-digipath, medical-imaging, year-in-review-2021; digital-pathology; grant-form100a</span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2020-embc-sikaroudi-supervision.pdf">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2020-embc-sikaroudi-supervision.pdf</a></span><br />
</dd>
<dt class="Key" id="basiri2020cdc">basiri2020cdc</dt>
<dd class="Pub">
	<span class="Title">Distributed Nonlinear Model Predictive Control and Metric Learning for Heterogeneous Vehicle Platooning with Cut-in/Cut-out Maneuvers</span><br />
	<span class="Author">Authors: M. H. Basiri, B. Ghojogh, N. L. Azad, S. Fischmeister, F. Karray, and M. Crowley</span><br />
    <span class="Journal">Journal: arXiv preprint arXiv:2004.00417</span><br />
    <span class="Journal">Conference: Proceeding of the 59th IEEE Conference on Decision and Control (CDC-2020)</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 2849-2856</span><br />
	(<span class="Date">Date: 2020</span>)<br />
    <div class="Abstract">Abstract: </div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: 29</span><br />
	<span class="Journal">Keywords: showcase; year-in-review-2021; grant-form100a</span><br />
</dd>
<dt class="Key" id="ghojogh2020fisher">ghojogh2020fisher</dt>
<dd class="Pub">
	<span class="Title">Fisher Discriminant Triplet and Contrastive Losses for Training Siamese Networks</span><br />
	<span class="Author">Authors: B. Ghojogh, M. Sikaroudi, S. Shafiei, H. R. Tizhoosh, F. Karray, and M. Crowley</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: IEEE International Joint Conference on Neural Networks (IJCNN)</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: </span><br />
	(<span class="Date">Date: 2020</span>)<br />
    <div class="Abstract">Abstract: </div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: year-in-review-2021; proj-digipath; medical-imaging; grant-form100a; digital-pathology</span><br />
</dd>
<dt class="Key" id="ghojogh2020weighted">ghojogh2020weighted</dt>
<dd class="Pub">
	<span class="Title">Weighted Fisher Discriminant Analysis in the Input and Feature Spaces</span><br />
	<span class="Author">Authors: B. Ghojogh, M. Sikaroudi, H. R. Tizhoosh, F. Karray, and M. Crowley</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: International Conference on Image Analysis and Recognition (ICIAR-2020)</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 9</span><br />
	(<span class="Date">Date: 2020</span>)<br />
    <div class="Abstract">Abstract: </div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: manifold-learning, year-in-review-2021; proj-digipath; medical-imaging; grant-form100a; digital-pathology</span><br />
</dd>
<dt class="Key" id="ghojogh2020backprojection">ghojogh2020backprojection</dt>
<dd class="Pub">
	<span class="Title">Backprojection for Training Feedforward Neural Networks in the Input and Feature Spaces</span><br />
	<span class="Author">Authors: B. Ghojogh, F. Karray, and M. Crowley</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: International Conference on Image Analysis and Recognition (ICIAR-2020)</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 9</span><br />
	(<span class="Date">Date: 2020</span>)<br />
    <div class="Abstract">Abstract: </div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: year-in-review-2021; deep-learning; grant-form100a</span><br />
</dd>
<dt class="Key" id="ghojogh2020theoretical">ghojogh2020theoretical</dt>
<dd class="Pub">
	<span class="Title">Theoretical Insights into the Use of Structural Similarity Index In Generative Models and Inferential Autoencoders</span><br />
	<span class="Author">Authors: B. Ghojogh, F. Karray, and M. Crowley</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: International Conference on Image Analysis and Recognition (ICIAR-2020)</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 9</span><br />
	(<span class="Date">Date: 2020</span>)<br />
    <div class="Abstract">Abstract: </div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: image-understanding, manifold-learning, representation-learning; year-in-review-2021; grant-form100a</span><br />
</dd>
<dt class="Key" id="ghojogh2019rda">ghojogh2019rda</dt>
<dd class="Pub">
	<span class="Title">Generalized Subspace Learning by Roweis Discriminant Analysis</span><br />
	<span class="Author">Authors: B. Ghojogh, F. Karray, and M. Crowley</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: International Conference on Image Analysis and Recognition (ICIAR-2020)</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 9</span><br />
	(<span class="Date">Date: 2020</span>)<br />
    <div class="Abstract">Abstract: We present a new method which generalizes subspace learning based on eigenvalue and generalized eigenvalue problems. This method, Roweis Discriminant Analysis (RDA), is named after Sam Roweis to whom the field of subspace learning owes significantly. RDA is a family of infinite number of algorithms where Principal Component Analysis (PCA), Supervised PCA (SPCA), and Fisher Discriminant Analysis (FDA) are special cases. One of the extreme special cases, which we name Double Supervised Discriminant Analysis (DSDA), uses the labels twice, it is novel and has not appeared elsewhere. We propose a dual for RDA for some special cases. We also propose kernel RDA, generalizing kernel PCA, kernel SPCA, and kernel FDA, using both dual RDA and representation theory. Our theoretical analysis explains previously known facts such as why SPCA can use regression but FDA cannot, why PCA and SPCA have duals but FDA does not, why kernel PCA and kernel SPCA use kernel trick but kernel FDA does not, and why PCA is the best linear method for reconstruction. Roweisfaces and kernel Roweisfaces are also proposed generalizing eigenfaces, Fisherfaces, supervised eigenfaces, and their kernel variants. We also report experiments showing the effectiveness of RDA and kernel RDA on some benchmark datasets.</div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: manifold-learning, numerosity-reduction; year-in-review-2021; grant-form100a; dimensionality-reduction</span><br />
	<span class="URL"><a href="http://arxiv.org/abs/1910.05437">http://arxiv.org/abs/1910.05437</a></span><br />
</dd>
<dt class="Key" id="ghojogh2020anomaly">ghojogh2020anomaly</dt>
<dd class="Pub">
	<span class="Title">Anomaly Detection and Prototype Selection Using Polyhedron Curvature</span><br />
	<span class="Author">Authors: B. Ghojogh, F. Karray, and M. Crowley</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: Canadian Conference on Artificial Intelligence</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 10</span><br />
	(<span class="Date">Date: 2020</span>)<br />
    <div class="Abstract">Abstract: </div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: anomaly-detection, representation-learning; year-in-review-2021; grant-form100a</span><br />
</dd>
<dt class="Key" id="bellinger2020reinforcement">bellinger2020reinforcement</dt>
<dd class="Pub">
	<span class="Title">Reinforcement Learning in a Physics-Inspired Semi-Markov Environment</span><br />
	<span class="Author">Authors: C. Bellinger, R. Coles, M. Crowley, and I. Tamblyn</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: Canadian Conference on Artificial Intelligence</span><br />
	<span class="Volume">Volume: 12109</span><br />
	<span class="Pages">Pages: 55-66</span><br />
	(<span class="Date">Date: 2020</span>)<br />
    <div class="Abstract">Abstract: </div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: Reinforcement-Learning, proj-chemgymrl, deep-learning,year-in-review-2021; digital-chemistry; machine-learning; ai-for-material-design; ai-for-science; ai-for-physics; ai-for-chemistry; grant-form100a</span><br />
	<span class="File"><a href="file:///Users/mcrowley/Dropbox/website_assets/markcrowley-ca/pdfs/2020-canai-bellinger-reinforcement.pdf">/Users/mcrowley/Dropbox/website_assets/markcrowley-ca/pdfs/2020-canai-bellinger-reinforcement.pdf</a></span><br />
</dd>
<dt class="Key" id="garijo2019sciknow">garijo2019sciknow</dt>
<dd class="Pub">
	<span class="Title">{Semantic Workflows and Machine Learning for the Assessment of Carbon Storage by Urban Trees}</span><br />
	<span class="Author">Authors: J. Carrillo, D. Garijo, M. Crowley, Y. Gil, and K. Borda</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: Third International Workshop on Capturing Scientific Knowledge (Sciknow 2019), Collocated with the tenth International Conference on Knowledge Capture (K-CAP)</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 6</span><br />
	(<span class="Date">Date: 2019</span>)<br />
    <div class="Abstract">Abstract: </div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: machine-learning, computational-sustainability, semantics, year-in-review-2021; grant-form100a</span><br />
</dd>
<dt class="Key" id="Sciknow19">Sciknow19</dt>
<dd class="Pub">
	<span class="Title">Proceedings of the Third International Workshop on Capturing Scientific Knowledge (SciKnow19)</span><br />
	<span class="Author">Authors: </span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: Third International Workshop on Capturing Scientific Knowledge (SciKnow19)</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: </span><br />
	(<span class="Date">Date: 2019</span>)<br />
    <div class="Abstract">Abstract: </div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: </span><br />
</dd>
<dt class="Key" id="carrillo2019tac">carrillo2019tac</dt>
<dd class="Pub">
	<span class="Title">{Comparison of Deep Learning models for Determining Road Surface Condition from Roadside Camera Images and Weather Data}</span><br />
	<span class="Author">Authors: J. Carrillo, M. Crowley, G. Pan, and L. Fu</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: TAC-ITS Canada Joint Conference</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 17</span><br />
	(<span class="Date">Date: 2019</span>)<br />
    <div class="Abstract">Abstract: Road maintenance during the Winter season is a safety critical and resource demanding operation. One of its key activities is determining road surface condition (RSC) in order to prioritize roads and allocate cleaning efforts such as plowing or salting. Two conventional approaches for determining RSC are: visual examination of roadside camera images by trained personnel and patrolling the roads to perform on-site inspections. However, with more than 500 cameras collecting images across Ontario, visual examination becomes a resource-intensive activity, difficult to scale especially during periods of snow storms. This paper presents the preliminary results of an ongoing study focused on improving the efficiency of road maintenance operations. We use multiple Deep Learning models to automatically determine RSC from roadside camera images and weather variables, extending previous research where similar methods have been used to deal with the problem. The dataset we use was collected during the 2017-2018 Winter season from 40 stations connected to the Ontario Road Weather Information System (RWIS), it includes 14.000 labelled images and 70.000 weather measurements. In particular, we train and evaluate the performance of seven state-of-the-art models from the Computer Vision literature, including the recent DenseNet, NASNet, and MobileNet. Also, by integrating observations from weather variables, the models are able to better ascertain RSC under poor visibility conditions.</div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: 24</span><br />
	<span class="Journal">Keywords: machine-learning,smart cities; grant-form100a</span><br />
	<span class="URL"><a href="https://tac-its.ca/conference-papers/comparison-deep-learning-models-determining-road-surface-condition-roadside-camera">https://tac-its.ca/conference-papers/comparison-deep-learning-models-determining-road-surface-condition-roadside-camera</a></span><br />
</dd>
<dt class="Key" id="ghojogh2019ccai">ghojogh2019ccai</dt>
<dd class="Pub">
	<span class="Title">{Instance Ranking and Numerosity Reduction Using Matrix Decompositionand Subspace Learning}</span><br />
	<span class="Author">Authors: B. Ghojogh and M. Crowley</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: Canadian Conference on Artificial Intelligence</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 12</span><br />
	(<span class="Date">Date: 2019</span>)<br />
    <div class="Abstract">Abstract: One way to deal with the ever increasing amount of available data for processing is to rank data instances by usefulness and reduce the dataset size. In this work, we introduce a framework to achieve this using matrix decomposition and subspace learning. Our central contribution is a novel similarity measure for data instances that uses the basis obtained from matrix decomposition of the dataset. Using this similarity measure, we propose several related algorithms for ranking data instances and performing numerosity reduction. We then validate the effectiveness of these algorithms for data reduction on several datasets for classification, regression, and clustering tasks.</div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: manifold-learning, data-reduction, numerosity-reduction, showcase; grant-form100a</span><br />
</dd>
<dt class="Key" id="Bhalla2019rldm">Bhalla2019rldm</dt>
<dd class="Pub">
	<span class="Title">{Learning Multi-Agent Communication with Reinforcement Learning}</span><br />
	<span class="Author">Authors: S. Bhalla, S. Ganapathi Subramanian, and M. Crowley</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: Conference on Reinforcement Learning and Decision Making (RLDM-19)</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 4</span><br />
	(<span class="Date">Date: 2019</span>)<br />
    <div class="Abstract">Abstract: </div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: autonomous-driving,reinforcement-learning,multi-agent-reinforcement-learning,Multi-Agent-Systems, vehicle-communication; grant-form100a</span><br />
</dd>
<dt class="Key" id="ghojogh2019llise">ghojogh2019llise</dt>
<dd class="Pub">
	<span class="Title">{Locally Linear Image Structural Embedding for Image Structure Manifold Learning}</span><br />
	<span class="Author">Authors: B. Ghojogh, F. Karray, and M. Crowley</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: International Conference on Image Analysis and Recognition (ICIAR-19)</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 126--138</span><br />
	(<span class="Date">Date: 2019</span>)<br />
    <div class="Abstract">Abstract: </div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: manifold-learning, data-reduction, numerosity-reduction; grant-form100a</span><br />
</dd>
<dt class="Key" id="ghojogh2019image">ghojogh2019image</dt>
<dd class="Pub">
	<span class="Title">{Image Structure Subspace Learning Using Structural Similarity Index}</span><br />
	<span class="Author">Authors: B. Ghojogh, F. Karray, and M. Crowley</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: International Conference on Image Analysis and Recognition (ICIAR-19)</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 33--44</span><br />
	(<span class="Date">Date: 2019</span>)<br />
    <div class="Abstract">Abstract: </div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: manifold-learning, numerosity-reduction; grant-form100a; dimensionality-reduction</span><br />
</dd>
<dt class="Key" id="ghojogh2019pcassim">ghojogh2019pcassim</dt>
<dd class="Pub">
	<span class="Title">{Principal Component Analysis Using Structural Similarity Index for Images}</span><br />
	<span class="Author">Authors: B. Ghojogh, F. Karray, and M. Crowley</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: International Conference on Image Analysis and Recognition (ICIAR-19)</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 77--88</span><br />
	(<span class="Date">Date: 2019</span>)<br />
    <div class="Abstract">Abstract: </div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: manifold-learning, numerosity-reduction; grant-form100a; dimensionality-reduction</span><br />
</dd>
<dt class="Key" id="nekoeiqachkanloo2019iaai">nekoeiqachkanloo2019iaai</dt>
<dd class="Pub">
	<span class="Title">{Artificial Counselor System For Stock Investment}</span><br />
	<span class="Author">Authors: H. Nekoei Qachkanloo, B. Ghojogh, A. S. Pasand, and M. Crowley</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: Innovative Applications of Artificial Intelligence (IAAI-19)</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 8</span><br />
	(<span class="Date">Date: 2019</span>)<br />
    <div class="Abstract">Abstract: </div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: 23</span><br />
	<span class="Journal">Keywords: finance, fuzzy-logic, machine-learning, stock-market; grant-form100a</span><br />
</dd>
<dt class="Key" id="bhalla2019ecml">bhalla2019ecml</dt>
<dd class="Pub">
	<span class="Title">{Compact Representation of a Multi-dimensional Combustion Manifold Using Deep Neural Networks}</span><br />
	<span class="Author">Authors: S. Bhalla, M. Yao, J.-P. Hickey, and M. Crowley</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: European Conference on Machine Learning (ECML-19)</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: </span><br />
	(<span class="Date">Date: 2019</span>)<br />
    <div class="Abstract">Abstract: The computational challenges in turbulent combustion simulations stem from the physical complexities and multi-scale nature of the problem which make it intractable to compute scaleesolving simulations. For most engineering applications, the large scale separation between the flame (typically submillimeter scale) and the characteristic turbulent flow (typically centimeter or meter scale) allows us to evoke simplifying assumptions--such as done for the flamelet model to precompute all the chemical reactions and map them to a low order manifold. The resulting manifold is then tabulated and looked up at runtime. As the physical complexity of combustion simulations increases (including radiation, soot formation, pressure variations etc.) the dimensionality of the resulting manifold grows which impedes an efficient tabulation and look up. In this paper we present a novel approach to model the multidimensional combustion manifold. We approximate the combustion manifold using a neural network function approximator and use it to predict the temperature and composition of the reaction. We present a novel training procedure which is developed to generate a smooth output curve for temperature over the course of a reaction. We then evaluate our work against the current approach of tabulation with linear interpolation in combustion simulations. We also provide an ablation study of our training procedure in the context of overfitting in our model. The combustion dataset used for the modeling of combustion of H2 and O2 in this work is released alongside this paper.</div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: 12</span><br />
	<span class="Journal">Keywords: deep-learning, combustion-modelling, experimental design; ai-for-physics; ai-for-science; digital-chemistry; machine-learning; ai-for-chemistry; showcase; grant-form100a</span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2019-ecml-bhalla-compact.pdf">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2019-ecml-bhalla-compact.pdf</a></span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2019-ecml-bhalla-compact1.pdf">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2019-ecml-bhalla-compact1.pdf</a></span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2019-ecml-bhalla-compact2.pdf">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2019-ecml-bhalla-compact2.pdf</a></span><br />
</dd>
<dt class="Key" id="Bhalla2019aamas">Bhalla2019aamas</dt>
<dd class="Pub">
	<span class="Title">{Training Cooperative Agents for Multi-Agent Reinforcement Learning}</span><br />
	<span class="Author">Authors: S. Bhalla, S. Ganapathi Subramanian, and M. Crowley</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: Proc. of the 18th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2019)</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: </span><br />
	(<span class="Date">Date: 2019</span>)<br />
    <div class="Abstract">Abstract: </div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: autonomous-driving,multi-agent-reinforcement-learning,Multi-Agent-Systems,reinforcement-learning; year-in-review-2021; vehicle-communication; showcase; grant-form100a</span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2019-aamas-bhalla-training">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2019-aamas-bhalla-training</a></span><br />
</dd>
<dt class="Key" id="carrillo2019carsp">carrillo2019carsp</dt>
<dd class="Pub">
	<span class="Title">{Integration of Roadside Camera Images and Weather Data for monitoring Winter Road Surface Conditions}</span><br />
	<span class="Author">Authors: J. Carrillo and M. Crowley</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: Canadian Association of Road Safety Professionals (CARSP) Conference</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 4</span><br />
	(<span class="Date">Date: 2019</span>)<br />
    <div class="Abstract">Abstract: Background/Context: During the Winter season, real-time monitoring of road surface conditions is critical for the safety of drivers and road maintenance operations. Previous research has evaluated the potential of image classification methods for detecting road snow coverage by processing images from roadside cameras installed in RWIS (Road Weather Information System) stations. However, it is a challenging task due to limitations such as image resolution, camera angle, and illumination. Two common approaches to improve the accuracy of image classification methods are: adding more input features to the model and increasing the number of samples in the training dataset. Additional input features can be weather variables and more sample images can be added by including other roadside cameras. Although RWIS stations are equipped with both cameras and weather measurement instruments, they are only a subset of the total number of roadside cameras installed across transportation networks, most of which do not have weather measurement instruments. Thus, improvements in use of image data could benefit from additional data sources. Aims/Objectives: The first objective of this study is to complete an exploratory data analysis over three data sources in Ontario: RWIS stations, all the other MTO (Ministry of Transportation of Ontario) roadside cameras, and Environment Canada weather stations. The second objective is to determine the feasibility of integrating these three datasets into a more extensive and richer dataset with weather variables as additional features and other MTO roadside cameras as additional sources of images. Methods/Targets: First, we quantify the advantage of adding other MTO roadside cameras using spatial statistics, the number of monitored roads, and the coverage of ecoregions with different climate regimes. We then analyze experimental variograms from the literature and determine the feasibility of using Environment Canada stations and RWIS stations to interpolate weather variables for all the other MTO roadside cameras without weather instruments. Results/Activities: By adding all other MTO cameras as image data sources, the total number of cameras in the dataset increases from 139 to 578 across Ontario. The average distance to the nearest camera decreases from 38.4km to 9.4km, and the number of monitored roads increases approximately four times. Additionally, six times more cameras are available in the four most populated ecoregions in Ontario. The experimental variograms show that it is feasible to interpolate weather variables with reasonable accuracy. Moreover, observations in the three datasets are collected with similar frequency, which facilitates our data integration approach. Discussion/Deliverables: Integrating these three datasets is feasible and can benefit the design and development of automated image classification methods for monitoring road snow coverage. We do not consider data from pavement-embedded sensors, an additional line of research may explore the integration of this data. Our approach can provide actionable insights which can be used to more selectively perform manual patrolling to better identify road surface conditions. Conclusions: Our initial results are promising and demonstrate that additional, image only datasets can be added to road monitoring data by using existing multimodal sensors as ground truth, which will lead to greater performance on the future image classification tasks.</div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: autonomous-driving,CNNs,Classification,Urban Infrastucture,machine-learning,smart cities; deep-learning; grant-form100a</span><br />
	<span class="URL"><a href="http://www.carsp.ca/research/research-papers/research-papers-search/download-info/integration-of-roadside-camera-images-and-weather-data-for-monitoring-winter-road-surface-conditions/">http://www.carsp.ca/research/research-papers/research-papers-search/download-info/integration-of-roadside-camera-images-and-weather-data-for-monitoring-winter-road-surface-conditions/</a></span><br />
</dd>
<dt class="Key" id="Subramanian2018CCAI">Subramanian2018CCAI</dt>
<dd class="Pub">
	<span class="Title">{Combining MCTS and A3C for prediction of spatially spreading processes in forest wildfire settings}</span><br />
	<span class="Author">Authors: S. Ganapathi Subramanian and M. Crowley</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: Canadian Conference on Artificial Intelligence</span><br />
	<span class="Volume">Volume: 10832 LNAI</span><br />
	<span class="Pages">Pages: 285--291</span><br />
	(<span class="Date">Date: 2018</span>)<br />
    <div class="Abstract">Abstract: In recent years, Deep Reinforcement Learning (RL) algorithms have shown super-human performance in a variety Atari and classic board games like chess and GO. Research into applications of RL in other domains with spatial considerations like environmental planning are still in their nascent stages. In this paper, we introduce a novel combination of Monte-Carlo Tree Search (MCTS) and A3C algorithms on an online simulator of a wildfire, on a pair of forest fires in Northern Alberta (Fort McMurray and Richardson fires) and on historical Saskatchewan fires previously compared by others to a physics-based simulator. We conduct several experiments to predict fire spread for several days before and after the given spatial information of fire spread and ignition points. Our results show that the advancements in Deep RL applications in the gaming world have advantages in spatially spreading real-world problems like forest fires. {\textcopyright} Springer International Publishing AG, part of Springer Nature 2018.</div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: 15</span><br />
	<span class="Journal">Keywords: A3C,computational-sustainability,forest-wildfire,Monte-Carlo-Tree-Search,Reinforcement-Learning, showcase; forest-management; image-processing; grant-form100a</span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2018-canai-ganapathi%20subramanian-combining.pdf">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2018-canai-ganapathi subramanian-combining.pdf</a></span><br />
	<span class="URL"><a href="https://doi.org/10.1007/978-3-319-89656-4_28">https://doi.org/10.1007/978-3-319-89656-4_28</a></span><br />
</dd>
<dt class="Key" id="ghojogh2018psa">ghojogh2018psa</dt>
<dd class="Pub">
	<span class="Title">{Principal Sample Analysis for Data Reduction}</span><br />
	<span class="Author">Authors: B. Ghojogh and M. Crowley</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: 2018 IEEE International Conference on Big Knowledge (ICBK)</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 350--357</span><br />
	(<span class="Date">Date: 2018</span>)<br />
    <div class="Abstract">Abstract: </div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: 2</span><br />
	<span class="Journal">Keywords: manifold-learning, data-reduction, numerosity-reduction; grant-form100a</span><br />
</dd>
<dt class="Key" id="Eaton2018">Eaton2018</dt>
<dd class="Pub">
	<span class="Title">{Blue Sky Ideas in Artificial Intelligence Education from the EAAI 2017 New and Future AI Educator Program}</span><br />
	<span class="Author">Authors: E. Eaton, S. Koenig, C. Schulz, F. Maurelli, J. Lee, J. Eckroth, M. Crowley, R. G. Freedman, R. E. Cardona-Rivera, T. Machado, and T. Williams</span><br />
    <span class="Journal">Journal: AI Matters</span><br />
    <span class="Journal">Conference: AI Matters</span><br />
	<span class="Volume">Volume: 3</span><br />
	<span class="Pages">Pages: 23--31</span><br />
	(<span class="Date">Date: 2018</span>)<br />
    <div class="Abstract">Abstract: </div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: 54</span><br />
	<span class="Journal">Keywords: artificial-intellgience; education-research</span><br />
	<span class="File"><a href=""></a></span><br />
	<span class="URL"><a href="http://doi.acm.org/10.1145/3175502.3175509">http://doi.acm.org/10.1145/3175502.3175509</a></span><br />
	<span class="URL"><a href="https://doi.org/10.1145/3175502.3175509">https://doi.org/10.1145/3175502.3175509</a></span><br />
</dd>
<dt class="Key" id="ganapathisubramanian2018aa">ganapathisubramanian2018aa</dt>
<dd class="Pub">
	<span class="Title">{Decision Assist for Self-Driving Cars}</span><br />
	<span class="Author">Authors: S. Ganapathi Subramanian, J. S. Sambee, B. Ghojogh, and M. Crowley</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: Canadian Conference on Artificial Intelligence</span><br />
	<span class="Volume">Volume: 10832 LNAI</span><br />
	<span class="Pages">Pages: 381--387</span><br />
	(<span class="Date">Date: 2018</span>)<br />
    <div class="Abstract">Abstract: Research into self-driving cars has grown enormously in the last decade primarily due to the advances in the fields of machine intelligence and image processing. An under-appreciated aspect of self-driving cars is actively avoiding high traffic zones, low visibility zones, and routes with rough weather conditions by learning different conditions and making decisions based on trained experiences. This paper addresses this challenge by introducing a novel hierarchical structure for dynamic path planning and experiential learning for vehicles. A multistage system is proposed for detecting and compensating for weather, lighting, and traffic conditions as well as a novel adaptive path planning algorithm named Checked State A3C. This algorithm improves upon the existing A3C Reinforcement Learning (RL) algorithm by adding state memory which provides the ability to learn an adaptive model of the best decisions to take from experience. {\textcopyright} Springer International Publishing AG, part of Springer Nature 2018.</div><br />
    <div class="Abstract">Short Description: 2</div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: autonomous-driving,machine-learning,path-planning,Reinforcement-Learning,weather-estimation; grant-form100a</span><br />
	<span class="URL"><a href="https://doi.org/10.1007/978-3-319-89656-4_44">https://doi.org/10.1007/978-3-319-89656-4_44</a></span><br />
</dd>
<dt class="Key" id="ganapathisubramanian2018frontict">ganapathisubramanian2018frontict</dt>
<dd class="Pub">
	<span class="Title">{Using Spatial Reinforcement Learning to Build Forest Wildfire Dynamics Models From Satellite Images}</span><br />
	<span class="Author">Authors: S. Ganapathi Subramanian and M. Crowley</span><br />
    <span class="Journal">Journal: Frontiers in ICT</span><br />
    <span class="Journal">Conference: </span><br />
	<span class="Volume">Volume: 5</span><br />
	<span class="Pages">Pages: 12</span><br />
	(<span class="Date">Date: 2018</span>)<br />
    <div class="Abstract">Abstract: Machine learning algorithms have increased tremendously in power in recent years but have yet to be fully utilized in many ecology and sustainable resource management domains such as wildlife reserve design, forest fire management and invasive species spread. One thing these domains have in common is that they contain dynamics that can be characterized as a Spatially Spreading Process (SSP) which requires many parameters to be set precisely to model the dynamics, spread rates and directional biases of the elements which are spreading. We present related work in Artificial Intelligence and Machine Learning for SSP sustainability domains including forest wildfire prediction. We then introduce a novel approach for learning in SSP domains using Reinforcement Learning (RL) where fire is the agent at any cell in the landscape and the set of actions the fire can take from a location at any point in time includes spreading North, South, East, West or not spreading. This approach inverts the usual RL setup since the dynamics of the corresponding Markov Decision Process (MDP) is a known function for immediate wildfire spread. Meanwhile, we learn an agent policy for a predictive model of the dynamics of a complex spatially-spreading process. Rewards are provided for correctly classifying which cells are on fire or not compared to satellite and other related data. We examine the behaviour of five RL algorithms on this problem: Value Iteration, Policy Iteration, Q-Learning, Monte Carlo Tree Search and Asynchronous Advantage Actor-Critic (A3C). We compare to a Gaussian process based supervised learning approach and discuss the relation of our approach to manually constructed, state-of-the-art methods from forest wildfire modelling. We also discuss the relation of our approach to manually constructed, state-of-the-art methods from forest wildfire modelling. We validate our approach with satellite image data of two massive wildfire events in Northern Alberta, Canada, the Fort McMurray fire of 2016 and the Richardson fire of 2011. The results show that we can learn predictive, agent-based policies as models of spatial dynamics using RL on readily available satellite images that other methods and have many additional advantages in terms of generalizability and interpretability.</div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: 52</span><br />
	<span class="Journal">Keywords: A3C,deep-learning, forest-wildfire,machine-learning,Reinforcement-Learning,spatiotemporal-planning,computational-sustainability, showcase; forest-management; image-processing; grant-form100a</span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2018-frontict-ganapathi%20subramanian-using.pdf">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2018-frontict-ganapathi subramanian-using.pdf</a></span><br />
	<span class="URL"><a href="http://journal.frontiersin.org/article/10.3389/fict.2018.00006/full">http://journal.frontiersin.org/article/10.3389/fict.2018.00006/full</a></span><br />
	<span class="URL"><a href="https://doi.org/10.3389/fict.2018.00006">https://doi.org/10.3389/fict.2018.00006</a></span><br />
</dd>
<dt class="Key" id="subramanian2017rldm">subramanian2017rldm</dt>
<dd class="Pub">
	<span class="Title">{Learning Forest Wildfire Dynamics from Satellite Images Using Reinforcement Learning}</span><br />
	<span class="Author">Authors: S. G. Subramanian and M. Crowley</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: Conference on Reinforcement Learning and Decision Making</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 244-248</span><br />
	(<span class="Date">Date: 2017</span>)<br />
    <div class="Abstract">Abstract: </div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: 23</span><br />
	<span class="Journal">Keywords: A2C, reinforcement-learning, forest-wildfire, showcase; forest-management; image-processing</span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2017-rldm-subramanian-learning.pdf">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2017-rldm-subramanian-learning.pdf</a></span><br />
</dd>
<dt class="Key" id="fernick2017rsa">fernick2017rsa</dt>
<dd class="Pub">
	<span class="Title">{Big Metadata : Machine Learning on Encrypted Communications}</span><br />
	<span class="Author">Authors: J. Fernick and M. Crowley</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: RSA Conference</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 8</span><br />
	(<span class="Date">Date: 2017</span>)<br />
    <div class="Abstract">Abstract: </div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: machine-learning; security; encryption; communications</span><br />
</dd>
<dt class="Key" id="maryam2017spie">maryam2017spie</dt>
<dd class="Pub">
	<span class="Title">{Application of probabilistically-weighted graphs to image-based diagnosis of Alzheimer's disease using diffusion MRI}</span><br />
	<span class="Author">Authors: S. Maryam, L. McCrackin, M. Crowley, Y. Rathi, and O. Michailovich</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: Proceedings of SPIE 101324, Medical Imaging 2017 : Computer-Aided Diagnosis</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: </span><br />
	(<span class="Date">Date: 2017</span>)<br />
    <div class="Abstract">Abstract: The world's aging population has given rise to an increasing awareness towards neurodegenerative disorders, including Alzheimers Disease (AD). Treatment options for AD are currently limited, but it is believed that future success depends on our ability to detect the onset of the disease in its early stages. The most frequently used tools for this include neuropsychological assessments, along with genetic, proteomic, and image-based diagnosis. Recently, the applicability of Diffusion Magnetic Resonance Imaging (dMRI) analysis for early diagnosis of AD has also been reported. The sensitivity of dMRI to the microstructural organization of cerebral tissue makes it particularly well-suited to detecting changes which are known to occur in the early stages of AD. Existing dMRI approaches can be divided into two broad categories: region-based and tract-based. In this work, we propose a new approach, which extends region-based approaches to the simultaneous characterization of multiple brain regions. Given a predefined set of features derived from dMRI data, we compute the probabilistic distances between different brain regions and treat the resulting connectivity pattern as an undirected, fully-connected graph. The characteristics of this graph are then used as markers to discriminate between AD subjects and normal controls (NC). Although in this preliminary work we omit subjects in the prodromal stage of AD, mild cognitive impairment (MCI), our method demonstrates perfect separability between AD and NC subject groups with substantial margin, and thus holds promise for fine-grained stratification of NC, MCI and AD populations.</div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: medical-imaging, machine-learning, image-processing, deep-learning</span><br />
	<span class="URL"><a href="http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.2254164">http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.2254164</a></span><br />
	<span class="URL"><a href="https://doi.org/10.1117/12.2254164">https://doi.org/10.1117/12.2254164</a></span><br />
</dd>
<dt class="Key" id="crowley2017seaai">crowley2017seaai</dt>
<dd class="Pub">
	<span class="Title">{AI Education Through Real World Problems}</span><br />
	<span class="Author">Authors: M. Crowley</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: The Seventh Symposium on Educational Advances in Artificial Intellgience.</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: </span><br />
	(<span class="Date">Date: 2017</span>)<br />
    <div class="Abstract">Abstract: </div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: showcase</span><br />
</dd>
<dt class="Key" id="Salem2016">Salem2016</dt>
<dd class="Pub">
	<span class="Title">{Inter-Arrival Curves for Multi-Mode and Online Anomaly Detection}</span><br />
	<span class="Author">Authors: M. Salem, M. Crowley, and S. Fischmeister</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: Euromicro Conference on Real-Time Systems 2016 - Work-in-Progress Proceedings</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: </span><br />
	(<span class="Date">Date: 2016</span>)<br />
    <div class="Abstract">Abstract: </div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: anomaly-detection,proj-MassiveTraceAnomalyDetection</span><br />
</dd>
<dt class="Key" id="salem2016ecrts">salem2016ecrts</dt>
<dd class="Pub">
	<span class="Title">{Anomaly Detection Using Inter-Arrival Curves for Real-time Systems}</span><br />
	<span class="Author">Authors: M. Salem, M. Crowley, and S. Fischmeister</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: 2016 28th Euromicro Conference on Real-Time Systems</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 97--106</span><br />
	(<span class="Date">Date: 2016</span>)<br />
    <div class="Abstract">Abstract: ---Real-time embedded systems are a significant class of applications, poised to grow even further as automated vehicles and the Internet of Things become a reality. An important problem for these systems is to detect anomalies during operation. Anomaly detection is a form of classification, which can be driven by data collected from the system at execution time. We propose inter-arrival curves as a novel analytic modelling technique for discrete event traces. Our approach relates to the existing technique of arrival curves and expands the technique to anomaly detection. Inter-arrival curves analyze the behaviour of events within a trace by providing upper and lower bounds to their inter-arrival occurrence. We exploit inter-arrival curves in a classification framework that detects deviations within these bounds for anomaly detection. Also, we show how inter-arrival curves act as good features to extract recurrent behaviour that these systems often exhibit. We demonstrate the feasibility and viability of the fully implemented approach with an industrial automotive case study (CAN traces) as well as a deployed aerospace case study (RTOS kernel traces).</div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: 37</span><br />
	<span class="Journal">Keywords: anomaly-detection,arrival-curves,embedded-systems,proj-MassiveTraceAnomalyDetection, showcase</span><br />
	<span class="URL"><a href="https://doi.org/10.1109/ECRTS.2016.22">https://doi.org/10.1109/ECRTS.2016.22</a></span><br />
</dd>
<dt class="Key" id="taleghan2015jmlr">taleghan2015jmlr</dt>
<dd class="Pub">
	<span class="Title">{PAC Optimal MDP Planning with Application to Invasive Species Management}</span><br />
	<span class="Author">Authors: M. A. Taleghan, T. G. Dietterich, M. Crowley, K. Hall, and H. J. Albers</span><br />
    <span class="Journal">Journal: Journal of Machine Learning Research</span><br />
    <span class="Journal">Conference: </span><br />
	<span class="Volume">Volume: 16</span><br />
	<span class="Pages">Pages: 3877--3903</span><br />
	(<span class="Date">Date: 2015</span>)<br />
    <div class="Abstract">Abstract: In a simulator-defined MDP, the Markovian dynamics and rewards are provided in the form of a simulator from which samples can be drawn. This paper studies MDP planning algorithms that attempt to minimize the number of simulator calls before terminating and outputting a policy that is approximately optimal with high probability. The paper introduces two heuristics for efficient exploration and an improved confidence interval that enables earlier termination with probabilis- tic guarantees. We prove that the heuristics and the confidence interval are sound and produce with high probability an approximately optimal policy in polynomial time. Experiments on two benchmark problems and two instances of an invasive species management problem show that the improved confidence intervals and the new search heuristics yield reductions of between 8{\%} and 47{\%} in the number of simulator calls required to reach near-optimal policies.</div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: 29</span><br />
	<span class="Journal">Keywords: good-turing-estimate,mdp,mdp,computational-sustainability,grant-wici16,invasive-species-management,machine-learning,mdp,optimization,Reinforcement-Learning, showcase; pac-learning</span><br />
	<span class="URL"><a href="http://jmlr.org/papers/v16/taleghan15a.html">http://jmlr.org/papers/v16/taleghan15a.html</a></span><br />
</dd>
<dt class="Key" id="crowley2015dmcs">crowley2015dmcs</dt>
<dd class="Pub">
	<span class="Title">{Answering Simple Questions About Spatially Spreading Systems}</span><br />
	<span class="Author">Authors: M. Crowley</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: 2015 Summer Solstice: 7th International Conference on Discrete Models of Complex Systems</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: </span><br />
	(<span class="Date">Date: 2015</span>)<br />
    <div class="Abstract">Abstract: </div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: complex-systems;</span><br />
</dd>
<dt class="Key" id="crowley2014ieeetoc">crowley2014ieeetoc</dt>
<dd class="Pub">
	<span class="Title">{Using equilibrium policy gradients for spatiotemporal planning in forest ecosystem management}</span><br />
	<span class="Author">Authors: M. Crowley</span><br />
    <span class="Journal">Journal: IEEE Transactions on Computers</span><br />
    <span class="Journal">Conference: </span><br />
	<span class="Volume">Volume: 63</span><br />
	<span class="Pages">Pages: 142--154</span><br />
	(<span class="Date">Date: 2014</span>)<br />
    <div class="Abstract">Abstract: Spatiotemporal planning involves making choices at multiple locations in space over some planning horizon to maximize utility and satisfy various constraints. In Forest Ecosystem Management, the problem is to choose actions for thousands of locations each year including harvesting, treating trees for fire or pests, or doing nothing. The utility models could place value on sale of lumber, ecosystem sustainability or employment levels and incorporate legal and logistical constraints on actions such as avoiding large contiguous areas of clearcutting. Simulators developed by forestry researchers provide detailed dynamics but are generally inaccesible black boxes. We model spatiotemporal planning as a factored Markov decision process and present a policy gradient planning algorithm to optimize a stochastic spatial policy using simulated dynamics. It is common in environmental and resource planning to have actions at different locations be spatially interelated, this makes representation and planning challenging. We define a global spatial policy in terms of interacting local policies defining distributions over actions at each location conditioned on actions at nearby locations. Markov chain Monte Carlo simulation is used to sample landscape policies and estimate their gradients. Evaluation is carried out on a forestry planning problem with 1,880 locations using a variety of value models and constraints. Index</div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: 7</span><br />
	<span class="Journal">Keywords: computational-sustainability,Ecosystem management,forest-management,machine-learning,mdp,Optimization,policy-gradient,Reinforcement-Learning,grant-wici16,proj-spatiallyspreadingprocess,spatiotemporal-planning, showcase</span><br />
	<span class="URL"><a href="http://www.computer.org/csdl/trans/tc/preprint/06514032-abs.html">http://www.computer.org/csdl/trans/tc/preprint/06514032-abs.html</a></span><br />
	<span class="URL"><a href="https://doi.org/10.1109/TC.2013.113">https://doi.org/10.1109/TC.2013.113</a></span><br />
</dd>
<dt class="Key" id="houtman2013ijwf">houtman2013ijwf</dt>
<dd class="Pub">
	<span class="Title">Allowing a wildfire to burn: Estimating the effect on future fire suppression costs</span><br />
	<span class="Author">Authors: R. M. Houtman, C. A. Montgomery, A. R. Gagnon, D. E. Calkin, T. G. Dietterich, S. McGregor, and M. Crowley</span><br />
    <span class="Journal">Journal: International Journal of Wildland Fire</span><br />
    <span class="Journal">Conference: </span><br />
	<span class="Volume">Volume: 22</span><br />
	<span class="Pages">Pages: 871--882</span><br />
	(<span class="Date">Date: 2013</span>)<br />
    <div class="Abstract">Abstract: Where a legacy of aggressive wildland fire suppression has left forests in need of fuel reduction, allowing wildland fire to burn may provide fuel treatment benefits, thereby reducing suppression costs from subsequent fires. The least-cost-plus-net-value-change model of wildland fire economics includes benefits of wildfire in a framework for evaluating suppression options. In this study, we estimated one component of that benefit -- the expected present value of the reduction in suppression costs for subsequent fires arising from the fuel treatment effect of a current fire. To that end, we employed Monte Carlo methods to generate a set of scenarios for subsequent fire ignition and weather events, which are referred to as sample paths, for a study area in central Oregon. We simulated fire on the landscape over a 100-year time horizon using existing models of fire behaviour, vegetation and fuels development, and suppression effectiveness, and we estimated suppression costs using an existing suppression cost model. Our estimates suggest that the potential cost savings may be substantial. Further research is needed to estimate the full least-cost-plus-net-value-change model. This line of research will extend the set of tools available for developing wildfire management plans for forested landscapes.</div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: 108</span><br />
	<span class="Journal">Keywords: bio-economic modelling,forest-wildfire,forest-wildfire,grant-wici16,proj-spatiallyspreadingprocess,spatial simulation,forest-wildfire, showcase; forest-management; grant-form100a</span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2013-ijwf-houtman-allowing.pdf">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2013-ijwf-houtman-allowing.pdf</a></span><br />
	<span class="URL"><a href="https://doi.org/10.1071/WF12157">https://doi.org/10.1071/WF12157</a></span><br />
</dd>
<dt class="Key" id="dietterich2013aaai">dietterich2013aaai</dt>
<dd class="Pub">
	<span class="Title">{PAC Optimal Planning for Invasive Species Management: Improved Exploration for Reinforcement Learning from Simulator-Defined MDPs}</span><br />
	<span class="Author">Authors: T. G. Dietterich, M. Alkaee Taleghan, and M. Crowley</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: Proceedings of the AAAI Conference on Artificial Intelligence (AAAI-2013)</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 7</span><br />
	(<span class="Date">Date: 2013</span>)<br />
    <div class="Abstract">Abstract: Often the most practical way to define a Markov Decision Process (MDP) is as a simulator that, given a state and an action, produces a resulting state and immediate reward sampled from the corresponding distributions. Simulators in natural resource management can be very expensive to execute, so that the time required to solve such MDPs is dominated by the number of calls to the simulator. This paper presents an algorithm, DDV, that combines improved confidence intervals on the Q values (as in interval estimation) with a novel upper bound on the discounted state occupancy probabilities to intelligently choose state-action pairs to explore. We prove that this algorithm terminates with a policy whose value is within $\epsilon$ of the optimal policy (with probability 1−$\delta$) after making only polynomially-many calls to the simulator. Experiments on one benchmark MDP and on an MDP for invasive species management show very large reductions in the number of simulator calls required.</div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: 22</span><br />
	<span class="Journal">Keywords: pac-learning,computational-sustainability,invasive-species-management,machine-learning,mdp, planning, showcase</span><br />
	<span class="URL"><a href="http://www.aaai.org/ocs/index.php/AAAI/AAAI13/paper/view/6478">http://www.aaai.org/ocs/index.php/AAAI/AAAI13/paper/view/6478</a></span><br />
</dd>
<dt class="Key" id="poole2013ijcai">poole2013ijcai</dt>
<dd class="Pub">
	<span class="Title">{Cyclic causal models with discrete variables: Markov chain equilibrium semantics and sample ordering}</span><br />
	<span class="Author">Authors: D. Poole and M. Crowley</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: International Joint Conference on Artificial Intelligence (IJCAI)</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 1060--1068</span><br />
	(<span class="Date">Date: 2013</span>)<br />
    <div class="Abstract">Abstract: We analyze the foundations of cyclic causal models for discrete variables, and compare structural equation models (SEMs) to an alternative semantics as the equilibrium (stationary) distribution of a Markov chain. We show under general conditions, discrete cyclic SEMs cannot have independent noise, even in the simplest case, cyclic structural equation models imply constraints on the noise. We give a formalization of an alternative Markov chain equilibrium semantics which requires not only the causal graph, but also a sample order. We show how the resulting equilibrium is a function of the sample ordering, both theoretically and empirically.</div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: 17</span><br />
	<span class="Journal">Keywords: causality, probabilistic-inference, showcase, mdp; probabilistic-graphical-models</span><br />
	<span class="URL"><a href="http://dl.acm.org/citation.cfm?id=2540281">http://dl.acm.org/citation.cfm?id=2540281</a></span><br />
</dd>
<dt class="Key" id="Crowley2013">Crowley2013</dt>
<dd class="Pub">
	<span class="Title">{Policy Gradient Optimization Using Equilibrium Policies for Spatial Planning Domains}</span><br />
	<span class="Author">Authors: M. Crowley</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: 13th INFORMS Computing Society Conference</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: </span><br />
	(<span class="Date">Date: 2013</span>)<br />
    <div class="Abstract">Abstract: </div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: reinforcement-learning; machine-learning; computational-sustainability; optimization; policy-gradient; showcase</span><br />
</dd>
<dt class="Key" id="Hall2012">Hall2012</dt>
<dd class="Pub">
	<span class="Title">{Managing Invasive Species in a River Network}</span><br />
	<span class="Author">Authors: K. Hall, M. Alkaee Taleghan, H. J. Albers, T. Dietterich, and M. Crowley</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: Third International Conference on Computational Sustainability</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: </span><br />
	(<span class="Date">Date: 2012</span>)<br />
    <div class="Abstract">Abstract: There are many pest species that invade valuable ecosystems and damage ecosystem services. An important management goal is to limit the spread of these species or even eradicate them. From the computational perspective, these problems can be formulated as Markov Decision Processes. However, solving them is difficult, because of their spatial nature. Viewed abstractly, the current state of the ecosystem can be formalized as a graph. Each node of the graph may be invaded or not, and at each time step, a ``local'' action must be selected at each node. Consequently, at the level of the whole MDP, each global action is a vector of local actions of length N, the number of nodes in the graph. The exponentially large action space raises major computational problems. During the state transitions, the invasive species can spread along the edges of the graph. We study a specific instance of this general problem based on the spread of Tamarisk in river networks. In this formulation, we work with the dual of the standard river network graph. Each node corresponds to a stretch of the river between two confluences (also called a ``reach''). We divide each reach into H ``slots'', where each slot can either be occupied by a single native tree, occupied by a single Tamarisk tree, or empty. In each time step, the plants (both native and invader) first must survive through winter (with some probability). Then, the surviving trees produce seeds that disperse through the river network according to a dispersal kernel that prefers downstream movement with high probability. Each dispersing seed lands at some slot in some node of the network. All seeds arriving at a slot compete to establish themselves in that slot (if the slot is empty). In our model, there are three local actions: simple eradication of invasive plants, eradication followed by planting of native plants, or doing nothing at all. Doing nothing costs nothing, while eradication is more expensive, and eradication plus planting is the most expensive. One local action must be chosen for each node (reach) at each time step, and it applies to all H slots at that node. The actions only succeed stochastically. The planning goal is to minimize the expected discounted sum of the cost of invasive damage and the cost of management actions. To solve this planning problem, we apply the standard value iteration algorithm. However, standard value iteration requires a fully-specified state transition matrix. In our problem, it is easy to write a simulator for drawing samples of the dispersal and competition processes, but it is computationally intractable to compute the exact transition probabilities. Hence, we estimate those probabilities by drawing a large number of samples from the simulator. Once we have an optimal policy on the approximated MDP, we explore its behaviour both directly and via simulated rollouts. The optimal policy can be visualized with one picture per state annotated by the types of plants in each reach and the optimal action that should be taken in each reach. We also run the optimal policy forward in time on many simulated trajectories in order to gather statistics about its behaviour such as: how long it takes to reach a steady state, average cost of a policy over time, or the frequency with which completely invaded or uninvaded states are reached. Comparisons of these statistics show that in many situations our optimal policies greatly outperform established rules of thumb from the literature. An example of a rule of thumb is to always prioritize treatment of upstream over downstream reaches. Another rule targets the most invaded reaches (those with the most slots occupied by Tamarisk) first. We have found that the optimality of these rules of thumb depends strongly on the dispersal and competition parameters. Some contributions this work makes to bioeconomics and ecology are showing evidence that the stochastic spread of the invasion process needs to be modelled and that the spatial characteristics of the system under invasion are relevant to optimal management. The computational challenges raised by this problem have led us into research on methods for planning that can provide bounds on the optimality of the policy while minimizing the number of calls to expensive simulators. We are also studying algorithms that can scale to large graphs with thousands of nodes and large out-degrees. Finally, we see potential in these problems for intelligently reducing the size of the state space and the complexity of the policy description by utilizing domain knowledge.</div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: computational-sustainability,ecology,invasive-species-management,Reinforcement-Learning,value iteration</span><br />
	<span class="URL"><a href="http://www.cs.ubc.ca/%7B~%7Dcrowley/papers/compsust2012.pdf">http://www.cs.ubc.ca/%7B~%7Dcrowley/papers/compsust2012.pdf</a></span><br />
</dd>
<dt class="Key" id="Crowley2011">Crowley2011</dt>
<dd class="Pub">
	<span class="Title">{Policy gradient planning for environmental decision making with existing simulators}</span><br />
	<span class="Author">Authors: M. Crowley and D. Poole</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: Proceedings of the Twenty-Fifth Conference on Artificial Intelligence (AAAI)</span><br />
	<span class="Volume">Volume: 2</span><br />
	<span class="Pages">Pages: 1323--1330</span><br />
	(<span class="Date">Date: 2011</span>)<br />
    <div class="Abstract">Abstract: In environmental and natural resource planning domains actions are taken at a large number of locations over multiple time periods. These problems have enormous state and action spaces, spatial correlation between actions, uncertainty and complex utility models. We present an approach for modeling these planning problems as factored Markov decision processes. The reward model can contain local and global components as well as spatial constraints between locations. The transition dynamics can be provided by existing simulators developed by domain experts. We propose a landscape policy defined as the equilibrium distribution of a Markov chain built from many locally-parameterized policies. This policy is optimized using a policy gradient algorithm. Experiments using a forestry simulator demonstrate the algorithm's ability to devise policies for sustainable harvest planning of a forest. Copyright {\textcopyright} 2011, Association for the Advancement of Artificial Intelligence. All rights reserved.</div><br />
    <div class="Abstract">Short Description: This contained the primary results from my PhD thesis. I was the primary writer for everything on this paper.</div><br />
	<span class="Pages">Citations: 14</span><br />
	<span class="Journal">Keywords: mdp,Reinforcement-Learning,spatiotemporal-planning,thesis research; showcase</span><br />
	<span class="URL"><a href="http://www.scopus.com/inward/record.url?eid=2-s2.0-80055051332%7B%5C&%7DpartnerID=tZOtx3y1">http://www.scopus.com/inward/record.url?eid=2-s2.0-80055051332%7B%5C&%7DpartnerID=tZOtx3y1</a></span><br />
</dd>
<dt class="Key" id="Crowley2011thesis">Crowley2011thesis</dt>
<dd class="Pub">
	<span class="Title">{Equilibrium Policy Gradients for Spatiotemporal Planning}</span><br />
	<span class="Author">Authors: M. Crowley</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: Electronic Theses and Dissertations (ETDs) 2008+</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 187 pages</span><br />
	(<span class="Date">Date: 2011</span>)<br />
    <div class="Abstract">Abstract: In spatiotemporal planning, agents choose actions at multiple locations in space over some planning horizon to maximize their utility and satisfy various constraints. In forestry planning, for example, the problem is to choose actions for thousands of locations in the forest each year. The actions at each location could include harvesting trees, treating trees against disease and pests, or doing nothing. A utility model could place value on sale of forest products, ecosystem sustainability or employment levels, and could incorporate legal and logistical constraints such as avoiding large contiguous areas of clearcutting and managing road access. Planning requires a model of the dynamics. Existing simulators developed by forestry researchers can provide detailed models of the dynamics of a forest over time, but these simulators are often not designed for use in automated planning. This thesis presents spatiotemoral planning in terms of factored Markov decision processes. A policy gradient planning algorithm optimizes a stochastic spatial policy using existing simulators for dynamics. When a planning problem includes spatial interaction between locations, deciding on an action to carry out at one location requires considering the actions performed at other locations. This spatial interdependence is common in forestry and other environmental planning problems and makes policy representation and planning challenging. We define a spatial policy in terms of local policies defined as distributions over actions at one location conditioned upon actions at other locations. A policy gradient planning algorithm using this spatial policy is presented which uses Markov Chain Monte Carlo simulation to sample the landscape policy, estimate its gradient and use this gradient to guide policy improvement. Evaluation is carried out on a forestry planning problem with 1880 locations using a variety of value models and constraints. The distribution over joint actions at all locations can be seen as the equilibrium of a cyclic causal model. This equilibrium semantics is compared to Structural Equation Models. We also define an algorithm for approximating the equilibrium distribution for cyclic causal networks which exploits graphical structure and analyse when the algorithm is exact.</div><br />
    <div class="Abstract">Short Description: This is Mark Crowley's PhD thesis on the theory and application of cyclical relations as a basis for policies in spatial planning and reinforcement learning domains, with a demonstration on sustainable forest management.</div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: mdp,computational-sustainability,graphical-models,machine-learning,reinforcement-learning,spatiotemporal-planning, forest-management</span><br />
	<span class="File"><a href="file:///Users/mcrowley/repos/markcrowley-ca/assets/pdf/2011-ubclibrary-crowley-equilibrium.pdf">/Users/mcrowley/repos/markcrowley-ca/assets/pdf/2011-ubclibrary-crowley-equilibrium.pdf</a></span><br />
	<span class="URL"><a href="http://hdl.handle.net/2429/38971">http://hdl.handle.net/2429/38971</a></span><br />
</dd>
<dt class="Key" id="Patitsas2010">Patitsas2010</dt>
<dd class="Pub">
	<span class="Title">{Circuits and logic in the lab : Toward a coherent picture of computation}</span><br />
	<span class="Author">Authors: E. Patitsas, K. Voll, M. Crowley, and S. Wolfman</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: 15th Western Canadian Conference on Computing Education</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 5</span><br />
	(<span class="Date">Date: 2010</span>)<br />
    <div class="Abstract">Abstract: We describe extensive modifications made over time to a first year computer science course at the University of British Columbia covering logic and digital circuits (among other topics). Smoothly integrating the hardware-based labs with the more theory-based lectures into a cohesive picture of computation has always been a challenge in this course. The seeming disconnect between implementation and abstraction has historically led to frustration and dissatisfaction among students. We describe changes to the lab curriculum, equipment logistics, the style of in-lab activities and evaluation. We have also made logistical changes to the management and ongoing training of teaching assistants, allowing us to better anchor our larger course story into the lab curriculum. These changes have greatly improved student and TA opinions of the lab experience, as well as the overall course.</div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: Pedagogy,curriculum,education-research,survey</span><br />
	<span class="URL"><a href="http://www.cs.ubc.ca/%7B~%7Dcrowley/papers/wccce2010.pdf">http://www.cs.ubc.ca/%7B~%7Dcrowley/papers/wccce2010.pdf</a></span><br />
	<span class="URL"><a href="https://doi.org/10.1145/1806512.1806523">https://doi.org/10.1145/1806512.1806523</a></span><br />
</dd>
<dt class="Key" id="Crowley2009">Crowley2009</dt>
<dd class="Pub">
	<span class="Title">{Seeing the Forest Despite the Trees : Large Scale Spatial-Temporal Decision Making}</span><br />
	<span class="Author">Authors: M. Crowley, J. Nelson, and D. Poole</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: Conference on Uncertainty in Artificial Intelligence (UAI09)</span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: 126--134</span><br />
	(<span class="Date">Date: 2009</span>)<br />
    <div class="Abstract">Abstract: We introduce a challenging real world planning problem where actions must be taken at each location in a spatial area at each point in time. We use forestry planning as the motivating application. In Large Scale Spatial-Temporal (LSST) planning problems, the state and action spaces are defined as the cross-products of many local state and action spaces spread over a large spatial area such as a city or forest. These problems possess state uncertainty, have complex utility functions involving spatial constraints and we generally must rely on simulations rather than an explicit transition model. We define LSST problems as reinforcement learning prob- lems and present a solution using policy gradients. We compare two different policy formulations: an explicit policy that identifies each location in space and the action to take there, and an abstract policy that defines the proportion of actions to take across all locations in space. We show that the abstract policy is more robust and achieves higher rewards with far fewer parameters than the elementary policy. This abstract policy is also a better fit to the properties that practitioners in LSST problem domains require for such methods to be widely useful</div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: mdp,computational-sustainability,forest-management,probabilistic-inference,planning,spatiotemporal-planning; showcase</span><br />
	<span class="URL"><a href="http://www.cs.ubc.ca/%7B~%7Dcrowley/papers/uai09-mark-crowley.pdf">http://www.cs.ubc.ca/%7B~%7Dcrowley/papers/uai09-mark-crowley.pdf</a></span><br />
</dd>
<dt class="Key" id="Crowley2007">Crowley2007</dt>
<dd class="Pub">
	<span class="Title">{Adding Local Constraints to Bayesian Networks}</span><br />
	<span class="Author">Authors: M. Crowley, B. Boerlage, D. Poole, Z. Kobti, and D. Wu</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: Advances in Artificial Intelligence</span><br />
	<span class="Volume">Volume: 4509</span><br />
	<span class="Pages">Pages: 344--355</span><br />
	(<span class="Date">Date: 2007</span>)<br />
    <div class="Abstract">Abstract: When using Bayesian networks, practitioners often express constraints among variables by conditioning a common child node to induce the desired distribution. For example, an `or' constraint can be easily expressed by a node modelling a logical `or' of its parents' values being conditioned to true. This has the desired effect that at least one parent must be true. However, conditioning also alters the distributions of further ancestors in the network. In this paper we argue that these side effects are undesirable when constraints are added during model design. We describe a method called shielding to remove these side effects while remaining within the directed language of Bayesian networks. This method is then compared to chain graphs which allow undirected and directed edges and which model equivalent distributions. Thus, in addition to solving this common modelling problem, shielded Bayesian networks provide a novel method for implementing chain graphs with existing Bayesian network tools.</div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: 6</span><br />
	<span class="Journal">Keywords: Computer Science,probabilistic-graphical-models,constraints,probabilistic-inference</span><br />
	<span class="URL"><a href="http://www.springerlink.com/content/u1j205nhr750m717/">http://www.springerlink.com/content/u1j205nhr750m717/</a></span><br />
	<span class="URL"><a href="https://doi.org/10.1007/978-3-540-72665-4">https://doi.org/10.1007/978-3-540-72665-4</a></span><br />
</dd>
<dt class="Key" id="Crowley2005">Crowley2005</dt>
<dd class="Pub">
	<span class="Title">{Shielding Against Conditioning Side-Effects in Graphical Models}</span><br />
	<span class="Author">Authors: M. A. Crowley</span><br />
    <span class="Journal">Journal: </span><br />
    <span class="Journal">Conference: </span><br />
	<span class="Volume">Volume: </span><br />
	<span class="Pages">Pages: </span><br />
	(<span class="Date">Date: 2005</span>)<br />
    <div class="Abstract">Abstract: </div><br />
    <div class="Abstract">Short Description: </div><br />
	<span class="Pages">Citations: </span><br />
	<span class="Journal">Keywords: probabilistic-graphical-models,constraints,probabilistic-inference,influence-diagrams,side-effects</span><br />
</dd>

</dl>
</div>
</body>
</html>

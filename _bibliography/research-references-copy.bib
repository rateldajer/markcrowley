%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Mark at 2024-09-04 12:02:27 -0400 


%% Saved with string encoding Unicode (UTF-8) 



@conference{DBLP:journals/corr/abs-2106-02617,
	arxiv = {2106.02617},
	author = {Parand Alizadeh Alamdari and Toryn Q. Klassen and Rodrigo Toro Icarte and Sheila A. McIlraith},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/abs-2106-02617.bib},
	booktitle = {Arxiv Preprint},
	date-added = {2024-09-04 11:56:20 -0400},
	date-modified = {2024-09-04 12:00:08 -0400},
	eprint = {2106.02617},
	eprinttype = {arXiv},
	hypoth = {https://hyp.is/go?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2106.02617&group=DM67BYBG},
	journal = {CoRR},
	keywords = {rd-middle},
	note = {Good paper on alternative ways to think about reward agent actions during learning beyond selfish/greedy policy optimization.},
	order = {3},
	timestamp = {Thu, 10 Jun 2021 16:34:18 +0200},
	title = {Be Considerate: Objectives, Side Effects, and Deciding How to Act},
	url = {https://arxiv.org/abs/2106.02617},
	venue-short = {arxiv},
	volume = {abs/2106.02617},
	year = {2021},
	bdsk-url-1 = {https://arxiv.org/abs/2106.02617}}

@inproceedings{li2024aaai,
	arxiv = {2312.15133},
	author = {Li, Shujuan and Zhou, Junsheng and Ma, Baorui and Liu, Yu-Shen and Han, Zhizhong},
	booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
	date-added = {2024-08-02 14:16:49 -0400},
	date-modified = {2024-08-02 14:17:57 -0400},
	hypoth = {https://hyp.is/go?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2312.15133&group=__world__},
	keywords = {lidar, manifold-learning, wildfire-management, proj-firecsalidar},
	title = {Learning Continuous Implicit Field with Local Distance Indicator for Arbitrary-Scale Point Cloud Upsampling},
	url = {https://lisj575.github.io/APU-LDI/},
	venue-short = {aaai},
	year = {2024},
	bdsk-url-1 = {https://lisj575.github.io/APU-LDI/}}

@article{chandar2016neuralcompjour,
	author = {Chandar, Sarath and Khapra, Mitesh M and Larochelle, Hugo and Ravindran, Balaraman},
	date-added = {2024-08-01 10:47:30 -0400},
	date-modified = {2024-08-01 10:52:09 -0400},
	hypoth = {https://hyp.is/go?url=https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FBalaraman-Ravindran%2Fpublication%2F275588055_Correlational_Neural_Networks%2Flinks%2F55ed84d308ae21d099c75c00%2FCorrelational-Neural-Networks.pdf&group=__world__},
	journal = {Neural Computation},
	keywords = {correlation-learning, machine-learning, inductive-bias, autoencoders},
	number = {2},
	pages = {257--285},
	pdf = {https://www.researchgate.net/profile/Balaraman-Ravindran/publication/275588055_Correlational_Neural_Networks/links/55ed84d308ae21d099c75c00/Correlational-Neural-Networks.pdf},
	publisher = {MIT Press},
	title = {Correlational neural networks},
	venue-short = {NeuralCompJour},
	volume = {28},
	year = {2016}}

@inproceedings{akiba2019sigkdd,
	annote = {Everyone using this in my RL course for tuning hyperparameters of Gymnasium RL algorithms.},
	arxiv = {1907.10902},
	author = {Akiba, Takuya and Sano, Shotaro and Yanase, Toshihiko and Ohta, Takeru and Koyama, Masanori},
	booktitle = {Proceedings of the 25th {ACM} {SIGKDD} International Conference on Knowledge Discovery and Data Mining},
	date-added = {2024-07-31 17:00:34 -0400},
	date-modified = {2024-07-31 17:02:58 -0400},
	hypoth = {https://hyp.is/go?url=https%3A%2F%2Farxiv.org%2Fpdf%2F1907.10902&group=DM67BYBG},
	keywords = {rd-reference; machine-learning; optimization; hyperparameter-tuning},
	order = {5},
	pdf = {https://arxiv.org/pdf/1907.10902},
	title = {Optuna: A Next-generation Hyperparameter Optimization Framework},
	venue-short = {SIGKDD},
	year = {2019}}

@article{WeiKoh,
	abstract = {How can we explain the predictions of a black-box model? In this paper, we use influence func-tions --- a classic technique from robust statis-tics --- to trace a model's prediction through the learning algorithm and back to its training data, thereby identifying training points most respon-sible for a given prediction. To scale up influence functions to modern machine learning settings, we develop a simple, efficient implementation that requires only oracle access to gradients and Hessian-vector products. We show that even on non-convex and non-differentiable models where the theory breaks down, approximations to influ-ence functions can still provide valuable infor-mation. On linear models and convolutional neu-ral networks, we demonstrate that influence func-tions are useful for multiple purposes: under-standing model behavior, debugging models, de-tecting dataset errors, and even creating visually-indistinguishable training-set attacks.},
	author = {{Wei Koh}, Pang and Liang, Percy},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	file = {:C$\backslash$:/Users/mcrowley/Documents/Mendeley Desktop/Wei Koh, Liang - Unknown - Understanding Black-box Predictions via Influence Functions.pdf:pdf},
	keywords = {from-nsercdg2018bib},
	title = {{Understanding Black-box Predictions via Influence Functions}},
	url = {https://arxiv.org/pdf/1703.04730.pdf},
	bdsk-url-1 = {https://arxiv.org/pdf/1703.04730.pdf}}

@inproceedings{DeVries2017,
	abstract = {Dataset augmentation, the practice of applying a wide array of domain-specific transformations to synthetically expand a training set, is a standard tool in supervised learning. While effective in tasks such as visual recognition, the set of transformations must be carefully designed, implemented, and tested for every new domain, limiting its re-use and generality. In this paper, we adopt a simpler, domain-agnostic approach to dataset augmentation. We start with existing data points and apply simple transformations such as adding noise, interpolating, or extrapolating between them. Our main insight is to perform the transformation not in input space, but in a learned feature space. A re-kindling of interest in unsupervised representation learning makes this technique timely and more effective. It is a simple proposal, but to-date one that has not been tested empirically. Working in the space of context vectors generated by sequence-to-sequence models, we demonstrate a technique that is effective for both static and sequential data.},
	address = {Toulon, France},
	archiveprefix = {arXiv},
	arxivid = {1702.05538},
	author = {DeVries, Terrance and Taylor, Graham W.},
	booktitle = {5th International Conference on Learning Representations},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	eprint = {1702.05538},
	file = {:C$\backslash$:/Users/mcrowley/Documents/Mendeley Desktop/DeVries, Taylor - 2017 - Dataset Augmentation in Feature Space.pdf:pdf},
	keywords = {from-nsercdg2018bib},
	month = {feb},
	title = {{Dataset Augmentation in Feature Space}},
	url = {http://arxiv.org/abs/1702.05538},
	year = {2017},
	bdsk-url-1 = {http://arxiv.org/abs/1702.05538}}

@article{Havaei2017c,
	abstract = {In this paper, we present a fully automatic brain tumor segmentation method based on Deep Neural Networks (DNNs). The proposed networks are tailored to glioblastomas (both low and high grade) pictured in MR images. By their very nature, these tumors can appear anywhere in the brain and have almost any kind of shape, size, and contrast. These reasons motivate our exploration of a machine learning solution that exploits a flexible, high capacity DNN while being extremely efficient. Here, we give a description of different model choices that we've found to be necessary for obtaining competitive performance. We explore in particular different architectures based on Convolutional Neural Networks (CNN), i.e. DNNs specifically adapted to image data.We present a novel CNN architecture which differs from those traditionally used in computer vision. Our CNN exploits both local features as well as more global contextual features simultaneously. Also, different from most traditional uses of CNNs, our networks use a final layer that is a convolutional implementation of a fully connected layer which allows a 40 fold speed up. We also describe a 2-phase training procedure that allows us to tackle difficulties related to the imbalance of tumor labels. Finally, we explore a cascade architecture in which the output of a basic CNN is treated as an additional source of information for a subsequent CNN. Results reported on the 2013 BRATS test data-set reveal that our architecture improves over the currently published state-of-the-art while being over 30 times faster.},
	annote = {for brain tumour detection but some good description of how to use CNNs for MRI data and citations to other work being done already. They use the approach I was thinking of, to use each mode or feature of output MRI data as an input layer wit hit's own CNN feature map.},
	archiveprefix = {arXiv},
	arxivid = {1505.03540},
	author = {Havaei, Mohammad and Davy, Axel and Warde-Farley, David and Biard, Antoine and Courville, Aaron and Bengio, Yoshua and Pal, Chris and Jodoin, Pierre Marc and Larochelle, Hugo},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	doi = {10.1016/j.media.2016.05.004},
	eprint = {1505.03540},
	file = {:C$\backslash$:/Users/mcrowley/Documents/Mendeley Desktop/Havaei et al. - 2017 - Brain tumor segmentation with Deep Neural Networks.pdf:pdf},
	issn = {13618423},
	journal = {Medical Image Analysis},
	keywords = {Brain tumor segmentation,Cascaded convolutional neural networks,Convolutional neural networks,Deep neural networks; from-nsercdg2018bib},
	pages = {18--31},
	title = {{Brain tumor segmentation with Deep Neural Networks}},
	url = {http://arxiv.org/abs/1505.03540},
	volume = {35},
	year = {2017},
	bdsk-url-1 = {http://arxiv.org/abs/1505.03540},
	bdsk-url-2 = {https://doi.org/10.1016/j.media.2016.05.004}}

@article{Chung2016e,
	abstract = {Learning both hierarchical and temporal representation has been among the long-standing challenges of recurrent neural networks. Multiscale recurrent neural networks have been considered as a promising approach to resolve this issue, yet there has been a lack of empirical evidence showing that this type of models can actually capture the temporal dependencies by discovering the latent hierarchical structure of the sequence. In this paper, we propose a novel multiscale approach, called the hierarchical multiscale recurrent neural networks, which can capture the latent hierarchical structure in the sequence by encoding the temporal dependencies with different timescales using a novel update mechanism. We show some evidence that our proposed multiscale architecture can discover underlying hierarchical structure in the sequences without using explicit boundary information. We evaluate our proposed model on character-level language modelling and handwriting sequence modelling.},
	annote = {hiearchical representation is improtant for spatial leanring. but hasn't been applied much to temporal. let alone both spatial and temporal},
	archiveprefix = {arXiv},
	arxivid = {1609.01704},
	author = {Chung, Junyoung and Ahn, Sungjin and Bengio, Yoshua},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	eprint = {1609.01704},
	file = {:C$\backslash$:/Users/mcrowley/Documents/Mendeley Desktop/Chung, Ahn, Bengio - 2016 - Hierarchical Multiscale Recurrent Neural Networks.pdf:pdf},
	journal = {Arxiv},
	keywords = {RNNs,deep learning,machine-learning,recurrent neural networks; from-nsercdg2018bib},
	mendeley-tags = {RNNs,deep learning,machine learning,recurrent neural networks},
	month = {sep},
	number = {c},
	pages = {1--13},
	title = {{Hierarchical Multiscale Recurrent Neural Networks}},
	url = {http://arxiv.org/abs/1609.01704},
	year = {2016},
	bdsk-url-1 = {http://arxiv.org/abs/1609.01704}}

@inproceedings{He_2016_CVPR,
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	keywords = {from-nsercdg2018bib},
	month = {jun},
	title = {{Deep Residual Learning for Image Recognition}},
	year = {2016}}

@inproceedings{Brock2016,
	address = {Barcelona, Spain},
	author = {Brock, Andrew and Lim, Theodore and Ritchie, J.M. and Weston, Nick},
	booktitle = {3D Deep Learning Workshop at Neural Information Processing Systems Conference},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	keywords = {from-nsercdg2018bib},
	title = {{Generative and Discriminative Voxel Modeling with Convolutional Neural NetworksNo Title}},
	year = {2016}}

@article{wang2016bayesian,
	annote = {This would be useful for sriram to look at. different ways to optimzie the paramters of rthe simulator once we have a value function that computes prediction error rf the input data

They extend the number of paramters you can deal with to higher dimensions


This paper is also useful for references to older work such ones on using Random Forests for Bayesian Optimization.

Question: can they provide guatantees on error?},
	author = {Wang, Ziyu and Hutter, Frank and Zoghi, Masrour and Matheson, David and de Feitas, Nando},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	file = {:C$\backslash$:/Users/mcrowley/Documents/Mendeley Desktop/Wang et al. - 2016 - Bayesian optimization in a billion dimensions via random embeddings.pdf:pdf},
	journal = {Journal of Artificial Intelligence Research},
	keywords = {from-nsercdg2018bib},
	pages = {361--387},
	title = {{Bayesian optimization in a billion dimensions via random embeddings}},
	volume = {55},
	year = {2016}}

@article{Silver2016,
	author = {Silver, David and Huang, Aja and Maddison, Christopher J and Guez, Arthur and Sifre, Laurent},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	journal = {Nature},
	keywords = {from-nsercdg2018bib},
	pages = {484--503},
	title = {{Mastering the game of Go with deep neural networks and tree search.}},
	volume = {529},
	year = {2016}}

@article{Shi2015,
	author = {Shi, Lei and Gangopadhyay, Aryya and Janeja, Vandana P.},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	doi = {10.1007/s10115-014-0733-3},
	file = {:C$\backslash$:/Users/mcrowley/Documents/Mendeley Desktop/Shi, Gangopadhyay, Janeja - 2015 - STenSr Spatio-temporal tensor streams for anomaly detection and pattern discovery.pdf:pdf},
	issn = {0219-1377},
	journal = {Knowledge and Information Systems},
	keywords = {from-nsercdg2018bib},
	month = {may},
	number = {2},
	pages = {333--353},
	publisher = {Springer London},
	title = {{STenSr: Spatio-temporal tensor streams for anomaly detection and pattern discovery}},
	url = {http://link.springer.com/10.1007/s10115-014-0733-3},
	volume = {43},
	year = {2015},
	bdsk-url-1 = {http://link.springer.com/10.1007/s10115-014-0733-3},
	bdsk-url-2 = {https://doi.org/10.1007/s10115-014-0733-3}}

@article{Martell2015c,
	abstract = {This is a review of recent efforts to develop and implement forest and wildland fire management decision sup- port systems (FMDSS) that fire managers can use to enhance their management of their fire suppression activities. Fire managers need to resolve complex decisions associated with fuel management, fire prevention, detection, the suppression of potentially destructive wildfires and the use of prescribed fire to achieve an appropriate balance between the beneficial and detrimental social, economic and ecological impacts of fire on flammable landscapes, often under considerable uncer- tainty. This review focuses on the use of operational research and management science (OR/MS) methods to address their suppression resource management decision support needs. Keywords},
	author = {Martell, David L},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	doi = {10.1007/s40725-015-0011-y},
	file = {:C$\backslash$:/Users/mcrowley/Documents/Mendeley Desktop/Martell - 2015 - A Review of Recent Forest and Wildland Fire Management Decision Support Systems Research.pdf:pdf},
	journal = {Current Forestry Reports},
	keywords = {wildland fire,forest-wildfire,grant-wici16; from-nsercdg2018bib},
	mendeley-tags = {forestfire,grant-wici16},
	number = {2},
	pages = {128--137},
	title = {{A Review of Recent Forest and Wildland Fire Management Decision Support Systems Research}},
	volume = {1},
	year = {2015},
	bdsk-url-1 = {https://doi.org/10.1007/s40725-015-0011-y}}

@inproceedings{Szegedy2015,
	abstract = {Abstract We propose a deep convolutional neural network architecture codenamed Incep- tion, which was responsible for setting the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC14). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. This was achieved by a carefully crafted design that allows for increasing the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC14 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection.},
	annote = {NULL},
	archiveprefix = {arXiv},
	arxivid = {1409.4842},
	author = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
	booktitle = {IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	doi = {10.1109/CVPR.2015.7298594},
	eprint = {1409.4842},
	file = {:C$\backslash$:/Users/mcrowley/Documents/Mendeley Desktop/Szegedy et al. - 2015 - Going deeper with convolutions.pdf:pdf},
	isbn = {9781467369640},
	issn = {10636919},
	keywords = {from-nsercdg2018bib},
	pages = {1--9},
	pmid = {24920543},
	title = {{Going deeper with convolutions}},
	volume = {07-12-June},
	year = {2015},
	bdsk-url-1 = {https://doi.org/10.1109/CVPR.2015.7298594}}

@article{Szegedy2015,
	abstract = {Abstract We propose a deep convolutional neural network architecture codenamed Incep- tion, which was responsible for setting the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC14). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. This was achieved by a carefully crafted design that allows for increasing the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC14 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection.},
	annote = {NULL},
	archiveprefix = {arXiv},
	arxivid = {1409.4842},
	author = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	doi = {10.1109/CVPR.2015.7298594},
	eprint = {1409.4842},
	isbn = {9781467369640},
	issn = {10636919},
	journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	keywords = {from-nsercdg2018bib},
	pages = {1--9},
	pmid = {24920543},
	title = {{Going deeper with convolutions}},
	volume = {07-12-June},
	year = {2015},
	bdsk-url-1 = {https://doi.org/10.1109/CVPR.2015.7298594}}

@article{Martell2015,
	abstract = {This is a review of recent efforts to develop and implement forest and wildland fire management decision support systems (FMDSS) that fire managers can use to enhance their management of their fire suppression activities. Fire managers need to resolve complex decisions associated with fuel management, fire prevention, detection, the suppression of potentially destructive wildfires and the use of prescribed fire to achieve an appropriate balance between the beneficial and detrimental social, economic and ecological impacts of fire on flammable landscapes, often under considerable uncertainty. This review focuses on the use of operational research and management science (OR/MS) methods to address their suppression resource management decision support needs.},
	annote = {NULL},
	author = {Martell, David L},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	doi = {10.1007/s40725-015-0011-y},
	issn = {2198-6436},
	journal = {Current Forestry Reports},
	keywords = {forest-wildfire,management science,operational research,optimization,planning under uncertainty,suppression resource management,wildland fire,wildland fire; from-nsercdg2018bib},
	mendeley-tags = {forestfire},
	number = {2},
	pages = {128--137},
	title = {{A Review of Recent Forest and Wildland Fire Management Decision Support Systems Research}},
	url = {http://dx.doi.org/10.1007/s40725-015-0011-y{\%}5Cnhttp://link.springer.com/10.1007/s40725-015-0011-y},
	volume = {1},
	year = {2015},
	bdsk-url-1 = {http://dx.doi.org/10.1007/s40725-015-0011-y}}

@inproceedings{Mathieu2015a,
	abstract = {Learning to predict future images from a video sequence involves the construction of an internal representation that models the image evolution accurately, and therefore, to some degree, its content and dynamics. This is why pixel-space video prediction is viewed as a promising avenue for unsupervised feature learning. In this work, we train a convolutional network to generate future frames given an input sequence. To deal with the inherently blurry predictions obtained from the standard Mean Squared Error (MSE) loss function, we propose three different and complementary feature learning strategies: a multi-scale architecture, an adversarial training method, and an image gradient difference loss function. We compare our predictions to different published results based on recurrent neural networks on the UCF101 dataset.},
	address = {San Diego, Calilfornia, USA},
	archiveprefix = {arXiv},
	arxivid = {1511.05440},
	author = {Mathieu, Michael and Couprie, Camille and LeCun, Yann},
	booktitle = {International Conference on Learning Representations},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	eprint = {1511.05440},
	file = {:C$\backslash$:/Users/mcrowley/Documents/Mendeley Desktop/Mathieu, Couprie, LeCun - 2015 - Deep multi-scale video prediction beyond mean square error.pdf:pdf},
	keywords = {from-nsercdg2018bib},
	number = {15},
	title = {{Deep multi-scale video prediction beyond mean square error}},
	url = {http://arxiv.org/abs/1511.05440},
	year = {2015},
	bdsk-url-1 = {http://arxiv.org/abs/1511.05440}}

@article{Castelli2015,
	annote = {NULL},
	author = {Castelli, M and Vanneschi, L and Popovic, a},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	doi = {10.4996/fireecology.110106},
	file = {:C$\backslash$:/Users/mcrowley/Documents/Mendeley Desktop/Castelli, Vanneschi, Popovic - 2015 - Predicting Burned Areas of Forest Firesan Artificial Intelligence Approach.pdf:pdf},
	issn = {1933-9747},
	journal = {Fire Ecology},
	keywords = {Portugal,climatic data,forest-wildfire,genetic programming,semantics; from-nsercdg2018bib},
	number = {1},
	pages = {106--118},
	title = {{Predicting Burned Areas of Forest Fires:an Artificial Intelligence Approach}},
	volume = {11},
	year = {2015},
	bdsk-url-1 = {https://doi.org/10.4996/fireecology.110106}}

@article{SchmidhuberNN2015,
	abstract = {In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarizes relevant work, much of it from the previous millennium. Shallow and Deep Learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning {\&} evolutionary computation, and indirect search for short programs encoding deep and large networks.},
	annote = {Published online 2014; based on TR arXiv:1404.7828 [cs.NE]},
	archiveprefix = {arXiv},
	arxivid = {1404.7828},
	author = {Schmidhuber, J{\"{u}}rgen},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:35:58 -0400},
	doi = {10.1016/j.neunet.2014.09.003},
	eprint = {1404.7828},
	file = {:C$\backslash$:/Users/mcrowley/Documents/Mendeley Desktop/Schmidhuber - 2015 - Deep Learning in neural networks An overview(2).pdf:pdf},
	isbn = {0893-6080},
	issn = {18792782},
	journal = {Neural Networks},
	keywords = {Deep learning,Evolutionary computation,reinforcement-learning,Supervised learning,Unsupervised learning; from-nsercdg2018bib; survey},
	pages = {85--117},
	pmid = {25462637},
	title = {{Deep Learning in neural networks: An overview}},
	volume = {61},
	year = {2015},
	bdsk-url-1 = {https://doi.org/10.1016/j.neunet.2014.09.003}}

@inproceedings{Donahue2015,
	abstract = {Models based on deep convolutional networks have dom- inated recent image interpretation tasks; we investigate whether models which are also recurrent, or ``temporally deep'', are effective for tasks involving sequences, visual and otherwise. We develop a novel recurrent convolutional architecture suitable for large-scale visual learning which is end-to-end trainable, and demonstrate the value of these models on benchmark video recognition tasks, image de- scription and retrieval problems, and video narration chal- lenges. In contrast to current models which assume a fixed spatio-temporal receptive field or simple temporal averag- ing for sequential processing, recurrent convolutional mod- els are ``doubly deep'' in that they can be compositional in spatial and temporal ``layers''. Such models may have advantages when target concepts are complex and/or train- ing data are limited. Learning long-term dependencies is possible when nonlinearities are incorporated into the net- work state updates. Long-term RNN models are appealing in that they directly can map variable-length inputs (e.g., video frames) to variable length outputs (e.g., natural lan- guage text) and can model complex temporal dynamics; yet they can be optimized with backpropagation. Our recurrent long-term models are directly connected to modern visual convnet models and can be jointly trained to simultaneously learn temporal dynamics and convolutional perceptual rep- resentations. Our results show such models have distinct advantages over state-of-the-art models for recognition or generation which are separately defined and/or optimized.},
	archiveprefix = {arXiv},
	arxivid = {arXiv:1411.4389v3},
	author = {Donahue, Jeff and Hendricks, Lisa Anne and Guadarrama, Sergio and Rohrbach, Marcus and Venugopalan, Subhashini and Darrell, Trevor and Saenko, Kate},
	booktitle = {IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	doi = {10.1109/CVPR.2015.7298878},
	eprint = {arXiv:1411.4389v3},
	file = {:C$\backslash$:/Users/mcrowley/Documents/Mendeley Desktop/Donahue et al. - 2015 - Long-term recurrent convolutional networks for visual recognition and description.pdf:pdf},
	isbn = {9781467369640},
	issn = {10636919},
	keywords = {from-nsercdg2018bib},
	pages = {2625--2634},
	pmid = {903},
	title = {{Long-term recurrent convolutional networks for visual recognition and description}},
	volume = {07-12-June},
	year = {2015},
	bdsk-url-1 = {https://doi.org/10.1109/CVPR.2015.7298878}}

@article{Zhang2015a,
	author = {Zhang, Wenlu and Li, Rongjian and Deng, Houtao and Wang, Li and Lin, Weili and Ji, Shuiwang and Shen, Dinggang},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	doi = {10.1126/scisignal.2001449.Engineering},
	file = {:C$\backslash$:/Users/mcrowley/Documents/Mendeley Desktop/Zhang et al. - 2015 - Deep Convolutional Neural Networks for Multi-Modality Isointense Infant Brain Image Segmentation.pdf:pdf},
	isbn = {8585348585},
	issn = {15378276},
	journal = {Neuroimage},
	keywords = {from-nsercdg2018bib},
	number = {108},
	pages = {214--224},
	pmid = {1000000221},
	title = {{Deep Convolutional Neural Networks for Multi-Modality Isointense Infant Brain Image Segmentation}},
	year = {2015},
	bdsk-url-1 = {https://doi.org/10.1126/scisignal.2001449.Engineering}}

@article{Goodfellow2014,
	abstract = {We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.},
	archiveprefix = {arXiv},
	arxivid = {1406.2661},
	author = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	eprint = {1406.2661},
	file = {:C$\backslash$:/Users/mcrowley/Documents/Mendeley Desktop/Goodfellow et al. - 2014 - Generative Adversarial Networks.pdf:pdf},
	keywords = {from-nsercdg2018bib},
	month = {jun},
	title = {{Generative Adversarial Networks}},
	url = {http://arxiv.org/abs/1406.2661},
	year = {2014},
	bdsk-url-1 = {http://arxiv.org/abs/1406.2661}}

@incollection{Montgomery2014,
	annote = {NULL},
	author = {Montgomery, Claire},
	booktitle = {The Oxford Handbook of Land Economics},
	chapter = {13},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	editor = {Duke, Joshua M. and Wu, JunJie},
	file = {:C$\backslash$:/Users/mcrowley/Documents/Mendeley Desktop/Montgomery - 2014 - Fire An Agent and a Consequence of Land Use Change.docx:docx;:C$\backslash$:/Users/mcrowley/Documents/Mendeley Desktop/Montgomery - 2014 - Fire An Agent and a Consequence of Land Use Change.pdf:pdf},
	keywords = {forest-management,economics,fire project; from-nsercdg2018bib},
	mendeley-tags = {economics,fire project},
	pages = {281--301},
	publisher = {Oxford University Press},
	title = {{Fire: An Agent and a Consequence of Land Use Change}},
	year = {2014}}

@article{Couprie2013a,
	abstract = {Scene labeling consists in labeling each pixel in an image with the category of the object it belongs to. We propose a method that uses a multiscale convolutional network trained from raw pixels to extract dense feature vectors that encode regions of multiple sizes centered on each pixel. The method alleviates the need for engineered features, and produces a powerful representation that captures texture, shape and contextual information.We report results using multiple post-processing methods to produce the final labeling. Among those, we propose a technique to automatically retrieve, from a pool of segmentation components, an optimal set of components that best explain the scene; these components are arbitrary, e.g. they can be taken from a segmentation tree, or from any family of over-segmentations. The system yields record accuracies on the Sift Flow Dataset (33 classes) and the Barcelona Dataset (170 classes) and near-record accuracy on Stanford Background Dataset (8 classes), while being an order of magnitude faster than competing approaches, producing a 320×240 image labeling in less than a second, including feature extraction.},
	annote = {Maintain learned features at multiple scales as you learn. Use input from lower level to build higher level features. this coud be very useful for us since we aren't just trying to identify objects but learn behavour

mentioend in pinheiro 2013},
	archiveprefix = {arXiv},
	arxivid = {arXiv:1011.1669v3},
	author = {Couprie, Camille and Najman, Laurent and Lecun, Yann},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	doi = {10.1109/TPAMI.2012.231},
	eprint = {arXiv:1011.1669v3},
	file = {:C$\backslash$:/Users/mcrowley/Documents/Mendeley Desktop/Couprie, Najman, Lecun - 2013 - Learning Hierarchical Features for Scene Labeling.pdf:pdf},
	isbn = {0162-8828},
	issn = {01628828},
	journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
	keywords = {Convolutional networks,deep learning,image classification,image segmentation,scene parsing; from-nsercdg2018bib},
	number = {8},
	pages = {1915--1929},
	pmid = {23787344},
	title = {{Learning Hierarchical Features for Scene Labeling}},
	volume = {35},
	year = {2013},
	bdsk-url-1 = {https://doi.org/10.1109/TPAMI.2012.231}}

@article{Guez2013f,
	abstract = {Bayesian planning is a formally elegant approach to learning optimal behaviour under model uncertainty, trading off exploration and exploitation in an ideal way. Unfortunately, planning optimally in the face of uncertainty is notoriously taxing, since the search space is enormous. In this paper we introduce a tractable, sample-based method for approximate Bayes-optimal planning which exploits Monte-Carlo tree search. Our approach avoids expensive applications of Bayes rule within the search tree by sampling models from current beliefs, and furthermore performs this sampling in a lazy manner. This enables it to outperform previous Bayesian model-based reinforcement learning algorithms by a significant margin on several well-known benchmark problems. As we show, our approach can even work in problems with an infinite state space that lie qualitatively out of reach of almost all previous work in Bayesian exploration.},
	annote = {suggested by tom to read on Dec 1 2013, to me, jesse, majid and sean},
	author = {Guez, Arthur and Silver, David and Dayan, Peter},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	doi = {10.1613/jair.4117},
	file = {:C$\backslash$:/Users/mcrowley/Documents/Mendeley Desktop/Guez, Silver, Dayan - 2013 - Scalable and efficient bayes-adaptive reinforcement learning based on Monte-Carlo tree search.pdf:pdf},
	issn = {10769757},
	journal = {Journal of Artificial Intelligence Research},
	keywords = {monte carlo tree search; from-nsercdg2018bib},
	mendeley-tags = {monte carlo tree search},
	pages = {841--883},
	title = {{Scalable and efficient bayes-adaptive reinforcement learning based on Monte-Carlo tree search}},
	volume = {48},
	year = {2013},
	bdsk-url-1 = {https://doi.org/10.1613/jair.4117}}

@article{mnih2013,
	author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin A},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	journal = {CoRR},
	keywords = {from-nsercdg2018bib},
	title = {{Playing Atari with Deep Reinforcement Learning}},
	url = {http://arxiv.org/abs/1312.5602},
	volume = {abs/1312.5},
	year = {2013},
	bdsk-url-1 = {http://arxiv.org/abs/1312.5602}}

@article{Finney2013,
	abstract = {Vamos explorar a base da compreens{\~{a}}o do comportamento dos inc{\^{e}}ndios florestais, com a inten{\c{c}}{\~{a}}o de estimular a curiosidade e promover investiga{\c{c}}{\~{o}}es fundamentais de problemas propaga{\c{c}}{\~{a}}o do fogo que persistem mesmo na presen{\c{c}}a de grandes avan{\c{c}}os de modelagem. Internacionalmente, muitos modelos de inc{\^{e}}ndio foram desenvolvidos com base em uma variedade de suposi{\c{c}}{\~{o}}es e express{\~{o}}es para os processos fundamentais de transfer{\^{e}}ncia de calor e de combust{\~{a}}o. A diversidade desses pressupostos levanta a quest{\~{a}}o de saber se a aus{\^{e}}ncia de uma teoria rigorosa e propaga{\c{c}}{\~{a}}o do fogo coerente {\'{e}} parcialmente respons{\'{a}}vel. Vamos explorar a tese de que, sem um entendimento comum do que ocorrer processos e como eles ocorrem, modelo de confiabilidade n{\~{a}}o pode ser confirmada. Uma teoria {\'{e}} definida como um conjunto de hip{\'{o}}teses logicamente conectados que fornecem uma explica{\c{c}}{\~{a}}o coerente sobre algum aspecto da realidade. Modelos implementar teoria para um prop{\'{o}}sito particular, incluindo hip{\'{o}}teses de fen{\^{o}}menos e aplica{\c{c}}{\~{o}}es pr{\'{a}}ticas, tais como previs{\~{a}}o. Enfatizamos a necessidade de teoria e demonstrar a diferen{\c{c}}a entre a teoria ea modelagem. Cada vez mais sofisticado controle de fogo requer capacidades de modelagem bem al{\'{e}}m da base fundamental dos modelos atuais. Esses recursos s{\'{o}} podem ser alcan{\c{c}}ados com a pesquisa fundamental o comportamento do fogo. Al{\'{e}}m disso, as possibilidades bem como limita{\c{c}}{\~{o}}es para a modela{\c{c}}{\~{a}}o pode n{\~{a}}o ser conhecida ou cognosc{\'{i}}vel sem primeiro ter a teoria.},
	annote = {NULL},
	author = {Finney, Mark A. and Cohen, Jack D. and McAllister, Sara S. and Jolly, W. Matt},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	doi = {10.1071/WF11117},
	file = {:C$\backslash$:/Users/mcrowley/Documents/Mendeley Desktop/Finney et al. - 2013 - On the need for a theory of wildland fire spread.pdf:pdf},
	issn = {10498001},
	journal = {International Journal of Wildland Fire},
	keywords = {fire behaviour,fuel ignition,heat transfer,live fuels; from-nsercdg2018bib},
	number = {1},
	pages = {25--36},
	title = {{On the need for a theory of wildland fire spread}},
	volume = {22},
	year = {2013},
	bdsk-url-1 = {https://doi.org/10.1071/WF11117}}

@inproceedings{Moldovan2012b,
	abstract = {In environments with uncertain dynamics exploration is necessary to learn how to perform well. Existing reinforcement learning algorithms provide strong exploration guarantees, but they tend to rely on an ergodicity assumption. The essence of ergodicity is that any state is eventually reachable from any other state by following a suitable policy. This assumption allows for exploration algorithms that operate by simply favoring states that have rarely been visited before. For most physical systems this assumption is impractical as the systems would break before any reasonable exploration has taken place, i.e., most physical systems don't satisfy the ergodicity assumption. In this paper we address the need for safe exploration methods in Markov decision processes. We first propose a general formulation of safety through ergodicity. We show that imposing safety by restricting attention to the resulting set of guaranteed safe policies is NP-hard. We then present an efficient algorithm for guaranteed safe, but potentially suboptimal, exploration. At the core is an optimization formulation in which the constraints restrict attention to a subset of the guaranteed safe policies and the objective favors exploration policies. Our framework is compatible with the majority of previously proposed exploration methods, which rely on an exploration bonus. Our experiments, which include a Martian terrain exploration problem, show that our method is able to explore better than classical exploration methods.},
	archiveprefix = {arXiv},
	arxivid = {1205.4810},
	author = {Moldovan, Teodor Mihai and Abbeel, Pieter},
	booktitle = {Proceedings of the 29th International Conference on Machine Learning},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	eprint = {1205.4810},
	file = {:C$\backslash$:/Users/mcrowley/Documents/Mendeley Desktop/Moldovan, Abbeel - 2012 - Safe Exploration in Markov Decision Processes.pdf:pdf},
	isbn = {978-1-4503-1285-1},
	keywords = {ICML,exploration,machine-learning,planning,safe,safety; planning; from-nsercdg2018bib},
	mendeley-tags = {mdp planning},
	month = {may},
	title = {{Safe Exploration in Markov Decision Processes}},
	url = {http://arxiv.org/abs/1205.4810},
	year = {2012},
	bdsk-url-1 = {http://arxiv.org/abs/1205.4810}}

@article{browne2012survey,
	author = {Browne, Cameron B and Powley, Edward and Whitehouse, Daniel and Lucas, Simon M and Cowling, Peter I and Rohlfshagen, Philipp and Tavener, Stephen and Perez, Diego and Samothrakis, Spyridon and Colton, Simon},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	journal = {IEEE Transactions on Computational Intelligence and AI in games},
	keywords = {from-nsercdg2018bib},
	number = {1},
	pages = {1--43},
	publisher = {IEEE},
	title = {{A survey of monte carlo tree search methods}},
	volume = {4},
	year = {2012}}

@book{Murphy2012,
	author = {Murphy, Kevin},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	keywords = {machine-learning,seminal, deep-learning, probabilistic-inference, theory, artificial-intelligence, foundational; from-nsercdg2018bib},
	mendeley-tags = {lect7,machine learning,seminal},
	publisher = {MIT Press},
	title = {{Machine Learning: A Probabilistic Perspective}},
	url = {http://www.amazon.com/Machine-Learning-Probabilistic-Perspective-Computation/dp/0262018020},
	year = {2012},
	bdsk-url-1 = {http://www.amazon.com/Machine-Learning-Probabilistic-Perspective-Computation/dp/0262018020}}

@article{li2011application,
	author = {Li, Jin and Heap, Andrew D and Potter, Anna and Daniell, James J},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	journal = {Environmental Modelling {\&} Software},
	keywords = {from-nsercdg2018bib},
	number = {12},
	pages = {1647--1659},
	publisher = {Elsevier},
	title = {{Application of machine learning methods to spatial interpolation of environmental variables}},
	volume = {26},
	year = {2011}}

@inproceedings{pmlr-v15-bengio11b,
	abstract = {Recent theoretical and empirical work in statistical machine learning has demonstrated the potential of learning algorithms for deep architectures, i.e., function classes obtained by composing multiple levels of representation. The hypothesis evaluated here is that intermediate levels of representation, because they can be shared across tasks and examples from different but related distributions, can yield even more benefits. Comparative experiments were performed on a large-scale handwritten character recognition setting with 62 classes (upper case, lower case, digits), using both a multi-task setting and perturbed examples in order to obtain out-of-distribution examples. The results agree with the hypothesis, and show that a deep learner did $\backslash$em beat previously published results and reached human-level performance. [pdf]},
	address = {Fort Lauderdale, FL, USA},
	author = {Bengio, Yoshua and Bastien, Frederic and Bergeron, Arnaud},
	booktitle = {Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	editor = {Gordon, Geoffrey and Dunson, David and Dud{\'{i}}k, Miroslav},
	keywords = {from-nsercdg2018bib},
	pages = {164--172},
	publisher = {PMLR},
	series = {Proceedings of Machine Learning Research},
	title = {{Deep Learners Benefit More from Out-of-Distribution Examples}},
	url = {http://proceedings.mlr.press/v15/bengio11b.html},
	volume = {15},
	year = {2011},
	bdsk-url-1 = {http://proceedings.mlr.press/v15/bengio11b.html}}

@inproceedings{Asmuth2011,
	abstract = {Bayes-optimal behavior, while well-defined, is often difficult to achieve. Recent advances in the use of Monte-Carlo tree search (MCTS) have shown that it is possible to act near-optimally in Markov Decision Processes (MDPs) with very large or infinite state spaces. Bayes-optimal behavior in an unknown MDP is equivalent to optimal behavior in the known belief-space MDP, although the size of this belief-space MDP grows exponentially with the amount of history retained, and is potentially infinite. We show how an agent can use one particular MCTS algorithm, Forward Search Sparse Sampling (FSSS), in an efficient way to act nearly Bayes-optimally for all but a polynomial number of steps, assuming that FSSS can be used to act efficiently in any possible underlying MDP.},
	annote = {big on maintaining bounds as it leanrs},
	archiveprefix = {arXiv},
	arxivid = {1202.3699},
	author = {Asmuth, John and Littman, Michael L},
	booktitle = {Uai},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	eprint = {1202.3699},
	file = {:C$\backslash$:/Users/mcrowley/Documents/Mendeley Desktop/Asmuth, Littman - 2011 - Learning is planning near Bayes-optimal reinforcement learning via Monte-Carlo tree search.pdf:pdf},
	isbn = {978-0-9749039-7-2},
	keywords = {dblp; from-nsercdg2018bib},
	pages = {19--26},
	title = {{Learning is planning: near Bayes-optimal reinforcement learning via Monte-Carlo tree search.}},
	url = {http://dblp.uni-trier.de/db/conf/uai/uai2011.html{\#}AsmuthL11},
	year = {2011},
	bdsk-url-1 = {http://dblp.uni-trier.de/db/conf/uai/uai2011.html%7B%5C#%7DAsmuthL11}}

@article{Janeja2010,
	author = {Janeja, Vandana P. and Adam, Nabil R. and Atluri, Vijayalakshmi and Vaidya, Jaideep},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	doi = {10.1007/s10618-009-0147-0},
	file = {:C$\backslash$:/Users/mcrowley/Documents/Mendeley Desktop/Janeja et al. - 2010 - Spatial neighborhood based anomaly detection in sensor datasets.pdf:pdf},
	issn = {1384-5810},
	journal = {Data Mining and Knowledge Discovery},
	keywords = {from-nsercdg2018bib},
	month = {mar},
	number = {2},
	pages = {221--258},
	publisher = {Springer US},
	title = {{Spatial neighborhood based anomaly detection in sensor datasets}},
	url = {http://link.springer.com/10.1007/s10618-009-0147-0},
	volume = {20},
	year = {2010},
	bdsk-url-1 = {http://link.springer.com/10.1007/s10618-009-0147-0},
	bdsk-url-2 = {https://doi.org/10.1007/s10618-009-0147-0}}

@inproceedings{Walsh2010a,
	address = {Atlanta, GA},
	annote = {Summary: This is the paper defining the PAC MDP planning algorithm FSSS. They show how to use approximate, sample based MDP solvers to learn a dynamics model that is sample efficient without being impacted by the size of the state space. Works on factorered MDPs


Great overview of model-based RL, sample based, UCT and others.



Sampling Based planning models the Q value function in terms of how many steps ahead the (s,a) is. So you learn a value function that estimates how much you'll get for taking certain actions in the near future and you stop at a fixed horizon. This is always useful when making decisions and it stretches out the value function a bit.},
	author = {Walsh, Thomas J and Goschin, Sergiu and Littman, Michael L},
	booktitle = {Twenty-Fourth AAAI Conference on Artificial Intelligence},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:35:39 -0400},
	file = {:C$\backslash$:/Users/mcrowley/Documents/Mendeley Desktop//Walsh, Goschin, Littman - 2010 - Integrating Sample-based Planning and Model-based Reinforcement Learning.pdf:pdf},
	keywords = {invasive species,reinforcement-learning; from-nsercdg2018bib; rdgrp-ece750T4-f24},
	mendeley-tags = {invasive species},
	title = {{Integrating Sample-based Planning and Model-based Reinforcement Learning}},
	year = {2010}}

@article{Konoshima2010b,
	author = {Konoshima, Masashi and Albers, Heidi J. and Montgomery, Claire a. and Arthur, Jeffrey L.},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	doi = {10.1139/X09-176},
	file = {:C$\backslash$:/Users/mcrowley/Documents/Mendeley Desktop/Konoshima et al. - 2010 - Optimal spatial patterns of fuel management and timber harvest with fire risk.pdf:pdf},
	issn = {0045-5067},
	journal = {Canadian Journal of Forest Research},
	keywords = {from-nsercdg2018bib},
	month = {jan},
	number = {1},
	pages = {95--108},
	title = {{Optimal spatial patterns of fuel management and timber harvest with fire risk}},
	url = {http://www.nrcresearchpress.com/doi/abs/10.1139/X09-176},
	volume = {40},
	year = {2010},
	bdsk-url-1 = {http://www.nrcresearchpress.com/doi/abs/10.1139/X09-176},
	bdsk-url-2 = {https://doi.org/10.1139/X09-176}}

@book{szepesvari2010,
	annote = {see external file for notes},
	author = {Szepesv{\'{a}}ri, Csaba},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:35:34 -0400},
	edition = {Lecture {\#}9},
	editor = {Brachman, Ronald J. and Dietterich, Thomas},
	file = {:C$\backslash$:/Users/mcrowley/Documents/Mendeley Desktop//Szepesv{\'{a}}ri - 2010 - Algorithms for Reinforcement Learning.pdf:pdf},
	keywords = {reinforcement-learning,spatemp; from-nsercdg2018bib; rdgrp-ece750T4-f24},
	publisher = {Morgan {\&} Claypool},
	series = {Synthesis Lectures on Artificial Intelligence and Machine Learning},
	title = {{Algorithms for Reinforcement Learning}},
	year = {2010}}

@article{Fields2010,
	author = {Fields, R.D.},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	journal = {Science},
	keywords = {from-nsercdg2018bib},
	number = {6005},
	pages = {768--769},
	title = {{Change in the Brain's White Matter}},
	volume = {330},
	year = {2010}}

@article{Taylor2010a,
	abstract = {We address the problem of learning good features for understanding video data. We introduce a model that learns latent representations of image sequences from pairs of successive images. The convolutional architecture of our model allows it to scale to realistic image sizes whilst using a compact parametrization. In experiments on the NORB dataset, we show our model extracts latent ``flow fields'' which correspond to the transformation between the pair of input frames. We also use our model to extract low-level motion features in a multi-stage architecture for action recognition, demonstrating competitive performance on both the KTH and Hollywood2 datasets.},
	annote = {learning good features from video data which represent changes between adjacent frames.

TODO: read it , get pardis to look at it},
	author = {Taylor, Graham W. and Fergus, Rob and LeCun, Yann and Bregler, Christoph},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	doi = {10.1007/978-3-642-15567-3_11},
	file = {:C$\backslash$:/Users/mcrowley/Documents/Mendeley Desktop/Taylor et al. - 2010 - Convolutional learning of spatio-temporal features.pdf:pdf},
	isbn = {3642155669},
	issn = {03029743},
	journal = {Lecture Notes in Computer Science},
	keywords = {activity recognition,convolutional nets,optical flow,restricted Boltzmann machines,unsupervised learning,video analysis; from-nsercdg2018bib},
	number = {6},
	pages = {140--153},
	title = {{Convolutional learning of spatio-temporal features}},
	volume = {6316},
	year = {2010},
	bdsk-url-1 = {https://doi.org/10.1007/978-3-642-15567-3_11}}

@article{Petersen2010,
	abstract = {BACKGROUND Neuroimaging measures and chemical biomarkers may be important indices of clinical progression in normal aging and mild cognitive impairment (MCI) and need to be evaluated longitudinally. OBJECTIVE To characterize cross-sectionally and longitudinally clinical measures in normal controls, subjects with MCI, and subjects with mild Alzheimer disease (AD) to enable the assessment of the utility of neuroimaging and chemical biomarker measures. METHODS A total of 819 subjects (229 cognitively normal, 398 with MCI, and 192 with AD) were enrolled at baseline and followed for 12 months using standard cognitive and functional measures typical of clinical trials. RESULTS The subjects with MCI were more memory impaired than the cognitively normal subjects but not as impaired as the subjects with AD. Nonmemory cognitive measures were only minimally impaired in the subjects with MCI. The subjects with MCI progressed to dementia in 12 months at a rate of 16.5{\%} per year. Approximately 50{\%} of the subjects with MCI were on antidementia therapies. There was minimal movement on the Alzheimer's Disease Assessment Scale-Cognitive Subscale for the normal control subjects, slight movement for the subjects with MCI of 1.1, and a modest change for the subjects with AD of 4.3. Baseline CSF measures of Abeta-42 separated the 3 groups as expected and successfully predicted the 12-month change in cognitive measures. CONCLUSION The Alzheimer's Disease Neuroimaging Initiative has successfully recruited cohorts of cognitively normal subjects, subjects with mild cognitive impairment (MCI), and subjects with Alzheimer disease with anticipated baseline characteristics. The 12-month progression rate of MCI was as predicted, and the CSF measures heralded progression of clinical measures over 12 months.},
	author = {Petersen, R. C. and Aisen, P. S. and Beckett, L. A. and Donohue, M. C. and Gamst, A. C. and Harvey, D. J. and Jack, C. R. and Jagust, W. J. and Shaw, L. M. and Toga, A. W. and Trojanowski, J. Q. and Weiner, M. W.},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	doi = {10.1212/WNL.0b013e3181cb3e25},
	issn = {0028-3878},
	journal = {Neurology},
	keywords = {from-nsercdg2018bib},
	month = {jan},
	number = {3},
	pages = {201--209},
	pmid = {20042704},
	title = {{Alzheimer's Disease Neuroimaging Initiative (ADNI): Clinical characterization}},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/20042704 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2809036 http://www.neurology.org/cgi/doi/10.1212/WNL.0b013e3181cb3e25},
	volume = {74},
	year = {2010},
	bdsk-url-1 = {http://www.ncbi.nlm.nih.gov/pubmed/20042704%20http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2809036%20http://www.neurology.org/cgi/doi/10.1212/WNL.0b013e3181cb3e25},
	bdsk-url-2 = {https://doi.org/10.1212/WNL.0b013e3181cb3e25}}

@inproceedings{forsell2009reinforcement,
	author = {Forsell, N and Garcia, F and Sabbadin, R},
	booktitle = {18 th World IMACS / MODSIM Congress},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	file = {:C$\backslash$:/Users/mcrowley/Documents/Mendeley Desktop/Forsell, Garcia, Sabbadin - 2009 - Reinforcement learning for spatial processes.pdf:pdf},
	keywords = {forest-management,planning,planning,spatialplanning,spattemp; reinforcement-learning; from-nsercdg2018bib},
	pages = {755--761},
	title = {{Reinforcement learning for spatial processes}},
	url = {http://www.mssanz.org.au/modsim09/C1/forsell.pdf},
	year = {2009},
	bdsk-url-1 = {http://www.mssanz.org.au/modsim09/C1/forsell.pdf}}

@article{Wei2008,
	annote = {This was one of the inspirations for Sean and Tom's approach to the Fire Project. We may want to compare to it.



Question: are the decisions all made at one time? at the beginning of the fire season and just one year is simulated? They don't talk about time at all so it must be. Yes




Question: When applying the four cell optimized model to a problem with 600 cells is there any flaw in having each cell be learned and applied multiple times, somtimes a cell is 'cell 1' and other times it is 'cell 4'?



Equation 8 ties together all the CR variables, risk of fire, by the actions that are taken, which is just what would happen after inference in a graphical model.



Fire modelled with two components: ignition risk and spread risk


I agree with their general approach: learn a general statistical policy of when to clear fuel rather than reacting to specific fires. Learn to reasc tto a risk field taht changes over time and generalizes well. But they make alot of simplifying assumptions to get the MIP formulation working, are they are all necessary? Can a dyanmic but approximate model work just as well without the vast simplifications?},
	author = {Wei, Yu and Rideout, Douglas and Kirsch, Andy},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	doi = {10.1139/X07-162},
	file = {:C$\backslash$:/Users/mcrowley/Documents/Mendeley Desktop//Wei, Rideout, Kirsch - 2008 - An optimization model for locating fuel treatments across a landscape to reduce expected fire losses.pdf:pdf},
	issn = {0045-5067},
	journal = {Canadian Journal of Forest Research},
	keywords = {fire project,integer programming,planning,optimization,planning; reinforcement-learning; from-nsercdg2018bib},
	mendeley-tags = {fire project},
	month = {apr},
	number = {4},
	pages = {868--877},
	title = {{An optimization model for locating fuel treatments across a landscape to reduce expected fire losses}},
	url = {http://www.nrcresearchpress.com/doi/abs/10.1139/X07-162},
	volume = {38},
	year = {2008},
	bdsk-url-1 = {http://www.nrcresearchpress.com/doi/abs/10.1139/X07-162},
	bdsk-url-2 = {https://doi.org/10.1139/X07-162}}

@article{Li2008c,
	abstract = {We introduce a learning framework that combines elements of the well-known
PAC and mistake-bound models. The KWIK (knows what it knows) framework
was designed particularly for its utility in learning settings where
active exploration can impact the training examples the learner is
exposed to, as is true in reinforcement-learning and active-learning
problems. We catalog several KWIK-learnable classes and open problems.},
	author = {Li, Lihong and Littman, Michael and Walsh, Thomas J},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	doi = {http://doi.acm.org/10.1145/1390156.1390228},
	file = {:C$\backslash$:/Users/mcrowley/Documents/Mendeley Desktop/Li, Littman, Walsh - 2008 - Knows What It Knows A Framework For Self-Aware Learning.pdf:pdf},
	isbn = {978-1-60558-205-4},
	journal = {Proceedings of the 25th International Conference on Machine Learning},
	keywords = {seminal; from-nsercdg2018bib},
	mendeley-tags = {seminal},
	pages = {568--575},
	title = {{Knows What It Knows: A Framework For Self-Aware Learning}},
	year = {2008},
	bdsk-url-1 = {http://doi.acm.org/10.1145/1390156.1390228}}

@article{Wedeen2008,
	author = {Wedeen, J.V. and Wang, R. and Schmahmann, J. D. and Benner, T. and Tseng, W. and Dai, G. and Pandya, G. and Hagmann, P. and D'Arceuil, H and de Crespign, A. J.},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	journal = {Neuroimage},
	keywords = {from-nsercdg2018bib},
	number = {4},
	pages = {1267--1277},
	title = {{Diffusion spectrum magnetic resonance imaging (DSI) tractography of crossing fibers.}},
	volume = {41},
	year = {2008}}

@book{Prince2006,
	address = {Upper Saddle River, New Jersey},
	author = {Prince, J.L. and Links, J.M.},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	keywords = {from-nsercdg2018bib},
	publisher = {Pearson Prentice Hall},
	title = {{Medical Imaging Signals and Systems}},
	year = {2006}}

@inproceedings{Kocsis2006,
	abstract = {For large state-space Markovian Decision Problems Monte-Carlo planning is one of the few viable approaches to find near-optimal solutions. In this paper we introduce a new algorithm, UCT, that applies bandit ideas to guide Monte-Carlo planning. In finite-horizon or discounted MDPs the algorithm is shown to be consistent and finite sample bounds are derived on the estimation error due to sampling. Experimental results show that in several domains, UCT is significantly more efficient than its alternatives.},
	address = {Berlin, Heidelberg},
	author = {Kocsis, Levente and Szepesv{\'{a}}ri, Csaba},
	booktitle = {ECML 2006},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	doi = {10.1007/11871842},
	editor = {F{\"{u}}rnkranz, Johannes and Scheffer, Tobias and Spiliopoulou, Myra},
	isbn = {978-3-540-45375-8},
	keywords = {machine-learning; from-nsercdg2018bib},
	mendeley-tags = {machine learning},
	pages = {282--293},
	publisher = {Springer Berlin Heidelberg},
	series = {Lecture Notes in Computer Science},
	title = {{Bandit Based Monte-Carlo Planning}},
	url = {http://www.springerlink.com/content/d232253353517276/},
	volume = {4212},
	year = {2006},
	bdsk-url-1 = {http://www.springerlink.com/content/d232253353517276/},
	bdsk-url-2 = {https://doi.org/10.1007/11871842}}

@inproceedings{Keogh2002,
	address = {New York, New York, USA},
	author = {Keogh, Eamonn and Lonardi, Stefano and Chiu, Bill 'Yuan-chi'},
	booktitle = {Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '02},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	doi = {10.1145/775047.775128},
	file = {:C$\backslash$:/Users/mcrowley/Documents/Mendeley Desktop/Keogh, Lonardi, Chiu - 2002 - Finding surprising patterns in a time series database in linear time and space.pdf:pdf},
	isbn = {158113567X},
	keywords = {Markov Model,anomaly detection,feature extraction,novelty detection,suffix tree,time series; from-nsercdg2018bib},
	pages = {550},
	publisher = {ACM Press},
	title = {{Finding surprising patterns in a time series database in linear time and space}},
	url = {http://portal.acm.org/citation.cfm?doid=775047.775128},
	year = {2002},
	bdsk-url-1 = {http://portal.acm.org/citation.cfm?doid=775047.775128},
	bdsk-url-2 = {https://doi.org/10.1145/775047.775128}}

@book{sutton:1998uq,
	address = {Cambridge, MA},
	author = {Sutton, Richard S and Barto, Andrew G},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	keywords = {reinforcement-learning,spattemp; from-nsercdg2018bib},
	publisher = {MIT Press},
	title = {{Reinforcement Learning: An Introduction}},
	year = {1998}}

@inproceedings{LeCun1998b,
	abstract = {Multilayer neural networks trained with the back-propagation$\backslash$nalgorithm constitute the best example of a successful gradient based$\backslash$nlearning technique. Given an appropriate network architecture,$\backslash$ngradient-based learning algorithms can be used to synthesize a complex$\backslash$ndecision surface that can classify high-dimensional patterns, such as$\backslash$nhandwritten characters, with minimal preprocessing. This paper reviews$\backslash$nvarious methods applied to handwritten character recognition and$\backslash$ncompares them on a standard handwritten digit recognition task.$\backslash$nConvolutional neural networks, which are specifically designed to deal$\backslash$nwith the variability of 2D shapes, are shown to outperform all other$\backslash$ntechniques. Real-life document recognition systems are composed of$\backslash$nmultiple modules including field extraction, segmentation recognition,$\backslash$nand language modeling. A new learning paradigm, called graph transformer$\backslash$nnetworks (GTN), allows such multimodule systems to be trained globally$\backslash$nusing gradient-based methods so as to minimize an overall performance$\backslash$nmeasure. Two systems for online handwriting recognition are described.$\backslash$nExperiments demonstrate the advantage of global training, and the$\backslash$nflexibility of graph transformer networks. A graph transformer network$\backslash$nfor reading a bank cheque is also described. It uses convolutional$\backslash$nneural network character recognizers combined with global training$\backslash$ntechniques to provide record accuracy on business and personal cheques.$\backslash$nIt is deployed commercially and reads several million cheques per day$\backslash$n},
	annote = {One of the founding papers of the new Deep Learning trend. Using deeply learned neural networks to classify entire documents.},
	archiveprefix = {arXiv},
	arxivid = {1102.0183},
	author = {LeCun, Yann and Bottou, L{\'{e}}on and Bengio, Yoshua and Haffner, Patrick},
	booktitle = {Proceedings of the IEEE},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	doi = {10.1109/5.726791},
	eprint = {1102.0183},
	isbn = {0018-9219},
	issn = {00189219},
	keywords = {CNN,Convolutional neural networks,Deep Learning,Document recognition,Finite state transducers,Gradient-based learning,Graph transformer networks,machine-learning,Neural networks,Optical character recognition (OCR),convolutional neural network,deep learning,machine-learning,seminal; from-nsercdg2018bib},
	mendeley-tags = {CNN,Deep Learning,convolutional neural network,deep learning,machine learning,seminal},
	number = {11},
	pages = {2278--2323},
	pmid = {15823584},
	title = {{Gradient-based learning applied to document recognition}},
	url = {http://ieeexplore.ieee.org/document/726791/},
	volume = {86},
	year = {1998},
	bdsk-url-1 = {http://ieeexplore.ieee.org/document/726791/},
	bdsk-url-2 = {https://doi.org/10.1109/5.726791}}

@article{Jones1998,
	author = {Jones, D and Schonlau, M and Welch, W},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	journal = {Journal of Global Optimization},
	keywords = {from-nsercdg2018bib},
	number = {4},
	pages = {455--492},
	title = {{Efficient global optimization of expensive black-box functions}},
	volume = {13},
	year = {1998}}

@article{Hochreiter1997,
	abstract = {Learning to store information over extended time intervals via recurrent backpropagation takes a very long time, mostly due to insuucient, decaying error back We brieey review Hochreiter's 1991 analysis of this problem, then address it by introducing a novel, eecient, gradient-based method called $\backslash$Long Short-Term Memory" (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete time steps by enforcing constant error through $\backslash$constant error carrousels" within special units. Multiplicative gate units learn to open and close access to the constant error LSTM is local in space and time; its computational complexity per time step and weight is O(1). Our experiments with artiicial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with RTRL, BPTT, Recurrent Cascade-Correlation, Elman nets, and Neural Sequence Chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artiicial long time lag tasks that have never been solved by previous recurrent network algorithms.},
	author = {Hochreiter, Sepp and {Urgen Schmidhuber}, J},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	file = {:C$\backslash$:/Users/mcrowley/Documents/Mendeley Desktop/Hochreiter, Urgen Schmidhuber - 1997 - Long Short-Term Memory.pdf:pdf},
	journal = {Neural Computation},
	keywords = {from-nsercdg2018bib},
	number = {8},
	pages = {1735--1780},
	title = {{Long Short-Term Memory}},
	url = {http://www7.informatik.tu-muenchen.de/{~}hochreit http://www.idsia.ch/{~}juergen},
	volume = {9},
	year = {1997},
	bdsk-url-1 = {http://www7.informatik.tu-muenchen.de/%7B~%7Dhochreit%20http://www.idsia.ch/%7B~%7Djuergen}}

@book{puterman1994,
	author = {Puterman, M},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	keywords = {planning,planning,reinforcement-learning,spatemp,value iteration; from-nsercdg2018bib},
	publisher = {Wiley},
	series = {Wiley Series in Probability and Mathematical Statistics},
	title = {{Markov Decision Processes: Discrete Stochastic Dynamic Programming}},
	year = {1994}}

@article{Watkins1992,
	author = {Watkins, Christopher J.C.H. and Dayan, Peter},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	doi = {10.1023/A:1022676722315},
	issn = {08856125},
	journal = {Machine Learning},
	keywords = {from-nsercdg2018bib},
	number = {3/4},
	pages = {279--292},
	publisher = {Kluwer Academic Publishers-Plenum Publishers},
	title = {{Technical Note: Q-Learning}},
	url = {http://link.springer.com/10.1023/A:1022676722315},
	volume = {8},
	year = {1992},
	bdsk-url-1 = {http://link.springer.com/10.1023/A:1022676722315},
	bdsk-url-2 = {https://doi.org/10.1023/A:1022676722315}}

@article{Schmidhuber1992,
	abstract = {Previous neural network learning algorithms for sequence processing are computationally expensive and perform poorly when it comes to long time lags. This paper first introduces a simple principle for reducing the descriptions of event sequences without loss of information. A consequence of this principle is that only unexpected inputs can be relevant. This insight leads to the construction of neural architectures that learn to ``divide and conquer'' by recursively decomposing sequences. I describe two architectures. The first functions as a self-organizing multilevel hierarchy of recurrent networks. The second, involving only two recurrent networks, tries to collapse a multilevel predictor hierarchy into a single recurrent net. Experiments show that the system can require less computation per time step and many fewer training sequences than conventional training algorithms for recurrent nets.},
	archiveprefix = {arXiv},
	arxivid = {1103.0398},
	author = {Schmidhuber, J{\"{u}}rgen},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:43 -0400},
	doi = {10.1162/neco.1992.4.2.234},
	eprint = {1103.0398},
	isbn = {1532-4435},
	issn = {0899-7667},
	journal = {Neural Computation},
	keywords = {from-nsercdg2018bib},
	number = {2},
	pages = {234--242},
	title = {{Learning Complex, Extended Sequences Using the Principle of History Compression}},
	url = {http://www.mitpressjournals.org/doi/10.1162/neco.1992.4.2.234},
	volume = {4},
	year = {1992},
	bdsk-url-1 = {http://www.mitpressjournals.org/doi/10.1162/neco.1992.4.2.234},
	bdsk-url-2 = {https://doi.org/10.1162/neco.1992.4.2.234}}

@article{Martell1982,
	abstract = {This paper is a comprehensive review of operational research studies in forest fire management during the years 1961 through 1981. It includes a brief discussion of fire management decision making, summaries of and comments regarding the practical merits of the work that has been done, and suggestions concerning future efforts in this field.},
	author = {Martell, D. L.},
	date-added = {2024-07-26 11:29:34 -0400},
	date-modified = {2024-07-26 11:32:23 -0400},
	doi = {10.1139/x82-020},
	file = {:C$\backslash$:/Users/mcrowley/Documents/Mendeley Desktop/Martell - 1982 - A review of operational research studies in forest fire management.pdf:pdf},
	issn = {0045-5067},
	journal = {Canadian Journal of Forest Research},
	keywords = {forest-management; forest-wildfire; survey; from-nsercdg2018bib},
	month = {jun},
	number = {2},
	pages = {119--140},
	publisher = {NRC Research Press Ottawa, Canada},
	title = {{A review of operational research studies in forest fire management}},
	url = {http://www.nrcresearchpress.com/doi/abs/10.1139/x82-020},
	volume = {12},
	year = {1982},
	bdsk-url-1 = {http://www.nrcresearchpress.com/doi/abs/10.1139/x82-020},
	bdsk-url-2 = {https://doi.org/10.1139/x82-020}}

@book{bellman:1957,
	address = {New Jersey},
	author = {Bellman, R},
	bdsk-color = {1},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {rd-foundational; from-paper-beeler2023digidiscjourn; reinforcement-learning; rdgrp-ece750T4-f24},
	publisher = {Princeton University Press},
	temp = {0},
	title = {{Dynamic Programming}},
	year = {1957}}

@article{puterman1978,
	author = {Puterman, Martin L and Shin, Moon Chirl},
	bdsk-color = {1},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {Management Science},
	keywords = {from-paper-beeler2023digidiscjourn; rd-foundational; reinforcement-learning; rdgrp-ece750T4-f24},
	number = {11},
	pages = {pp. 1127--1137},
	temp = {0},
	title = {{Modified Policy Iteration Algorithms for Discounted Markov Decision Problems}},
	volume = {24},
	year = {1978}}

@phdthesis{watkins1989,
	address = {UK},
	author = {Watkins, C J},
	bdsk-color = {1},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {from-paper-beeler2023digidiscjourn; rd-foundational; reinforcement-learning; rdgrp-ece750T4-f24},
	school = {King's College, Cambridge},
	temp = {0},
	title = {{Learning from Delayed Rewards}},
	year = {1989}}

@incollection{Werbos1992,
	author = {Werbos, Paul},
	bdsk-color = {1},
	booktitle = {HANDBOOK OF INTELLIGENT CONTROL},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	editor = {White, David A and Sorge, Donald A},
	keywords = {from-paper-beeler2023digidiscjourn; rd-foundational; reinforcement-learning; rdgrp-ece750T4-f24},
	pages = {65--89},
	temp = {0},
	title = {{Neurocontrol and Supervised Learning: An Overview and Evaluation}},
	year = {1992}}

@article{williams1992,
	author = {Williams, Ronald J},
	bdsk-color = {1},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {Machine Learning},
	keywords = {from-paper-beeler2023digidiscjourn; rd-foundational; reinforcement-learning; reinforce; policy-gradient; rdgrp-ece750T4-f24},
	number = {2},
	pages = {229--256},
	temp = {0},
	title = {{Simple statistical gradient-following algorithms for connectionist reinforcement learning}},
	volume = {8},
	year = {1992}}

@book{bertsekas1996,
	address = {Nashua, NH.},
	author = {Bertsekas, Dimitri P and Tsitsiklis, John N},
	bdsk-color = {1},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {from-paper-beeler2023digidiscjourn; rd-foundational; reinforcement-learning; rdgrp-ece750T4-f24},
	publisher = {Athena Scientific},
	temp = {0},
	title = {{Neuro-Dymanic Programming}},
	year = {1996}}

@article{amari1998,
	author = {Amari, S},
	bdsk-color = {1},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {Neural Computation},
	keywords = {from-paper-beeler2023digidiscjourn; rd-foundational; reinforcement-learning; policy-gradient; rdgrp-ece750T4-f24},
	pages = {251--276},
	temp = {0},
	title = {{Natural gradient works efficiently in learning.}},
	volume = {10},
	year = {1998}}

@book{sutton:1998,
	abbr = {RL Book},
	address = {Cambridge, MA},
	author = {Sutton, R.S. and Barto, A.G.},
	bdsk-color = {1},
	date-added = {2024-07-26 00:17:34 -0400},
	date-discussed = {Sept (6, 13, 20), 2024 by Prof. Mark Crowley for the first few weeks.},
	date-modified = {2024-07-26 11:25:06 -0400},
	edition = {Second},
	keywords = {rd-lectures; rd-current;from-paper-beeler2023digidiscjourn; rd-foundational; rd-reference; reinforcement-learning; rdgrp-ece750T4-f24},
	note = {This is the seminal textbook for the core concepts of Reinforcement Learning. The second edition is free online to read and use. The core concepts will be covered in the first few weeks from this book.},
	order = {1},
	pdf = {http://incompleteideas.net/book/RLbook2020.pdf},
	publisher = {MIT Press},
	temp = {0},
	title = {{Reinforcement Learning: An Introduction}},
	url = {http://incompleteideas.net/book/the-book-2nd.html},
	year = {2018},
	bdsk-url-1 = {http://incompleteideas.net/book/the-book-2nd.html}}

@inproceedings{konda1999actor,
	author = {Konda, Vijay and Tsitsiklis, John},
	bdsk-color = {1},
	booktitle = {Advances in Neural Information Processing Systems},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	editor = {S. Solla and T. Leen and K. M\"{u}ller},
	keywords = {from-paper-beeler2023digidiscjourn; rd-foundational; reinforcement-learning; policy-gradient; rdgrp-ece750T4-f24},
	publisher = {MIT Press},
	temp = {0},
	title = {Actor-Critic Algorithms},
	url = {https://proceedings.neurips.cc/paper_files/paper/1999/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf},
	volume = {12},
	year = {1999},
	bdsk-url-1 = {https://proceedings.neurips.cc/paper_files/paper/1999/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf}}

@article{sutton1999policy,
	author = {Sutton, Richard S and McAllester, David and Singh, Satinder and Mansour, Yishay},
	bdsk-color = {1},
	booktitle = {Advances in Neural Information Processing Systems},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	editor = {S. Solla and T. Leen and K. M\"{u}ller},
	keywords = {from-paper-beeler2023digidiscjourn; rd-foundational; reinforcement-learning; policy-gradient; rdgrp-ece750T4-f24},
	publisher = {MIT Press},
	temp = {0},
	title = {Policy Gradient Methods for Reinforcement Learning with Function Approximation},
	url = {https://proceedings.neurips.cc/paper_files/paper/1999/file/464d828b85b0bed98e80ade0a5c43b0f-Paper.pdf},
	volume = {12},
	year = {1999},
	bdsk-url-1 = {https://proceedings.neurips.cc/paper_files/paper/1999/file/464d828b85b0bed98e80ade0a5c43b0f-Paper.pdf}}

@inproceedings{Peters:2005fk,
	author = {Peters, Jan and Vijayakumar, Sethu and Schaal, Stefan},
	bdsk-color = {1},
	booktitle = {European Conference on Machine Learning},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	editor = {Et. al., J Gama},
	keywords = {from-paper-beeler2023digidiscjourn; rd-foundational; reinforcement-learning; actor-critic; rdgrp-ece750T4-f24},
	pages = {280--291},
	publisher = {Springer Verlag, Berlin},
	series = {Lecture Notes in Computer Science},
	temp = {0},
	title = {{Natural Actor Critic}},
	volume = {3720},
	year = {2005}}

@article{Mnih2015,
	author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei a and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
	bdsk-color = {2},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {Nature},
	keywords = {rd-early; from-paper-beeler2023digidiscjourn; seminal; dqn, deep-learning; deep-reinforcement-learning; atari; reinforcement-learning; rdgrp-ece750T4-f24},
	number = {7540},
	pages = {529--533},
	temp = {0},
	title = {{Human-level control through deep reinforcement learning}},
	volume = {518},
	year = {2015}}

@inproceedings{Mnih2016,
	author = {Mnih, Volodymyr and Badia, Adri{\`{a}} Puigdom{\`{e}}nech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy P. and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
	bdsk-color = {2},
	booktitle = {Proceedings of The 33rd International Conference on Machine Learning (ICML)},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {from-paper-beeler2023digidiscjourn; actor-critic; deep-reinforcement-learning; reinforcement-learning; rdgrp-ece750T4-f24; rd-early},
	pages = {1928--1937},
	temp = {0},
	title = {{Asynchronous Methods for Deep Reinforcement Learning}},
	year = {2016}}

@inproceedings{Schaul2016prioritized,
	author = {Tom Schaul and John Quan and Ioannis Antonoglou and David Silver},
	bdsk-color = {2},
	booktitle = {4th International Conference on Learning Representations, {ICLR} 2016, San Juan, Puerto Rico, May 2-4, 2016, Conference Track Proceedings},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	editor = {Yoshua Bengio and Yann LeCun},
	keywords = {rd-early; from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; dqn; reinforcement-learning; rdgrp-ece750T4-f24},
	temp = {0},
	title = {Prioritized Experience Replay},
	year = {2016}}

@inproceedings{marcin2017hindsight,
	author = {Marcin Andrychowicz and Dwight Crow and Alex Ray and Jonas Schneider and Rachel Fong and Peter Welinder and Bob McGrew and Josh Tobin and Pieter Abbeel and Wojciech Zaremba},
	bdsk-color = {4},
	booktitle = {Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, {USA}},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; rdgrp-ece750T4-f24; rd-middle},
	pages = {5048--5058},
	temp = {0},
	title = {Hindsight Experience Replay},
	year = {2017}}

@inproceedings{haarnoja2018soft,
	author = {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
	bdsk-color = {4},
	booktitle = {International conference on machine learning},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {rd-middle; from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; policy-gradient; rdgrp-ece750T4-f24},
	organization = {PMLR},
	pages = {1861--1870},
	temp = {0},
	title = {Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
	year = {2018}}

@inproceedings{fedus2020revisiting,
	author = {Fedus, William and Ramachandran, Prajit and Agarwal, Rishabh and Bengio, Yoshua and Larochelle, Hugo and Rowland, Mark and Dabney, Will},
	bdsk-color = {6},
	booktitle = {International Conference on Machine Learning},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; rd-later; rdgrp-ece750T4-f24},
	organization = {PMLR},
	pages = {3061--3071},
	title = {Revisiting fundamentals of experience replay},
	year = {2020}}

@book{bellemare2023distributional,
	author = {Bellemare, Marc G and Dabney, Will and Rowland, Mark},
	bdsk-color = {6},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {rd-later; rdgrp-ece750T4-f24; from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	publisher = {MIT Press},
	temp = {0},
	title = {Distributional reinforcement learning},
	year = {2023}}

@article{garcia2015comprehensive,
	author = {Garc{\i}a, Javier and Fern{\'a}ndez, Fernando},
	bdsk-color = {7},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {Journal of Machine Learning Research},
	keywords = {from-paper-beeler2023digidiscjourn; reinforcement-learning; survey; confidence; safety; performance-guarantees},
	number = {1},
	pages = {1437--1480},
	title = {A comprehensive survey on safe reinforcement learning},
	volume = {16},
	year = {2015}}

@article{Young2017,
	author = {Young, Oran R.},
	bdsk-color = {7},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {IEEE SIGNAL PROCESSING MAGAZINE, SPECIAL ISSUE ON DEEP LEARNING FOR IMAGE UNDERSTANDING (ARXIV},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; survey},
	title = {{A Brief Survey of Deep Reinforcement Learning}},
	year = {2017}}

@article{narvekar2020curriculum,
	author = {Narvekar, Sanmit and Peng, Bei and Leonetti, Matteo and Sinapov, Jivko and Taylor, Matthew E and Stone, Peter},
	bdsk-color = {7},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {The Journal of Machine Learning Research},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; survey; curriculum-learning},
	number = {1},
	pages = {7382--7431},
	publisher = {JMLRORG},
	title = {Curriculum learning for reinforcement learning domains: A framework and survey},
	volume = {21},
	year = {2020}}

@article{levine2020offline,
	author = {Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
	bdsk-color = {7},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {arXiv preprint arXiv:2005.01643},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; survey},
	title = {Offline reinforcement learning: Tutorial, review, and perspectives on open problems},
	year = {2020}}

@inproceedings{liu2021policy,
	author = {Liu, Yongshuai and Halev, Avishai and Liu, Xin},
	bdsk-color = {7},
	booktitle = {The 30th International Joint Conference on Artificial Intelligence (IJCAI)},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; survey},
	title = {Policy learning with constraints in model-free reinforcement learning: A survey},
	year = {2021}}

@article{moerland2023model,
	author = {Moerland, Thomas M and Broekens, Joost and Plaat, Aske and Jonker, Catholijn M and others},
	bdsk-color = {7},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {Foundations and Trends{\textregistered} in Machine Learning},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; survey; model-based},
	number = {1},
	pages = {1--118},
	publisher = {Now Publishers, Inc.},
	title = {Model-based reinforcement learning: A survey},
	volume = {16},
	year = {2023}}

@article{Strehl2006,
	author = {Strehl, Alexander L and Wiewiora, Eric and Langford, John and Littman, Michael L},
	bdsk-color = {582077695},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {Update},
	keywords = {from-paper-beeler2023digidiscjourn; reinforcement-learning; performance-guarantees; confidence; rd-potential; rdgrp-ece750T4-f24},
	temp = {0},
	title = {{PAC Model-Free Reinforcement Learning}},
	year = {2006}}

@article{Li2008c,
	author = {Li, Lihong and Littman, Michael and Walsh, Thomas J},
	bdsk-color = {582077695},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {Proceedings of the 25th International Conference on Machine Learning},
	keywords = {from-paper-beeler2023digidiscjourn; reinforcement-learning; rd-potential; rdgrp-ece750T4-f24},
	pages = {568--575},
	temp = {0},
	title = {{Knows What It Knows: A Framework For Self-Aware Learning}},
	year = {2008}}

@article{lillicrap2015continuous,
	author = {Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
	bdsk-color = {582077695},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {arXiv preprint arXiv:1509.02971},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; policy-gradient; rd-potential; rdgrp-ece750T4-f24},
	temp = {0},
	title = {Continuous control with deep reinforcement learning},
	year = {2015}}

@inproceedings{bellemare2017distributional,
	author = {Bellemare, Marc G and Dabney, Will and Munos, R{\'e}mi},
	bdsk-color = {582077695},
	booktitle = {International conference on machine learning},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; rd-potential; rdgrp-ece750T4-f24},
	organization = {PMLR},
	pages = {449--458},
	temp = {0},
	title = {A distributional perspective on reinforcement learning},
	year = {2017}}

@inproceedings{achiam2017constrained,
	author = {Achiam, Joshua and Held, David and Tamar, Aviv and Abbeel, Pieter},
	bdsk-color = {582077695},
	booktitle = {International conference on machine learning},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; rd-potential; rdgrp-ece750T4-f24},
	organization = {PMLR},
	pages = {22--31},
	temp = {0},
	title = {Constrained policy optimization},
	year = {2017}}

@article{kurutach2018model,
	author = {Kurutach, Thanard and Clavera, Ignasi and Duan, Yan and Tamar, Aviv and Abbeel, Pieter},
	bdsk-color = {582077695},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {arXiv preprint arXiv:1802.10592},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; rd-potential; rdgrp-ece750T4-f24},
	title = {Model-ensemble trust-region policy optimization},
	year = {2018}}

@article{yang2019analyzing,
	author = {Yang, Kevin and Swanson, Kyle and Jin, Wengong and Coley, Connor and Eiden, Philipp and Gao, Hua and Guzman-Perez, Angel and Hopper, Timothy and Kelley, Brian and Mathea, Miriam and others},
	bdsk-color = {4230545407},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {Journal of chemical information and modeling},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; digital-chemistry},
	number = {8},
	pages = {3370--3388},
	publisher = {ACS Publications},
	title = {Analyzing learned molecular representations for property prediction},
	volume = {59},
	year = {2019}}

@article{coley2019robotic,
	author = {Coley, Connor W and Thomas III, Dale A and Lummiss, Justin AM and Jaworski, Jonathan N and Breen, Christopher P and Schultz, Victor and Hart, Travis and Fishman, Joshua S and Rogers, Luke and Gao, Hanyu and others},
	bdsk-color = {4230545407},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {Science},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; digital-chemistry},
	number = {6453},
	pages = {eaax1566},
	publisher = {American Association for the Advancement of Science},
	title = {A robotic platform for flow synthesis of organic compounds informed by AI planning},
	volume = {365},
	year = {2019}}

@article{roch2020chemos,
	author = {Roch, Lo{\"\i}c M and H{\"a}se, Florian and Kreisbeck, Christoph and Tamayo-Mendoza, Teresa and Yunker, Lars PE and Hein, Jason E and Aspuru-Guzik, Al{\'a}n},
	bdsk-color = {4247388159},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {PLoS One},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; digital-chemistry},
	number = {4},
	pages = {e0229862},
	publisher = {Public Library of Science San Francisco, CA USA},
	title = {ChemOS: An orchestration software to democratize autonomous discovery},
	volume = {15},
	year = {2020}}

@article{flores2020materials,
	author = {Flores-Leonar, Martha M and Mej{\'\i}a-Mendoza, Luis M and Aguilar-Granda, Andr{\'e}s and Sanchez-Lengeling, Benjamin and Tribukait, Hermann and Amador-Bedolla, Carlos and Aspuru-Guzik, Al{\'a}n},
	bdsk-color = {4247388159},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {Current Opinion in Green and Sustainable Chemistry},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; digital-chemistry},
	pages = {100370},
	publisher = {Elsevier},
	title = {Materials acceleration platforms: On the way to autonomous experimentation},
	volume = {25},
	year = {2020}}

@article{porwol2020autonomous,
	author = {Porwol, Luzian and Kowalski, Daniel J and Henson, Alon and Long, De-Liang and Bell, Nicola L and Cronin, Leroy},
	bdsk-color = {4247388159},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {Angewandte Chemie},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; digital-chemistry},
	number = {28},
	pages = {11352--11357},
	publisher = {Wiley Online Library},
	title = {An autonomous chemical robot discovers the rules of inorganic coordination chemistry without prior knowledge},
	volume = {132},
	year = {2020}}

@inproceedings{gottipati2020learning,
	author = {Gottipati, Sai Krishna and Sattarov, Boris and Niu, Sufeng and Pathak, Yashaswi and Wei, Haoran and Liu, Shengchao and Blackburn, Simon and Thomas, Karam and Coley, Connor and Tang, Jian and others},
	bdsk-color = {4230545407},
	booktitle = {International Conference on Machine Learning},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; digital-chemistry},
	organization = {PMLR},
	pages = {3668--3679},
	title = {Learning to navigate the synthetically accessible chemical space using reinforcement learning},
	year = {2020}}

@article{caramelli2021discovering,
	author = {Caramelli, Dario and Granda, Jaros{\l}aw M and Mehr, S Hessam M and Cambi{\'e}, Dario and Henson, Alon B and Cronin, Leroy},
	bdsk-color = {4247388159},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {ACS Central Science},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; digital-chemistry},
	number = {11},
	pages = {1821--1830},
	publisher = {ACS Publications},
	title = {Discovering new chemistry with an autonomous robotic platform driven by a reactivity-seeking neural network},
	volume = {7},
	year = {2021}}

@article{pyzer2021accelerating,
	author = {Pyzer-Knapp, Edward O and Chen, Linjiang and Day, Graeme M and Cooper, Andrew I},
	bdsk-color = {4247388159},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {Science Advances},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; digital-chemistry},
	number = {33},
	pages = {eabi4763},
	publisher = {American Association for the Advancement of Science},
	title = {Accelerating computational discovery of porous solids through improved navigation of energy-structure-function maps},
	volume = {7},
	year = {2021}}

@article{li2021combining,
	author = {Li, Xiaobo and Maffettone, Phillip M and Che, Yu and Liu, Tao and Chen, Linjiang and Cooper, Andrew I},
	bdsk-color = {4247388159},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {Chemical Science},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; digital-chemistry},
	number = {32},
	pages = {10742--10754},
	publisher = {Royal Society of Chemistry},
	title = {Combining machine learning and high-throughput experimentation to discover photocatalytically active organic molecules},
	volume = {12},
	year = {2021}}

@article{jiang2022artificial,
	author = {Jiang, Yibin and Salley, Daniel and Sharma, Abhishek and Keenan, Graham and Mullin, Margaret and Cronin, Leroy},
	bdsk-color = {4247388159},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {Science Advances},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; digital-chemistry},
	number = {40},
	pages = {eabo2626},
	publisher = {American Association for the Advancement of Science},
	title = {An artificial intelligence enabled chemical synthesis robot for exploration and optimization of nanomaterials},
	volume = {8},
	year = {2022}}

@article{she2022robotic,
	author = {She, Shan and Bell, Nicola L and Zheng, Dazhong and Mathieson, Jennifer S and Castro, Maria D and Long, De-Liang and Koehnke, Jesko and Cronin, Leroy},
	bdsk-color = {4247388159},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {Chem},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; digital-chemistry},
	number = {10},
	pages = {2734--2748},
	publisher = {Elsevier},
	title = {Robotic synthesis of peptides containing metal-oxide-based amino acids},
	volume = {8},
	year = {2022}}

@article{manzano2022autonomous,
	author = {Manzano, J Sebasti{\'a}n and Hou, Wenduan and Zalesskiy, Sergey S and Frei, Przemyslaw and Wang, Hsin and Kitson, Philip J and Cronin, Leroy},
	bdsk-color = {4247388159},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {Nature Chemistry},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; digital-chemistry},
	number = {11},
	pages = {1311--1318},
	publisher = {Nature Publishing Group UK London},
	title = {An autonomous portable platform for universal chemical synthesis},
	volume = {14},
	year = {2022}}

@article{bubliauskas2022digitizing,
	author = {Bubliauskas, Andrius and Blair, Daniel J and Powell-Davies, Henry and Kitson, Philip J and Burke, Martin D and Cronin, Leroy},
	bdsk-color = {4247388159},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {Angewandte Chemie},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; digital-chemistry},
	number = {24},
	pages = {e202116108},
	publisher = {Wiley Online Library},
	title = {Digitizing chemical synthesis in 3D printed reactionware},
	volume = {134},
	year = {2022}}

@inproceedings{pizzuto2022solis,
	author = {Pizzuto, Gabriella and De Berardinis, Jacopo and Longley, Louis and Fakhruldeen, Hatem and Cooper, Andrew I},
	bdsk-color = {4247388159},
	booktitle = {2022 International Joint Conference on Neural Networks (IJCNN)},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; digital-chemistry},
	organization = {IEEE},
	pages = {1--7},
	title = {SOLIS: Autonomous Solubility Screening using Deep Neural Networks},
	year = {2022}}

@inproceedings{fakhruldeen2022archemist,
	author = {Fakhruldeen, Hatem and Pizzuto, Gabriella and Glowacki, Jakub and Cooper, Andrew Ian},
	bdsk-color = {4247388159},
	booktitle = {2022 International Conference on Robotics and Automation (ICRA)},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; digital-chemistry},
	organization = {IEEE},
	pages = {6013--6019},
	title = {Archemist: Autonomous robotic chemistry system architecture},
	year = {2022}}

@inproceedings{fievez2022machine,
	author = {Fievez, Mathilde and Taherimakhsousi, Nina and MacLeod, Benjamin P and Booker, Edward P and Matheron, Muriel and Manceau, Matthieu and Cros, St{\'e}phane and Berson, Solenn and Berlinguette, Curtis P},
	bdsk-color = {4247388159},
	booktitle = {2022 IEEE 49th Photovoltaics Specialists Conference (PVSC)},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; digital-chemistry},
	organization = {IEEE},
	pages = {1072--1072},
	title = {A machine vision tool for facilitating the optimization of large-area perovskite photovoltaics},
	year = {2022}}

@article{macleod2022self,
	author = {MacLeod, Benjamin P and Parlane, Fraser GL and Rupnow, Connor C and Dettelbach, Kevan E and Elliott, Michael S and Morrissey, Thomas D and Haley, Ted H and Proskurin, Oleksii and Rooney, Michael B and Taherimakhsousi, Nina and others},
	bdsk-color = {4230545407},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {Nature communications},
	keywords = {from-paper-beeler2023digidiscjourn; digital-chemistry},
	number = {1},
	pages = {995},
	publisher = {Nature Publishing Group UK London},
	title = {A self-driving laboratory advances the Pareto front for material properties},
	volume = {13},
	year = {2022}}

@incollection{macleod2022flexible,
	author = {MacLeod, Benjamin P and Parlane, Fraser GL and Brown, Amanda K and Hein, Jason E and Berlinguette, Curtis P},
	bdsk-color = {4247388159},
	booktitle = {Accelerated Materials Discovery},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; digital-chemistry},
	pages = {105--122},
	publisher = {De Gruyter},
	title = {Flexible automation for self-driving laboratories},
	year = {2022}}

@article{rooney2022self,
	author = {Rooney, Michael B and MacLeod, Benjamin P and Oldford, Ryan and Thompson, Zachary J and White, Kolby L and Tungjunyatham, Justin and Stankiewicz, Brian J and Berlinguette, Curtis P},
	bdsk-color = {4247388159},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {Digital Discovery},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; digital-chemistry},
	number = {4},
	pages = {382--389},
	publisher = {Royal Society of Chemistry},
	title = {A self-driving laboratory designed to accelerate the discovery of adhesive materials},
	volume = {1},
	year = {2022}}

@article{seifrid2022autonomous,
	author = {Seifrid, Martin and Pollice, Robert and Aguilar-Granda, Andr{\'e}s and Morgan Chan, Zamyla and Hotta, Kazuhiro and Ser, Cher Tian and Vestfrid, Jenya and Wu, Tony C and Aspuru-Guzik, Al{\'a}n},
	bdsk-color = {4247388159},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {Accounts of Chemical Research},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; digital-chemistry},
	number = {17},
	pages = {2454--2466},
	publisher = {ACS Publications},
	title = {Autonomous chemical experiments: Challenges and perspectives on establishing a self-driving lab},
	volume = {55},
	year = {2022}}

@article{bennett2022autonomous,
	author = {Bennett, Jeffrey A and Abolhasani, Milad},
	bdsk-color = {4247388159},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {Current Opinion in Chemical Engineering},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; digital-chemistry},
	pages = {100831},
	publisher = {Elsevier},
	title = {Autonomous chemical science and engineering enabled by self-driving laboratories},
	volume = {36},
	year = {2022}}

@article{yoshikawa2023digital,
	author = {Yoshikawa, Naruki and Darvish, Kourosh and Garg, Animesh and Aspuru-Guzik, Alan},
	bdsk-color = {4247388159},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {ChemRxiv preprint},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; digital-chemistry},
	title = {Digital pipette: Open hardware for liquid transfer in self-driving laboratories},
	year = {2023}}

@unpublished{singh:1993pg,
	author = {Singh, S and Gullapalli, V},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {from-paper-beeler2023digidiscjourn; reinforcement-learning},
	title = {{Asynchronous modified policy iteration with single-sided updates}},
	year = {1993}}

@book{hairer1993solving,
	author = {Hairer, Ernst and N{\o}rsett, Syvert P and Wanner, Gerhard},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {from-paper-beeler2023digidiscjourn; reinforcement-learning},
	publisher = {Springer-Vlg},
	title = {Solving ordinary differential equations. 1, Nonstiff problems},
	year = {1993}}

@article{sutton1999between,
	author = {Sutton, Richard S and Precup, Doina and Singh, Satinder},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {Artificial intelligence},
	keywords = {from-paper-beeler2023digidiscjourn; reinforcement-learning},
	number = {1-2},
	pages = {181--211},
	publisher = {Elsevier},
	title = {Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning},
	volume = {112},
	year = {1999}}

@inproceedings{ng1999policy,
	author = {Andrew Y. Ng and Daishi Harada and Stuart J. Russell},
	booktitle = {Proceedings of the Sixteenth International Conference on Machine Learning {(ICML} 1999), Bled, Slovenia, June 27 - 30, 1999},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {from-paper-beeler2023digidiscjourn; reinforcement-learning},
	pages = {278--287},
	publisher = {Morgan Kaufmann},
	title = {Policy {I}nvariance {U}nder {R}eward {T}ransformations: {T}heory and {A}pplication to {R}eward {S}haping},
	year = {1999}}

@inproceedings{gaskett1999q,
	author = {Gaskett, Chris and Wettergreen, David and Zelinsky, Alexander},
	booktitle = {Australasian joint conference on artificial intelligence},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {from-paper-beeler2023digidiscjourn; reinforcement-learning},
	organization = {Springer},
	pages = {417--428},
	title = {Q-learning in continuous state and action spaces},
	year = {1999}}

@inproceedings{Strens2000,
	author = {Strens, Malcolm and Dera, Mjstrens and Uk, G O V},
	booktitle = {Proceeedings of the Seventeenth International Conference on Machine Learning (ICML-2000)},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {from-paper-beeler2023digidiscjourn; reinforcement-learning},
	title = {{A Bayesian Framework for Reinforcement Learning}},
	year = {2000}}

@article{Diettrich.:2000fk,
	author = {Diettrich., T G},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {Journal of Artificial Intelligence Research},
	keywords = {from-paper-beeler2023digidiscjourn; reinforcement-learning},
	pages = {227--303},
	title = {{Hierarchical reinforcement learning with the maxq value function decomposition.}},
	volume = {13},
	year = {2000}}

@inproceedings{ng2000algorithms,
	address = {Stanford University, Stanford, CA, USA},
	author = {Andrew Y. Ng and Stuart J. Russell},
	booktitle = {ICML, June 29 - July 2, 2000},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {from-paper-beeler2023digidiscjourn; reinforcement-learning},
	pages = {663--670},
	publisher = {Morgan Kaufmann},
	title = {Algorithms for {I}nverse {R}einforcement {L}earning},
	year = {2000}}

@misc{Mihatsch2002,
	author = {Mihatsch, Oliver and Neuneier, Ralph},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {from-paper-beeler2023digidiscjourn; reinforcement-learning},
	title = {{Risk-sensitive reinforcement learning}},
	year = {2002}}

@inproceedings{Guestrin02-CRL-sh,
	author = {Guestrin, Carlos and Lagoudakis, Michail and Parr, Ronald},
	booktitle = {ICML},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {from-paper-beeler2023digidiscjourn; reinforcement-learning},
	pages = {227--234},
	title = {{Coordinated Reinforcement Learning}},
	year = {2002}}

@techreport{u9barto:2003cr,
	author = {Barto, A and Mahadevan, S},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	institution = {University of Massachusetts},
	keywords = {from-paper-beeler2023digidiscjourn; reinforcement-learning; hierarchical-reinforcement-learning},
	title = {{Recent advances in hierarchical reinforcement learning}},
	year = {2003}}

@inproceedings{wiewiora2003principled,
	author = {Eric Wiewiora and Garrison W. Cottrell and Charles Elkan},
	booktitle = {Proceedings of the Twentieth International Conference of Machine Learning {(ICML} 2003), August 21-24, 2003, Washington, DC, {USA}},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {from-paper-beeler2023digidiscjourn; reinforcement-learning},
	pages = {792--799},
	publisher = {{AAAI} Press},
	title = {Principled {M}ethods for {A}dvising {R}einforcement {L}earning {A}gents},
	year = {2003}}

@book{laud2004theory,
	author = {Laud, Adam Daniel},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {from-paper-beeler2023digidiscjourn; reinforcement-learning},
	publisher = {University of Illinois at Urbana-Champaign},
	title = {Theory and application of reward shaping in reinforcement learning},
	year = {2004}}

@inproceedings{Riedmiller:2007fk,
	author = {Riedmiller, Martin and Peters, Jan and Schaal, Stefan},
	booktitle = {IEEE Symposium on Approximate Dynamic Programming and Reinforcement Learning},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {from-paper-beeler2023digidiscjourn; reinforcement-learning; policy-gradient},
	pages = {254--261},
	title = {{Evaluation of Policy Gradient Methods and Variants on the Cart-Pole Benchmark}},
	year = {2007}}

@techreport{Abernethy2008,
	author = {Abernethy, Jacob Duncan and Hazan, Elad and Rakhlin, Alexander},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	institution = {EECS Department, University of California, Berkeley},
	keywords = {from-paper-beeler2023digidiscjourn; reinforcement-learning},
	month = {feb},
	number = {UCB/EECS-2008-18},
	title = {{An Efficient Algorithm for Bandit Linear Optimization}},
	year = {2008}}

@inproceedings{hasselt2010,
	author = {Hasselt, Hado Van and Group, Adaptive Computation and Wiskunde, Centrum},
	booktitle = {Advances in Neural Information Processing Systems 23},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	editor = {Lafferty, J D and Williams, C K I and Shawe-Taylor, J and Zemel, R S and Culotta, A},
	keywords = {from-paper-beeler2023digidiscjourn; reinforcement-learning; q-learning},
	pages = {1--9},
	publisher = {Curran Associates, Inc.},
	title = {{Double Q-learning}},
	year = {2010}}

@book{russell2010artificial,
	author = {Russell, Stuart J},
	bdsk-color = {7},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {from-paper-beeler2023digidiscjourn; rd-reference; reinforcement-learning; rdgrp-ece750T4-f24},
	publisher = {Pearson Education, Inc.},
	temp = {0},
	title = {Artificial intelligence a modern approach},
	year = {2010}}

@inproceedings{todorov2012mujoco,
	author = {Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
	booktitle = {2012 IEEE/RSJ international conference on intelligent robots and systems},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {from-paper-beeler2023digidiscjourn; reinforcement-learning},
	organization = {IEEE},
	pages = {5026--5033},
	title = {Mujoco: A physics engine for model-based control},
	year = {2012}}

@inproceedings{piot2014boosted,
	author = {Piot, Bilal and Geist, Matthieu and Pietquin, Olivier},
	booktitle = {Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2014, Nancy, France, September 15-19, 2014. Proceedings, Part II 14},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {from-paper-beeler2023digidiscjourn; reinforcement-learning},
	organization = {Springer},
	pages = {549--564},
	title = {Boosted bellman residual minimization handling expert demonstrations},
	year = {2014}}

@inproceedings{harutyunyan2015expressing,
	author = {Harutyunyan, Anna and Devlin, Sam and Vrancx, Peter and Now{\'e}, Ann},
	booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	number = {1},
	title = {Expressing arbitrary reward functions as potential-based advice},
	volume = {29},
	year = {2015}}

@inproceedings{hausknecht2015deep,
	author = {Hausknecht, Matthew and Stone, Peter},
	booktitle = {2015 aaai fall symposium series},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	title = {Deep recurrent q-learning for partially observable mdps},
	year = {2015}}

@article{Wang2015dueling,
	author = {Ziyu Wang and Nando de Freitas and Marc Lanctot},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {CoRR},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	pages = {1511},
	title = {Dueling Network Architectures for Deep Reinforcement Learning},
	volume = {abs/1511.06581},
	year = {2015}}

@article{Crawford2016b,
	author = {Crawford, Daniel and Levit, Anna and Ghadermarzy, Navid and Oberoi, Jaspreet S. and Ronagh, Pooya},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	pages = {1--17},
	title = {{Reinforcement Learning Using Quantum Boltzmann Machines}},
	year = {2016}}

@inproceedings{hausknecht2016half,
	author = {Hausknecht, Matthew and Mupparaju, Prannoy and Subramanian, Sandeep and Kalyanakrishnan, Shivaram and Stone, Peter},
	booktitle = {AAMAS Adaptive Learning Agents (ALA) Workshop},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	organization = {sn},
	title = {Half field offense: An environment for multiagent learning and ad hoc teamwork},
	volume = {3},
	year = {2016}}

@article{graves2016hybrid,
	author = {Graves, Alex and Wayne, Greg and Reynolds, Malcolm and Harley, Tim and Danihelka, Ivo and Grabska-Barwi{\'n}ska, Agnieszka and Colmenarejo, Sergio G{\'o}mez and Grefenstette, Edward and Ramalho, Tiago and Agapiou, John and others},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {Nature},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	number = {7626},
	pages = {471--476},
	publisher = {Nature Publishing Group UK London},
	title = {Hybrid computing using a neural network with dynamic external memory},
	volume = {538},
	year = {2016}}

@article{brockman2016openai,
	author = {Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
	bdsk-color = {2491993343},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {arXiv preprint arXiv:1606.01540},
	keywords = {from-paper-beeler2023digidiscjourn; rd-environment; deep-reinforcement-learning; reinforcement-learning; rdgrp-ece750T4-f24},
	title = {Openai gym},
	year = {2016}}

@inproceedings{hasselt2016deep,
	author = {Hado van Hasselt and Arthur Guez and David Silver},
	booktitle = {Proceedings of the Thirtieth {AAAI} Conference on Artificial Intelligence, February 12-17, 2016, Phoenix, Arizona, {USA}},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	editor = {Dale Schuurmans and Michael P. Wellman},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; q-learning; reinforcement-learning},
	pages = {2094--2100},
	publisher = {{AAAI} Press},
	title = {Deep Reinforcement Learning with Double Q-Learning},
	year = {2016}}

@article{Sutton2017,
	author = {Sutton, Richard S and Barto, Andrew G},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {UCL,Computer Science Department, Reinforcement Learning Lectures},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	pages = {1054},
	title = {{Reinforcement learning: an introduction 2018 complete draft}},
	year = {2017}}

@article{schulman2017proximal,
	abbr = {PPO},
	arxiv = {1707.06347},
	author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	hypoth = {https://hyp.is/go?url=https%3A%2F%2Farxiv.org%2Fpdf%2F1707.06347&group=DM67BYBG},
	journal = {arXiv preprint arXiv:1707.06347},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; rd-lectures},
	note = {A pivotal paper for policy gradient methods, proposing a simplified version of the TRPO approach of explicitly treating RL as a policy optimization problem.},
	order = {8},
	pdf = {https://arxiv.org/pdf/1707.06347},
	title = {Proximal policy optimization algorithms},
	year = {2017}}

@article{zhou2017optimizing,
	author = {Zhou, Zhenpeng and Li, Xiaocheng and Zare, Richard N},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {ACS central science},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	number = {12},
	pages = {1337--1344},
	publisher = {ACS Publications},
	title = {Optimizing chemical reactions with deep reinforcement learning},
	volume = {3},
	year = {2017}}

@article{racaniere2017imagination,
	author = {Racani{\`e}re, S{\'e}bastien and Weber, Th{\'e}ophane and Reichert, David and Buesing, Lars and Guez, Arthur and Jimenez Rezende, Danilo and Puigdom{\`e}nech Badia, Adri{\`a} and Vinyals, Oriol and Heess, Nicolas and Li, Yujia and others},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {Advances in neural information processing systems},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	title = {Imagination-augmented agents for deep reinforcement learning},
	volume = {30},
	year = {2017}}

@inproceedings{tessler2017deep,
	author = {Tessler, Chen and Givony, Shahar and Zahavy, Tom and Mankowitz, Daniel and Mannor, Shie},
	booktitle = {Proceedings of the AAAI conference on artificial intelligence},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	number = {1},
	title = {A deep hierarchical approach to lifelong learning in minecraft},
	volume = {31},
	year = {2017}}

@inproceedings{grzes2017reward,
	address = {Richland, SC},
	author = {Grzeundefined, Marek},
	booktitle = {Proceedings of the 16th Conference on Autonomous Agents and MultiAgent Systems},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {reinforcement-learning, potential-based reward shaping, multiagent learning, reward structures for learning, reward shaping; from-paper-beeler2023digidiscjourn; deep-reinforcement-learning},
	location = {S\~{a}o Paulo, Brazil},
	numpages = {9},
	pages = {565--573},
	publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
	series = {AAMAS '17},
	title = {Reward Shaping in Episodic Reinforcement Learning},
	year = {2017}}

@inproceedings{bacon2017option,
	author = {Bacon, Pierre-Luc and Harb, Jean and Precup, Doina},
	booktitle = {Proceedings of the AAAI conference on artificial intelligence},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	number = {1},
	title = {The option-critic architecture},
	volume = {31},
	year = {2017}}

@article{Igl2018,
	author = {Igl, Maximilian and Zintgraf, Luisa and Le, Tuan Anh and Wood, Frank and Whiteson, Shimon},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	title = {{Deep Variational Reinforcement Learning for POMDPs}},
	year = {2018}}

@book{sutton2018reinforcement,
	author = {Sutton, Richard S and Barto, Andrew G},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	publisher = {MIT press},
	title = {Reinforcement learning: An introduction},
	year = {2018}}

@inproceedings{fujimoto2018addressing,
	author = {Fujimoto, Scott and Hoof, Herke and Meger, David},
	booktitle = {International conference on machine learning},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; policy-gradient},
	organization = {PMLR},
	pages = {1587--1596},
	title = {Addressing function approximation error in actor-critic methods},
	year = {2018}}

@inproceedings{silva2018object,
	author = {Silva, Felipe Leno Da and Costa, Anna Helena Reali},
	booktitle = {Proceedings of the 17th international conference on autonomous agents and multiagent systems},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	pages = {1026--1034},
	title = {Object-oriented curriculum generation for reinforcement learning},
	year = {2018}}

@article{kim2018screenernet,
	author = {Kim, Tae-Hoon and Choi, Jonghyun},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {arXiv preprint arXiv:1801.00904},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	title = {Screenernet: Learning self-paced curriculum for deep neural networks},
	year = {2018}}

@article{yang2018cm3,
	author = {Yang, Jiachen and Nakhaei, Alireza and Isele, David and Fujimura, Kikuo and Zha, Hongyuan},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {arXiv preprint arXiv:1809.05188},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	title = {Cm3: Cooperative multi-goal multi-stage multi-agent reinforcement learning},
	year = {2018}}

@inproceedings{lopez2018microscopic,
	author = {Lopez, Pablo Alvarez and Behrisch, Michael and Bieker-Walz, Laura and Erdmann, Jakob and Fl{\"o}tter{\"o}d, Yun-Pang and Hilbrich, Robert and L{\"u}cken, Leonhard and Rummel, Johannes and Wagner, Peter and Wie{\ss}ner, Evamarie},
	booktitle = {2018 21st international conference on intelligent transportation systems (ITSC)},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	organization = {IEEE},
	pages = {2575--2582},
	title = {Microscopic traffic simulation using sumo},
	year = {2018}}

@article{tessler2018reward,
	author = {Tessler, Chen and Mankowitz, Daniel J and Mannor, Shie},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {arXiv preprint arXiv:1805.11074},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	title = {Reward constrained policy optimization},
	year = {2018}}

@inproceedings{dabney2018distributional,
	author = {Dabney, Will and Rowland, Mark and Bellemare, Marc and Munos, R{\'e}mi},
	booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	number = {1},
	title = {Distributional reinforcement learning with quantile regression},
	volume = {32},
	year = {2018}}

@inproceedings{hester2018deep,
	author = {Hester, Todd and Vecerik, Matej and Pietquin, Olivier and Lanctot, Marc and Schaul, Tom and Piot, Bilal and Horgan, Dan and Quan, John and Sendonaris, Andrew and Osband, Ian and others},
	booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	number = {1},
	title = {Deep q-learning from demonstrations},
	volume = {32},
	year = {2018}}

@article{gao2018reinforcement,
	author = {Gao, Yang and Xu, Huazhe and Lin, Ji and Yu, Fisher and Levine, Sergey and Darrell, Trevor},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {arXiv preprint arXiv:1802.05313},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	title = {Reinforcement learning from imperfect demonstrations},
	year = {2018}}

@article{burda2018exploration,
	author = {Burda, Yuri and Edwards, Harrison and Storkey, Amos and Klimov, Oleg},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {arXiv preprint arXiv:1810.12894},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	title = {Exploration by random network distillation},
	year = {2018}}

@article{segler2018planning,
	author = {Segler, Marwin HS and Preuss, Mike and Waller, Mark P},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {Nature},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; digital-chemistry},
	number = {7698},
	pages = {604--610},
	publisher = {Nature Publishing Group UK London},
	title = {Planning chemical syntheses with deep neural networks and symbolic AI},
	volume = {555},
	year = {2018}}

@article{kim2018deep,
	author = {Kim, Kyungdoc and Kang, Seokho and Yoo, Jiho and Kwon, Youngchun and Nam, Youngmin and Lee, Dongseon and Kim, Inkoo and Choi, Youn-Suk and Jung, Yongsik and Kim, Sangmo and others},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {npj Computational Materials},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	number = {1},
	pages = {67},
	publisher = {Nature Publishing Group UK London},
	title = {Deep-learning-based inverse design model for intelligent discovery of organic molecules},
	volume = {4},
	year = {2018}}

@article{xiong2018parametrized,
	author = {Xiong, Jiechao and Wang, Qing and Yang, Zhuoran and Sun, Peng and Han, Lei and Zheng, Yang and Fu, Haobo and Zhang, Tong and Liu, Ji and Liu, Han},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {arXiv preprint arXiv:1810.06394},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; q-learning},
	title = {Parametrized deep q-networks learning: Reinforcement learning with discrete-continuous hybrid action space},
	year = {2018}}

@article{guss2019minerl,
	author = {Guss, William H and Houghton, Brandon and Topin, Nicholay and Wang, Phillip and Codel, Cayden and Veloso, Manuela and Salakhutdinov, Ruslan},
	bdsk-color = {2491993343},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {arXiv preprint arXiv:1907.13440},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; rd-environment; rdgrp-ece750T4-f24},
	title = {Minerl: A large-scale dataset of minecraft demonstrations},
	year = {2019}}

@article{samvelyan2019starcraft,
	author = {Samvelyan, Mikayel and Rashid, Tabish and De Witt, Christian Schroeder and Farquhar, Gregory and Nardelli, Nantas and Rudner, Tim GJ and Hung, Chia-Man and Torr, Philip HS and Foerster, Jakob and Whiteson, Shimon},
	bdsk-color = {4},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {arXiv preprint arXiv:1902.04043},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; rd-middle; rd-environment; rdgrp-ece750T4-f24},
	title = {The starcraft multi-agent challenge},
	year = {2019}}

@article{zha2019experience,
	author = {Zha, Daochen and Lai, Kwei-Herng and Zhou, Kaixiong and Hu, Xia},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {arXiv preprint arXiv:1906.08387},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	title = {Experience replay optimization},
	year = {2019}}

@article{ray2019benchmarking,
	author = {Ray, Alex and Achiam, Joshua and Amodei, Dario},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {arXiv preprint arXiv:1910.01708},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	number = {1},
	pages = {2},
	title = {Benchmarking safe exploration in deep reinforcement learning},
	volume = {7},
	year = {2019}}

@article{wang2019benchmarking,
	author = {Wang, Tingwu and Bao, Xuchan and Clavera, Ignasi and Hoang, Jerrick and Wen, Yeming and Langlois, Eric and Zhang, Shunshi and Zhang, Guodong and Abbeel, Pieter and Ba, Jimmy},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {arXiv preprint arXiv:1907.02057},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	title = {Benchmarking model-based reinforcement learning},
	year = {2019}}

@article{ryu2019caql,
	author = {Ryu, Moonkyung and Chow, Yinlam and Anderson, Ross and Tjandraatmadja, Christian and Boutilier, Craig},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {arXiv preprint arXiv:1909.12397},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	title = {CAQL: Continuous action Q-learning},
	year = {2019}}

@article{fu2020d4rl,
	author = {Fu, Justin and Kumar, Aviral and Nachum, Ofir and Tucker, George and Levine, Sergey},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {arXiv preprint arXiv:2004.07219},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	title = {D4rl: Datasets for deep data-driven reinforcement learning},
	year = {2020}}

@inproceedings{liu2020ipo,
	author = {Liu, Yongshuai and Ding, Jiaxin and Liu, Xin},
	booktitle = {Proceedings of the AAAI conference on artificial intelligence},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	number = {04},
	pages = {4940--4947},
	title = {Ipo: Interior-point policy optimization under constraints},
	volume = {34},
	year = {2020}}

@article{struble2020current,
	author = {Struble, Thomas J and Alvarez, Juan C and Brown, Scott P and Chytil, Milan and Cisar, Justin and DesJarlais, Renee L and Engkvist, Ola and Frank, Scott A and Greve, Daniel R and Griffin, Daniel J and others},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {Journal of medicinal chemistry},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; digital-chemistry},
	number = {16},
	pages = {8667--8682},
	publisher = {ACS Publications},
	title = {Current and future roles of artificial intelligence in medicinal chemistry synthesis},
	volume = {63},
	year = {2020}}

@inproceedings{Lan2020maxmin,
	author = {Qingfeng Lan and Yangchen Pan and Alona Fyshe and Martha White},
	booktitle = {8th International Conference on Learning Representations, {ICLR} 2020, Addis Ababa, Ethiopia, April 26-30, 2020},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	publisher = {OpenReview.net},
	title = {Maxmin Q-learning: Controlling the Estimation Bias of Q-learning},
	year = {2020}}

@article{raffin2021stable,
	author = {Raffin, Antonin and Hill, Ashley and Gleave, Adam and Kanervisto, Anssi and Ernestus, Maximilian and Dormann, Noah},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {The Journal of Machine Learning Research},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	number = {1},
	pages = {12348--12355},
	publisher = {JMLRORG},
	title = {Stable-baselines3: Reliable reinforcement learning implementations},
	volume = {22},
	year = {2021}}

@article{dulac2021challenges,
	author = {Dulac-Arnold, Gabriel and Levine, Nir and Mankowitz, Daniel J and Li, Jerry and Paduraru, Cosmin and Gowal, Sven and Hester, Todd},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {Machine Learning},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	pages = {1--50},
	publisher = {Springer},
	title = {Challenges of real-world reinforcement learning: {D}efinitions, {B}enchmarks and {A}nalysis},
	volume = {1},
	year = {2021}}

@inproceedings{shoham2021solving,
	author = {Shoham, Yaron and Elidan, Gal},
	booktitle = {Proceedings of the International Symposium on Combinatorial Search},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	number = {1},
	pages = {191--193},
	title = {Solving sokoban with forward-backward reinforcement learning},
	volume = {12},
	year = {2021}}

@article{jumper2021highly,
	author = {Jumper, John and Evans, Richard and Pritzel, Alexander and Green, Tim and Figurnov, Michael and Ronneberger, Olaf and Tunyasuvunakool, Kathryn and Bates, Russ and {\v{Z}}{\'\i}dek, Augustin and Potapenko, Anna and others},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {Nature},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	number = {7873},
	pages = {583--589},
	publisher = {Nature Publishing Group UK London},
	title = {Highly accurate protein structure prediction with AlphaFold},
	volume = {596},
	year = {2021}}

@article{zhu2021improved,
	author = {Zhu, Zhengwei and Hu, Can and Zhu, Chenyang and Zhu, Yanping and Sheng, Yu},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {Journal of Marine Science and Engineering},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	number = {11},
	pages = {1267},
	publisher = {MDPI},
	title = {An improved dueling deep double-q network based on prioritized experience replay for path planning of unmanned surface vehicles},
	volume = {9},
	year = {2021}}

@article{chunduru2022attention,
	author = {Chunduru, Raviteja and Precup, Doina},
	bdsk-color = {6},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {arXiv preprint arXiv:2201.02628},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; rd-later; rdgrp-ece750T4-f24},
	title = {Attention option-critic},
	year = {2022}}

@article{angello2022closed,
	author = {Angello, Nicholas H and Rathore, Vandana and Beker, Wiktor and Wo{\l}os, Agnieszka and Jira, Edward R and Roszak, Rafa{\l} and Wu, Tony C and Schroeder, Charles M and Aspuru-Guzik, Al{\'a}n and Grzybowski, Bartosz A and others},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {Science},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	number = {6618},
	pages = {399--405},
	publisher = {American Association for the Advancement of Science},
	title = {Closed-loop optimization of general reaction conditions for heteroaryl Suzuki-Miyaura coupling},
	volume = {378},
	year = {2022}}

@article{greenman2022multi,
	author = {Greenman, Kevin P and Green, William H and G{\'o}mez-Bombarelli, Rafael},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {Chemical science},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; digital-chemistry},
	number = {4},
	pages = {1152--1162},
	publisher = {Royal Society of Chemistry},
	title = {Multi-fidelity prediction of molecular optical peaks with deep learning},
	volume = {13},
	year = {2022}}

@article{m2023digitizing,
	author = {M. Mehr, S Hessam and Caramelli, Dario and Cronin, Leroy},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {Proceedings of the National Academy of Sciences},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	number = {17},
	pages = {e2220045120},
	publisher = {National Acad Sciences},
	title = {Digitizing chemical discovery with a Bayesian explorer for interpreting reactivity data},
	volume = {120},
	year = {2023}}

@article{hickman2023self,
	author = {Hickman, Riley J and Bannigan, Pauric and Bao, Zeqing and Aspuru-Guzik, Al{\'a}n and Allen, Christine},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {Matter},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	number = {4},
	pages = {1071--1081},
	publisher = {Elsevier},
	title = {Self-driving laboratories: A paradigm shift in nanomedicine development},
	volume = {6},
	year = {2023}}

@article{choubisa2023accelerated,
	author = {Choubisa, Hitarth and Abed, Jehad and Mendoza, Douglas and Matsumura, Hidetoshi and Sugimura, Masahiko and Yao, Zhenpeng and Wang, Ziyun and Sutherland, Brandon R and Aspuru-Guzik, Al{\'a}n and Sargent, Edward H},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {Matter},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	number = {2},
	pages = {605--625},
	publisher = {Elsevier},
	title = {Accelerated chemical space search using a quantum-inspired cluster expansion approach},
	volume = {6},
	year = {2023}}

@article{volk2023alphaflow,
	author = {Volk, Amanda A and Epps, Robert W and Yonemoto, Daniel T and Masters, Benjamin S and Castellano, Felix N and Reyes, Kristofer G and Abolhasani, Milad},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {Nature Communications},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; digital-chemistry},
	number = {1},
	pages = {1403},
	publisher = {Nature Publishing Group UK London},
	title = {AlphaFlow: autonomous discovery and optimization of multi-step chemistry using a self-driven fluidic lab guided by reinforcement learning},
	volume = {14},
	year = {2023}}

@article{morad2023popgym,
	author = {Morad, Steven and Kortvelesy, Ryan and Bettini, Matteo and Liwicki, Stephan and Prorok, Amanda},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {arXiv preprint arXiv:2303.01859},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	title = {POPGym: Benchmarking Partially Observable Reinforcement Learning},
	year = {2023}}

@article{nature2023research,
	author = {Editorial},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {Nature},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	number = {438},
	title = {For chemists, the AI revolution has yet to happen},
	volume = {617},
	year = {2023}}

@article{beeler2023chemgymrl,
	author = {Beeler, Chris and Subramanian, Sriram Ganapathi and Sprague, Kyle and Chatti, Nouha and Bellinger, Colin and Shahen, Mitchell and Paquin, Nicholas and Baula, Mark and Dawit, Amanuel and Yang, Zihan and others},
	bdsk-color = {2},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {arXiv preprint arXiv:2305.14177},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; digital-chemistry; rdgrp-ece750T4-f24; rd-environment; rd-early},
	self = {1},
	title = {ChemGymRL: An Interactive Framework for Reinforcement Learning for Digital Chemistry},
	year = {2023}}

@article{bellinger2023dynamic,
	author = {Bellinger, Colin and Crowley, Mark and Tamblyn, Isaac},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	journal = {arXiv preprint arXiv:2307.02620},
	keywords = {from-paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	self = {1},
	title = {Dynamic Observation Policies in Observation Cost-Sensitive Reinforcement Learning},
	year = {2023}}

@book{Kolobov,
	author = {Kolobov, Andrey and Mausam},
	date-added = {2024-07-26 00:17:34 -0400},
	date-modified = {2024-07-26 11:25:06 -0400},
	keywords = {from-paper-beeler2023digidiscjourn; reinforcement-learning},
	title = {{Planning with MDPs}}}

@book{hu2023artofrl,
	author = {Hu, Michael},
	bdsk-color = {7},
	date-added = {2024-07-03 14:12:07 -0400},
	date-modified = {2024-07-26 01:19:52 -0400},
	doi = {https://doi.org/10.1007/978-1-4842-9606-6},
	edition = {1},
	isbn = {978-1-4842-9605-9},
	keywords = {rd-reference; reinforcement-learning, artificial-intelligence, python, machine-learning; rdgrp-ece750T4-f24},
	order = {3},
	publisher = {Apress Berkeley, CA},
	title = {The Art of Reinforcement Learning: Fundamentals, Mathematics, and Implementations with Python},
	url = {https://books.google.ca/books?id=1ijwzwEACAAJ},
	venue-short = {TextBook},
	year = {2023},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEDouLi8uLi8uLi8uLi8uVHJhc2gvYXNzZXRzL3BkZi8yMDIzLXRleHRib29rLWh1LXRoZS1hcnQucGRmTxEC/GJvb2v8AgAAAAAEEDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQCAAAFAAAAAQEAAFVzZXJzAAAACAAAAAEBAABtY3Jvd2xleQYAAAABAQAALlRyYXNoAAAGAAAAAQEAAGFzc2V0cwAAAwAAAAEBAABwZGYAHAAAAAEBAAAyMDIzLXRleHRib29rLWh1LXRoZS1hcnQucGRmGAAAAAEGAAAEAAAAFAAAACQAAAA0AAAARAAAAFAAAAAIAAAABAMAABVdAAAAAAAACAAAAAQDAAA56AMAAAAAAAgAAAAEAwAAohwEAAAAAAAIAAAABAMAACh9RgMAAAAACAAAAAQDAAApfUYDAAAAAAgAAAAEAwAAx3ZGAwAAAAAYAAAAAQYAAJQAAACkAAAAtAAAAMQAAADUAAAA5AAAAAgAAAAABAAAQcYa5R5TMl8YAAAAAQIAAAEAAAAAAAAADwAAAAAAAAAAAAAAAAAAAAgAAAAEAwAABAAAAAAAAAAEAAAAAwMAAPUBAAAIAAAAAQkAAGZpbGU6Ly8vDAAAAAEBAABNYWNpbnRvc2ggSEQIAAAABAMAAACQgpbnAAAACAAAAAAEAABBxiPsm4AAACQAAAABAQAAMDlCN0VBQkUtNjc5NS00Q0RGLUFCMjQtM0ZGMDg1NjVEMDE2GAAAAAECAACBAAAAAQAAAO8TAAABAAAAAAAAAAAAAAABAAAAAQEAAC8AAAAAAAAAAQUAAMAAAAD+////AQAAAAAAAAAPAAAABBAAAHQAAAAAAAAABRAAAPQAAAAAAAAAEBAAACQBAAAAAAAAQBAAABQBAAAAAAAAAiAAAPABAAAAAAAABSAAAGABAAAAAAAAECAAAHABAAAAAAAAESAAAKQBAAAAAAAAEiAAAIQBAAAAAAAAEyAAAJQBAAAAAAAAICAAANABAAAAAAAAMCAAAPwBAAAAAAAAAcAAAEQBAAAAAAAAEcAAABQAAAAAAAAAEsAAAFQBAAAAAAAAAAgADQAaACMAYAAAAAAAAAIBAAAAAAAAAAUAAAAAAAAAAAAAAAAAAANg},
	bdsk-url-1 = {https://books.google.ca/books?id=1ijwzwEACAAJ}}

@article{Subramanian2017a,
	abstract = {Machine learning algorithms have increased tremendously in power in recent years but have yet to be fully utilized in many ecology and sustainable resource management domains such as wildlife reserve design, forest fire management and invasive species spread. One thing these domains have in common is that they contain dynamics that can be characterized as a Spatially Spreading Process (SSP) which requires many parameters to be set precisely to model the dynamics, spread rates and directional biases of the elements which are spreading. We present related work in Artificial Intelligence and Machine Learning for SSP sustainability domains including forest wildfire prediction. We then introduce a novel approach for learning in SSP domains using Reinforcement Learning (RL) where fire is the agent at any cell in the landscape and the set of actions the fire can take from a location at any point in time includes spreading North, South, East, West or not spreading. This approach inverts the usual RL setup since the dynamics of the corresponding Markov Decision Process (MDP) is a known function for immediate wildfire spread. Meanwhile, we learn an agent policy for a predictive model of the dynamics of a complex spatially-spreading process. Rewards are provided for correctly classifying which cells are on fire or not compared to satellite and other related data. We examine the behaviour of five RL algorithms on this problem: Value Iteration, Policy Iteration, Q-Learning, Monte Carlo Tree Search and Asynchronous Advantage Actor-Critic (A3C). We compare to a Gaussian process based supervised learning approach and discuss the relation of our approach to manually constructed, state-of-the-art methods from forest wildfire modelling. We also discuss the relation of our approach to manually constructed, state-of-the-art methods from forest wildfire modelling. We validate our approach with satellite image data of two massive wildfire events in Northern Alberta, Canada; the Fort McMurray fire of 2016 and the Richardson fire of 2011. The results show that we can learn predictive, agent-based policies as models of spatial dynamics using RL on readily available satellite images that other methods and have many additional advantages in terms of generalizability and interpretability.},
	author = {{Ganapathi Subramanian}, Sriram and Crowley, Mark},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-07-25 23:14:25 -0400},
	doi = {10.3389/FICT.2018.00006},
	file = {:Users/mcrowley/Dropbox/MendeleyDesktop/fict-05-00006.pdf:pdf},
	issn = {2297-198X},
	journal = {Frontiers in ICT},
	keywords = {A3C,deep-learning,forest-management,machine-learning,spatially spreading processes,sustainabtility; forest-management; forest-wildfire; reinforcement-learning},
	pages = {6},
	publisher = {Frontiers},
	title = {{Using Spatial Reinforcement Learning to Build Forest Wildfire Dynamics Models from Satellite Images}},
	url = {https://www.frontiersin.org/articles/10.3389/fict.2018.00006/abstract},
	volume = {5},
	year = {2018},
	bdsk-url-1 = {https://www.frontiersin.org/articles/10.3389/fict.2018.00006/abstract},
	bdsk-url-2 = {https://doi.org/10.3389/FICT.2018.00006}}

@article{Hanes2018,
	abstract = {Contemporary fire regimes of Canadian forests have been well documented based on forest fire records between the late 1950s to 1990s. Due to known limitations of fire datasets, an analysis of changes in fire-regime characteristics could not be easily undertaken. This paper presents fire regime trends nationally and within two zonation systems, the homogeneous fire regime zones and ecozones, for two time periods: 1959-2015 and 1980-2015. Nationally, trends in both area burned and number of large fires (≥ 200 ha) have increased significantly since 1959, which might be due to increases in lightning-caused fires. Human-caused fires, in contrast, have shown a decline. Results suggest that large fires have been getting larger over the last 57 years, and that the fire season has been starting approximately one week earlier and ending one week later. At the regional level, trends in fire regimes are variable across the country, with fewer significant trends. Area burned, number of large fires, and lightning-cause...},
	author = {Hanes, Chelene and Wang, Xianli and Jain, Piyush and Parisien, Marc-Andr{\'{e}} and Little, John and Flannigan, Mike},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-06-27 16:46:20 -0400},
	doi = {10.1139/cjfr-2018-0293},
	file = {:Users/mcrowley/Dropbox/MendeleyDesktop/FireRegimeChange.pdf:pdf},
	issn = {0045-5067},
	journal = {Canadian Journal of Forest Research},
	keywords = {forest-management; forest-wildfire},
	pages = {cjfr--2018--0293},
	title = {{Fire regime changes in Canada over the last half century}},
	url = {http://www.nrcresearchpress.com/doi/10.1139/cjfr-2018-0293},
	year = {2018},
	bdsk-url-1 = {http://www.nrcresearchpress.com/doi/10.1139/cjfr-2018-0293},
	bdsk-url-2 = {https://doi.org/10.1139/cjfr-2018-0293}}

@article{Jain2017,
	abstract = {We have constructed a fire weather climatology over North America from 1979 to 2015 using the North American Regional Reanalysis dataset and the Canadian Fire Weather Index (FWI) System. We tested for the presence of trends in potential fire season length, based on a meteorological definition, and extreme fire weather using the non-parametric Theil--Sen slope estimator and Mann--Kendall test. Applying field significance testing (i.e. joint significance of multiple tests) allowed the identification of the locations of significant trends, taking into account spatial correlations. Fire season length was found to be increasing over large areas of North America, especially in eastern Canada and the south-western US, which is consistent with a later fire season end and an earlier fire season start. Both positive and negative trends in potential fire spread days and the 99th percentile of FWI occurred in Canada and the contiguous United States, although the trends of largest magnitude and statistical significance were mostly positive. In contrast, the proportion of trends with significant decreases in these variables were much lower, indicating an overall increase in extreme fire weather. The smaller proportion of significant positive trends found over Canada reflects the truncation of the time series, necessary because assimilation of precipitation observations over Canada ceased in the reanalysis post-2002.},
	author = {Jain, Piyush and Wang, Xianli and Flannigan, Mike D.},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-07-25 23:14:40 -0400},
	doi = {10.1071/WF17008},
	file = {:Users/mcrowley/Dropbox/MendeleyDesktop/Jain, Wang, Flannigan - 2017 - Trend analysis of fire season length and extreme fire weather in North America between 1979 and 2015.pdf:pdf},
	issn = {1049-8001},
	journal = {International Journal of Wildland Fire},
	keywords = {climate-change,forest-fire-weather,reanalysis,time series.; forest-management; forest-wildfire},
	month = {jan},
	number = {12},
	pages = {1009},
	publisher = {CSIRO PUBLISHING},
	title = {{Trend analysis of fire season length and extreme fire weather in North America between 1979 and 2015}},
	url = {http://www.publish.csiro.au/?paper=WF17008},
	volume = {26},
	year = {2017},
	bdsk-url-1 = {http://www.publish.csiro.au/?paper=WF17008},
	bdsk-url-2 = {https://doi.org/10.1071/WF17008}}

@article{Kirchmeier-Young2017,
	abstract = {{\textcopyright} 2017, The Author(s). Canada is expected to see an increase in fire risk under future climate projections. Large fires, such as that near Fort McMurray, Alberta in 2016, can be devastating to the communities affected. Understanding the role of human emissions in the occurrence of such extreme fire events can lend insight into how these events might change in the future. An event attribution framework is used to quantify the influence of anthropogenic forcings on extreme fire risk in the current climate of a western Canada region. Fourteen metrics from the Canadian Forest Fire Danger Rating System are used to define the extreme fire seasons. For the majority of these metrics and during the current decade, the combined effect of anthropogenic and natural forcing is estimated to have made extreme fire risk events in the region 1.5 to 6 times as likely compared to a climate that would have been with natural forcings alone.},
	author = {Kirchmeier-Young, Megan C. and Zwiers, Francis W. and Gillett, Nathan P. and Cannon, Alex J.},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-07-25 23:14:40 -0400},
	doi = {10.1007/s10584-017-2030-0},
	file = {:Users/mcrowley/Dropbox/MendeleyDesktop/Kirchmeier-Young et al. - 2017 - Attributing extreme fire risk in Western Canada to human emissions.pdf:pdf},
	isbn = {9788362936571},
	issn = {15731480},
	journal = {Climatic Change},
	keywords = {Event attribution,Extremes,forest-fire-weather; forest-management; forest-wildfire},
	month = {sep},
	number = {2},
	pages = {365--379},
	publisher = {Springer Netherlands},
	title = {{Attributing extreme fire risk in Western Canada to human emissions}},
	url = {http://link.springer.com/10.1007/s10584-017-2030-0},
	volume = {144},
	year = {2017},
	bdsk-url-1 = {http://link.springer.com/10.1007/s10584-017-2030-0},
	bdsk-url-2 = {https://doi.org/10.1007/s10584-017-2030-0}}

@article{Lagerquist2017,
	abstract = {Wildfires burn an average of 2 million hectares per year in Canada, most of which can be attributed to only a few days of severe fire weather. These " spread days " are often associated with large-scale weather systems. We used extreme threshold values of three Canadian Fire Weather Index System (CFWIS) variables --- the fine fuel moisture code (FFMC), initial spread index (ISI), and fire weather index (FWI) --- as a proxy for spread days. Then we used self-organizing maps (SOMs) to predict spread days, with sea-level pressure and 500 hPa geopotential height as predictors. SOMs require many input parameters, and we performed an experiment to optimize six key parameters. For each month of the fire season (May--August), we also tested whether SOMs performed better when trained with only one month or with neighbouring months as well. Good performance (AUC of 0.8) was achieved for FFMC and ISI, while nearly good performance was achieved for FWI. To our knowledge, this is the first study to develop a machine-learning model for extreme fire weather that could be deployed in real time. R{\'{e}}sum{\'{e}} : Les feux, dont la plupart peuvent {\^{e}}tre imput{\'{e}}s {\`{a}} seulement quelques jours durant lesquels les conditions m{\'{e}}t{\'{e}}orologiques sont propices aux incendies forestiers s{\'{e}}v{\`{e}}res, d{\'{e}}truisent en moyenne deux millions d'hectares de for{\^{e}}t par ann{\'{e}}e au Canada. Ces jours propices {\`{a}} la propagation des feux sont souvent associ{\'{e}}s {\`{a}} de vastes syst{\`{e}}mes m{\'{e}}t{\'{e}}orologiques. Nous avons utilis{\'{e}} des valeurs seuils extr{\^{e}}mes pour trois variables de la m{\'{e}}thode canadienne de l'indice for{\^{e}}t-m{\'{e}}t{\'{e}}o (MCIFM) : l'indice du combustible l{\'{e}}ger (ICL), l'indice de propagation initiale (IPI) et l'indice for{\^{e}}t-m{\'{e}}t{\'{e}}o (IFM) en tant que substituts pour les jours propices {\`{a}} la propagation des feux. Ensuite, nous avons utilis{\'{e}} des cartes autoorganisables (SOM) pour pr{\'{e}}dire les jours propices {\`{a}} la propagation des feux avec comme pr{\'{e}}dicteurs la pression au niveau de la mer et une hauteur du g{\'{e}}opotentiel de 500 hPa. Les SOM exigent plusieurs param{\`{e}}tres d'entr{\'{e}}e et nous avons effectu{\'{e}} une exp{\'{e}}rience pour optimiser six param{\`{e}}tres cl{\'{e}}s. Pour chaque mois de la saison des feux (mai--ao{\^{u}}t), nous avons aussi test{\'{e}} si les SOM {\'{e}}taient plus performantes lorsqu'elles {\'{e}}taient entra{\^{i}}n{\'{e}}es avec seulement un mois ou en incluant aussi les mois voisins. Une bonne performance (AUC de 0,8) a {\'{e}}t{\'{e}} obtenue pour ICL et IPI, alors qu'une performance satisfaisante a {\'{e}}t{\'{e}} obtenue pour IFM. {\`{A}} notre connaissance, il s'agit de la premi{\`{e}}re {\'{e}}tude qui {\'{e}}labore un mod{\`{e}}le d'apprentissage automatique pour des conditions m{\'{e}}t{\'{e}}orologiques extr{\^{e}}mes propices aux incendies forest-iers qui peut {\^{e}}tre d{\'{e}}ploy{\'{e}} en temps r{\'{e}}el. [Traduit par la R{\'{e}}daction] Mots-cl{\'{e}}s : feux de for{\^{e}}t, danger d'incendie, r{\'{e}}gime des feux, cartes autoorganisables (SOM), conditions m{\'{e}}t{\'{e}}orologiques.},
	author = {Lagerquist, Ryan and Flannigan, Mike D and Wang, Xianli and Marshall, Ginny A},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-06-27 16:46:20 -0400},
	doi = {10.1139/cjfr-2017-0063},
	file = {:Users/mcrowley/Dropbox/MendeleyDesktop/Lagerquist et al. - 2017 - Automated prediction of extreme fire weather from synoptic(2).pdf:pdf},
	issn = {12086037},
	journal = {Canadian Journal of Forest Research},
	keywords = {wildfire-management; forest-management; forest-wildfire},
	number = {August},
	pages = {1175--1183},
	title = {{Automated prediction of extreme fire weather from synoptic}},
	url = {http://www.nrcresearchpress.com/doi/pdf/10.1139/cjfr-2017-0063},
	volume = {1183},
	year = {2017},
	bdsk-url-1 = {http://www.nrcresearchpress.com/doi/pdf/10.1139/cjfr-2017-0063},
	bdsk-url-2 = {https://doi.org/10.1139/cjfr-2017-0063}}

@article{Mann2017,
	abstract = {Influence of Anthropogenic Climate Change on Planetary Wave Resonance and Extreme Weather Events},
	author = {Mann, Michael E. and Rahmstorf, Stefan and Kornhuber, Kai and Steinman, Byron A. and Miller, Sonya K. and Coumou, Dim},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-06-27 16:46:20 -0400},
	doi = {10.1038/srep45242},
	issn = {2045-2322},
	journal = {Scientific Reports},
	keywords = {Atmospheric science,climate-change; forest-management; forest-wildfire},
	month = {dec},
	number = {1},
	pages = {45242},
	publisher = {Nature Publishing Group},
	title = {{Influence of Anthropogenic Climate Change on Planetary Wave Resonance and Extreme Weather Events}},
	url = {http://www.nature.com/articles/srep45242},
	volume = {7},
	year = {2017},
	bdsk-url-1 = {http://www.nature.com/articles/srep45242},
	bdsk-url-2 = {https://doi.org/10.1038/srep45242}}

@inproceedings{Subramanian2018,
	address = {Toronto, Ontario, Canada},
	author = {Subramanian, Sriram Ganapathi and Crowley, Mark},
	booktitle = {Canadian Conference on Artificial Intelligence},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-07-24 15:08:40 -0400},
	file = {:Users/mcrowley/Dropbox/MendeleyDesktop/Subramanian, Crowley - 2018 - Combining MCTS and A3C for Prediction of Spatially Spreading Processes in Forest Wildfire Settings.pdf:pdf;:Users/mcrowley/Dropbox/MendeleyDesktop/Canadian{\_}AI{\_}forestfire{\_}2.pdf:pdf},
	keywords = {a3c,computational-sustainability,forest-wildfire,forest-wildfire,monte-carlo tree search,forest-management; forest-wildfire; reinforcement-learning},
	title = {{Combining MCTS and A3C for Prediction of Spatially Spreading Processes in Forest Wildfire Settings}},
	year = {2018}}

@article{Taleghan2015,
	abstract = {In a simulator-defined MDP, the Markovian dynamics and rewards are provided in the form of a simulator from which samples can be drawn. This paper studies MDP planning algorithms that attempt to minimize the number of simulator calls before terminating and outputting a policy that is approximately optimal with high probability. The paper introduces two heuristics for efficient exploration and an improved confidence interval that enables earlier termination with probabilis- tic guarantees. We prove that the heuristics and the confidence interval are sound and produce with high probability an approximately optimal policy in polynomial time. Experiments on two benchmark problems and two instances of an invasive species management problem show that the improved confidence intervals and the new search heuristics yield reductions of between 8{\%} and 47{\%} in the number of simulator calls required to reach near-optimal policies.},
	author = {Taleghan, Majid Alkaee and Dietterich, Thomas G. and Crowley, Mark and Hall, Kim and Albers, H. Jo},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-07-25 23:13:43 -0400},
	file = {:Users/mcrowley/Dropbox/MendeleyDesktop/Taleghan et al. - 2015 - PAC Optimal MDP Planning with Application to Invasive Species Management.pdf:pdf},
	issn = {15337928},
	journal = {Journal of Machine Learning Research},
	keywords = {good-turing,MDP planning,Markov decision processes,computational-sustainability,grant-wici16,invasive species management,machine-learning,mdp planning,optimization,forest-management; forest-wildfire; reinforcement-learning},
	mendeley-tags = {computational sustainability,grant-wici16,machine learning,mdp planning,optimization},
	pages = {3877--3903},
	title = {{PAC Optimal MDP Planning with Application to Invasive Species Management}},
	url = {http://jmlr.org/papers/v16/taleghan15a.html},
	volume = {16},
	year = {2015},
	bdsk-url-1 = {http://jmlr.org/papers/v16/taleghan15a.html}}

@inproceedings{Tsang-AAAI-2013,
	author = {Tsang, Alan and Larson, Kate and Mcalpine, Rob},
	booktitle = {Proceedings of the Twenty-Seventh AAAI Conference on Artificial Intelligence Resource},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-06-27 16:46:20 -0400},
	file = {:Users/mcrowley/Dropbox/MendeleyDesktop/6404-30900-1-PB.pdf:pdf;:Users/mcrowley/Dropbox/MendeleyDesktop/CS-2012-11.pdf:pdf},
	isbn = {9781577356158},
	keywords = {Special Track on Computational Sustainability and; forest-management; forest-wildfire},
	pages = {1355--1361},
	title = {{Resource Sharing for Control of Wildland Fires}},
	url = {http://www.aaai.org/ocs/index.php/AAAI/AAAI13/paper/view/6404},
	year = {2013},
	bdsk-url-1 = {http://www.aaai.org/ocs/index.php/AAAI/AAAI13/paper/view/6404}}

@article{Wang2017,
	author = {Wang, Xianli and Wotton, B. Mike and Cantin, Alan S. and Parisien, Marc-Andr{\'{e}} and Anderson, Kerry and Moore, Brett and Flannigan, Mike D.},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-06-27 16:46:20 -0400},
	doi = {10.1186/s13717-017-0070-z},
	file = {:Users/mcrowley/Dropbox/MendeleyDesktop/Wang et al. - 2017 - cffdrs an R package for the Canadian Forest Fire Danger Rating System.pdf:pdf},
	issn = {2192-1709},
	journal = {Ecological Processes},
	keywords = {forest-management; forest-wildfire},
	month = {dec},
	number = {1},
	pages = {5},
	publisher = {Springer Berlin Heidelberg},
	title = {{cffdrs: an R package for the Canadian Forest Fire Danger Rating System}},
	url = {http://ecologicalprocesses.springeropen.com/articles/10.1186/s13717-017-0070-z},
	volume = {6},
	year = {2017},
	bdsk-url-1 = {http://ecologicalprocesses.springeropen.com/articles/10.1186/s13717-017-0070-z},
	bdsk-url-2 = {https://doi.org/10.1186/s13717-017-0070-z}}

@article{Wang-ERL-2017,
	abstract = {In the face of climate change, predicting and understanding future fire regimes across Canada is a high priority for wildland fire research and management. Due in large part to the difficulties in obtaining future daily fire weather projections, one of the major challenges in predicting future fire activity is to estimate how much of the change in weather potential could translate into on-the-ground fire spread. As a result, past studies have used monthly, annual, or multi-decadal weather projections to predict future fires, thereby sacrificing information relevant to day-to-day fire spread. Using climate projections from the fifth phase of the Coupled Model Intercomparison Project (CMIP5), historical weather observations, MODIS fire detection data, and the national fire database of Canada, this study investigated potential changes in the number of active burning days of wildfires by relating `spread days' to patterns of daily fire-conducive weather. Results suggest that climate change over the next century may have significant impacts on fire spread days in almost all parts of Canada's forested landmass; the number of fire spread days could experience a 2-to-3-fold increase under a high CO 2 forcing scenario in eastern Canada, and a greater than 50{\%} increase in western Canada, where the fire potential is already high. The change in future fire spread is critical in understanding fire regime changes, but is also imminently relevant to fire management operations and in fire risk mitigation.},
	author = {Wang, Xianli and Parisien, Marc Andr{\'{e}} and Taylor, Steve W. and Candau, Jean No{\"{e}}l and Stralberg, Diana and Marshall, Ginny A. and Little, John M. and Flannigan, Mike D.},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-07-25 23:14:40 -0400},
	doi = {10.1088/1748-9326/aa5835},
	file = {:Users/mcrowley/Dropbox/MendeleyDesktop/FireRegimeChange(2).pdf:pdf},
	issn = {17489326},
	journal = {Environmental Research Letters},
	keywords = {Canadian forests,climate-change,forest-fire-weather,wildfire-spread-day; forest-management; forest-wildfire},
	month = {feb},
	number = {2},
	pages = {025005},
	pmid = {23110131},
	title = {{Projected changes in daily fire spread across Canada over the next century}},
	url = {http://stacks.iop.org/1748-9326/12/i=2/a=025005?key=crossref.8043842fba0f06f383dbb079aeb2f59d},
	volume = {12},
	year = {2017},
	bdsk-url-1 = {http://stacks.iop.org/1748-9326/12/i=2/a=025005?key=crossref.8043842fba0f06f383dbb079aeb2f59d},
	bdsk-url-2 = {https://doi.org/10.1088/1748-9326/aa5835}}

@inproceedings{ronneberger2015miccai,
	author = {O. Ronneberger and P.Fischer and T. Brox},
	booktitle = {Medical Image Computing and Computer-Assisted Intervention (MICCAI)},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-06-27 16:46:20 -0400},
	keywords = {forest-management; forest-wildfire; fund-waii-nexus-seed-2024-wildfire},
	note = {(available on arXiv:1505.04597 [cs.CV])},
	pages = {234--241},
	publisher = {Springer},
	series = {LNCS},
	title = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
	url = {http://lmb.informatik.uni-freiburg.de/Publications/2015/RFB15a},
	venue-short = {miccai},
	volume = {9351},
	year = {2015},
	bdsk-url-1 = {http://lmb.informatik.uni-freiburg.de/Publications/2015/RFB15a}}

@article{parks2019ecosphere,
	abstract = {Abstract Forests are an incredibly important resource across the globe, yet they are threatened by climate change through stressors such as drought, insect outbreaks, and wildfire. Trailing edge forests---those areas expected to experience range contractions under a changing climate---are of particular concern because of the potential for abrupt conversion to non-forest. However, due to plant-climate disequilibrium, broad-scale forest die-off and range contraction in trailing edge forests are unlikely to occur over short timeframes (<~25--50 yr) without a disturbance catalyst (e.g., wildfire). This underscores that explicit attention to both climate and disturbance is necessary to understand how the distribution of forests will respond to climate change. As such, we first identify the expected location of trailing edge forests in the intermountain western United States by mid-21st century. We then identify those trailing edge forests that have a high probability of stand-replacing fire and consider such sites to have an elevated risk of fire-facilitated transition to non-forest. Results show that 18\% of trailing edge forest and 6.6\% of all forest are at elevated risk of fire-facilitated conversion to non-forest in the intermountain western United States by mid-21st century. This estimate, however, assumes that fire burns under average weather conditions. For a subset of the study area (the southwestern United States), we were able to incorporate expected fire severity under extreme weather conditions. For this spatial subset, we found that 61\% of trailing edge forest and 30\% of all forest are at elevated risk of fire-facilitated conversion to non-forest under extreme burning conditions. However, due to compounding error in our process that results in unknowable uncertainty, we urge caution in a strict interpretation of these estimates. Nevertheless, our findings suggest the potential for transformed landscapes in the intermountain western United States that will affect ecosystem services such as watershed integrity, wildlife habitat, wood production, and recreation.},
	author = {Parks, Sean A. and Dobrowski, Solomon Z. and Shaw, John D. and Miller, Carol},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-06-27 16:46:20 -0400},
	doi = {https://doi.org/10.1002/ecs2.2651},
	eprint = {https://esajournals.onlinelibrary.wiley.com/doi/pdf/10.1002/ecs2.2651},
	journal = {Ecosphere},
	keywords = {climate analog model, climate-change, climatic debt, disequilibrium, disturbance, trailing edge forest, type conversion, forest-wildfire, wildland fire; forest-management; forest-wildfire; fund-waii-nexus-seed-2024-wildfire},
	number = {3},
	pages = {e02651},
	title = {Living on the edge: trailing edge forests at risk of fire-facilitated conversion to non-forest},
	url = {https://esajournals.onlinelibrary.wiley.com/doi/abs/10.1002/ecs2.2651},
	venue-short = {ecosphere},
	volume = {10},
	year = {2019},
	bdsk-url-1 = {https://esajournals.onlinelibrary.wiley.com/doi/abs/10.1002/ecs2.2651},
	bdsk-url-2 = {https://doi.org/10.1002/ecs2.2651}}

@webpage{flannigan2020canadawildfire,
	author = {Flannigan, Mike and others},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-06-27 16:46:20 -0400},
	doi = {https://www.canadawildfire.org/nsercnetwork},
	institution = {{Canada Wildfire}},
	keywords = {canadawildfire, forest-wildfire, forest-wildfire; forest-management; forest-wildfire; fund-waii-nexus-seed-2024-wildfire},
	title = {{Canada Wildfire NSERC Strategic Network}},
	url = {https://www.canadawildfire.org/nsercnetwork},
	venue-short = {canadawildfire},
	year = {2020 (https://www.canadawildfire.org/nsercnetwork)},
	bdsk-url-1 = {https://www.canadawildfire.org/nsercnetwork}}

@article{wang2023scitotenviro,
	abstract = {A spread day is defined as a day in which fires grow a substantial amount of area; such days usually occur during high or extreme fire weather conditions. The identification and prediction of a spread day based on fire weather conditions could help both our understanding of fire regimes as well as forecasting and managing fires operationally. This study explores the relationships between fire weather and spread days in the forested areas of Canada by spatially and temporally matching a daily fire growth database to a daily gridded fire weather database that spans from 2001 to 2019. By examining the correlations between spread day fire weather conditions and location, conifer coverage (%), and elevation, we found that a spread day happens under less severe fire weather conditions as latitude increases for the entire study area and as conifer coverage increases within non-mountainous study areas. In the western mountain areas, however, with increasing conifer coverage more severe fire weather conditions are required for a spread day to occur. Using two modeling approaches, we were able to identify spread day indicators (generalized additive model) and to predict the occurrence of spread days (semi-binomial regression model) by Canadian Ecozones both annually and seasonally. Overall, Fine Fuel Moisture Code (FFMC), Initial Spread Index (ISI), and Fire Weather Index (FWI) performed the best in all models built for spread day identification and prediction but varied depending on the conditions mentioned above. FFMC was the most consistent across all spatial and temporal scales.},
	author = {Xianli Wang and Jacqueline Oliver and Tom Swystun and Chelene C. Hanes and Sandy Erni and Mike D. Flannigan},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-07-25 23:14:40 -0400},
	doi = {https://doi.org/10.1016/j.scitotenv.2023.161831},
	issn = {0048-9697},
	journal = {Science of The Total Environment},
	keywords = {forest-fire-weather, wildfire-spread-day, Thresholds, Area burned, Canada; forest-management; forest-wildfire; fund-waii-nexus-seed-2024-wildfire},
	pages = {161831},
	title = {Critical fire weather conditions during active fire spread days in Canada},
	url = {https://www.sciencedirect.com/science/article/pii/S0048969723004461},
	venue-short = {scitotenviro},
	volume = {869},
	year = {2023},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0048969723004461},
	bdsk-url-2 = {https://doi.org/10.1016/j.scitotenv.2023.161831}}

@article{gincheva2024scidata,
	author = {Gincheva, Andrina and Pausas, Juli G and Edwards, Andrew and Provenzale, Antonello and Cerd{\`a}, Artemi and Hanes, Chelene and Roy{\'e}, Dominic and Chuvieco, Emilio and Mouillot, Florent and Vissio, Gabriele and others},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-06-27 16:46:20 -0400},
	journal = {Scientific data},
	keywords = {forest-management; forest-wildfire; fund-waii-nexus-seed-2024-wildfire},
	number = {1},
	pages = {352},
	publisher = {Nature Publishing Group UK London},
	title = {A monthly gridded burned area database of national wildland fire data},
	venue-short = {scidata},
	volume = {11},
	year = {2024}}

@techreport{tymstra2010nrcan,
	address = {Edmonton, Alberta},
	author = {Tymstra, C.; Bryce, R.W.; Wotton, B.M.; Taylor, S.W.; Armitage, O.B.},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-06-27 16:46:20 -0400},
	institution = {Natural Resources Canada, Canadian Forest Service, Northern Forestry Centre},
	keywords = {prometheus, forest-wildfire, simulation; forest-management; forest-wildfire; fund-waii-nexus-seed-2024-wildfire},
	number = {Information Report NOR-X-417.},
	pages = {102},
	title = {Development and structure of Prometheus: the Canadian Wildland Fire Growth Simulation Model.},
	venue-short = {nrcan},
	year = {2010}}

@article{zheng2017forest,
	author = {Zheng, Zhong and Huang, Wei and Li, Songnian and Zeng, Yongnian},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-06-27 16:46:20 -0400},
	journal = {Ecological Modelling},
	keywords = {forest-management; forest-wildfire; fund-waii-nexus-seed-2024-wildfire},
	pages = {33--43},
	publisher = {Elsevier},
	title = {Forest fire spread simulating model using cellular automaton with extreme learning machine},
	volume = {348},
	year = {2017}}

@article{crowley2014ieeetoc,
	abstract = {Spatiotemporal planning involves making choices at multiple locations in space over some planning horizon to maximize utility and satisfy various constraints. In Forest Ecosystem Management, the problem is to choose actions for thousands of locations each year including harvesting, treating trees for fire or pests, or doing nothing. The utility models could place value on sale of lumber, ecosystem sustainability or employment levels and incorporate legal and logistical constraints on actions such as avoiding large contiguous areas of clearcutting. Simulators developed by forestry researchers provide detailed dynamics but are generally inaccesible black boxes. We model spatiotemporal planning as a factored Markov decision process and present a policy gradient planning algorithm to optimize a stochastic spatial policy using simulated dynamics. It is common in environmental and resource planning to have actions at different locations be spatially interelated, this makes representation and planning challenging. We define a global spatial policy in terms of interacting local policies defining distributions over actions at each location conditioned on actions at nearby locations. Markov chain Monte Carlo simulation is used to sample landscape policies and estimate their gradients. Evaluation is carried out on a forestry planning problem with 1,880 locations using a variety of value models and constraints. Index},
	author = {Crowley, Mark},
	citations = {7},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-06-27 16:46:20 -0400},
	doi = {10.1109/TC.2013.113},
	file = {:Users/mcrowley/Dropbox/MendeleyDesktop/Crowley - 2014 - Using equilibrium policy gradients for spatiotemporal planning in forest ecosystem management(2).pdf:pdf},
	in-cv = {1},
	issn = {00189340},
	journal = {IEEE Transactions on Computers},
	keywords = {computational-sustainability,Ecosystem management,forest-management,machine-learning,mdp,Optimization,policy-gradient,Reinforcement-Learning,grant-wici16,proj-spatiallyspreadingprocess,spatiotemporal-planning, showcase; forest-wildfire; fund-waii-nexus-seed-2024-wildfire},
	mendeley-tags = {grant-wici16,proj-spatiallyspreadingprocess,spatiotemporal planning},
	number = {1},
	pages = {142--154},
	publisher = {IEEE computer Society Digital Library. IEEE Computer Society.},
	self = {1},
	self-citations = {2},
	seminal = {0},
	status = {1},
	tempflag = {0},
	title = {{Using equilibrium policy gradients for spatiotemporal planning in forest ecosystem management}},
	url = {http://www.computer.org/csdl/trans/tc/preprint/06514032-abs.html},
	venue-short = {IEEEToC},
	volume = {63},
	year = {2014},
	bdsk-url-1 = {http://www.computer.org/csdl/trans/tc/preprint/06514032-abs.html},
	bdsk-url-2 = {https://doi.org/10.1109/TC.2013.113}}

@inproceedings{Crowley2009,
	abstract = {We introduce a challenging real world planning problem where actions must be taken at each location in a spatial area at each point in time. We use forestry planning as the motivating application. In Large Scale Spatial-Temporal (LSST) planning problems, the state and action spaces are defined as the cross-products of many local state and action spaces spread over a large spatial area such as a city or forest. These problems possess state uncertainty, have complex utility functions involving spatial constraints and we generally must rely on simulations rather than an explicit transition model. We define LSST problems as reinforcement learning prob- lems and present a solution using policy gradients. We compare two different policy formulations: an explicit policy that identifies each location in space and the action to take there, and an abstract policy that defines the proportion of actions to take across all locations in space. We show that the abstract policy is more robust and achieves higher rewards with far fewer parameters than the elementary policy. This abstract policy is also a better fit to the properties that practitioners in LSST problem domains require for such methods to be widely useful},
	address = {Montreal, Canada},
	author = {Crowley, Mark and Nelson, John and Poole, David},
	booktitle = {Conference on Uncertainty in Artificial Intelligence (UAI09)},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-06-27 16:46:20 -0400},
	file = {:Users/mcrowley/Dropbox/MendeleyDesktop/Crowley, Nelson, Poole - 2009 - Seeing the Forest Despite the Trees Large Scale Spatial-Temporal Decision Making.pdf:pdf},
	in-cv = {1},
	keywords = {mdp,computational-sustainability,forest-management,probabilistic-inference,planning,spatiotemporal-planning; showcase; forest-wildfire; fund-waii-nexus-seed-2024-wildfire},
	pages = {126--134},
	self = {1},
	status = {1},
	tempflag = {0},
	title = {{Seeing the Forest Despite the Trees : Large Scale Spatial-Temporal Decision Making}},
	url = {http://www.cs.ubc.ca/{~}crowley/papers/uai09-mark-crowley.pdf},
	venue-short = {UAI},
	year = {2009},
	bdsk-url-1 = {http://www.cs.ubc.ca/%7B~%7Dcrowley/papers/uai09-mark-crowley.pdf}}

@inproceedings{ganapathisubramanian2021aamas,
	abbr = {PO-MFRL},
	abstract = {Traditional multi-agent reinforcement learning algorithms are not scalable to environments with more than a few agents, since these algorithms are exponential in the number of agents. Recent research has introduced successful methods to scale multi-agent reinforcement learning algorithms to many agent scenarios using mean field theory. Previous work in this field assumes that an agent has access to exact cumulative metrics regarding the mean field behaviour of the system, which it can then use to take its actions. In this paper, we relax this assumption and maintain a distribution to model the uncertainty regarding the mean field of the system. We consider two different settings for this problem. In the first setting, only agents in a fixed neighbourhood are visible, while in the second setting, the visibility of agents is determined at random based on distances. For each of these settings, we introduce a Q-learning based algorithm that can learn effectively. We prove that this Q-learning estimate stays very close to the Nash Q-value (under a common set of assumptions) for the first setting. We also empirically show our algorithms outperform multiple baselines in three different games in the MAgents framework, which supports large environments with many agents learning simultaneously to achieve possibly distinct goals.},
	address = {London, United Kingdom},
	arxiv = {2012.15791},
	author = {Ganapathi Subramanian, Sriram and Taylor, Matthew and Crowley, Mark and Poupart, Pascal},
	booktitle = {Proceedings of the 20th International Conference on Autonomous Agents and MultiAgent Systems (AAMAS)},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-06-27 16:46:20 -0400},
	editor = {U. Endriss, A. Now{\'e}, F. Dignu and A. Lomuscio},
	in-cv = {1},
	isbn = {9781450383073},
	keywords = {game-theory, multi-agent-reinforcement-learning, reinforcement-learning, mean-field-theory, incomplete-information, partially-observable-problems, showcase; year-in-review-2021; forest-wildfire; forest-management; fund-waii-nexus-seed-2024-wildfire},
	location = {Virtual Event, United Kingdom},
	month = {May},
	numpages = {9},
	pages = {537-545},
	pdf = {2021-aamas-ganapathi subramanian-partially.pdf},
	publicationstatus = {published},
	publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
	self = {1},
	series = {AAMAS '21},
	status = {1},
	tempflag = {0},
	title = {Partially Observable Mean Field Reinforcement Learning},
	venue-short = {AAMAS},
	year = {2021},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEFouLi8uLi8uLi8uLi9yZXBvcy9tYXJrY3Jvd2xleS1jYS9hc3NldHMvcGRmLzIwMjEtYWFtYXMtZ2FuYXBhdGhpIHN1YnJhbWFuaWFuLXBhcnRpYWxseS5wZGZPEQRkYm9va2QEAAAAAAQQMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYAMAAAUAAAABAQAAVXNlcnMAAAAIAAAAAQEAAG1jcm93bGV5BQAAAAEBAAByZXBvcwAAAA4AAAABAQAAbWFya2Nyb3dsZXktY2EAAAYAAAABAQAAYXNzZXRzAAADAAAAAQEAAHBkZgAuAAAAAQEAADIwMjEtYWFtYXMtZ2FuYXBhdGhpIHN1YnJhbWFuaWFuLXBhcnRpYWxseS5wZGYAABwAAAABBgAABAAAABQAAAAkAAAANAAAAEwAAABcAAAAaAAAAAgAAAAEAwAAFV0AAAAAAAAIAAAABAMAADnoAwAAAAAACAAAAAQDAABokgoAAAAAAAgAAAAEAwAAh9YQAAAAAAAIAAAABAMAAETPfwMAAAAACAAAAAQDAAC3z38DAAAAAAgAAAAEAwAAzM9/AwAAAAAcAAAAAQYAAMQAAADUAAAA5AAAAPQAAAAEAQAAFAEAACQBAAAIAAAAAAQAAEHDfHhyAAAAGAAAAAECAAABAAAAAAAAAA8AAAAAAAAAAAAAAAAAAAAIAAAABAMAAAUAAAAAAAAABAAAAAMDAAD1AQAACAAAAAEJAABmaWxlOi8vLwwAAAABAQAATWFjaW50b3NoIEhECAAAAAQDAAAAkIKW5wAAAAgAAAAABAAAQcYj7JuAAAAkAAAAAQEAADA5QjdFQUJFLTY3OTUtNENERi1BQjI0LTNGRjA4NTY1RDAxNhgAAAABAgAAgQAAAAEAAADvEwAAAQAAAAAAAAAAAAAAAQAAAAEBAAAvAAAAAAAAAAEFAAAQAQAAAQIAADNlYzlhZGJiYzA0MTkzYmZjMWZlMzJmNWVmOTVjYmQ3N2IwZWJjMDU5YzExYWEyNDRiOTAyNTY1NzU5M2Q0YjM7MDA7MDAwMDAwMDA7MDAwMDAwMDA7MDAwMDAwMDA7MDAwMDAwMDAwMDAwMDAyMDtjb20uYXBwbGUuYXBwLXNhbmRib3gucmVhZC13cml0ZTswMTswMTAwMDAxMTswMDAwMDAwMDAzN2ZjZmNjOzAxOy91c2Vycy9tY3Jvd2xleS9yZXBvcy9tYXJrY3Jvd2xleS1jYS9hc3NldHMvcGRmLzIwMjEtYWFtYXMtZ2FuYXBhdGhpIHN1YnJhbWFuaWFuLXBhcnRpYWxseS5wZGYAzAAAAP7///8BAAAAAAAAABAAAAAEEAAAoAAAAAAAAAAFEAAANAEAAAAAAAAQEAAAaAEAAAAAAABAEAAAWAEAAAAAAAACIAAANAIAAAAAAAAFIAAApAEAAAAAAAAQIAAAtAEAAAAAAAARIAAA6AEAAAAAAAASIAAAyAEAAAAAAAATIAAA2AEAAAAAAAAgIAAAFAIAAAAAAAAwIAAAQAIAAAAAAAABwAAAiAEAAAAAAAARwAAAFAAAAAAAAAASwAAAmAEAAAAAAACA8AAASAIAAAAAAAAACAANABoAIwCAAAAAAAAAAgEAAAAAAAAABQAAAAAAAAAAAAAAAAAABOg=}}

@article{houtman2013ijwf,
	abstract = {Where a legacy of aggressive wildland fire suppression has left forests in need of fuel reduction, allowing wildland fire to burn may provide fuel treatment benefits, thereby reducing suppression costs from subsequent fires. The least-cost-plus-net-value-change model of wildland fire economics includes benefits of wildfire in a framework for evaluating suppression options. In this study, we estimated one component of that benefit -- the expected present value of the reduction in suppression costs for subsequent fires arising from the fuel treatment effect of a current fire. To that end, we employed Monte Carlo methods to generate a set of scenarios for subsequent fire ignition and weather events, which are referred to as sample paths, for a study area in central Oregon. We simulated fire on the landscape over a 100-year time horizon using existing models of fire behaviour, vegetation and fuels development, and suppression effectiveness, and we estimated suppression costs using an existing suppression cost model. Our estimates suggest that the potential cost savings may be substantial. Further research is needed to estimate the full least-cost-plus-net-value-change model. This line of research will extend the set of tools available for developing wildfire management plans for forested landscapes.},
	annote = {NULL},
	author = {Houtman, Rachel M. and Montgomery, Claire A. and Gagnon, Aaron R. and Calkin, David E. and Dietterich, Thomas G. and McGregor, Sean and Crowley, Mark},
	citations = {108},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-06-27 16:48:05 -0400},
	doi = {10.1071/WF12157},
	file = {:Users/mcrowley/Dropbox/MendeleyDesktop/Houtman et al. - 2013 - Allowing a wildfire to burn Estimating the effect on future fire suppression costs(2).pdf:pdf},
	in-cv = {1},
	in-website = {0},
	issn = {10498001},
	journal = {International Journal of Wildland Fire},
	keywords = {bio-economic modelling,forest-wildfire,forest-wildfire,grant-wici16,proj-spatiallyspreadingprocess,spatial simulation,forest-wildfire, showcase; forest-management; fund-waii-nexus-seed-2024-wildfire},
	mendeley-tags = {grant-wici16,proj-spatiallyspreadingprocess,spatial simulation},
	number = {7},
	pages = {871--882},
	pdf = {2013-ijwf-houtman-allowing.pdf},
	rating = {5},
	self = {1},
	self-citations = {3},
	seminal = {1},
	status = {1},
	tempflag = {0},
	title = {Allowing a wildfire to burn: Estimating the effect on future fire suppression costs},
	url = {https://www.publish.csiro.au/wf/WF12157},
	venue-short = {IJWF},
	volume = {22},
	year = {2013},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEEouLi8uLi8uLi8uLi9yZXBvcy9tYXJrY3Jvd2xleS1jYS9hc3NldHMvcGRmLzIwMTMtaWp3Zi1ob3V0bWFuLWFsbG93aW5nLnBkZk8RBERib29rRAQAAAAABBAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAAwAABQAAAAEBAABVc2VycwAAAAgAAAABAQAAbWNyb3dsZXkFAAAAAQEAAHJlcG9zAAAADgAAAAEBAABtYXJrY3Jvd2xleS1jYQAABgAAAAEBAABhc3NldHMAAAMAAAABAQAAcGRmAB4AAAABAQAAMjAxMy1pandmLWhvdXRtYW4tYWxsb3dpbmcucGRmAAAcAAAAAQYAAAQAAAAUAAAAJAAAADQAAABMAAAAXAAAAGgAAAAIAAAABAMAABVdAAAAAAAACAAAAAQDAAA56AMAAAAAAAgAAAAEAwAAaJIKAAAAAAAIAAAABAMAAIfWEAAAAAAACAAAAAQDAABEz38DAAAAAAgAAAAEAwAAt89/AwAAAAAIAAAABAMAALrPfwMAAAAAHAAAAAEGAAC0AAAAxAAAANQAAADkAAAA9AAAAAQBAAAUAQAACAAAAAAEAABBw4yVbYAAABgAAAABAgAAAQAAAAAAAAAPAAAAAAAAAAAAAAAAAAAACAAAAAQDAAAFAAAAAAAAAAQAAAADAwAA9QEAAAgAAAABCQAAZmlsZTovLy8MAAAAAQEAAE1hY2ludG9zaCBIRAgAAAAEAwAAAJCClucAAAAIAAAAAAQAAEHGI+ybgAAAJAAAAAEBAAAwOUI3RUFCRS02Nzk1LTRDREYtQUIyNC0zRkYwODU2NUQwMTYYAAAAAQIAAIEAAAABAAAA7xMAAAEAAAAAAAAAAAAAAAEAAAABAQAALwAAAAAAAAABBQAAAAEAAAECAAA5NzU0N2VhMWY5MmY1NDQzMjkwMDU1ZGM2MTIyMmJjZTcxY2M0ZDY0ODNkYTVkOTMwMjY2YzA0NDZmYTI3M2JkOzAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwMDAwMDAwMjA7Y29tLmFwcGxlLmFwcC1zYW5kYm94LnJlYWQtd3JpdGU7MDE7MDEwMDAwMTE7MDAwMDAwMDAwMzdmY2ZiYTswMTsvdXNlcnMvbWNyb3dsZXkvcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi8yMDEzLWlqd2YtaG91dG1hbi1hbGxvd2luZy5wZGYAzAAAAP7///8BAAAAAAAAABAAAAAEEAAAkAAAAAAAAAAFEAAAJAEAAAAAAAAQEAAAWAEAAAAAAABAEAAASAEAAAAAAAACIAAAJAIAAAAAAAAFIAAAlAEAAAAAAAAQIAAApAEAAAAAAAARIAAA2AEAAAAAAAASIAAAuAEAAAAAAAATIAAAyAEAAAAAAAAgIAAABAIAAAAAAAAwIAAAMAIAAAAAAAABwAAAeAEAAAAAAAARwAAAFAAAAAAAAAASwAAAiAEAAAAAAACA8AAAOAIAAAAAAAAACAANABoAIwBwAAAAAAAAAgEAAAAAAAAABQAAAAAAAAAAAAAAAAAABLg=},
	bdsk-url-1 = {https://doi.org/10.1071/WF12157}}

@inproceedings{subramanian2018neurips-ai4sg,
	address = {NeurIPS},
	author = {Subramanian, Sriram Ganapathi and Crowley, Mark},
	booktitle = {Neural Information Processing Systems (AI for social good workshop)},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-06-27 16:46:20 -0400},
	in-cv = {1},
	keywords = {reinforcement-learning; machine-learning; mcts; forest-wildfire; forest-management; computational-sustainability; fund-waii-nexus-seed-2024-wildfire},
	pdf = {2018-neurips-ai-subramanian-a complementary.pdf},
	self = {1},
	status = {1},
	tempflag = {0},
	title = {A Complementary Approach to Improve WildFire Prediction Systems.},
	url = {https://aiforsocialgood.github.io/2018/acceptedpapers.htm},
	venue-short = {neurips-ai4sg},
	year = {2018},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEFsuLi8uLi8uLi8uLi9yZXBvcy9tYXJrY3Jvd2xleS1jYS9hc3NldHMvcGRmLzIwMTgtbmV1cmlwcy1haS1zdWJyYW1hbmlhbi1hIGNvbXBsZW1lbnRhcnkucGRmTxEEaGJvb2toBAAAAAAEEDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGQDAAAFAAAAAQEAAFVzZXJzAAAACAAAAAEBAABtY3Jvd2xleQUAAAABAQAAcmVwb3MAAAAOAAAAAQEAAG1hcmtjcm93bGV5LWNhAAAGAAAAAQEAAGFzc2V0cwAAAwAAAAEBAABwZGYALwAAAAEBAAAyMDE4LW5ldXJpcHMtYWktc3VicmFtYW5pYW4tYSBjb21wbGVtZW50YXJ5LnBkZgAcAAAAAQYAAAQAAAAUAAAAJAAAADQAAABMAAAAXAAAAGgAAAAIAAAABAMAABVdAAAAAAAACAAAAAQDAAA56AMAAAAAAAgAAAAEAwAAaJIKAAAAAAAIAAAABAMAAIfWEAAAAAAACAAAAAQDAABEz38DAAAAAAgAAAAEAwAAt89/AwAAAAAIAAAABAMAAL/PfwMAAAAAHAAAAAEGAADEAAAA1AAAAOQAAAD0AAAABAEAABQBAAAkAQAACAAAAAAEAABBw6yoU4AAABgAAAABAgAAAQAAAAAAAAAPAAAAAAAAAAAAAAAAAAAACAAAAAQDAAAFAAAAAAAAAAQAAAADAwAA9QEAAAgAAAABCQAAZmlsZTovLy8MAAAAAQEAAE1hY2ludG9zaCBIRAgAAAAEAwAAAJCClucAAAAIAAAAAAQAAEHGI+ybgAAAJAAAAAEBAAAwOUI3RUFCRS02Nzk1LTRDREYtQUIyNC0zRkYwODU2NUQwMTYYAAAAAQIAAIEAAAABAAAA7xMAAAEAAAAAAAAAAAAAAAEAAAABAQAALwAAAAAAAAABBQAAEQEAAAECAAA2ZWJhYzZhYWQzODk5MTJkOWExNzllNDQ2YzdiOTAwMTVhMzg1OWI1NDcyZDk4OGY2NGQzZWIxODc3N2EzM2M3OzAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwMDAwMDAwMjA7Y29tLmFwcGxlLmFwcC1zYW5kYm94LnJlYWQtd3JpdGU7MDE7MDEwMDAwMTE7MDAwMDAwMDAwMzdmY2ZiZjswMTsvdXNlcnMvbWNyb3dsZXkvcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi8yMDE4LW5ldXJpcHMtYWktc3VicmFtYW5pYW4tYSBjb21wbGVtZW50YXJ5LnBkZgAAAADMAAAA/v///wEAAAAAAAAAEAAAAAQQAACgAAAAAAAAAAUQAAA0AQAAAAAAABAQAABoAQAAAAAAAEAQAABYAQAAAAAAAAIgAAA0AgAAAAAAAAUgAACkAQAAAAAAABAgAAC0AQAAAAAAABEgAADoAQAAAAAAABIgAADIAQAAAAAAABMgAADYAQAAAAAAACAgAAAUAgAAAAAAADAgAABAAgAAAAAAAAHAAACIAQAAAAAAABHAAAAUAAAAAAAAABLAAACYAQAAAAAAAIDwAABIAgAAAAAAAAAIAA0AGgAjAIEAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAE7Q==},
	bdsk-url-1 = {https://aiforsocialgood.github.io/2018/acceptedpapers.htm}}

@inproceedings{subramanian2017rldm,
	address = {Ann Arbor, MI, USA.},
	author = {Subramanian, Sriram Ganapathi and Crowley, Mark},
	booktitle = {Conference on Reinforcement Learning and Decision Making},
	citations = {15},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-06-27 16:46:20 -0400},
	in-cv = {1},
	keywords = {A2C, reinforcement-learning, forest-wildfire, showcase; forest-management; image-processing; fund-waii-nexus-seed-2024-wildfire},
	note = {1},
	pages = {244-248},
	self = {1},
	self-citations = {5},
	status = {1},
	tempflag = {0},
	title = {{Learning Forest Wildfire Dynamics from Satellite Images Using Reinforcement Learning}},
	venue-short = {RLDM},
	year = {2017},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEE4uLi8uLi8uLi8uLi9yZXBvcy9tYXJrY3Jvd2xleS1jYS9hc3NldHMvcGRmLzIwMTctcmxkbS1zdWJyYW1hbmlhbi1sZWFybmluZy5wZGZPEQRMYm9va0wEAAAAAAQQMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAASAMAAAUAAAABAQAAVXNlcnMAAAAIAAAAAQEAAG1jcm93bGV5BQAAAAEBAAByZXBvcwAAAA4AAAABAQAAbWFya2Nyb3dsZXktY2EAAAYAAAABAQAAYXNzZXRzAAADAAAAAQEAAHBkZgAiAAAAAQEAADIwMTctcmxkbS1zdWJyYW1hbmlhbi1sZWFybmluZy5wZGYAABwAAAABBgAABAAAABQAAAAkAAAANAAAAEwAAABcAAAAaAAAAAgAAAAEAwAAFV0AAAAAAAAIAAAABAMAADnoAwAAAAAACAAAAAQDAABokgoAAAAAAAgAAAAEAwAAh9YQAAAAAAAIAAAABAMAAETPfwMAAAAACAAAAAQDAAC3z38DAAAAAAgAAAAEAwAAvM9/AwAAAAAcAAAAAQYAALgAAADIAAAA2AAAAOgAAAD4AAAACAEAABgBAAAIAAAAAAQAAEHDfHhxgAAAGAAAAAECAAABAAAAAAAAAA8AAAAAAAAAAAAAAAAAAAAIAAAABAMAAAUAAAAAAAAABAAAAAMDAAD1AQAACAAAAAEJAABmaWxlOi8vLwwAAAABAQAATWFjaW50b3NoIEhECAAAAAQDAAAAkIKW5wAAAAgAAAAABAAAQcYj7JuAAAAkAAAAAQEAADA5QjdFQUJFLTY3OTUtNENERi1BQjI0LTNGRjA4NTY1RDAxNhgAAAABAgAAgQAAAAEAAADvEwAAAQAAAAAAAAAAAAAAAQAAAAEBAAAvAAAAAAAAAAEFAAAEAQAAAQIAAGRmOGQ0NGQzODBhY2JiYTNlZWUwZjkzNDdiMTEwZGIxNTAyMzNkMzM3Y2U3MTllZGE4ZWZhZjk3NzEwZDM3YWY7MDA7MDAwMDAwMDA7MDAwMDAwMDA7MDAwMDAwMDA7MDAwMDAwMDAwMDAwMDAyMDtjb20uYXBwbGUuYXBwLXNhbmRib3gucmVhZC13cml0ZTswMTswMTAwMDAxMTswMDAwMDAwMDAzN2ZjZmJjOzAxOy91c2Vycy9tY3Jvd2xleS9yZXBvcy9tYXJrY3Jvd2xleS1jYS9hc3NldHMvcGRmLzIwMTctcmxkbS1zdWJyYW1hbmlhbi1sZWFybmluZy5wZGYAzAAAAP7///8BAAAAAAAAABAAAAAEEAAAlAAAAAAAAAAFEAAAKAEAAAAAAAAQEAAAXAEAAAAAAABAEAAATAEAAAAAAAACIAAAKAIAAAAAAAAFIAAAmAEAAAAAAAAQIAAAqAEAAAAAAAARIAAA3AEAAAAAAAASIAAAvAEAAAAAAAATIAAAzAEAAAAAAAAgIAAACAIAAAAAAAAwIAAANAIAAAAAAAABwAAAfAEAAAAAAAARwAAAFAAAAAAAAAASwAAAjAEAAAAAAACA8AAAPAIAAAAAAAAACAANABoAIwB0AAAAAAAAAgEAAAAAAAAABQAAAAAAAAAAAAAAAAAABMQ=}}

@article{jain2020review,
	abbr = {WildfireMLRev},
	abstract = {
Artificial intelligence has been applied in wildfire science and management since the 1990s, with early applications including neural networks and expert systems. Since then the field has rapidly progressed congruently with the wide adoption of machine learning (ML) methods in the environmental sciences. Here, we present a scoping review of ML applications in wildfire science and management. Our overall objective is to improve awareness of ML methods among wildfire researchers and managers, as well as illustrate the diverse and challenging range of problems in wildfire science available to ML data scientists. To that end, we first present an overview of popular ML approaches used in wildfire science to date, and then review the use of ML in wildfire science as broadly categorized into six problem domains, including: 1) fuels characterization, fire detection, and mapping; 2) fire weather and climate change; 3) fire occurrence, susceptibility, and risk; 4) fire behavior prediction; 5) fire effects; and 6) fire management. Furthermore, we discuss the advantages and limitations of various ML approaches relating to data size, computational requirements, generalizability, and interpretability, as well as identify opportunities for future advances in the science and management of wildfires within a data science context. In total, we identified 298 relevant publications, where the most frequently used ML methods across problem domains included random forests, MaxEnt, artificial neural networks, decision trees, support vector machines, and genetic algorithms. As such, there exists opportunities to apply more current ML methods --- including deep learning and agent based learning --- in the wildfire sciences, especially in instances involving very large multivariate datasets. We must recognize, however, that despite the ability of ML models to learn on their own, expertise in wildfire science is necessary to ensure realistic modelling of fire processes across multiple scales, while the complexity of some ML methods, such as deep learning, requires a dedicated and sophisticated knowledge of their application. Finally, we stress that the wildfire research and management communities play an active role in providing relevant, high quality, and freely available wildfire data for use by practitioners of ML methods.},
	arxiv = {2003.00646},
	author = {Jain, Piyush and Coogan, Sean CP and Ganapathi Subramanian, Sriram and Crowley, Mark and Taylor, Steve and Flannigan, Mike D},
	citations = {474},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-06-27 16:48:06 -0400},
	doi = {https://doi.org/10.1139/er-2020-0019},
	in-cv = {1},
	in-website = {0},
	journal = {Environmental Reviews},
	keywords = {showcase; year-in-review-2021; forest-management; machine-learning; forest-wildfire; tree-based-ensembles; fund-waii-nexus-seed-2024-wildfire},
	month = {July},
	number = {3},
	paperdesc = {This review paper arose from my visit to BC to speak on the use of AI for Forest Fire management and led to a collaboration amongst these senior researchers, myself and my PhD student Sriram. We collaborated on every part of the paper, I especially wrote the general AI/ML background and checked that each specific Forest Fire domain was connected correctly to the ML literature. It will serve as a much-needed resource for researches in my field as well as applied Forest Fire Management and Science fields. Note, that for the tutorials there is some self-citation included.},
	pdf = {2020-envrevjrnl-jain-review.pdf},
	publisher = {Canadian Science Publishing},
	rating = {4},
	self = {1},
	slides = {https://www.dropbox.com/scl/fi/5236qksp44pp96tll8egl/2020-envrevjrnl-jain-review1.pdf?rlkey=1ycxvh8tyfxi8cxlzcctxch2y&raw=1},
	status = {1},
	tempflag = {0},
	title = {A review of machine learning applications in wildfire science and management},
	url = {https://cdnsciencepub.com/doi/10.1139/er-2020-0019},
	venue-short = {EnvRevJrnl},
	volume = {28},
	year = {2020},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEEsuLi8uLi8uLi8uLi9yZXBvcy9tYXJrY3Jvd2xleS1jYS9hc3NldHMvcGRmLzIwMjAtZW52cmV2anJubC1qYWluLXJldmlldy5wZGZPEQRIYm9va0gEAAAAAAQQMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAARAMAAAUAAAABAQAAVXNlcnMAAAAIAAAAAQEAAG1jcm93bGV5BQAAAAEBAAByZXBvcwAAAA4AAAABAQAAbWFya2Nyb3dsZXktY2EAAAYAAAABAQAAYXNzZXRzAAADAAAAAQEAAHBkZgAfAAAAAQEAADIwMjAtZW52cmV2anJubC1qYWluLXJldmlldy5wZGYAHAAAAAEGAAAEAAAAFAAAACQAAAA0AAAATAAAAFwAAABoAAAACAAAAAQDAAAVXQAAAAAAAAgAAAAEAwAAOegDAAAAAAAIAAAABAMAAGiSCgAAAAAACAAAAAQDAACH1hAAAAAAAAgAAAAEAwAARM9/AwAAAAAIAAAABAMAALfPfwMAAAAACAAAAAQDAADGz38DAAAAABwAAAABBgAAtAAAAMQAAADUAAAA5AAAAPQAAAAEAQAAFAEAAAgAAAAABAAAQcYUQv6AAAAYAAAAAQIAAAEAAAAAAAAADwAAAAAAAAAAAAAAAAAAAAgAAAAEAwAABQAAAAAAAAAEAAAAAwMAAPUBAAAIAAAAAQkAAGZpbGU6Ly8vDAAAAAEBAABNYWNpbnRvc2ggSEQIAAAABAMAAACQgpbnAAAACAAAAAAEAABBxiPsm4AAACQAAAABAQAAMDlCN0VBQkUtNjc5NS00Q0RGLUFCMjQtM0ZGMDg1NjVEMDE2GAAAAAECAACBAAAAAQAAAO8TAAABAAAAAAAAAAAAAAABAAAAAQEAAC8AAAAAAAAAAQUAAAEBAAABAgAAYzcxY2QyOWIwMjQ5MzdjZDQ0YzY4MWFjZTE4NjNjYzcxOGQ0ZDg1YjcxYzc1M2JlOTJiYTM3N2Q5NzhjYWFiMjswMDswMDAwMDAwMDswMDAwMDAwMDswMDAwMDAwMDswMDAwMDAwMDAwMDAwMDIwO2NvbS5hcHBsZS5hcHAtc2FuZGJveC5yZWFkLXdyaXRlOzAxOzAxMDAwMDExOzAwMDAwMDAwMDM3ZmNmYzY7MDE7L3VzZXJzL21jcm93bGV5L3JlcG9zL21hcmtjcm93bGV5LWNhL2Fzc2V0cy9wZGYvMjAyMC1lbnZyZXZqcm5sLWphaW4tcmV2aWV3LnBkZgAAAADMAAAA/v///wEAAAAAAAAAEAAAAAQQAACQAAAAAAAAAAUQAAAkAQAAAAAAABAQAABYAQAAAAAAAEAQAABIAQAAAAAAAAIgAAAkAgAAAAAAAAUgAACUAQAAAAAAABAgAACkAQAAAAAAABEgAADYAQAAAAAAABIgAAC4AQAAAAAAABMgAADIAQAAAAAAACAgAAAEAgAAAAAAADAgAAAwAgAAAAAAAAHAAAB4AQAAAAAAABHAAAAUAAAAAAAAABLAAACIAQAAAAAAAIDwAAA4AgAAAAAAAAAIAA0AGgAjAHEAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAEvQ==},
	bdsk-file-2 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxAuLi4vYXNzZXRzL3BkZi8yMDIwLWVudnJldmpybmwtamFpbi1yZXZpZXcxLnBkZk8RAbwAAAAAAbwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAAAAAABCRAAB/////x8yMDIwLWVudnJldmpybmwtamEjRkZGRkZGRkYucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/////AAAAAAAAAAAAAAAAAAEAAwAACiBjdQAAAAAAAAAAAAAAAAADcGRmAAACAFEvOlVzZXJzOm1jcm93bGV5OnJlcG9zOm1hcmtjcm93bGV5LWNhOmFzc2V0czpwZGY6MjAyMC1lbnZyZXZqcm5sLWphaW4tcmV2aWV3MS5wZGYAAA4AQgAgADIAMAAyADAALQBlAG4AdgByAGUAdgBqAHIAbgBsAC0AagBhAGkAbgAtAHIAZQB2AGkAZQB3ADEALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAE9Vc2Vycy9tY3Jvd2xleS9yZXBvcy9tYXJrY3Jvd2xleS1jYS9hc3NldHMvcGRmLzIwMjAtZW52cmV2anJubC1qYWluLXJldmlldzEucGRmAAATAAEvAAAVAAIAD///AAAACAANABoAJABVAAAAAAAAAgEAAAAAAAAABQAAAAAAAAAAAAAAAAAAAhU=}}

@article{ghali2023fire,
	abstract = {Wildland fires are one of the most dangerous natural risks, causing significant economic damage and loss of lives worldwide. Every year, millions of hectares are lost, and experts warn that the frequency and severity of wildfires will increase in the coming years due to climate change. To mitigate these hazards, numerous deep learning models were developed to detect and map wildland fires, estimate their severity, and predict their spread. In this paper, we provide a comprehensive review of recent deep learning techniques for detecting, mapping, and predicting wildland fires using satellite remote sensing data. We begin by introducing remote sensing satellite systems and their use in wildfire monitoring. Next, we review the deep learning methods employed for these tasks, including fire detection and mapping, severity estimation, and spread prediction. We further present the popular datasets used in these studies. Finally, we address the challenges faced by these models to accurately predict wildfire behaviors, and suggest future directions for developing reliable and robust wildland fire models.},
	article-number = {192},
	author = {Ghali, Rafik and Akhloufi, Moulay A.},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-06-27 16:46:20 -0400},
	doi = {10.3390/fire6050192},
	issn = {2571-6255},
	journal = {Fire},
	keywords = {forest-management; forest-wildfire; fund-waii-nexus-seed-2024-wildfire},
	number = {5},
	title = {Deep Learning Approaches for Wildland Fires Using Satellite Remote Sensing Data: Detection, Mapping, and Prediction},
	url = {https://www.mdpi.com/2571-6255/6/5/192},
	venue-short = {fire},
	volume = {6},
	year = {2023},
	bdsk-url-1 = {https://www.mdpi.com/2571-6255/6/5/192},
	bdsk-url-2 = {https://doi.org/10.3390/fire6050192}}

@inproceedings{pmlr-v81-buolamwini18a,
	abstract = {Recent studies demonstrate that machine learning algorithms can discriminate based on classes like race and gender. In this work, we present an approach to evaluate bias present in automated facial analysis algorithms and datasets with respect to phenotypic subgroups. Using the dermatologist  approved Fitzpatrick Skin Type classification system, we characterize the gender and skin type distribution of two facial analysis benchmarks, IJB-A and Adience. We find that these datasets are overwhelmingly composed of lighter-skinned subjects (79.6% for IJB-A and 86.2% for Adience) and introduce a new facial analysis dataset which is balanced by gender and skin type. We evaluate 3 commercial gender classification systems using our dataset and show that darker-skinned females are the most misclassified group (with error rates of up to 34.7%). The maximum error rate for lighter-skinned males is 0.8%. The substantial disparities in the accuracy of classifying darker females, lighter females, darker males, and lighter males in gender classification systems require urgent attention if commercial companies are to build genuinely fair, transparent and accountable facial analysis algorithms.},
	author = {Buolamwini, Joy and Gebru, Timnit},
	booktitle = {Proceedings of the 1st Conference on Fairness, Accountability and Transparency},
	date-added = {2024-06-06 16:58:23 -0400},
	date-modified = {2024-06-06 17:01:03 -0400},
	editor = {Friedler, Sorelle A. and Wilson, Christo},
	keywords = {course-watspeed-ai, ethical-ai, bias, fairness, deep-learning, racism, value-alignment},
	month = {23--24 Feb},
	pages = {77--91},
	pdf = {http://proceedings.mlr.press/v81/buolamwini18a/buolamwini18a.pdf},
	publisher = {PMLR},
	series = {Proceedings of Machine Learning Research},
	title = {Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification},
	url = {https://proceedings.mlr.press/v81/buolamwini18a.html},
	venue-short = {pmlr},
	volume = {81},
	year = {2018},
	bdsk-url-1 = {https://proceedings.mlr.press/v81/buolamwini18a.html}}

@book{ghojogh2022springerbook,
	abbr = {Textbook},
	abstract = {Dimensionality reduction, also known as manifold learning, is an area of machine learning used for extracting informative features from data, for better representation of data or separation between classes. This book presents a cohesive review of linear and nonlinear dimensionality reduction and manifold learning. Three main aspects of dimensionality reduction are covered -- spectral dimensionality reduction, probabilistic dimensionality reduction, and neural network-based dimensionality reduction, which have geometric, probabilistic, and information-theoretic points of view to dimensionality reduction, respectively. This book delves into basic concepts and recent developments in the field of dimensionality reduction and manifold learning, providing the reader with a comprehensive understanding. The necessary background and preliminaries, on linear algebra, optimization, and kernels, are also explained in the book to ensure a comprehensive understanding of the algorithms.

The tools this book introduces are applied to various applications involving feature extraction, image processing, computer vision, and signal processing. This book is applicable to a wide audience who would like to acquire a deep understanding of the various ways to extract, transform, and understand the structure of data. The intended audiences are academics, students, and industry professionals. Academic researchers and students can use this book as a textbook for machine learning and dimensionality reduction. Data scientists, machine learning scientists, computer vision scientists, computer scientists, statisticians, and mathematicians in the fields of applied mathematics, statistical learning, Riemannian manifolds, subspace analysis, linear algebra, and optimization can use this book as a reference book for both technical and applied concepts. Industry professionals, including applied engineers, data engineers, and engineers in various fields of science dealing with machine learning, can use this book as a guidebook for feature extraction from their data as the raw data in industry often requires pre-processing. Data feature extraction is useful in various fields of science including engineering, physics, chemistry, biometrics, biomedical signals and images, etc.

This book is structured as a reference textbook, so that it can be used for advanced courses, as an in-depth supplementary resource or for researchers or practitioners who want to learn about dimensionality reduction and manifold learning. The book is grounded in theory, but provides thorough explanations and diverse examples to improve the readers comprehension of the advanced topics. Advanced methods are explained in a step-by-step manner so that readers of all levels can follow the reasoning and come to a deep understanding of the concepts. This book does not assume the reader has an advanced theoretical background in machine learning and provides necessary background, though an undergraduate-level background in linear algebra and calculus is recommended.},
	annote = {My former PhD student Ghojogh (grad S21) led completion of our textbook on the subject of his thesis Dimensionality Reduction and Manifold Learning.  He created the primary content for the book with significant contributions from the coauthors. In the Spring 2022 we hired a copy-editor to improve the text flow, and the draft book was submitted to Springer Nature in the early Fall of 2022. The publisher now has our final copy edits and the book is expected to be published in early 2023.},
	author = {Benyamin Ghojogh and Mark Crowley and Fakhri Karray and Ali Ghodsi},
	citations = {11},
	date-added = {2024-04-22 20:04:33 -0400},
	date-modified = {2024-04-22 20:04:33 -0400},
	in-cv = {1},
	in-website = {1},
	isbn-10 = {3031106016},
	isbn-13 = {978-3031106016},
	keywords = {manifold-learning, dimensionality-reduction, machine-learning, metric-learning, showcase},
	month = {February},
	pages = {363},
	publicationstatus = {published},
	publisher = {Springer Nature},
	rating = {5},
	self = {1},
	self-citation = {4},
	status = {1},
	title = {Elements of Dimensionality Reduction and Manifold Learning},
	url = {https://link.springer.com/book/10.1007/978-3-031-10602-6},
	venue-short = {SpringerBook},
	year = {2023},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEJsuLi8uLi8uLi9Eb2N1bWVudHNXYXRlcmxvby9Qcm9qZWN0cy9vbGQtZG9uZS1oaWRkZW4vTWFuZm9sZExlYXJuaW5nQm9vay9maW5hbCBwdWJsaXNoZWQvRWxlbWVudHNfb2ZfRGltZW5zaW9uYWxpdHlfUmVkdWN0aW9uX2FuZF9NYW5pZm9sZF9MZWFybmluZ18yMDIzLnBkZk8RBThib29rOAUAAAAABBAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA0BAAABQAAAAEBAABVc2VycwAAAAgAAAABAQAAbWNyb3dsZXkHAAAAAQEAAERyb3Bib3gAEQAAAAEBAABEb2N1bWVudHNXYXRlcmxvbwAAAAgAAAABAQAAUHJvamVjdHMPAAAAAQEAAG9sZC1kb25lLWhpZGRlbgATAAAAAQEAAE1hbmZvbGRMZWFybmluZ0Jvb2sADwAAAAEBAABmaW5hbCBwdWJsaXNoZWQAQwAAAAEBAABFbGVtZW50c19vZl9EaW1lbnNpb25hbGl0eV9SZWR1Y3Rpb25fYW5kX01hbmlmb2xkX0xlYXJuaW5nXzIwMjMucGRmACQAAAABBgAABAAAABQAAAAkAAAANAAAAFAAAABgAAAAeAAAAJQAAACsAAAACAAAAAQDAAAVXQAAAAAAAAgAAAAEAwAAOegDAAAAAAAIAAAABAMAAF91BAAAAAAACAAAAAQDAADQjgQAAAAAAAgAAAAEAwAAnI8EAAAAAAAIAAAABAMAAJWSBAAAAAAACAAAAAQDAABskwQAAAAAAAgAAAAEAwAAmoh+AAAAAAAIAAAABAMAAOFEwAAAAAAAJAAAAAEGAAAkAQAANAEAAEQBAABUAQAAZAEAAHQBAACEAQAAlAEAAKQBAAAIAAAAAAQAAEHEyiv+H+eYGAAAAAECAAABAAAAAAAAAA8AAAAAAAAAAAAAAAAAAAAIAAAABAMAAAcAAAAAAAAABAAAAAMDAAD1AQAACAAAAAEJAABmaWxlOi8vLwwAAAABAQAATWFjaW50b3NoIEhECAAAAAQDAAAAkIKW5wAAAAgAAAAABAAAQcYj7JuAAAAkAAAAAQEAADA5QjdFQUJFLTY3OTUtNENERi1BQjI0LTNGRjA4NTY1RDAxNhgAAAABAgAAgQAAAAEAAADvEwAAAQAAAAAAAAAAAAAAAQAAAAEBAAAvAAAAAAAAAAEFAABcAQAAAQIAADc5MTY0YjY5ZGRkOGE0MWIyMWUyNDgyYzFiZmM0MjM1MjFhMWE5ODcyMzE0NjA3Mjk5ZWI3MTkxNjg3YjFkYWM7MDA7MDAwMDAwMDA7MDAwMDAwMDA7MDAwMDAwMDA7MDAwMDAwMDAwMDAwMDAyMDtjb20uYXBwbGUuYXBwLXNhbmRib3gucmVhZC13cml0ZTswMTswMTAwMDAxMTswMDAwMDAwMDAwYzA0NGUxOzAxOy91c2Vycy9tY3Jvd2xleS9kcm9wYm94L2RvY3VtZW50c3dhdGVybG9vL3Byb2plY3RzL29sZC1kb25lLWhpZGRlbi9tYW5mb2xkbGVhcm5pbmdib29rL2ZpbmFsIHB1Ymxpc2hlZC9lbGVtZW50c19vZl9kaW1lbnNpb25hbGl0eV9yZWR1Y3Rpb25fYW5kX21hbmlmb2xkX2xlYXJuaW5nXzIwMjMucGRmAMwAAAD+////AQAAAAAAAAAQAAAABBAAAPgAAAAAAAAABRAAALQBAAAAAAAAEBAAAPABAAAAAAAAQBAAAOABAAAAAAAAAiAAALwCAAAAAAAABSAAACwCAAAAAAAAECAAADwCAAAAAAAAESAAAHACAAAAAAAAEiAAAFACAAAAAAAAEyAAAGACAAAAAAAAICAAAJwCAAAAAAAAMCAAAMgCAAAAAAAAAcAAABACAAAAAAAAEcAAABQAAAAAAAAAEsAAACACAAAAAAAAgPAAANACAAAAAAAAAAgADQAaACMAwQAAAAAAAAIBAAAAAAAAAAUAAAAAAAAAAAAAAAAAAAX9},
	bdsk-url-1 = {https://www.amazon.ca/Elements-Dimensionality-Reduction-Manifold-Learning/dp/3031106016/ref=sr_1_1?keywords=9783031106019&linkCode=qs&qid=1659572815&returnFromLogin=1&s=books&sr=1-1},
	bdsk-url-2 = {https://link.springer.com/book/10.1007/978-3-031-10602-6}}

@inproceedings{2024-submission142-canai-gpu-job,
	booktitle = {(under review) The 37th Canadian Conference on Artificial Intelligence},
	date-added = {2024-03-25 00:48:06 -0400},
	date-modified = {2024-03-25 00:49:00 -0400},
	keywords = {reinforcement-learning, gpu-scheduling, systems, scheduling, optimization, heuristics},
	title = {GPU Job Scheduler with Deep Reinforcement Learning},
	year = {2024},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEC9hc3NldHMvcGRmLzIwMjQtc3VibWlzc2lvbjE0Mi1jYW5haS1ncHUtam9iLnBkZk8RBKxib29rrAQAAAAABBAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACoAwAABQAAAAEBAABVc2VycwAAAAgAAAABAQAAbWNyb3dsZXkHAAAAAQEAAERyb3Bib3gABAAAAAEBAABBcHBzDQAAAAEBAAByZW1vdGVseS1zYXZlAAAACAAAAAEBAABBSVRvcGljcwYAAAABAQAAYXNzZXRzAAADAAAAAQEAAHBkZgAkAAAAAQEAADIwMjQtc3VibWlzc2lvbjE0Mi1jYW5haS1ncHUtam9iLnBkZiQAAAABBgAABAAAABQAAAAkAAAANAAAAEAAAABYAAAAaAAAAHgAAACEAAAACAAAAAQDAAAVXQAAAAAAAAgAAAAEAwAAOegDAAAAAAAIAAAABAMAAF91BAAAAAAACAAAAAQDAADRjgQAAAAAAAgAAAAEAwAAEFF0AgAAAAAIAAAABAMAAJ4W5wIAAAAACAAAAAQDAAA1z+ACAAAAAAgAAAAEAwAANs/gAgAAAAAIAAAABAMAAPti6QIAAAAAJAAAAAEGAADcAAAA7AAAAPwAAAAMAQAAHAEAACwBAAA8AQAATAEAAFwBAAAIAAAAAAQAAEHF2JunJ7C5GAAAAAECAAABAAAAAAAAAA8AAAAAAAAAAAAAAAAAAAAIAAAABAMAAAcAAAAAAAAABAAAAAMDAAD1AQAACAAAAAEJAABmaWxlOi8vLwwAAAABAQAATWFjaW50b3NoIEhECAAAAAQDAAAAkIKW5wAAAAgAAAAABAAAQcYj7JuAAAAkAAAAAQEAADA5QjdFQUJFLTY3OTUtNENERi1BQjI0LTNGRjA4NTY1RDAxNhgAAAABAgAAgQAAAAEAAADvEwAAAQAAAAAAAAAAAAAAAQAAAAEBAAAvAAAAAAAAAAEFAAAVAQAAAQIAADg4MTNhNDk1ZjVkMzVjMzViZDBmM2ZkZTZlMTc4YWYxYjVmYTlmMWJjMmFlYzU2ZGU4ZWY4NTkzYzlmNTk4NmE7MDA7MDAwMDAwMDA7MDAwMDAwMDA7MDAwMDAwMDA7MDAwMDAwMDAwMDAwMDAyMDtjb20uYXBwbGUuYXBwLXNhbmRib3gucmVhZC13cml0ZTswMTswMTAwMDAxMTswMDAwMDAwMDAyZTk2MmZiOzAxOy91c2Vycy9tY3Jvd2xleS9kcm9wYm94L2FwcHMvcmVtb3RlbHktc2F2ZS9haXRvcGljcy9hc3NldHMvcGRmLzIwMjQtc3VibWlzc2lvbjE0Mi1jYW5haS1ncHUtam9iLnBkZgAAAADMAAAA/v///wEAAAAAAAAAEAAAAAQQAACwAAAAAAAAAAUQAABsAQAAAAAAABAQAACoAQAAAAAAAEAQAACYAQAAAAAAAAIgAAB0AgAAAAAAAAUgAADkAQAAAAAAABAgAAD0AQAAAAAAABEgAAAoAgAAAAAAABIgAAAIAgAAAAAAABMgAAAYAgAAAAAAACAgAABUAgAAAAAAADAgAACAAgAAAAAAAAHAAADIAQAAAAAAABHAAAAUAAAAAAAAABLAAADYAQAAAAAAAIDwAACIAgAAAAAAAAAIAA0AGgAjAFUAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAFBQ==}}

@inproceedings{2024-submission73-canai-deep-hedging,
	booktitle = {(under review) The 37th Canadian Conference on Artificial Intelligence},
	date-added = {2024-03-25 00:46:03 -0400},
	date-modified = {2024-03-25 00:47:43 -0400},
	keywords = {reinforcement-learning, finance, quantitative-analysis, hedging},
	title = {Deep Hedging with Market Impact},
	year = {2024},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEDNhc3NldHMvcGRmLzIwMjQtc3VibWlzc2lvbjczLWNhbmFpLWRlZXAtaGVkZ2luZy5wZGZPEQS0Ym9va7QEAAAAAAQQMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsAMAAAUAAAABAQAAVXNlcnMAAAAIAAAAAQEAAG1jcm93bGV5BwAAAAEBAABEcm9wYm94AAQAAAABAQAAQXBwcw0AAAABAQAAcmVtb3RlbHktc2F2ZQAAAAgAAAABAQAAQUlUb3BpY3MGAAAAAQEAAGFzc2V0cwAAAwAAAAEBAABwZGYAKAAAAAEBAAAyMDI0LXN1Ym1pc3Npb243My1jYW5haS1kZWVwLWhlZGdpbmcucGRmJAAAAAEGAAAEAAAAFAAAACQAAAA0AAAAQAAAAFgAAABoAAAAeAAAAIQAAAAIAAAABAMAABVdAAAAAAAACAAAAAQDAAA56AMAAAAAAAgAAAAEAwAAX3UEAAAAAAAIAAAABAMAANGOBAAAAAAACAAAAAQDAAAQUXQCAAAAAAgAAAAEAwAAnhbnAgAAAAAIAAAABAMAADXP4AIAAAAACAAAAAQDAAA2z+ACAAAAAAgAAAAEAwAAagLhAgAAAAAkAAAAAQYAAOAAAADwAAAAAAEAABABAAAgAQAAMAEAAEABAABQAQAAYAEAAAgAAAAABAAAQcXYm57yrBgYAAAAAQIAAAEAAAAAAAAADwAAAAAAAAAAAAAAAAAAAAgAAAAEAwAABwAAAAAAAAAEAAAAAwMAAPUBAAAIAAAAAQkAAGZpbGU6Ly8vDAAAAAEBAABNYWNpbnRvc2ggSEQIAAAABAMAAACQgpbnAAAACAAAAAAEAABBxiPsm4AAACQAAAABAQAAMDlCN0VBQkUtNjc5NS00Q0RGLUFCMjQtM0ZGMDg1NjVEMDE2GAAAAAECAACBAAAAAQAAAO8TAAABAAAAAAAAAAAAAAABAAAAAQEAAC8AAAAAAAAAAQUAABkBAAABAgAANjYwNDhiMDAzMzNkYzI3YTExMzg2MmZmNTI2OTUyOWEwYTEzOTUzMWY5MTg5ZjMyMDVmMWIyYmYxNzA4MDEyZDswMDswMDAwMDAwMDswMDAwMDAwMDswMDAwMDAwMDswMDAwMDAwMDAwMDAwMDIwO2NvbS5hcHBsZS5hcHAtc2FuZGJveC5yZWFkLXdyaXRlOzAxOzAxMDAwMDExOzAwMDAwMDAwMDJlMTAyNmE7MDE7L3VzZXJzL21jcm93bGV5L2Ryb3Bib3gvYXBwcy9yZW1vdGVseS1zYXZlL2FpdG9waWNzL2Fzc2V0cy9wZGYvMjAyNC1zdWJtaXNzaW9uNzMtY2FuYWktZGVlcC1oZWRnaW5nLnBkZgAAAADMAAAA/v///wEAAAAAAAAAEAAAAAQQAAC0AAAAAAAAAAUQAABwAQAAAAAAABAQAACsAQAAAAAAAEAQAACcAQAAAAAAAAIgAAB4AgAAAAAAAAUgAADoAQAAAAAAABAgAAD4AQAAAAAAABEgAAAsAgAAAAAAABIgAAAMAgAAAAAAABMgAAAcAgAAAAAAACAgAABYAgAAAAAAADAgAACEAgAAAAAAAAHAAADMAQAAAAAAABHAAAAUAAAAAAAAABLAAADcAQAAAAAAAIDwAACMAgAAAAAAAAAIAA0AGgAjAFkAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAFEQ==}}

@incollection{rodriguezsoto2021ijcai-Multi-Objective-Reinforcement,
	date-added = {2024-03-25 00:16:29 -0400},
	date-modified = {2024-03-25 00:17:21 -0400},
	keywords = {ai-morality},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEENhc3NldHMvcGRmL3JvZHJpZ3VlenNvdG8yMDIxaWpjYWktTXVsdGktT2JqZWN0aXZlLVJlaW5mb3JjZW1lbnQucGRmTxEE1GJvb2vUBAAAAAAEEDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANADAAAFAAAAAQEAAFVzZXJzAAAACAAAAAEBAABtY3Jvd2xleQcAAAABAQAARHJvcGJveAAEAAAAAQEAAEFwcHMNAAAAAQEAAHJlbW90ZWx5LXNhdmUAAAAIAAAAAQEAAEFJVG9waWNzBgAAAAEBAABhc3NldHMAAAMAAAABAQAAcGRmADgAAAABAQAAcm9kcmlndWV6c290bzIwMjFpamNhaS1NdWx0aS1PYmplY3RpdmUtUmVpbmZvcmNlbWVudC5wZGYkAAAAAQYAAAQAAAAUAAAAJAAAADQAAABAAAAAWAAAAGgAAAB4AAAAhAAAAAgAAAAEAwAAFV0AAAAAAAAIAAAABAMAADnoAwAAAAAACAAAAAQDAABfdQQAAAAAAAgAAAAEAwAA0Y4EAAAAAAAIAAAABAMAABBRdAIAAAAACAAAAAQDAACeFucCAAAAAAgAAAAEAwAANc/gAgAAAAAIAAAABAMAADbP4AIAAAAACAAAAAQDAADc9eACAAAAACQAAAABBgAA8AAAAAABAAAQAQAAIAEAADABAABAAQAAUAEAAGABAABwAQAACAAAAAAEAABBxdiXVo1siRgAAAABAgAAAQAAAAAAAAAPAAAAAAAAAAAAAAAAAAAACAAAAAQDAAAHAAAAAAAAAAQAAAADAwAA9QEAAAgAAAABCQAAZmlsZTovLy8MAAAAAQEAAE1hY2ludG9zaCBIRAgAAAAEAwAAAJCClucAAAAIAAAAAAQAAEHGI+ybgAAAJAAAAAEBAAAwOUI3RUFCRS02Nzk1LTRDREYtQUIyNC0zRkYwODU2NUQwMTYYAAAAAQIAAIEAAAABAAAA7xMAAAEAAAAAAAAAAAAAAAEAAAABAQAALwAAAAAAAAABBQAAKQEAAAECAAAxMzAwNTJlODNiMzFhNDRhZDU3NzQ0YmFhNGIyMmM5MjJmMzEwNTI1MDQ5ZTA3Y2Y5NDYzYjY2YmE3ZGFmZTcwOzAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwMDAwMDAwMjA7Y29tLmFwcGxlLmFwcC1zYW5kYm94LnJlYWQtd3JpdGU7MDE7MDEwMDAwMTE7MDAwMDAwMDAwMmUwZjVkYzswMTsvdXNlcnMvbWNyb3dsZXkvZHJvcGJveC9hcHBzL3JlbW90ZWx5LXNhdmUvYWl0b3BpY3MvYXNzZXRzL3BkZi9yb2RyaWd1ZXpzb3RvMjAyMWlqY2FpLW11bHRpLW9iamVjdGl2ZS1yZWluZm9yY2VtZW50LnBkZgAAAADMAAAA/v///wEAAAAAAAAAEAAAAAQQAADEAAAAAAAAAAUQAACAAQAAAAAAABAQAAC8AQAAAAAAAEAQAACsAQAAAAAAAAIgAACIAgAAAAAAAAUgAAD4AQAAAAAAABAgAAAIAgAAAAAAABEgAAA8AgAAAAAAABIgAAAcAgAAAAAAABMgAAAsAgAAAAAAACAgAABoAgAAAAAAADAgAACUAgAAAAAAAAHAAADcAQAAAAAAABHAAAAUAAAAAAAAABLAAADsAQAAAAAAAIDwAACcAgAAAAAAAAAIAA0AGgAjAGkAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAFQQ==}}

@incollection{peschl2021arxiv-MORAL-Aligning,
	date-added = {2024-03-25 00:10:55 -0400},
	date-modified = {2024-03-25 00:17:21 -0400},
	keywords = {ai-morality},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEC1hc3NldHMvcGRmL3Blc2NobDIwMjFhcnhpdi1NT1JBTC1BbGlnbmluZy5wZGZPEQSoYm9va6gEAAAAAAQQMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAApAMAAAUAAAABAQAAVXNlcnMAAAAIAAAAAQEAAG1jcm93bGV5BwAAAAEBAABEcm9wYm94AAQAAAABAQAAQXBwcw0AAAABAQAAcmVtb3RlbHktc2F2ZQAAAAgAAAABAQAAQUlUb3BpY3MGAAAAAQEAAGFzc2V0cwAAAwAAAAEBAABwZGYAIgAAAAEBAABwZXNjaGwyMDIxYXJ4aXYtTU9SQUwtQWxpZ25pbmcucGRmAAAkAAAAAQYAAAQAAAAUAAAAJAAAADQAAABAAAAAWAAAAGgAAAB4AAAAhAAAAAgAAAAEAwAAFV0AAAAAAAAIAAAABAMAADnoAwAAAAAACAAAAAQDAABfdQQAAAAAAAgAAAAEAwAA0Y4EAAAAAAAIAAAABAMAABBRdAIAAAAACAAAAAQDAACeFucCAAAAAAgAAAAEAwAANc/gAgAAAAAIAAAABAMAADbP4AIAAAAACAAAAAQDAAD19eACAAAAACQAAAABBgAA3AAAAOwAAAD8AAAADAEAABwBAAAsAQAAPAEAAEwBAABcAQAACAAAAAAEAABBxdiXV6/82xgAAAABAgAAAQAAAAAAAAAPAAAAAAAAAAAAAAAAAAAACAAAAAQDAAAHAAAAAAAAAAQAAAADAwAA9QEAAAgAAAABCQAAZmlsZTovLy8MAAAAAQEAAE1hY2ludG9zaCBIRAgAAAAEAwAAAJCClucAAAAIAAAAAAQAAEHGI+ybgAAAJAAAAAEBAAAwOUI3RUFCRS02Nzk1LTRDREYtQUIyNC0zRkYwODU2NUQwMTYYAAAAAQIAAIEAAAABAAAA7xMAAAEAAAAAAAAAAAAAAAEAAAABAQAALwAAAAAAAAABBQAAEwEAAAECAAA2MzZmZGY0NTNhOWM2NzBmZTNkYmQ0Y2RkNGM1MDk5YzZlOWM4NWYyN2NjNmI4ZDZkNDYwNWY4YTU2ZDg2NTU5OzAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwMDAwMDAwMjA7Y29tLmFwcGxlLmFwcC1zYW5kYm94LnJlYWQtd3JpdGU7MDE7MDEwMDAwMTE7MDAwMDAwMDAwMmUwZjVmNTswMTsvdXNlcnMvbWNyb3dsZXkvZHJvcGJveC9hcHBzL3JlbW90ZWx5LXNhdmUvYWl0b3BpY3MvYXNzZXRzL3BkZi9wZXNjaGwyMDIxYXJ4aXYtbW9yYWwtYWxpZ25pbmcucGRmAADMAAAA/v///wEAAAAAAAAAEAAAAAQQAACwAAAAAAAAAAUQAABsAQAAAAAAABAQAACoAQAAAAAAAEAQAACYAQAAAAAAAAIgAAB0AgAAAAAAAAUgAADkAQAAAAAAABAgAAD0AQAAAAAAABEgAAAoAgAAAAAAABIgAAAIAgAAAAAAABMgAAAYAgAAAAAAACAgAABUAgAAAAAAADAgAACAAgAAAAAAAAHAAADIAQAAAAAAABHAAAAUAAAAAAAAABLAAADYAQAAAAAAAIDwAACIAgAAAAAAAAAIAA0AGgAjAFMAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAE/w==}}

@incollection{rodriguezsoto2023nca-Multi-objective,
	date-added = {2024-03-25 00:10:29 -0400},
	date-modified = {2024-03-25 00:17:21 -0400},
	keywords = {ai-morality},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEDNhc3NldHMvcGRmL3JvZHJpZ3VlenNvdG8yMDIzbmNhLU11bHRpLW9iamVjdGl2ZS5wZGZPEQS0Ym9va7QEAAAAAAQQMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsAMAAAUAAAABAQAAVXNlcnMAAAAIAAAAAQEAAG1jcm93bGV5BwAAAAEBAABEcm9wYm94AAQAAAABAQAAQXBwcw0AAAABAQAAcmVtb3RlbHktc2F2ZQAAAAgAAAABAQAAQUlUb3BpY3MGAAAAAQEAAGFzc2V0cwAAAwAAAAEBAABwZGYAKAAAAAEBAAByb2RyaWd1ZXpzb3RvMjAyM25jYS1NdWx0aS1vYmplY3RpdmUucGRmJAAAAAEGAAAEAAAAFAAAACQAAAA0AAAAQAAAAFgAAABoAAAAeAAAAIQAAAAIAAAABAMAABVdAAAAAAAACAAAAAQDAAA56AMAAAAAAAgAAAAEAwAAX3UEAAAAAAAIAAAABAMAANGOBAAAAAAACAAAAAQDAAAQUXQCAAAAAAgAAAAEAwAAnhbnAgAAAAAIAAAABAMAADXP4AIAAAAACAAAAAQDAAA2z+ACAAAAAAgAAAAEAwAA3/XgAgAAAAAkAAAAAQYAAOAAAADwAAAAAAEAABABAAAgAQAAMAEAAEABAABQAQAAYAEAAAgAAAAABAAAQcXYl1aOuWkYAAAAAQIAAAEAAAAAAAAADwAAAAAAAAAAAAAAAAAAAAgAAAAEAwAABwAAAAAAAAAEAAAAAwMAAPUBAAAIAAAAAQkAAGZpbGU6Ly8vDAAAAAEBAABNYWNpbnRvc2ggSEQIAAAABAMAAACQgpbnAAAACAAAAAAEAABBxiPsm4AAACQAAAABAQAAMDlCN0VBQkUtNjc5NS00Q0RGLUFCMjQtM0ZGMDg1NjVEMDE2GAAAAAECAACBAAAAAQAAAO8TAAABAAAAAAAAAAAAAAABAAAAAQEAAC8AAAAAAAAAAQUAABkBAAABAgAAYThlYmE3NDgxY2NlODJjMGY2MDk5NjlkNzZjN2VmZGQzY2U0ZWE1YWZkMmI1YTRkODcyMjE4NjRiMGI4YTJlOTswMDswMDAwMDAwMDswMDAwMDAwMDswMDAwMDAwMDswMDAwMDAwMDAwMDAwMDIwO2NvbS5hcHBsZS5hcHAtc2FuZGJveC5yZWFkLXdyaXRlOzAxOzAxMDAwMDExOzAwMDAwMDAwMDJlMGY1ZGY7MDE7L3VzZXJzL21jcm93bGV5L2Ryb3Bib3gvYXBwcy9yZW1vdGVseS1zYXZlL2FpdG9waWNzL2Fzc2V0cy9wZGYvcm9kcmlndWV6c290bzIwMjNuY2EtbXVsdGktb2JqZWN0aXZlLnBkZgAAAADMAAAA/v///wEAAAAAAAAAEAAAAAQQAAC0AAAAAAAAAAUQAABwAQAAAAAAABAQAACsAQAAAAAAAEAQAACcAQAAAAAAAAIgAAB4AgAAAAAAAAUgAADoAQAAAAAAABAgAAD4AQAAAAAAABEgAAAsAgAAAAAAABIgAAAMAgAAAAAAABMgAAAcAgAAAAAAACAgAABYAgAAAAAAADAgAACEAgAAAAAAAAHAAADMAQAAAAAAABHAAAAUAAAAAAAAABLAAADcAQAAAAAAAIDwAACMAgAAAAAAAAAIAA0AGgAjAFkAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAFEQ==}}

@incollection{bai2022arxiv-constitutional-ai,
	date-added = {2024-03-25 00:09:40 -0400},
	date-modified = {2024-03-25 00:17:21 -0400},
	keywords = {ai-morality},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEC1hc3NldHMvcGRmL2JhaTIwMjJhcnhpdi1jb25zdGl0dXRpb25hbC1haS5wZGZPEQSoYm9va6gEAAAAAAQQMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAApAMAAAUAAAABAQAAVXNlcnMAAAAIAAAAAQEAAG1jcm93bGV5BwAAAAEBAABEcm9wYm94AAQAAAABAQAAQXBwcw0AAAABAQAAcmVtb3RlbHktc2F2ZQAAAAgAAAABAQAAQUlUb3BpY3MGAAAAAQEAAGFzc2V0cwAAAwAAAAEBAABwZGYAIgAAAAEBAABiYWkyMDIyYXJ4aXYtY29uc3RpdHV0aW9uYWwtYWkucGRmAAAkAAAAAQYAAAQAAAAUAAAAJAAAADQAAABAAAAAWAAAAGgAAAB4AAAAhAAAAAgAAAAEAwAAFV0AAAAAAAAIAAAABAMAADnoAwAAAAAACAAAAAQDAABfdQQAAAAAAAgAAAAEAwAA0Y4EAAAAAAAIAAAABAMAABBRdAIAAAAACAAAAAQDAACeFucCAAAAAAgAAAAEAwAANc/gAgAAAAAIAAAABAMAADbP4AIAAAAACAAAAAQDAADe9eACAAAAACQAAAABBgAA3AAAAOwAAAD8AAAADAEAABwBAAAsAQAAPAEAAEwBAABcAQAACAAAAAAEAABBxdiXVo6fZRgAAAABAgAAAQAAAAAAAAAPAAAAAAAAAAAAAAAAAAAACAAAAAQDAAAHAAAAAAAAAAQAAAADAwAA9QEAAAgAAAABCQAAZmlsZTovLy8MAAAAAQEAAE1hY2ludG9zaCBIRAgAAAAEAwAAAJCClucAAAAIAAAAAAQAAEHGI+ybgAAAJAAAAAEBAAAwOUI3RUFCRS02Nzk1LTRDREYtQUIyNC0zRkYwODU2NUQwMTYYAAAAAQIAAIEAAAABAAAA7xMAAAEAAAAAAAAAAAAAAAEAAAABAQAALwAAAAAAAAABBQAAEwEAAAECAAAwNTJlNzk1M2E4MjM2ZTU3MWVjZTE1YTQwOTFlM2NiNTMxMjVhMTA3NDU0YTY5NDAzNTRhYjczZTMxMzM2MzI1OzAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwMDAwMDAwMjA7Y29tLmFwcGxlLmFwcC1zYW5kYm94LnJlYWQtd3JpdGU7MDE7MDEwMDAwMTE7MDAwMDAwMDAwMmUwZjVkZTswMTsvdXNlcnMvbWNyb3dsZXkvZHJvcGJveC9hcHBzL3JlbW90ZWx5LXNhdmUvYWl0b3BpY3MvYXNzZXRzL3BkZi9iYWkyMDIyYXJ4aXYtY29uc3RpdHV0aW9uYWwtYWkucGRmAADMAAAA/v///wEAAAAAAAAAEAAAAAQQAACwAAAAAAAAAAUQAABsAQAAAAAAABAQAACoAQAAAAAAAEAQAACYAQAAAAAAAAIgAAB0AgAAAAAAAAUgAADkAQAAAAAAABAgAAD0AQAAAAAAABEgAAAoAgAAAAAAABIgAAAIAgAAAAAAABMgAAAYAgAAAAAAACAgAABUAgAAAAAAADAgAACAAgAAAAAAAAHAAADIAQAAAAAAABHAAAAUAAAAAAAAABLAAADYAQAAAAAAAIDwAACIAgAAAAAAAAAIAA0AGgAjAFMAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAE/w==}}

@incollection{tomasik2014-artificial-reinforcement,
	date-added = {2024-03-25 00:09:29 -0400},
	date-modified = {2024-03-25 00:17:21 -0400},
	keywords = {ai-morality},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEDNhc3NldHMvcGRmL3RvbWFzaWsyMDE0LWFydGlmaWNpYWwtcmVpbmZvcmNlbWVudC5wZGZPEQS0Ym9va7QEAAAAAAQQMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsAMAAAUAAAABAQAAVXNlcnMAAAAIAAAAAQEAAG1jcm93bGV5BwAAAAEBAABEcm9wYm94AAQAAAABAQAAQXBwcw0AAAABAQAAcmVtb3RlbHktc2F2ZQAAAAgAAAABAQAAQUlUb3BpY3MGAAAAAQEAAGFzc2V0cwAAAwAAAAEBAABwZGYAKAAAAAEBAAB0b21hc2lrMjAxNC1hcnRpZmljaWFsLXJlaW5mb3JjZW1lbnQucGRmJAAAAAEGAAAEAAAAFAAAACQAAAA0AAAAQAAAAFgAAABoAAAAeAAAAIQAAAAIAAAABAMAABVdAAAAAAAACAAAAAQDAAA56AMAAAAAAAgAAAAEAwAAX3UEAAAAAAAIAAAABAMAANGOBAAAAAAACAAAAAQDAAAQUXQCAAAAAAgAAAAEAwAAnhbnAgAAAAAIAAAABAMAADXP4AIAAAAACAAAAAQDAAA2z+ACAAAAAAgAAAAEAwAA2fXgAgAAAAAkAAAAAQYAAOAAAADwAAAAAAEAABABAAAgAQAAMAEAAEABAABQAQAAYAEAAAgAAAAABAAAQcXYl1aMfVQYAAAAAQIAAAEAAAAAAAAADwAAAAAAAAAAAAAAAAAAAAgAAAAEAwAABwAAAAAAAAAEAAAAAwMAAPUBAAAIAAAAAQkAAGZpbGU6Ly8vDAAAAAEBAABNYWNpbnRvc2ggSEQIAAAABAMAAACQgpbnAAAACAAAAAAEAABBxiPsm4AAACQAAAABAQAAMDlCN0VBQkUtNjc5NS00Q0RGLUFCMjQtM0ZGMDg1NjVEMDE2GAAAAAECAACBAAAAAQAAAO8TAAABAAAAAAAAAAAAAAABAAAAAQEAAC8AAAAAAAAAAQUAABkBAAABAgAANzZiZGQzZTQyZGQ4YmJmN2VmNzQ1Mjk1MDkxMDQ5M2Y2YTlmOGMyMDNmZjE5NzdlMDkyY2UwMTYwZTdjZjA0ZjswMDswMDAwMDAwMDswMDAwMDAwMDswMDAwMDAwMDswMDAwMDAwMDAwMDAwMDIwO2NvbS5hcHBsZS5hcHAtc2FuZGJveC5yZWFkLXdyaXRlOzAxOzAxMDAwMDExOzAwMDAwMDAwMDJlMGY1ZDk7MDE7L3VzZXJzL21jcm93bGV5L2Ryb3Bib3gvYXBwcy9yZW1vdGVseS1zYXZlL2FpdG9waWNzL2Fzc2V0cy9wZGYvdG9tYXNpazIwMTQtYXJ0aWZpY2lhbC1yZWluZm9yY2VtZW50LnBkZgAAAADMAAAA/v///wEAAAAAAAAAEAAAAAQQAAC0AAAAAAAAAAUQAABwAQAAAAAAABAQAACsAQAAAAAAAEAQAACcAQAAAAAAAAIgAAB4AgAAAAAAAAUgAADoAQAAAAAAABAgAAD4AQAAAAAAABEgAAAsAgAAAAAAABIgAAAMAgAAAAAAABMgAAAcAgAAAAAAACAgAABYAgAAAAAAADAgAACEAgAAAAAAAAHAAADMAQAAAAAAABHAAAAUAAAAAAAAABLAAADcAQAAAAAAAIDwAACMAgAAAAAAAAAIAA0AGgAjAFkAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAFEQ==}}

@incollection{haas2022dnhni_pdf,
	date-added = {2024-03-25 00:09:07 -0400},
	date-modified = {2024-03-25 00:17:21 -0400},
	keywords = {ai-morality},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEBxhc3NldHMvcGRmL2hhYXMyMDIyZG5obmkucGRmTxEEiGJvb2uIBAAAAAAEEDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIQDAAAFAAAAAQEAAFVzZXJzAAAACAAAAAEBAABtY3Jvd2xleQcAAAABAQAARHJvcGJveAAEAAAAAQEAAEFwcHMNAAAAAQEAAHJlbW90ZWx5LXNhdmUAAAAIAAAAAQEAAEFJVG9waWNzBgAAAAEBAABhc3NldHMAAAMAAAABAQAAcGRmABEAAAABAQAAaGFhczIwMjJkbmhuaS5wZGYAAAAkAAAAAQYAAAQAAAAUAAAAJAAAADQAAABAAAAAWAAAAGgAAAB4AAAAhAAAAAgAAAAEAwAAFV0AAAAAAAAIAAAABAMAADnoAwAAAAAACAAAAAQDAABfdQQAAAAAAAgAAAAEAwAA0Y4EAAAAAAAIAAAABAMAABBRdAIAAAAACAAAAAQDAACeFucCAAAAAAgAAAAEAwAANc/gAgAAAAAIAAAABAMAADbP4AIAAAAACAAAAAQDAADh9eACAAAAACQAAAABBgAAzAAAANwAAADsAAAA/AAAAAwBAAAcAQAALAEAADwBAABMAQAACAAAAAAEAABBxdiXVo7VlBgAAAABAgAAAQAAAAAAAAAPAAAAAAAAAAAAAAAAAAAACAAAAAQDAAAHAAAAAAAAAAQAAAADAwAA9QEAAAgAAAABCQAAZmlsZTovLy8MAAAAAQEAAE1hY2ludG9zaCBIRAgAAAAEAwAAAJCClucAAAAIAAAAAAQAAEHGI+ybgAAAJAAAAAEBAAAwOUI3RUFCRS02Nzk1LTRDREYtQUIyNC0zRkYwODU2NUQwMTYYAAAAAQIAAIEAAAABAAAA7xMAAAEAAAAAAAAAAAAAAAEAAAABAQAALwAAAAAAAAABBQAAAgEAAAECAABlNTQ3MTE0M2JmY2ZiNGI1ODhlZjc0ODQ3YzlkYWRiNzIzNDU4NGIwNjU0MTFjNThkNjMyMmQ1YjQ2ODVlYWY2OzAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwMDAwMDAwMjA7Y29tLmFwcGxlLmFwcC1zYW5kYm94LnJlYWQtd3JpdGU7MDE7MDEwMDAwMTE7MDAwMDAwMDAwMmUwZjVlMTswMTsvdXNlcnMvbWNyb3dsZXkvZHJvcGJveC9hcHBzL3JlbW90ZWx5LXNhdmUvYWl0b3BpY3MvYXNzZXRzL3BkZi9oYWFzMjAyMmRuaG5pLnBkZgAAAMwAAAD+////AQAAAAAAAAAQAAAABBAAAKAAAAAAAAAABRAAAFwBAAAAAAAAEBAAAJgBAAAAAAAAQBAAAIgBAAAAAAAAAiAAAGQCAAAAAAAABSAAANQBAAAAAAAAECAAAOQBAAAAAAAAESAAABgCAAAAAAAAEiAAAPgBAAAAAAAAEyAAAAgCAAAAAAAAICAAAEQCAAAAAAAAMCAAAHACAAAAAAAAAcAAALgBAAAAAAAAEcAAABQAAAAAAAAAEsAAAMgBAAAAAAAAgPAAAHgCAAAAAAAAAAgADQAaACMAQgAAAAAAAAIBAAAAAAAAAAUAAAAAAAAAAAAAAAAAAATO}}

@unpublished{ghojogh2020osfpreprint,
	abstract = {This is a tutorial and survey paper on the attention mechanism, transformers, BERT, and GPT. We first explain attention mechanism, sequence-to-sequence model without and with attention, self-attention, and attention in different areas such as natural language processing and computer vision. Then, we explain transformers which do not use any recurrence. We explain all the parts of encoder and decoder in the transformer, including positional encoding, multihead self-attention and cross-attention, and masked multihead attention. Thereafter, we introduce the Bidirectional Encoder Representations from Transformers (BERT) and Generative Pre-trained Transformer (GPT) as the stacks of encoders and decoders of transformer, respectively. We explain their characteristics and how they work.},
	author = {Benyamin Ghojogh and Ali Ghodsi},
	cited-by = {https://paperswithcode.com/paper/attention-mechanism-transformers-bert-and-gpt},
	date-added = {2024-03-24 23:37:59 -0400},
	date-discussed = {2023-05-24 led by Benyamin Ghojogh},
	date-modified = {2024-07-26 00:19:48 -0400},
	doi = {https://osf.io/m6gcn},
	howpublished = {preprint},
	in-website = {1},
	keywords = {rd-done, machine-learning, transformer, nlp, recurrent-neural-networks, lstm; rdgrp-s23},
	month = {December},
	order = {1},
	pdf = {2020-osfpreprin-ghojogh-attention},
	status = {1},
	title = {Attention Mechanism, Transformers, BERT, and GPT: Tutorial and Survey},
	toread = {1},
	url = {https://osf.io/m6gcn},
	venue-short = {osfpreprint},
	year = {2020},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfECVhc3NldHMvcGRmL2dob2pvZ2gyMDIwb3NmcHJlcHJpbnQucGRmTxEEmGJvb2uYBAAAAAAEEDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJQDAAAFAAAAAQEAAFVzZXJzAAAACAAAAAEBAABtY3Jvd2xleQcAAAABAQAARHJvcGJveAAEAAAAAQEAAEFwcHMNAAAAAQEAAHJlbW90ZWx5LXNhdmUAAAAIAAAAAQEAAEFJVG9waWNzBgAAAAEBAABhc3NldHMAAAMAAAABAQAAcGRmABoAAAABAQAAZ2hvam9naDIwMjBvc2ZwcmVwcmludC5wZGYAACQAAAABBgAABAAAABQAAAAkAAAANAAAAEAAAABYAAAAaAAAAHgAAACEAAAACAAAAAQDAAAVXQAAAAAAAAgAAAAEAwAAOegDAAAAAAAIAAAABAMAAF91BAAAAAAACAAAAAQDAADRjgQAAAAAAAgAAAAEAwAAEFF0AgAAAAAIAAAABAMAAJ4W5wIAAAAACAAAAAQDAAA1z+ACAAAAAAgAAAAEAwAANs/gAgAAAAAIAAAABAMAADRY3QIAAAAAJAAAAAEGAADUAAAA5AAAAPQAAAAEAQAAFAEAACQBAAA0AQAARAEAAFQBAAAIAAAAAAQAAEHF06TRgAAAGAAAAAECAAABAAAAAAAAAA8AAAAAAAAAAAAAAAAAAAAIAAAABAMAAAcAAAAAAAAABAAAAAMDAAD1AQAACAAAAAEJAABmaWxlOi8vLwwAAAABAQAATWFjaW50b3NoIEhECAAAAAQDAAAAkIKW5wAAAAgAAAAABAAAQcYj7JuAAAAkAAAAAQEAADA5QjdFQUJFLTY3OTUtNENERi1BQjI0LTNGRjA4NTY1RDAxNhgAAAABAgAAgQAAAAEAAADvEwAAAQAAAAAAAAAAAAAAAQAAAAEBAAAvAAAAAAAAAAEFAAALAQAAAQIAADQ3MzJmMzU3MjFiNjI3YjM3MzA3YTMwOTA1N2YzMTc2M2ZmNjBiZDA0MjJiOTRhN2E3OGM1N2VmMDFjMGFjZDM7MDA7MDAwMDAwMDA7MDAwMDAwMDA7MDAwMDAwMDA7MDAwMDAwMDAwMDAwMDAyMDtjb20uYXBwbGUuYXBwLXNhbmRib3gucmVhZC13cml0ZTswMTswMTAwMDAxMTswMDAwMDAwMDAyZGQ1ODM0OzAxOy91c2Vycy9tY3Jvd2xleS9kcm9wYm94L2FwcHMvcmVtb3RlbHktc2F2ZS9haXRvcGljcy9hc3NldHMvcGRmL2dob2pvZ2gyMDIwb3NmcHJlcHJpbnQucGRmAADMAAAA/v///wEAAAAAAAAAEAAAAAQQAACoAAAAAAAAAAUQAABkAQAAAAAAABAQAACgAQAAAAAAAEAQAACQAQAAAAAAAAIgAABsAgAAAAAAAAUgAADcAQAAAAAAABAgAADsAQAAAAAAABEgAAAgAgAAAAAAABIgAAAAAgAAAAAAABMgAAAQAgAAAAAAACAgAABMAgAAAAAAADAgAAB4AgAAAAAAAAHAAADAAQAAAAAAABHAAAAUAAAAAAAAABLAAADQAQAAAAAAAIDwAACAAgAAAAAAAAAIAA0AGgAjAEsAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAE5w==}}

@inproceedings{yang2020acmikm,
	address = {{Virtual Event Ireland}},
	annotation = {ACM-IKM},
	annote = {We did not get to this paper in the Spring 2023 reading group.},
	author = {Yang, Liu and Zhang, Mingyang and Li, Cheng and Bendersky, Michael and Najork, Marc},
	bdsk-color = {582077695},
	booktitle = {Proceedings of the 29th {{ACM International Conference}} on {{Information}} \& {{Knowledge Management}}},
	date-added = {2024-03-24 23:37:48 -0400},
	date-modified = {2024-07-26 00:23:20 -0400},
	doi = {10.1145/3340531.3411908},
	in-website = {1},
	isbn = {978-1-4503-6859-9},
	keywords = {NLP,siamese,transformers; rd-potential; rdgrp-ece750T4-f24},
	langid = {english},
	month = oct,
	pages = {1725--1734},
	publisher = {{ACM}},
	status = {1},
	title = {Beyond 512 {{Tokens}}: {{Siamese Multi-depth Transformer-based Hierarchical Encoder}} for {{Long-Form Document Matching}}},
	toread = {1},
	urldate = {2021-02-25},
	venue-short = {acmikm},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1145/3340531.3411908}}

@inproceedings{igl2022icra,
	annote = {We did not get to this paper in the Spring 2023 reading group.},
	author = {Igl, Maximilian and Kim, Daewoo and Kuefler, Alex and Mougin, Paul and Shah, Punit and Shiarlis, Kyriacos and Anguelov, Dragomir and Palatucci, Mark and White, Brandyn and Whiteson, Shimon},
	bdsk-color = {582077695},
	booktitle = {International Conference on Robotics and Automation (ICRA)},
	date-added = {2024-03-24 23:36:46 -0400},
	date-modified = {2024-07-26 00:23:20 -0400},
	doi = {https://ieeexplore.ieee.org/document/9811990},
	event = {ICRA},
	in-website = {1},
	keywords = {autonomous-driving, machine-learning; rd-potential; rdgrp-ece750T4-f24},
	pages = {2445-2451},
	status = {1},
	title = {Symphony: Learning Realistic and Diverse Agents for Autonomous Driving Simulation},
	titleshort = {Symphony},
	toread = {1},
	venue-short = {ICRA},
	year = {2022},
	bdsk-url-1 = {https://doi.org/10.1109/ICRA46639.2022.9811990},
	bdsk-url-2 = {https://arxiv.org/abs/2205.03195}}

@inproceedings{theile2020ieeersj,
	annotation = {IROS},
	annote = {We did not get to this paper in the Spring 2023 reading group.},
	author = {Theile, Mirco and Bayerlein, Harald and Nai, Richard and Gesbert, David and Caccamo, Marco},
	bdsk-color = {582077695},
	booktitle = {2020 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
	date-added = {2024-03-24 23:36:46 -0400},
	date-modified = {2024-07-26 00:23:20 -0400},
	in-website = {1},
	keywords = {rd-potential; rdgrp-ece750T4-f24},
	pages = {1444--1449},
	publisher = {{IEEE}},
	status = {1},
	title = {{{UAV}} Coverage Path Planning under Varying Power Constraints Using Deep Reinforcement Learning},
	toread = {1},
	venue-short = {IEEERSJ},
	year = {2020}}

@article{thoppilan2022arxiv,
	annote = {Facebook enters the ring...},
	archiveprefix = {arXiv},
	author = {Romal Thoppilan and Daniel De Freitas and Jamie Hall and Noam Shazeer and Apoorv Kulshreshtha and Heng-Tze Cheng and Alicia Jin and Taylor Bos and Leslie Baker and Yu Du and YaGuang Li and Hongrae Lee and Huaixiu Steven Zheng and Amin Ghafouri and Marcelo Menegali and Yanping Huang and Maxim Krikun and Dmitry Lepikhin and James Qin and Dehao Chen and Yuanzhong Xu and Zhifeng Chen and Adam Roberts and Maarten Bosma and Vincent Zhao and Yanqi Zhou and Chung-Ching Chang and Igor Krivokon and Will Rusch and Marc Pickett and Pranesh Srinivasan and Laichee Man and Kathleen Meier-Hellstern and Meredith Ringel Morris and Tulsee Doshi and Renelito Delos Santos and Toju Duke and Johnny Soraker and Ben Zevenbergen and Vinodkumar Prabhakaran and Mark Diaz and Ben Hutchinson and Kristen Olson and Alejandra Molina and Erin Hoffman-John and Josh Lee and Lora Aroyo and Ravi Rajakumar and Alena Butryna and Matthew Lamm and Viktoriya Kuzmina and Joe Fenton and Aaron Cohen and Rachel Bernstein and Ray Kurzweil and Blaise Aguera-Arcas and Claire Cui and Marian Croak and Ed Chi and Quoc Le},
	date-added = {2024-03-24 23:36:46 -0400},
	date-discussed = {2023-7-12 led by Delin},
	date-modified = {2024-07-26 00:19:48 -0400},
	eprint = {2201.08239},
	in-website = {1},
	journal = {Arxiv Preprint},
	keywords = {rd-done; transformers; large-language-models; gpt; rdgrp-s23},
	order = {6},
	pdf = {2022-arxiv-thoppilan-lamda},
	primaryclass = {cs.CL},
	title = {LaMDA: Language Models for Dialog Applications},
	toread = {1},
	venue-short = {arxiv},
	year = {2022},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxBKLi4vLi4vLi4vLi4vcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi8yMDIyLWFyeGl2LXRob3BwaWxhbi1sYW1kYS5wZGZPEQG0AAAAAAG0AAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAAAAAAAAQkQAAf////8eMjAyMi1hcnhpdi10aG9wcGlsYW4tbGFtZGEucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/////wAAAAAAAAAAAAAAAAAEAAUAAAogY3UAAAAAAAAAAAAAAAAAA3BkZgAAAgBPLzpVc2VyczptY3Jvd2xleTpyZXBvczptYXJrY3Jvd2xleS1jYTphc3NldHM6cGRmOjIwMjItYXJ4aXYtdGhvcHBpbGFuLWxhbWRhLnBkZgAADgA+AB4AMgAwADIAMgAtAGEAcgB4AGkAdgAtAHQAaABvAHAAcABpAGwAYQBuAC0AbABhAG0AZABhAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBNVXNlcnMvbWNyb3dsZXkvcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi8yMDIyLWFyeGl2LXRob3BwaWxhbi1sYW1kYS5wZGYAABMAAS8AABUAAgAP//8AAAAIAA0AGgAkAHEAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAACKQ==}}

@inproceedings{gpt2,
	abstract = {Natural language processing tasks, such as question answering, machine translation, reading comprehension, and summarization, are typically approached with supervised learning on taskspecific datasets. We demonstrate that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of millions of webpages called WebText. When conditioned on a document plus questions, the answers generated by the language model reach 55 F1 on the CoQA dataset matching or exceeding the performance of 3 out of 4 baseline systems without using the 127,000+ training examples. The capacity of the language model is essential to the success of zero-shot task transfer and increasing it improves performance in a log-linear fashion across tasks. Our largest model, GPT-2, is a 1.5B parameter Transformer that achieves state of the art results on 7 out of 8 tested language modeling datasets in a zero-shot setting but still underfits WebText. Samples from the model reflect these improvements and contain coherent paragraphs of text. These findings suggest a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations. },
	author = {Alec Radford and Jeff Wu and Rewon Child and David Luan and Dario Amodei and Ilya Sutskever},
	date-added = {2024-03-24 23:35:53 -0400},
	date-discussed = {2023-06-28 led by Felix},
	date-modified = {2024-07-26 00:19:48 -0400},
	hypoth = {https://hyp.is/go?url=https%3A%2F%2Fd4mucfpksywv.cloudfront.net%2Fbetter-language-models%2Flanguage-models.pdf&group=__world__},
	keywords = {rd-done; transformers; large-language-models; gpt; rdgrp-s23},
	order = {5},
	pdf = {2019-arxiv-radford-language},
	title = {Language Models are Unsupervised Multitask Learners},
	url = {https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf},
	venue-short = {arxiv},
	year = {2019},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxBLLi4vLi4vLi4vLi4vcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi8yMDE5LWFyeGl2LXJhZGZvcmQtbGFuZ3VhZ2UucGRmTxEBtgAAAAABtgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAAAAAAEJEAAH/////HzIwMTktYXJ4aXYtcmFkZm9yZC1sYW5ndWFnZS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP////8AAAAAAAAAAAAAAAAABAAFAAAKIGN1AAAAAAAAAAAAAAAAAANwZGYAAAIAUC86VXNlcnM6bWNyb3dsZXk6cmVwb3M6bWFya2Nyb3dsZXktY2E6YXNzZXRzOnBkZjoyMDE5LWFyeGl2LXJhZGZvcmQtbGFuZ3VhZ2UucGRmAA4AQAAfADIAMAAxADkALQBhAHIAeABpAHYALQByAGEAZABmAG8AcgBkAC0AbABhAG4AZwB1AGEAZwBlAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBOVXNlcnMvbWNyb3dsZXkvcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi8yMDE5LWFyeGl2LXJhZGZvcmQtbGFuZ3VhZ2UucGRmABMAAS8AABUAAgAP//8AAAAIAA0AGgAkAHIAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAACLA==},
	bdsk-url-1 = {https://paperswithcode.com/paper/language-models-are-unsupervised-multitask},
	bdsk-url-2 = {https://www.semanticscholar.org/paper/Language-Models-are-Unsupervised-Multitask-Learners-Radford-Wu/9405cc0d6169988371b2755e573cc28650d14dfe}}

@article{lewis2019arxiv,
	annote = {This paper builds on the success of BERT but maintaining full encoder-decoder framework.},
	author = {Lewis, Mike and Liu, Yinhan and Goyal, Naman and Ghazvininejad, Marjan and Mohamed, Abdelrahman and Levy, Omer and Stoyanov, Ves and Zettlemoyer, Luke},
	date-added = {2024-03-24 23:35:53 -0400},
	date-modified = {2024-07-26 00:19:48 -0400},
	in-website = {1},
	journal = {arXiv preprint arXiv:1910.13461},
	keywords = {rd-done; transformers; large-language-models; BERT; rdgrp-s23},
	order = {5},
	pdf = {2019-arxiv-lewis-bart},
	title = {Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension},
	toread = {1},
	venue-short = {arxiv},
	year = {2019},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxBFLi4vLi4vLi4vLi4vcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi8yMDE5LWFyeGl2LWxld2lzLWJhcnQucGRmTxEBngAAAAABngACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAAAAAAEJEAAH/////GTIwMTktYXJ4aXYtbGV3aXMtYmFydC5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP////8AAAAAAAAAAAAAAAAABAAFAAAKIGN1AAAAAAAAAAAAAAAAAANwZGYAAAIASi86VXNlcnM6bWNyb3dsZXk6cmVwb3M6bWFya2Nyb3dsZXktY2E6YXNzZXRzOnBkZjoyMDE5LWFyeGl2LWxld2lzLWJhcnQucGRmAA4ANAAZADIAMAAxADkALQBhAHIAeABpAHYALQBsAGUAdwBpAHMALQBiAGEAcgB0AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBIVXNlcnMvbWNyb3dsZXkvcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi8yMDE5LWFyeGl2LWxld2lzLWJhcnQucGRmABMAAS8AABUAAgAP//8AAAAIAA0AGgAkAGwAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAACDg==}}

@article{liu2019,
	abstract = {Language model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes, and, as we will show, hyperparameter choices have significant impact on the final results. We present a replication study of BERT pretraining (Devlin et al., 2019) that carefully measures the impact of many key hyperparameters and training data size. We find that BERT was significantly undertrained, and can match or exceed the performance of every model published after it. Our best model achieves state-of-the-art results on GLUE, RACE and SQuAD. These results highlight the importance of previously overlooked design choices, and raise questions about the source of recently reported improvements. We release our models and code.},
	annote = {Where does the annotation show up? anywhere?},
	author = {Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and Mike Lewis and Luke Zettlemoyer and Veselin Stoyanov},
	date-added = {2024-03-24 23:35:53 -0400},
	date-discussed = {2023-06-21 led by Mark Crowley},
	date-modified = {2024-07-26 00:19:48 -0400},
	eprint = {1907.11692},
	hypothesis = {https://hyp.is/go?url=https%3A%2F%2Farxiv.org%2Fpdf%2F1907.11692.pdf&group=__world__},
	in-website = {1},
	keywords = {rd-done, transformers, BERT, large-language-models; rdgrp-s23},
	month = {07},
	order = {3},
	pdf = {2019-arxiv-liu-roberta.pdf},
	seminal = {1},
	status = {1},
	title = {RoBERTa: A Robustly Optimized BERT Pretraining Approach},
	toread = {1},
	url = {https://arxiv.org/pdf/1907.11692.pdf},
	venue-short = {arxiv},
	year = {2019},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxBGLi4vLi4vLi4vLi4vcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi8yMDE5LWFyeGl2LWxpdS1yb2JlcnRhLnBkZk8RAaQAAAAAAaQAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAAAAAABCRAAB/////xoyMDE5LWFyeGl2LWxpdS1yb2JlcnRhLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/////AAAAAAAAAAAAAAAAAAQABQAACiBjdQAAAAAAAAAAAAAAAAADcGRmAAACAEsvOlVzZXJzOm1jcm93bGV5OnJlcG9zOm1hcmtjcm93bGV5LWNhOmFzc2V0czpwZGY6MjAxOS1hcnhpdi1saXUtcm9iZXJ0YS5wZGYAAA4ANgAaADIAMAAxADkALQBhAHIAeABpAHYALQBsAGkAdQAtAHIAbwBiAGUAcgB0AGEALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAElVc2Vycy9tY3Jvd2xleS9yZXBvcy9tYXJrY3Jvd2xleS1jYS9hc3NldHMvcGRmLzIwMTktYXJ4aXYtbGl1LXJvYmVydGEucGRmAAATAAEvAAAVAAIAD///AAAACAANABoAJABtAAAAAAAAAgEAAAAAAAAABQAAAAAAAAAAAAAAAAAAAhU=},
	bdsk-url-1 = {https://arxiv.org/pdf/1907.11692.pdf},
	bdsk-url-2 = {https://arxiv.org/abs/1907.11692},
	bdsk-url-3 = {https://openreview.net/forum?id=SyxS0T4tvS}}

@inproceedings{mahendran2022acmwww,
	abstract = {Extracting information regarding novel chemicals and chemical reactions from chemical patents plays a vital role in the chemical and pharmaceutical industry. Due to the increasing volume of chemical patents, there is an urgent need for automated solutions to extract relations between chemical compounds. Several studies have used models that apply attention mechanisms such as Bidirectional Encoder Representations from Transformers (BERT) to capture the contextual information within a text. However, these models do not capture the global information about a specific vocabulary. On the other hand, Graph Convolutional Networks (GCNs) capture global dependencies between terms within a corpus but not the local contextual information. In this work, we propose two novel approaches, GCN-Vanilla and GCN-BERT, for chemical relation extraction. GCN-Vanilla approach builds a single graph for the whole corpus based on word co-occurrence and sentence-word relations. Then, we model the graph with GCN to capture the global information and classify the sentence nodes. GCN-BERT approach combines GCN and BERT to capture both global and local information, and build together a final representation for relation extraction. We evaluate our approaches on the CLEF-2020 dataset. Our results show the combined GCN-BERT approach outperforms standalone BERT and GCN models, and achieves a higher F1 than that reported in our previous studies.},
	address = {{New York, NY, USA}},
	annote = {We did not get to this paper in the Spring 2023 reading group.},
	author = {Mahendran, Darshini and Tang, Christina and McInnes, Bridget T.},
	bdsk-color = {582077695},
	booktitle = {Companion {{Proceedings}} of the {{Web Conference}} 2022},
	date-added = {2024-03-24 23:35:53 -0400},
	date-modified = {2024-07-26 00:23:20 -0400},
	doi = {10.1145/3487553.3524702},
	in-website = {1},
	isbn = {978-1-4503-9130-6},
	keywords = {BERT,chemical natural language processing,graph convolutional neural networks,relation extraction, rd-potential; rdgrp-ece750T4-f24},
	month = apr,
	pages = {833--842},
	publisher = {{Association for Computing Machinery}},
	series = {{{WWW}} '22},
	status = {1},
	title = {Graph {{Convolutional Networks}} for {{Chemical Relation Extraction}}},
	toread = {1},
	urldate = {2022-09-26},
	venue-short = {ACMWWW},
	year = {2022},
	bdsk-url-1 = {https://doi.org/10.1145/3487553.3524702}}

@article{radfordopenai,
	annote = {The founding paper for GPT 1.0 posted online as a preprint.},
	author = {Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
	date-added = {2024-03-24 23:35:53 -0400},
	date-discussed = {2023-06-14 led by Hao Pu},
	date-modified = {2024-07-26 00:19:48 -0400},
	in-website = {1},
	journal = {Preprint},
	keywords = {transformers, gpt, openai, nlp, large-language-models, rd-done; rdgrp-s23},
	local-url = {2018-openai-radford-improving},
	order = {3},
	paperdesc = {The original paper for the GPT 1.0 model.},
	pdf = {2018-openai-radford-improving},
	read = {1},
	title = {Improving Language Understanding by Generative Pre-Training},
	toread = {0},
	venue-short = {openai},
	year = {2018},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxBNLi4vLi4vLi4vLi4vcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi8yMDE4LW9wZW5haS1yYWRmb3JkLWltcHJvdmluZy5wZGZPEQG+AAAAAAG+AAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAAAAAAAAQkQAAf////8fMjAxOC1vcGVuYWktcmFkZm9yI0ZGRkZGRkZGLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/////wAAAAAAAAAAAAAAAAAEAAUAAAogY3UAAAAAAAAAAAAAAAAAA3BkZgAAAgBSLzpVc2VyczptY3Jvd2xleTpyZXBvczptYXJrY3Jvd2xleS1jYTphc3NldHM6cGRmOjIwMTgtb3BlbmFpLXJhZGZvcmQtaW1wcm92aW5nLnBkZgAOAEQAIQAyADAAMQA4AC0AbwBwAGUAbgBhAGkALQByAGEAZABmAG8AcgBkAC0AaQBtAHAAcgBvAHYAaQBuAGcALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAFBVc2Vycy9tY3Jvd2xleS9yZXBvcy9tYXJrY3Jvd2xleS1jYS9hc3NldHMvcGRmLzIwMTgtb3BlbmFpLXJhZGZvcmQtaW1wcm92aW5nLnBkZgATAAEvAAAVAAIAD///AAAACAANABoAJAB0AAAAAAAAAgEAAAAAAAAABQAAAAAAAAAAAAAAAAAAAjY=},
	bdsk-file-2 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxBXLi4vLi4vLi4vLi4vcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi8yMDE4LW9wZW5haS1yYWRmb3JkLWltcHJvdmluZy1hbm5vdGF0ZWQucGRmTxEB5gAAAAAB5gACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAAAAAAEJEAAH/////HzIwMTgtb3BlbmFpLXJhZGZvciNGRkZGRkZGRi5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP////8AAAAAAAAAAAAAAAAABAAFAAAKIGN1AAAAAAAAAAAAAAAAAANwZGYAAAIAXC86VXNlcnM6bWNyb3dsZXk6cmVwb3M6bWFya2Nyb3dsZXktY2E6YXNzZXRzOnBkZjoyMDE4LW9wZW5haS1yYWRmb3JkLWltcHJvdmluZy1hbm5vdGF0ZWQucGRmAA4AWAArADIAMAAxADgALQBvAHAAZQBuAGEAaQAtAHIAYQBkAGYAbwByAGQALQBpAG0AcAByAG8AdgBpAG4AZwAtAGEAbgBuAG8AdABhAHQAZQBkAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBaVXNlcnMvbWNyb3dsZXkvcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi8yMDE4LW9wZW5haS1yYWRmb3JkLWltcHJvdmluZy1hbm5vdGF0ZWQucGRmABMAAS8AABUAAgAP//8AAAAIAA0AGgAkAH4AAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAACaA==},
	bdsk-file-3 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxBeLi4vLi4vLi4vLi4vcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi8yMDE4LW9wZW5haS1yYWRmb3JkLWltcHJvdmluZy1hbm5vdGF0ZWQtZXhwb3J0LnBkZk8RAgQAAAAAAgQAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAAAAAABCRAAB/////x8yMDE4LW9wZW5haS1yYWRmb3IjRkZGRkZGRkYucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/////AAAAAAAAAAAAAAAAAAQABQAACiBjdQAAAAAAAAAAAAAAAAADcGRmAAACAGMvOlVzZXJzOm1jcm93bGV5OnJlcG9zOm1hcmtjcm93bGV5LWNhOmFzc2V0czpwZGY6MjAxOC1vcGVuYWktcmFkZm9yZC1pbXByb3ZpbmctYW5ub3RhdGVkLWV4cG9ydC5wZGYAAA4AZgAyADIAMAAxADgALQBvAHAAZQBuAGEAaQAtAHIAYQBkAGYAbwByAGQALQBpAG0AcAByAG8AdgBpAG4AZwAtAGEAbgBuAG8AdABhAHQAZQBkAC0AZQB4AHAAbwByAHQALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAGFVc2Vycy9tY3Jvd2xleS9yZXBvcy9tYXJrY3Jvd2xleS1jYS9hc3NldHMvcGRmLzIwMTgtb3BlbmFpLXJhZGZvcmQtaW1wcm92aW5nLWFubm90YXRlZC1leHBvcnQucGRmAAATAAEvAAAVAAIAD///AAAACAANABoAJACFAAAAAAAAAgEAAAAAAAAABQAAAAAAAAAAAAAAAAAAAo0=}}

@article{shanahan2022arxiv,
	abstract = {Thanks to rapid progress in artificial intelligence, we have entered an era when technology and philosophy intersect in interesting ways. Sitting squarely at the centre of this intersection are large language models (LLMs). The more adept LLMs become at mimicking human language, the more vulnerable we become to anthropomorphism, to seeing the systems in which they are embedded as more human-like than they really are. This trend is amplified by the natural tendency to use philosophically loaded terms, such as "knows", "believes", and "thinks", when describing these systems. To mitigate this trend, this paper advocates the practice of repeatedly stepping back to remind ourselves of how LLMs, and the systems of which they form a part, actually work. The hope is that increased scientific precision will encourage more philosophical nuance in the discourse around artificial intelligence, both within the field and in the public sphere.},
	arxiv = {2212.03551},
	author = {Murray Shanahan},
	bdsk-color = {582077695},
	date-added = {2024-03-24 23:35:53 -0400},
	date-modified = {2024-07-26 00:23:20 -0400},
	eprint = {2212.03551},
	in-website = {1},
	journal = {Arxiv Preprint},
	keywords = {rd-potential; rdgrp-s23; rdgrp-ece750T4-f24},
	month = {12},
	order = {9},
	pdf = {2022-arxiv-shanahan-talking},
	title = {Talking About Large Language Models},
	toread = {1},
	url = {https://arxiv.org/pdf/2212.03551.pdf},
	venue-short = {arxiv},
	year = {2022},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxBLLi4vLi4vLi4vLi4vcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi8yMDIyLWFyeGl2LXNoYW5haGFuLXRhbGtpbmcucGRmTxEBtgAAAAABtgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAAAAAAEJEAAH/////HzIwMjItYXJ4aXYtc2hhbmFoYW4tdGFsa2luZy5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP////8AAAAAAAAAAAAAAAAABAAFAAAKIGN1AAAAAAAAAAAAAAAAAANwZGYAAAIAUC86VXNlcnM6bWNyb3dsZXk6cmVwb3M6bWFya2Nyb3dsZXktY2E6YXNzZXRzOnBkZjoyMDIyLWFyeGl2LXNoYW5haGFuLXRhbGtpbmcucGRmAA4AQAAfADIAMAAyADIALQBhAHIAeABpAHYALQBzAGgAYQBuAGEAaABhAG4ALQB0AGEAbABrAGkAbgBnAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBOVXNlcnMvbWNyb3dsZXkvcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi8yMDIyLWFyeGl2LXNoYW5haGFuLXRhbGtpbmcucGRmABMAAS8AABUAAgAP//8AAAAIAA0AGgAkAHIAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAACLA==},
	bdsk-file-2 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxBdLi4vLi4vLi4vLi4vcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi8yMDIyLWFyeGl2LXNoYW5haGFuLXRhbGtpbmctYW5ub3RhdGVkMjAyMzA2MTIucGRmTxEB/gAAAAAB/gACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAAAAAAEJEAAH/////HzIwMjItYXJ4aXYtc2hhbmFoYSNGRkZGRkZGRi5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP////8AAAAAAAAAAAAAAAAABAAFAAAKIGN1AAAAAAAAAAAAAAAAAANwZGYAAAIAYi86VXNlcnM6bWNyb3dsZXk6cmVwb3M6bWFya2Nyb3dsZXktY2E6YXNzZXRzOnBkZjoyMDIyLWFyeGl2LXNoYW5haGFuLXRhbGtpbmctYW5ub3RhdGVkMjAyMzA2MTIucGRmAA4AZAAxADIAMAAyADIALQBhAHIAeABpAHYALQBzAGgAYQBuAGEAaABhAG4ALQB0AGEAbABrAGkAbgBnAC0AYQBuAG4AbwB0AGEAdABlAGQAMgAwADIAMwAwADYAMQAyAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBgVXNlcnMvbWNyb3dsZXkvcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi8yMDIyLWFyeGl2LXNoYW5haGFuLXRhbGtpbmctYW5ub3RhdGVkMjAyMzA2MTIucGRmABMAAS8AABUAAgAP//8AAAAIAA0AGgAkAIQAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAChg==},
	bdsk-url-1 = {https://arxiv.org/pdf/2212.03551.pdf},
	bdsk-url-2 = {https://arxiv.org/abs/2212.03551}}

@inproceedings{tay2021acl,
	abstract = {In the era of pre-trained language models, Transformers are the de facto choice of model architectures. While recent research has shown promise in entirely convolutional, or CNN, architectures, they have not been explored using the pre-train-fine-tune paradigm. In the context of language models, are convolutional models competitive to Transformers when pre-trained? This paper investigates this research question and presents several interesting findings. Across an extensive set of experiments on 8 datasets/tasks, we find that CNN-based pre-trained models are competitive and outperform their Transformer counterpart in certain scenarios, albeit with caveats. Overall, the findings outlined in this paper suggest that conflating pre-training and architectural advances is misguided and that both advances should be considered independently. We believe our research paves the way for a healthy amount of optimism in alternative architectures.},
	address = {Online.},
	author = {Tay, Yi and Dehghani, Mostafa and Gupta, Jai Prakash and Aribandi, Vamsi and Bahri, Dara and Qin, Zhen and Metzler, Donald},
	booktitle = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
	date-added = {2024-03-24 23:35:53 -0400},
	date-discussed = {2023-07-05 led by Mark Crowley},
	date-modified = {2024-07-26 00:19:48 -0400},
	doi = {10.18653/v1/2021.acl-long.335},
	eprint = {2105.03322},
	hypoth = {https://hyp.is/go?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2105.03322.pdf&group=__world__},
	keywords = {rd-done; transformers; deep-learning; rdgrp-s23},
	month = August,
	order = {7},
	pages = {4349--4359},
	pdf = {2021-acl-tay-are pretrained},
	publisher = {Association for Computational Linguistics},
	title = {Are Pretrained Convolutions Better than Pretrained Transformers?},
	url = {https://aclanthology.org/2021.acl-long.335},
	venue-short = {ACL},
	year = {2021},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxBLLi4vLi4vLi4vLi4vcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi8yMDIxLWFjbC10YXktYXJlIHByZXRyYWluZWQucGRmTxEBtgAAAAABtgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAAAAAAEJEAAH/////HzIwMjEtYWNsLXRheS1hcmUgcHJldHJhaW5lZC5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP////8AAAAAAAAAAAAAAAAABAAFAAAKIGN1AAAAAAAAAAAAAAAAAANwZGYAAAIAUC86VXNlcnM6bWNyb3dsZXk6cmVwb3M6bWFya2Nyb3dsZXktY2E6YXNzZXRzOnBkZjoyMDIxLWFjbC10YXktYXJlIHByZXRyYWluZWQucGRmAA4AQAAfADIAMAAyADEALQBhAGMAbAAtAHQAYQB5AC0AYQByAGUAIABwAHIAZQB0AHIAYQBpAG4AZQBkAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBOVXNlcnMvbWNyb3dsZXkvcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi8yMDIxLWFjbC10YXktYXJlIHByZXRyYWluZWQucGRmABMAAS8AABUAAgAP//8AAAAIAA0AGgAkAHIAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAACLA==},
	bdsk-url-1 = {https://aclanthology.org/2021.acl-long.335},
	bdsk-url-2 = {https://doi.org/10.18653/v1/2021.acl-long.335}}

@article{taylor2022arxiv,
	annote = {A promising approach to scientific reasoning with LLMs.},
	archiveprefix = {arXiv},
	author = {Ross Taylor and Marcin Kardas and Guillem Cucurull and Thomas Scialom and Anthony Hartshorn and Elvis Saravia and Andrew Poulton and Viktor Kerkez and Robert Stojnic},
	bdsk-color = {582077695},
	date-added = {2024-03-24 23:35:53 -0400},
	date-modified = {2024-07-26 00:23:20 -0400},
	eprint = {2211.09085},
	in-website = {1},
	journal = {Arxiv Preprint},
	keywords = {rdgrp-s23; rd-potential; large-language-models; transformers; NLP; rdgrp-ece750T4-f24},
	order = {?},
	pdf = {2022-arxiv-taylor-galactica},
	primaryclass = {cs.CL},
	title = {Galactica: A Large Language Model for Science},
	toread = {1},
	venue-short = {arxiv},
	year = {2022},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxBLLi4vLi4vLi4vLi4vcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi8yMDIyLWFyeGl2LXRheWxvci1nYWxhY3RpY2EucGRmTxEBtgAAAAABtgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAAAAAAEJEAAH/////HzIwMjItYXJ4aXYtdGF5bG9yLWdhbGFjdGljYS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP////8AAAAAAAAAAAAAAAAABAAFAAAKIGN1AAAAAAAAAAAAAAAAAANwZGYAAAIAUC86VXNlcnM6bWNyb3dsZXk6cmVwb3M6bWFya2Nyb3dsZXktY2E6YXNzZXRzOnBkZjoyMDIyLWFyeGl2LXRheWxvci1nYWxhY3RpY2EucGRmAA4AQAAfADIAMAAyADIALQBhAHIAeABpAHYALQB0AGEAeQBsAG8AcgAtAGcAYQBsAGEAYwB0AGkAYwBhAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBOVXNlcnMvbWNyb3dsZXkvcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi8yMDIyLWFyeGl2LXRheWxvci1nYWxhY3RpY2EucGRmABMAAS8AABUAAgAP//8AAAAIAA0AGgAkAHIAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAACLA==}}

@inproceedings{peschl2022aamas,
	abstract = {Inferring reward functions from demonstrations and pairwise preferences are auspicious approaches for aligning Reinforcement Learning (RL) agents with human intentions. However, state-of-the art methods typically focus on learning a single reward model, thus rendering it difficult to trade off different reward functions from multiple experts. We propose Multi-Objective Reinforced Active Learning (MORAL), a novel method for combining diverse demonstrations of social norms into a Pareto-optimal policy. Through maintaining a distribution over scalarization weights, our approach is able to interactively tune a deep RL agent towards a variety of preferences, while eliminating the need for computing multiple policies. We empirically demonstrate the effectiveness of MORAL in two scenarios, which model a delivery and an emergency task that require an agent to act in the presence of normative conflicts. Overall, we consider our research a step towards multi-objective RL with learned rewards, bridging the gap between current reward learning and machine ethics literature.},
	address = {Richland, SC},
	author = {Peschl, Markus and Zgonnikov, Arkady and Oliehoek, Frans A. and Siebert, Luciano C.},
	booktitle = {Proceedings of the 21st International Conference on Autonomous Agents and Multiagent Systems},
	date-added = {2024-03-08 22:18:51 -0500},
	date-modified = {2024-03-25 00:20:20 -0400},
	isbn = {9781450392136},
	keywords = {active learning, inverse reinforcement learning, multi-objective decision-making, value alignment; ai-morality},
	location = {Virtual Event, New Zealand},
	numpages = {9},
	pages = {1038--1046},
	publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
	series = {AAMAS '22},
	title = {MORAL: Aligning AI with Human Norms through Multi-Objective Reinforced Active Learning},
	toread = {1},
	venue-short = {AAMAS},
	year = {2022},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxA/Li4vLi4vLi4vLi4vcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi9wZXNjaGwyMDIyYWFtYXMucGRmTxEBhgAAAAABhgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAAAAAAEJEAAH/////E3Blc2NobDIwMjJhYW1hcy5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP////8AAAAAAAAAAAAAAAAABAAFAAAKIGN1AAAAAAAAAAAAAAAAAANwZGYAAAIARC86VXNlcnM6bWNyb3dsZXk6cmVwb3M6bWFya2Nyb3dsZXktY2E6YXNzZXRzOnBkZjpwZXNjaGwyMDIyYWFtYXMucGRmAA4AKAATAHAAZQBzAGMAaABsADIAMAAyADIAYQBhAG0AYQBzAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBCVXNlcnMvbWNyb3dsZXkvcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi9wZXNjaGwyMDIyYWFtYXMucGRmABMAAS8AABUAAgAP//8AAAAIAA0AGgAkAGYAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAB8A==}}

@inproceedings{hadfield-menell2017neurips,
	author = {Hadfield-Menell, Dylan and Milli, Smitha and Abbeel, Pieter and Russell, Stuart J and Dragan, Anca},
	booktitle = {Advances in Neural Information Processing Systems},
	date-added = {2024-03-08 20:21:03 -0500},
	date-modified = {2024-03-25 00:20:06 -0400},
	editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
	keywords = {ai-morality; value alignment},
	publisher = {Curran Associates, Inc.},
	title = {Inverse Reward Design},
	url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/32fdab6559cdfa4f167f8c31b9199643-Paper.pdf},
	venue-short = {neurips},
	volume = {30},
	year = {2017},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxBKLi4vLi4vLi4vLi4vcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi9oYWRmaWVsZC1tZW5lbGwyMDE3bmV1cmlwcy5wZGZPEQG0AAAAAAG0AAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAAAAAAAAQkQAAf////8eaGFkZmllbGQtbWVuZWxsMjAxN25ldXJpcHMucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/////wAAAAAAAAAAAAAAAAAEAAUAAAogY3UAAAAAAAAAAAAAAAAAA3BkZgAAAgBPLzpVc2VyczptY3Jvd2xleTpyZXBvczptYXJrY3Jvd2xleS1jYTphc3NldHM6cGRmOmhhZGZpZWxkLW1lbmVsbDIwMTduZXVyaXBzLnBkZgAADgA+AB4AaABhAGQAZgBpAGUAbABkAC0AbQBlAG4AZQBsAGwAMgAwADEANwBuAGUAdQByAGkAcABzAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBNVXNlcnMvbWNyb3dsZXkvcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi9oYWRmaWVsZC1tZW5lbGwyMDE3bmV1cmlwcy5wZGYAABMAAS8AABUAAgAP//8AAAAIAA0AGgAkAHEAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAACKQ==},
	bdsk-url-1 = {https://proceedings.neurips.cc/paper_files/paper/2017/file/32fdab6559cdfa4f167f8c31b9199643-Paper.pdf}}

@inproceedings{abel2016aaaiaies,
	author = {David Abel and James MacGlashan and Michael L. Littman},
	bdsk-color = {4},
	booktitle = {AAAI Workshop: AI, Ethics, and Society},
	date-added = {2024-02-24 15:31:30 -0500},
	date-modified = {2024-07-26 00:27:00 -0400},
	keywords = {rd-middle, ai-morality, ai-ethics, reinforcement-learning, pomdp; rdgrp-ece750T4-f24},
	order = {2},
	title = {Reinforcement Learning as a Framework for Ethical Decision Making},
	url = {https://api.semanticscholar.org/CorpusID:14717578},
	venue-short = {aaaiaies},
	year = {2016},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEDhhc3NldHMvcGRmLzIwMTYtYWFhaWFpZXMtYWJlbC1yZWluZm9yY2VtZW50LWxlYXJuaW5nLnBkZk8RBMBib29rwAQAAAAABBAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC8AwAABQAAAAEBAABVc2VycwAAAAgAAAABAQAAbWNyb3dsZXkHAAAAAQEAAERyb3Bib3gABAAAAAEBAABBcHBzDQAAAAEBAAByZW1vdGVseS1zYXZlAAAACAAAAAEBAABBSVRvcGljcwYAAAABAQAAYXNzZXRzAAADAAAAAQEAAHBkZgAtAAAAAQEAADIwMTYtYWFhaWFpZXMtYWJlbC1yZWluZm9yY2VtZW50LWxlYXJuaW5nLnBkZgAAACQAAAABBgAABAAAABQAAAAkAAAANAAAAEAAAABYAAAAaAAAAHgAAACEAAAACAAAAAQDAAAVXQAAAAAAAAgAAAAEAwAAOegDAAAAAAAIAAAABAMAAF91BAAAAAAACAAAAAQDAADRjgQAAAAAAAgAAAAEAwAAEFF0AgAAAAAIAAAABAMAAJ4W5wIAAAAACAAAAAQDAAA1z+ACAAAAAAgAAAAEAwAANs/gAgAAAAAIAAAABAMAAKD04AIAAAAAJAAAAAEGAADoAAAA+AAAAAgBAAAYAQAAKAEAADgBAABIAQAAWAEAAGgBAAAIAAAAAAQAAEHF2JcFfvlmGAAAAAECAAABAAAAAAAAAA8AAAAAAAAAAAAAAAAAAAAIAAAABAMAAAcAAAAAAAAABAAAAAMDAAD1AQAACAAAAAEJAABmaWxlOi8vLwwAAAABAQAATWFjaW50b3NoIEhECAAAAAQDAAAAkIKW5wAAAAgAAAAABAAAQcYj7JuAAAAkAAAAAQEAADA5QjdFQUJFLTY3OTUtNENERi1BQjI0LTNGRjA4NTY1RDAxNhgAAAABAgAAgQAAAAEAAADvEwAAAQAAAAAAAAAAAAAAAQAAAAEBAAAvAAAAAAAAAAEFAAAeAQAAAQIAADhjZTE5MzFhMzgyYTZiM2M4YjVkZWE5MDBkZTMxZTg4MmQ0ZTJhYWVhZWZhYzkxMzMyMTc1ZmViOGQ0YmYyOTQ7MDA7MDAwMDAwMDA7MDAwMDAwMDA7MDAwMDAwMDA7MDAwMDAwMDAwMDAwMDAyMDtjb20uYXBwbGUuYXBwLXNhbmRib3gucmVhZC13cml0ZTswMTswMTAwMDAxMTswMDAwMDAwMDAyZTBmNGEwOzAxOy91c2Vycy9tY3Jvd2xleS9kcm9wYm94L2FwcHMvcmVtb3RlbHktc2F2ZS9haXRvcGljcy9hc3NldHMvcGRmLzIwMTYtYWFhaWFpZXMtYWJlbC1yZWluZm9yY2VtZW50LWxlYXJuaW5nLnBkZgAAAMwAAAD+////AQAAAAAAAAAQAAAABBAAALwAAAAAAAAABRAAAHgBAAAAAAAAEBAAALQBAAAAAAAAQBAAAKQBAAAAAAAAAiAAAIACAAAAAAAABSAAAPABAAAAAAAAECAAAAACAAAAAAAAESAAADQCAAAAAAAAEiAAABQCAAAAAAAAEyAAACQCAAAAAAAAICAAAGACAAAAAAAAMCAAAIwCAAAAAAAAAcAAANQBAAAAAAAAEcAAABQAAAAAAAAAEsAAAOQBAAAAAAAAgPAAAJQCAAAAAAAAAAgADQAaACMAXgAAAAAAAAIBAAAAAAAAAAUAAAAAAAAAAAAAAAAAAAUi},
	bdsk-url-1 = {https://api.semanticscholar.org/CorpusID:14717578}}

@incollection{haas2022dnhni,
	author = {Haas, Julia},
	booktitle = {Does Neuroscience Have Normative Implications?},
	date-added = {2024-02-24 15:22:44 -0500},
	date-modified = {2024-03-25 00:19:51 -0400},
	editor = {Geoffrey Holtzman and Elisabeth Hildt.},
	keywords = {ai-morality},
	publisher = {Cham: Springer International Publishing AG},
	title = {Revising and Expanding Cushman's Learning-Based Model of Moral Cognition.},
	venue-short = {dnhni},
	year = {2022},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxA9Li4vLi4vLi4vLi4vcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi9oYWFzMjAyMmRuaG5pLnBkZk8RAX4AAAAAAX4AAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAAAAAABCRAAB/////xFoYWFzMjAyMmRuaG5pLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/////AAAAAAAAAAAAAAAAAAQABQAACiBjdQAAAAAAAAAAAAAAAAADcGRmAAACAEIvOlVzZXJzOm1jcm93bGV5OnJlcG9zOm1hcmtjcm93bGV5LWNhOmFzc2V0czpwZGY6aGFhczIwMjJkbmhuaS5wZGYADgAkABEAaABhAGEAcwAyADAAMgAyAGQAbgBoAG4AaQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAQFVzZXJzL21jcm93bGV5L3JlcG9zL21hcmtjcm93bGV5LWNhL2Fzc2V0cy9wZGYvaGFhczIwMjJkbmhuaS5wZGYAEwABLwAAFQACAA///wAAAAgADQAaACQAZAAAAAAAAAIBAAAAAAAAAAUAAAAAAAAAAAAAAAAAAAHm}}

@article{haas2020mindsmachines,
	abstract = {I describe a suite of reinforcement learning environments in which artificial agents learn to value and respond to moral content and contexts. I illustrate the core principles of the framework by characterizing one such environment, or ``gridworld,''in which an agent learns to trade-off between monetary profit and fair dealing, as applied in a standard behavioral economic paradigm. I then highlight the core technical and philosophical advantages of the learning approach for modeling moral cognition, and for addressing the so-called value alignment problem in AI.},
	author = {Haas, Julia},
	bdsk-color = {4},
	date = {2020/06/01},
	date-added = {2024-02-24 15:12:56 -0500},
	date-modified = {2024-07-26 00:27:00 -0400},
	doi = {10.1007/s11023-020-09524-9},
	id = {Haas2020},
	isbn = {1572-8641},
	journal = {Minds and Machines},
	keywords = {rd-middle, ai-morality, ai-ethics, philosophy, reinforcement-learning; rdgrp-ece750T4-f24},
	number = {2},
	order = {4},
	pages = {219--246},
	title = {Moral Gridworlds: A Theoretical Proposal for Modeling Artificial Moral Cognition},
	url = {https://doi.org/10.1007/s11023-020-09524-9},
	venue-short = {mindsmachines},
	volume = {30},
	year = {2020},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEDdhc3NldHMvcGRmLzIwMjAtbWluZHNtYWNoaW5lcy1oYWFzLW1vcmFsLWdyaWR3b3JsZHMucGRmTxEEvGJvb2u8BAAAAAAEEDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALgDAAAFAAAAAQEAAFVzZXJzAAAACAAAAAEBAABtY3Jvd2xleQcAAAABAQAARHJvcGJveAAEAAAAAQEAAEFwcHMNAAAAAQEAAHJlbW90ZWx5LXNhdmUAAAAIAAAAAQEAAEFJVG9waWNzBgAAAAEBAABhc3NldHMAAAMAAAABAQAAcGRmACwAAAABAQAAMjAyMC1taW5kc21hY2hpbmVzLWhhYXMtbW9yYWwtZ3JpZHdvcmxkcy5wZGYkAAAAAQYAAAQAAAAUAAAAJAAAADQAAABAAAAAWAAAAGgAAAB4AAAAhAAAAAgAAAAEAwAAFV0AAAAAAAAIAAAABAMAADnoAwAAAAAACAAAAAQDAABfdQQAAAAAAAgAAAAEAwAA0Y4EAAAAAAAIAAAABAMAABBRdAIAAAAACAAAAAQDAACeFucCAAAAAAgAAAAEAwAANc/gAgAAAAAIAAAABAMAADbP4AIAAAAACAAAAAQDAADy9eACAAAAACQAAAABBgAA5AAAAPQAAAAEAQAAFAEAACQBAAA0AQAARAEAAFQBAABkAQAACAAAAAAEAABBxdiXV5xp4hgAAAABAgAAAQAAAAAAAAAPAAAAAAAAAAAAAAAAAAAACAAAAAQDAAAHAAAAAAAAAAQAAAADAwAA9QEAAAgAAAABCQAAZmlsZTovLy8MAAAAAQEAAE1hY2ludG9zaCBIRAgAAAAEAwAAAJCClucAAAAIAAAAAAQAAEHGI+ybgAAAJAAAAAEBAAAwOUI3RUFCRS02Nzk1LTRDREYtQUIyNC0zRkYwODU2NUQwMTYYAAAAAQIAAIEAAAABAAAA7xMAAAEAAAAAAAAAAAAAAAEAAAABAQAALwAAAAAAAAABBQAAHQEAAAECAAA4YTQ2ZmFmODEwNDA1YTEyY2NjNTg1YTM1ZmFjZGEwMjA1ZmQwNjhhYjBhYjQwMjBiMWVlMWYzMTc1YmIyNjQzOzAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwMDAwMDAwMjA7Y29tLmFwcGxlLmFwcC1zYW5kYm94LnJlYWQtd3JpdGU7MDE7MDEwMDAwMTE7MDAwMDAwMDAwMmUwZjVmMjswMTsvdXNlcnMvbWNyb3dsZXkvZHJvcGJveC9hcHBzL3JlbW90ZWx5LXNhdmUvYWl0b3BpY3MvYXNzZXRzL3BkZi8yMDIwLW1pbmRzbWFjaGluZXMtaGFhcy1tb3JhbC1ncmlkd29ybGRzLnBkZgAAAADMAAAA/v///wEAAAAAAAAAEAAAAAQQAAC4AAAAAAAAAAUQAAB0AQAAAAAAABAQAACwAQAAAAAAAEAQAACgAQAAAAAAAAIgAAB8AgAAAAAAAAUgAADsAQAAAAAAABAgAAD8AQAAAAAAABEgAAAwAgAAAAAAABIgAAAQAgAAAAAAABMgAAAgAgAAAAAAACAgAABcAgAAAAAAADAgAACIAgAAAAAAAAHAAADQAQAAAAAAABHAAAAUAAAAAAAAABLAAADgAQAAAAAAAIDwAACQAgAAAAAAAAAIAA0AGgAjAF0AAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAFHQ==},
	bdsk-url-1 = {https://doi.org/10.1007/s11023-020-09524-9}}

@article{christopoulos2017jourbusethics,
	abstract = {In business settings, decision makers facing moral issues often experience the challenges of continuous changes. This dynamic process has been less examined in previous literature on moral decision making. We borrow theories on learning strategies and computational models from decision neuroscience to explain the updating and learning mechanisms underlying moral decision processes. Specifically, we present two main learning strategies: model-free learning, wherein the values of choices are updated in a trial-and-error fashion sustaining the formation of habits and model-based learning, wherein the brain updates more general cognitive maps and associations, thus sustaining flexible and state-dependent behaviors. We then summarize studies explaining the neuro-computational processes of both learning strategies---the calculation of prediction errors and valuation. We conclude by emphasizing how the incorporation of dynamic aspects in moral decision making could open new avenues for understanding moral behaviors in a changing world.},
	author = {Christopoulos, George I. and Liu, Xiao-Xiao and Hong, Ying-yi},
	date = {2017/09/01},
	date-added = {2024-02-24 14:41:39 -0500},
	date-modified = {2024-02-24 14:42:28 -0500},
	doi = {10.1007/s10551-016-3058-1},
	id = {Christopoulos2017},
	isbn = {1573-0697},
	journal = {Journal of Business Ethics},
	keywords = {ai-ethics, ai-morality, decision-making, philosophy},
	number = {4},
	pages = {699--715},
	title = {Toward an Understanding of Dynamic Moral Decision Making: Model-Free and Model-Based Learning},
	url = {https://doi.org/10.1007/s10551-016-3058-1},
	venue-short = {JourBusEthics},
	volume = {144},
	year = {2017},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEDlhc3NldHMvcGRmLzIwMTctam91cmJ1c2V0aGljcy1jaHJpc3RvcG91bG9zLXRvd2FyZC1hbi5wZGZPEQTAYm9va8AEAAAAAAQQMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAvAMAAAUAAAABAQAAVXNlcnMAAAAIAAAAAQEAAG1jcm93bGV5BwAAAAEBAABEcm9wYm94AAQAAAABAQAAQXBwcw0AAAABAQAAcmVtb3RlbHktc2F2ZQAAAAgAAAABAQAAQUlUb3BpY3MGAAAAAQEAAGFzc2V0cwAAAwAAAAEBAABwZGYALgAAAAEBAAAyMDE3LWpvdXJidXNldGhpY3MtY2hyaXN0b3BvdWxvcy10b3dhcmQtYW4ucGRmAAAkAAAAAQYAAAQAAAAUAAAAJAAAADQAAABAAAAAWAAAAGgAAAB4AAAAhAAAAAgAAAAEAwAAFV0AAAAAAAAIAAAABAMAADnoAwAAAAAACAAAAAQDAABfdQQAAAAAAAgAAAAEAwAA0Y4EAAAAAAAIAAAABAMAABBRdAIAAAAACAAAAAQDAACeFucCAAAAAAgAAAAEAwAANc/gAgAAAAAIAAAABAMAADbP4AIAAAAACAAAAAQDAADa9eACAAAAACQAAAABBgAA6AAAAPgAAAAIAQAAGAEAACgBAAA4AQAASAEAAFgBAABoAQAACAAAAAAEAABBxdiXVo1OCRgAAAABAgAAAQAAAAAAAAAPAAAAAAAAAAAAAAAAAAAACAAAAAQDAAAHAAAAAAAAAAQAAAADAwAA9QEAAAgAAAABCQAAZmlsZTovLy8MAAAAAQEAAE1hY2ludG9zaCBIRAgAAAAEAwAAAJCClucAAAAIAAAAAAQAAEHGI+ybgAAAJAAAAAEBAAAwOUI3RUFCRS02Nzk1LTRDREYtQUIyNC0zRkYwODU2NUQwMTYYAAAAAQIAAIEAAAABAAAA7xMAAAEAAAAAAAAAAAAAAAEAAAABAQAALwAAAAAAAAABBQAAHwEAAAECAABlMzMwMGFhZjEwYWNjZTJjZTFhYjU3MjNhMWFkOGEyMDJiNzRjOTRlMGVlMmExZTI5OGY3NTE4M2FjYzJhYTFmOzAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwMDAwMDAwMjA7Y29tLmFwcGxlLmFwcC1zYW5kYm94LnJlYWQtd3JpdGU7MDE7MDEwMDAwMTE7MDAwMDAwMDAwMmUwZjVkYTswMTsvdXNlcnMvbWNyb3dsZXkvZHJvcGJveC9hcHBzL3JlbW90ZWx5LXNhdmUvYWl0b3BpY3MvYXNzZXRzL3BkZi8yMDE3LWpvdXJidXNldGhpY3MtY2hyaXN0b3BvdWxvcy10b3dhcmQtYW4ucGRmAADMAAAA/v///wEAAAAAAAAAEAAAAAQQAAC8AAAAAAAAAAUQAAB4AQAAAAAAABAQAAC0AQAAAAAAAEAQAACkAQAAAAAAAAIgAACAAgAAAAAAAAUgAADwAQAAAAAAABAgAAAAAgAAAAAAABEgAAA0AgAAAAAAABIgAAAUAgAAAAAAABMgAAAkAgAAAAAAACAgAABgAgAAAAAAADAgAACMAgAAAAAAAAHAAADUAQAAAAAAABHAAAAUAAAAAAAAABLAAADkAQAAAAAAAIDwAACUAgAAAAAAAAAIAA0AGgAjAF8AAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAFIw==},
	bdsk-url-1 = {https://doi.org/10.1007/s10551-016-3058-1}}

@inproceedings{badea2022sgai,
	abstract = {We present what we call the Interpretation Problem, whereby any rule in symbolic form is open to infinite interpretation in ways that we might disapprove of and argue that any attempt to build morality into machines is subject to it. We show how the Interpretation Problem in Artificial Intelligence is an illustration of Wittgenstein's general claim that no rule can contain the criteria for its own application, and that the risks created by this problem escalates in proportion to the degree to which a machine is causally connected to the world, in what we call the Law of Interpretative Exposure. Using games as an illustration, we attempt to define the structure of normative spaces and argue that any rule-following within a normative space is guided by values that are external to that space and which cannot themselves be represented as rules. In light of this, we categorise the types of mistakes an artificial moral agent could make into Mistakes of Intention and Instrumental Mistakes, and we propose ways of building morality into machines by getting them to interpret the rules we give in accordance with these external values, through explicit moral reasoning, the ``Show, not Tell'' paradigm, the adjustment of causal power and structure of the agent, and relational values, with the ultimate aim that the machine develop a virtuous character and that the impact of the Interpretation Problem is minimised.},
	address = {Cham},
	author = {Badea, Cosmin and Artus, Gregory},
	bdsk-color = {4},
	booktitle = {Artificial Intelligence XXXIX},
	date-added = {2024-02-23 12:03:27 -0500},
	date-modified = {2024-07-26 00:27:00 -0400},
	editor = {Bramer, Max and Stahl, Frederic},
	isbn = {978-3-031-21441-7},
	keywords = {rd-middle; ai-morality, ai-ethics, philosophy, wittgenstein, reinforcement-learning; rdgrp-ece750T4-f24},
	order = {3},
	pages = {124--137},
	publisher = {Springer International Publishing},
	title = {Morality, Machines, and the Interpretation Problem: A Value-based, Wittgensteinian Approach to Building Moral Agents},
	toread = {0},
	venue-short = {sgai},
	year = {2022},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEDBhc3NldHMvcGRmLzIwMjItc2dhaS1iYWRlYS1tb3JhbGl0eS1tYWNoaW5lcy5wZGZPEQSwYm9va7AEAAAAAAQQMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAArAMAAAUAAAABAQAAVXNlcnMAAAAIAAAAAQEAAG1jcm93bGV5BwAAAAEBAABEcm9wYm94AAQAAAABAQAAQXBwcw0AAAABAQAAcmVtb3RlbHktc2F2ZQAAAAgAAAABAQAAQUlUb3BpY3MGAAAAAQEAAGFzc2V0cwAAAwAAAAEBAABwZGYAJQAAAAEBAAAyMDIyLXNnYWktYmFkZWEtbW9yYWxpdHktbWFjaGluZXMucGRmAAAAJAAAAAEGAAAEAAAAFAAAACQAAAA0AAAAQAAAAFgAAABoAAAAeAAAAIQAAAAIAAAABAMAABVdAAAAAAAACAAAAAQDAAA56AMAAAAAAAgAAAAEAwAAX3UEAAAAAAAIAAAABAMAANGOBAAAAAAACAAAAAQDAAAQUXQCAAAAAAgAAAAEAwAAnhbnAgAAAAAIAAAABAMAADXP4AIAAAAACAAAAAQDAAA2z+ACAAAAAAgAAAAEAwAA2uXgAgAAAAAkAAAAAQYAAOAAAADwAAAAAAEAABABAAAgAQAAMAEAAEABAABQAQAAYAEAAAgAAAAABAAAQcXYkpjaAHQYAAAAAQIAAAEAAAAAAAAADwAAAAAAAAAAAAAAAAAAAAgAAAAEAwAABwAAAAAAAAAEAAAAAwMAAPUBAAAIAAAAAQkAAGZpbGU6Ly8vDAAAAAEBAABNYWNpbnRvc2ggSEQIAAAABAMAAACQgpbnAAAACAAAAAAEAABBxiPsm4AAACQAAAABAQAAMDlCN0VBQkUtNjc5NS00Q0RGLUFCMjQtM0ZGMDg1NjVEMDE2GAAAAAECAACBAAAAAQAAAO8TAAABAAAAAAAAAAAAAAABAAAAAQEAAC8AAAAAAAAAAQUAABYBAAABAgAAZjM4Zjc5ZWFiMTFlZWEwZDcwMWUwMjBlYjAzNWRkZmM1MzBjZGQ0MWM3MzEwNWM1NGU0ZjdhZDZjODE5MmVlZDswMDswMDAwMDAwMDswMDAwMDAwMDswMDAwMDAwMDswMDAwMDAwMDAwMDAwMDIwO2NvbS5hcHBsZS5hcHAtc2FuZGJveC5yZWFkLXdyaXRlOzAxOzAxMDAwMDExOzAwMDAwMDAwMDJlMGU1ZGE7MDE7L3VzZXJzL21jcm93bGV5L2Ryb3Bib3gvYXBwcy9yZW1vdGVseS1zYXZlL2FpdG9waWNzL2Fzc2V0cy9wZGYvMjAyMi1zZ2FpLWJhZGVhLW1vcmFsaXR5LW1hY2hpbmVzLnBkZgAAAMwAAAD+////AQAAAAAAAAAQAAAABBAAALQAAAAAAAAABRAAAHABAAAAAAAAEBAAAKwBAAAAAAAAQBAAAJwBAAAAAAAAAiAAAHgCAAAAAAAABSAAAOgBAAAAAAAAECAAAPgBAAAAAAAAESAAACwCAAAAAAAAEiAAAAwCAAAAAAAAEyAAABwCAAAAAAAAICAAAFgCAAAAAAAAMCAAAIQCAAAAAAAAAcAAAMwBAAAAAAAAEcAAABQAAAAAAAAAEsAAANwBAAAAAAAAgPAAAIwCAAAAAAAAAAgADQAaACMAVgAAAAAAAAIBAAAAAAAAAAUAAAAAAAAAAAAAAAAAAAUK}}

@inproceedings{herlau2022icccr,
	author = {Herlau, Tue},
	booktitle = {2022 2nd International Conference on Computer, Control and Robotics (ICCCR)},
	date-added = {2024-02-18 12:13:32 -0500},
	date-modified = {2024-07-26 11:28:44 -0400},
	doi = {10.1109/ICCCR54399.2022.9790262},
	hypoth = {https://hyp.is/go?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2205.08192.pdf&group=__world__},
	keywords = {Digital control;Costs;Toy manufacturing industry;forest-management;Causality;Actual Causation;ai-ethics; ai-morality; reinforcement-learning},
	pages = {179-185},
	title = {Moral Reinforcement Learning Using Actual Causation},
	toread = {1},
	venue-short = {icccr},
	year = {2022},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEDRhc3NldHMvcGRmLzIwMjItaWNjY3ItaGVybGF1LW1vcmFsLXJlaW5mb3JjZW1lbnQucGRmTxEEuGJvb2u4BAAAAAAEEDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALQDAAAFAAAAAQEAAFVzZXJzAAAACAAAAAEBAABtY3Jvd2xleQcAAAABAQAARHJvcGJveAAEAAAAAQEAAEFwcHMNAAAAAQEAAHJlbW90ZWx5LXNhdmUAAAAIAAAAAQEAAEFJVG9waWNzBgAAAAEBAABhc3NldHMAAAMAAAABAQAAcGRmACkAAAABAQAAMjAyMi1pY2Njci1oZXJsYXUtbW9yYWwtcmVpbmZvcmNlbWVudC5wZGYAAAAkAAAAAQYAAAQAAAAUAAAAJAAAADQAAABAAAAAWAAAAGgAAAB4AAAAhAAAAAgAAAAEAwAAFV0AAAAAAAAIAAAABAMAADnoAwAAAAAACAAAAAQDAABfdQQAAAAAAAgAAAAEAwAA0Y4EAAAAAAAIAAAABAMAABBRdAIAAAAACAAAAAQDAACeFucCAAAAAAgAAAAEAwAANc/gAgAAAAAIAAAABAMAADbP4AIAAAAACAAAAAQDAADb9eACAAAAACQAAAABBgAA5AAAAPQAAAAEAQAAFAEAACQBAAA0AQAARAEAAFQBAABkAQAACAAAAAAEAABBxdiXVo1cdxgAAAABAgAAAQAAAAAAAAAPAAAAAAAAAAAAAAAAAAAACAAAAAQDAAAHAAAAAAAAAAQAAAADAwAA9QEAAAgAAAABCQAAZmlsZTovLy8MAAAAAQEAAE1hY2ludG9zaCBIRAgAAAAEAwAAAJCClucAAAAIAAAAAAQAAEHGI+ybgAAAJAAAAAEBAAAwOUI3RUFCRS02Nzk1LTRDREYtQUIyNC0zRkYwODU2NUQwMTYYAAAAAQIAAIEAAAABAAAA7xMAAAEAAAAAAAAAAAAAAAEAAAABAQAALwAAAAAAAAABBQAAGgEAAAECAABmNWY5NmRhODlhNmNmYTBiODZkYjdiZDA0N2UwNDM4MTE5ZGVhODU4NTQxNjNhMjEyNzNmZDY2NzljYTBjYWJjOzAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwMDAwMDAwMjA7Y29tLmFwcGxlLmFwcC1zYW5kYm94LnJlYWQtd3JpdGU7MDE7MDEwMDAwMTE7MDAwMDAwMDAwMmUwZjVkYjswMTsvdXNlcnMvbWNyb3dsZXkvZHJvcGJveC9hcHBzL3JlbW90ZWx5LXNhdmUvYWl0b3BpY3MvYXNzZXRzL3BkZi8yMDIyLWljY2NyLWhlcmxhdS1tb3JhbC1yZWluZm9yY2VtZW50LnBkZgAAAMwAAAD+////AQAAAAAAAAAQAAAABBAAALgAAAAAAAAABRAAAHQBAAAAAAAAEBAAALABAAAAAAAAQBAAAKABAAAAAAAAAiAAAHwCAAAAAAAABSAAAOwBAAAAAAAAECAAAPwBAAAAAAAAESAAADACAAAAAAAAEiAAABACAAAAAAAAEyAAACACAAAAAAAAICAAAFwCAAAAAAAAMCAAAIgCAAAAAAAAAcAAANABAAAAAAAAEcAAABQAAAAAAAAAEsAAAOABAAAAAAAAgPAAAJACAAAAAAAAAAgADQAaACMAWgAAAAAAAAIBAAAAAAAAAAUAAAAAAAAAAAAAAAAAAAUW},
	bdsk-url-1 = {https://doi.org/10.1109/ICCCR54399.2022.9790262}}

@article{ayars2016jourcognition,
	abstract = {Dual-systems frameworks propose that moral judgments are derived from both an immediate emotional response, and controlled/rational cognition. Recently Cushman (2013) proposed a new dual-system theory based on model-free and model-based reinforcement learning. Model-free learning attaches values to actions based on their history of reward and punishment, and explains some deontological, non-utilitarian judgments. Model-based learning involves the construction of a causal model of the world and allows for far-sighted planning; this form of learning fits well with utilitarian considerations that seek to maximize certain kinds of outcomes. I present three concerns regarding the use of model-free reinforcement learning to explain deontological moral judgment. First, many actions that humans find aversive from model-free learning are not judged to be morally wrong. Moral judgment must require something in addition to model-free learning. Second, there is a dearth of evidence for central predictions of the reinforcement account---e.g., that people with different reinforcement histories will, all else equal, make different moral judgments. Finally, to account for the effect of intention within the framework requires certain assumptions which lack support. These challenges are reasonable foci for future empirical/theoretical work on the model-free/model-based framework.},
	author = {Alisabeth Ayars},
	date-added = {2024-02-18 11:50:18 -0500},
	date-modified = {2024-07-24 15:08:40 -0400},
	doi = {https://doi.org/10.1016/j.cognition.2016.02.002},
	hypoth = {https://hyp.is/go?url=https%3A%2F%2Fpdf.sciencedirectassets.com%2F271061%2F1-s2.0-S0010027716X00030%2F1-s2.0-S0010027716300300%2Fam.pdf%3FX-Amz-Security-Token%3DIQoJb3JpZ2luX2VjEBkaCXVzLWVhc3QtMSJIMEYCIQDSrlQ2%252FwMRUQYLXcyJsvA%252FD78LcAoEOqzKeA3VRyhFFAIhAOoj2FmqkF1ap10phRf3285JCN9%252Fgc%252B63iZoHyVcHcvEKrsFCPH%252F%252F%252F%252F%252F%252F%252F%252F%252F%252FwEQBRoMMDU5MDAzNTQ2ODY1IgxHtaeR%252BdxL1Gryc40qjwVZhRrguJCGp82jIJrPl7ATnmlb1nAG0ArISExDhEmAsakcaVnyQsiPF7iW%252FAd7ZtFUsbDDfDXK8nME9sxyTLXQcZoN3IAqTu4%252BpqCpnHQCtuVec1V4JqzvXjCCirEPO134eYfx5wn8lyPUdUSl4Kl3crcLPt6LpKwmaiE4jURhWltY2xOTF6PGeFftCwRAQN91yIfKPMYFGtgpwnGXO8trg1GddYz9QcOFND%252F5zdPrKLgZOdJpPKyU4nDTkbh%252FezcAgqkdfeXY%252FyWus8HP%252BpSZ50BwdA6VMnQwgmcSKG4%252FtzMNMIcE0wX1eVbAPC8JPt17Wb861shHacE3PWcSlPPci1gY0bhUTKp1LRZtdYRKVglwAq%252FIwUGTAH2%252FXU7gUE2qX2okzXl7jqzoRAw4zRsYxRsu1VHZu1tGQVVwYQe%252BGuk8IGzFtCR5jqTd5cMLNpPG5LY1fScwraKL%252Ft0v8jU7EkeXZwzRGstGVlu7jN7lgJn1hJgE%252B86%252BhF5h3HsfOvfaUt794s7kRxX9%252BS3Gam6USuHlv38lx50Oo%252B1h1goDp%252BZdj4At8LeP2tNSSVtYCBILUJKYTT3NCoXt%252FyTQLwQxNEZukx5BXNA3uxAJLl3ZdOddJhaAyGQAyd%252FWJ37XOYhJs5v7qxvXDVRacW8C90m6UNR5Zm%252BvDbOPbfLEWVy5dopLsikosHCWRkk%252F%252Fx%252BH4t71UwYUSMoIajVYBKmevJsn4ZWdVlyRI9f1PzUURVlslen81vJX%252BOGqoDrpUdiSrj4T3Oo0sU2kixy0o3rn%252BvDIKq5NC80mSWcd8rRrM9As%252FZYG15rPcwJDMU7hVZxlHpbssMuh9w2U3OXuS9EE%252FnKOS6KE1hvBWd0bRHCFb1VKMNzayK4GOrABAWcW7lsKo%252BjGoFJsqYTqtR1C3s%252Fz7MVHG1qHhOR4yZwDGQRcJpGB4vZgqjekEWOAAnfs1WanAS7TH6QaXsBBYqCPU4TcGyI4%252B%252BChmnKd7C3g6JpNCzINPKe55PXtdodH3Bh%252BEC8JNQuNH7mEkuIWcSpQkyVJirsJYLQ%252BPeqHAHSME2PhW9yC1ngxsztcT0%252BcOV0QP9fC%252BZN%252FHWT7qE%252FFy9mmPM%252Bc5ScPaGRp8pPhiTI%253D%26X-Amz-Algorithm%3DAWS4-HMAC-SHA256%26X-Amz-Date%3D20240218T164230Z%26X-Amz-SignedHeaders%3Dhost%26X-Amz-Expires%3D300%26X-Amz-Credential%3DASIAQ3PHCVTYQEPLVETU%252F20240218%252Fus-east-1%252Fs3%252Faws4_request%26X-Amz-Signature%3Dfc9a2aa4f6990030ce0552b2b0810521ca08b9d9e83ce60e6d70b19c8f4d923d%26hash%3D5edaf95f4c6380a596fa370e2a9aca696b0e21361b739d4ac6a10be02d8d539e%26host%3D68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61%26pii%3DS0010027716300300%26tid%3Dpdf-557cb268-9fe2-4c31-ad63-bfa5525003e8%26sid%3D4cb73e9469cc5247698a38d863c0e12aebdagxrqa%26type%3Dclient&group=__world__},
	issn = {0010-0277},
	journal = {Cognition},
	keywords = {Moral judgment, Model-free, Model-based, Dual-system, ai-morality, ai-ethics; reinforcement-learning},
	pages = {232-242},
	title = {Can model-free reinforcement learning explain deontological moral judgments?},
	toread = {0},
	url = {https://www.sciencedirect.com/science/article/pii/S0010027716300300},
	venue-short = {JourCognition},
	volume = {150},
	year = {2016},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEDFhc3NldHMvcGRmLzIwMTYtam91cmNvZ25pdGlvbi1heWFycy1jYW4tbW9kZWwucGRmTxEEsGJvb2uwBAAAAAAEEDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKwDAAAFAAAAAQEAAFVzZXJzAAAACAAAAAEBAABtY3Jvd2xleQcAAAABAQAARHJvcGJveAAEAAAAAQEAAEFwcHMNAAAAAQEAAHJlbW90ZWx5LXNhdmUAAAAIAAAAAQEAAEFJVG9waWNzBgAAAAEBAABhc3NldHMAAAMAAAABAQAAcGRmACYAAAABAQAAMjAxNi1qb3VyY29nbml0aW9uLWF5YXJzLWNhbi1tb2RlbC5wZGYAACQAAAABBgAABAAAABQAAAAkAAAANAAAAEAAAABYAAAAaAAAAHgAAACEAAAACAAAAAQDAAAVXQAAAAAAAAgAAAAEAwAAOegDAAAAAAAIAAAABAMAAF91BAAAAAAACAAAAAQDAADRjgQAAAAAAAgAAAAEAwAAEFF0AgAAAAAIAAAABAMAAJ4W5wIAAAAACAAAAAQDAAA1z+ACAAAAAAgAAAAEAwAANs/gAgAAAAAIAAAABAMAAOf14AIAAAAAJAAAAAEGAADgAAAA8AAAAAABAAAQAQAAIAEAADABAABAAQAAUAEAAGABAAAIAAAAAAQAAEHF2JdWlQbLGAAAAAECAAABAAAAAAAAAA8AAAAAAAAAAAAAAAAAAAAIAAAABAMAAAcAAAAAAAAABAAAAAMDAAD1AQAACAAAAAEJAABmaWxlOi8vLwwAAAABAQAATWFjaW50b3NoIEhECAAAAAQDAAAAkIKW5wAAAAgAAAAABAAAQcYj7JuAAAAkAAAAAQEAADA5QjdFQUJFLTY3OTUtNENERi1BQjI0LTNGRjA4NTY1RDAxNhgAAAABAgAAgQAAAAEAAADvEwAAAQAAAAAAAAAAAAAAAQAAAAEBAAAvAAAAAAAAAAEFAAAXAQAAAQIAADU1MmUwZTRiYWRkYTUyNDdhY2ZhZDA3NTdkMTllYmJjZjcwODYwNTU2Yzc2ZTMxMmNkMDlhMjkxZGRhMDdiMmM7MDA7MDAwMDAwMDA7MDAwMDAwMDA7MDAwMDAwMDA7MDAwMDAwMDAwMDAwMDAyMDtjb20uYXBwbGUuYXBwLXNhbmRib3gucmVhZC13cml0ZTswMTswMTAwMDAxMTswMDAwMDAwMDAyZTBmNWU3OzAxOy91c2Vycy9tY3Jvd2xleS9kcm9wYm94L2FwcHMvcmVtb3RlbHktc2F2ZS9haXRvcGljcy9hc3NldHMvcGRmLzIwMTYtam91cmNvZ25pdGlvbi1heWFycy1jYW4tbW9kZWwucGRmAADMAAAA/v///wEAAAAAAAAAEAAAAAQQAAC0AAAAAAAAAAUQAABwAQAAAAAAABAQAACsAQAAAAAAAEAQAACcAQAAAAAAAAIgAAB4AgAAAAAAAAUgAADoAQAAAAAAABAgAAD4AQAAAAAAABEgAAAsAgAAAAAAABIgAAAMAgAAAAAAABMgAAAcAgAAAAAAACAgAABYAgAAAAAAADAgAACEAgAAAAAAAAHAAADMAQAAAAAAABHAAAAUAAAAAAAAABLAAADcAQAAAAAAAIDwAACMAgAAAAAAAAAIAA0AGgAjAFcAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAFCw==},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0010027716300300},
	bdsk-url-2 = {https://doi.org/10.1016/j.cognition.2016.02.002}}

@article{wang2023nature,
	abbr = {AI4Science},
	abstract = {Artificial intelligence (AI) is being increasingly integrated into scientific discovery to augment and accelerate research, helping scientists to generate hypotheses, design experiments, collect and interpret large datasets, and gain insights that might not have been possible using traditional scientific methods alone. Here we examine breakthroughs over the past decade that include self-supervised learning, which allows models to be trained on vast amounts of unlabelled data, and geometric deep learning, which leverages knowledge about the structure of scientific data to enhance model accuracy and efficiency. Generative AI methods can create designs, such as small-molecule drugs and proteins, by analysing diverse data modalities, including images and sequences. We discuss how these methods can help scientists throughout the scientific process and the central issues that remain despite such advances. Both developers and users of AI tools need a better understanding of when such approaches need improvement, and challenges posed by poor data quality and stewardship remain. These issues cut across scientific disciplines and require developing foundational algorithmic approaches that can contribute to scientific understanding or acquire it autonomously, making them critical areas of focus for AI innovation.},
	annote = {This is a great paper to look at for an update on the many ways AI/ML/RL are being used for science. It is written by the organizers of the regular [AI for Science workshop](https://ai4sciencecommunity.github.io/) held at multiple major conferences. There are extensive notes in the hypothesis link of the webpage version of the paper, click the hypothesis link to see the notes.},
	author = {Wang, Hanchen and Fu, Tianfan and Du, Yuanqi and Gao, Wenhao and Huang, Kexin and Liu, Ziming and Chandak, Payal and Liu, Shengchao and Van Katwyk, Peter and Deac, Andreea and Anandkumar, Anima and Bergen, Karianne and Gomes, Carla P. and Ho, Shirley and Kohli, Pushmeet and Lasenby, Joan and Leskovec, Jure and Liu, Tie-Yan and Manrai, Arjun and Marks, Debora and Ramsundar, Bharath and Song, Le and Sun, Jimeng and Tang, Jian and Veli{\v c}kovi{\'c}, Petar and Welling, Max and Zhang, Linfeng and Coley, Connor W. and Bengio, Yoshua and Zitnik, Marinka},
	date = {2023/08/01},
	date-added = {2024-02-15 17:44:23 -0500},
	date-discussed = {2023-10-23 led by Mark Crowley},
	date-modified = {2024-07-26 00:19:48 -0400},
	doi = {10.1038/s41586-023-06221-2},
	hypoth = {https://hyp.is/go?url=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41586-023-06221-2&group=__world__},
	id = {Wang2023},
	in-website = {1},
	isbn = {1476-4687},
	journal = {Nature},
	keywords = {rd-done, ai-for-science, deep-learning, generative-models, large-language-models, nlp, ai-for-physics; rdgrp-f23},
	number = {7972},
	order = {1},
	pages = {47--60},
	title = {Scientific discovery in the age of artificial intelligence},
	toread = {1},
	url = {https://doi.org/10.1038/s41586-023-06221-2},
	venue-short = {Nature},
	volume = {620},
	year = {2023},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEEsuLi8uLi8uLi93ZWJzaXRlX2Fzc2V0cy9tYXJrY3Jvd2xleS1jYS9wZGZzLzIwMjMtbmF0dXJlLXdhbmctc2NpZW50aWZpYy5wZGZPEQRYYm9va1gEAAAAAAQQMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAVAMAAAUAAAABAQAAVXNlcnMAAAAIAAAAAQEAAG1jcm93bGV5BwAAAAEBAABEcm9wYm94AA4AAAABAQAAd2Vic2l0ZV9hc3NldHMAAA4AAAABAQAAbWFya2Nyb3dsZXktY2EAAAQAAAABAQAAcGRmcx8AAAABAQAAMjAyMy1uYXR1cmUtd2FuZy1zY2llbnRpZmljLnBkZgAcAAAAAQYAAAQAAAAUAAAAJAAAADQAAABMAAAAZAAAAHAAAAAIAAAABAMAABVdAAAAAAAACAAAAAQDAAA56AMAAAAAAAgAAAAEAwAAX3UEAAAAAAAIAAAABAMAAAajyQEAAAAACAAAAAQDAACMpMkBAAAAAAgAAAAEAwAAq6TJAQAAAAAIAAAABAMAAJ5rzwEAAAAAHAAAAAEGAAC8AAAAzAAAANwAAADsAAAA/AAAAAwBAAAcAQAACAAAAAAEAABBxVfA19956BgAAAABAgAAAQAAAAAAAAAPAAAAAAAAAAAAAAAAAAAACAAAAAQDAAAFAAAAAAAAAAQAAAADAwAA9QEAAAgAAAABCQAAZmlsZTovLy8MAAAAAQEAAE1hY2ludG9zaCBIRAgAAAAEAwAAAJCClucAAAAIAAAAAAQAAEHGI+ybgAAAJAAAAAEBAAAwOUI3RUFCRS02Nzk1LTRDREYtQUIyNC0zRkYwODU2NUQwMTYYAAAAAQIAAIEAAAABAAAA7xMAAAEAAAAAAAAAAAAAAAEAAAABAQAALwAAAAAAAAABBQAADAEAAAECAAA1YmQwYmU5NmY2Y2Q3MDZiYTc0MWUxZjBjNjQxMjNlNzhjODYzYTdjMmRiYjk3ZWU2NmFiOTZmZWNiYTUyMmJmOzAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwMDAwMDAwMjA7Y29tLmFwcGxlLmFwcC1zYW5kYm94LnJlYWQtd3JpdGU7MDE7MDEwMDAwMTE7MDAwMDAwMDAwMWNmNmI5ZTswMTsvdXNlcnMvbWNyb3dsZXkvZHJvcGJveC93ZWJzaXRlX2Fzc2V0cy9tYXJrY3Jvd2xleS1jYS9wZGZzLzIwMjMtbmF0dXJlLXdhbmctc2NpZW50aWZpYy5wZGYAzAAAAP7///8BAAAAAAAAABAAAAAEEAAAmAAAAAAAAAAFEAAALAEAAAAAAAAQEAAAYAEAAAAAAABAEAAAUAEAAAAAAAACIAAALAIAAAAAAAAFIAAAnAEAAAAAAAAQIAAArAEAAAAAAAARIAAA4AEAAAAAAAASIAAAwAEAAAAAAAATIAAA0AEAAAAAAAAgIAAADAIAAAAAAAAwIAAAOAIAAAAAAAABwAAAgAEAAAAAAAARwAAAFAAAAAAAAAASwAAAkAEAAAAAAACA8AAAQAIAAAAAAAAACAANABoAIwBxAAAAAAAAAgEAAAAAAAAABQAAAAAAAAAAAAAAAAAABM0=},
	bdsk-url-1 = {https://doi.org/10.1038/s41586-023-06221-2}}

@article{zecevic2023tmlr,
	abstract = {Some argue scale is all what is needed to achieve AI, covering even causal models. We make it clear that large language models (LLMs) cannot be causal and give reason onto why sometimes we might feel otherwise. To this end, we define and exemplify a new subgroup of Structural Causal Model (SCM) that we call meta SCM which encode causal facts about other SCM within their variables. We conjecture that in the cases where LLM succeed in doing causal inference, underlying was a respective meta SCM that exposed correlations between causal facts in natural language on whose data the LLM was ultimately trained. If our hypothesis holds true, then this would imply that LLMs are like parrots in that they simply recite the causal knowledge embedded in the data. Our empirical analysis provides favoring evidence that current LLMs are even weak `causal parrots.'},
	annote = {This paper has a very bold premise to show clearly what causality and conceptual reasoning means in terms of Large Language Models. They define it clearly int terms of evidence existing in the training set and argue that LLMs can only learn causal relations in those cases. These authors are organizing a workshop on this very topic for NeurIPS 2023.},
	arxiv = {2308.13067},
	author = {Matej Ze{\v{c}}evi{\'c} and Moritz Willig and Devendra Singh Dhami and Kristian Kersting},
	date-added = {2024-02-15 17:44:23 -0500},
	date-discussed = {2023-10-30 led by Shayan},
	date-modified = {2024-07-26 00:19:48 -0400},
	hypoth = {https://hyp.is/go?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2308.13067.pdf&group=__world__},
	in-website = {1},
	issn = {2835-8856},
	journal = {Transactions on Machine Learning Research},
	keywords = {large-language-models, causality, rd-done; rdgrp-f23},
	month = {August},
	order = {2},
	pdf = {2023-tmlr-zecevic-causal.pdf},
	rating = {4},
	title = {Causal Parrots: Large Language Models May Talk Causality But Are Not Causal},
	toread = {1},
	url = {https://openreview.net/forum?id=tv46tCzs83},
	venue-short = {TMLR},
	year = {2023},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxBQLi4vLi4vLi4vRHJvcGJveC93ZWJzaXRlX2Fzc2V0cy9tYXJrY3Jvd2xleS1jYS9wZGZzLzIwMjMtdG1sci16ZWNldmljLWNhdXNhbC5wZGZPEQHAAAAAAAHAAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAAAAAAAAQkQAAf////8cMjAyMy10bWxyLXplY2V2aWMtY2F1c2FsLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/////wAAAAAAAAAAAAAAAAADAAUAAAogY3UAAAAAAAAAAAAAAAAABHBkZnMAAgBYLzpVc2VyczptY3Jvd2xleTpEcm9wYm94OndlYnNpdGVfYXNzZXRzOm1hcmtjcm93bGV5LWNhOnBkZnM6MjAyMy10bWxyLXplY2V2aWMtY2F1c2FsLnBkZgAOADoAHAAyADAAMgAzAC0AdABtAGwAcgAtAHoAZQBjAGUAdgBpAGMALQBjAGEAdQBzAGEAbAAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAVlVzZXJzL21jcm93bGV5L0Ryb3Bib3gvd2Vic2l0ZV9hc3NldHMvbWFya2Nyb3dsZXktY2EvcGRmcy8yMDIzLXRtbHItemVjZXZpYy1jYXVzYWwucGRmABMAAS8AABUAAgAP//8AAAAIAA0AGgAkAHcAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAACOw==}}

@misc{wu2023arxiv,
	abbr = {SPRING},
	arxiv = {2305.15486},
	author = {Yue Wu and Shrimai Prabhumoye and So Yeon Min and Yonatan Bisk and Ruslan Salakhutdinov and Amos Azaria and Tom Mitchell and Yuanzhi Li},
	bdsk-color = {6},
	date-added = {2024-02-15 17:44:23 -0500},
	date-modified = {2024-07-26 00:18:48 -0400},
	howpublished = {arxiv},
	hypoth = {https://hyp.is/go?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2305.15486.pdf&group=__world__},
	in-website = {1},
	keywords = {rd-later, large-language-models, reinforcement-learning; rdgrp-f23; rdgrp-ece750T4-f24},
	order = {3},
	pdf = {2023-arxiv-wu-spring.pdf},
	title = {SPRING: GPT-4 Out-performs RL Algorithms by Studying Papers and Reasoning},
	toread = {1},
	venue-short = {arxiv},
	year = {2023},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfECNhc3NldHMvcGRmLzIwMjMtYXJ4aXYtd3Utc3ByaW5nLnBkZk8RBJRib29rlAQAAAAABBAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACQAwAABQAAAAEBAABVc2VycwAAAAgAAAABAQAAbWNyb3dsZXkHAAAAAQEAAERyb3Bib3gABAAAAAEBAABBcHBzDQAAAAEBAAByZW1vdGVseS1zYXZlAAAACAAAAAEBAABBSVRvcGljcwYAAAABAQAAYXNzZXRzAAADAAAAAQEAAHBkZgAYAAAAAQEAADIwMjMtYXJ4aXYtd3Utc3ByaW5nLnBkZiQAAAABBgAABAAAABQAAAAkAAAANAAAAEAAAABYAAAAaAAAAHgAAACEAAAACAAAAAQDAAAVXQAAAAAAAAgAAAAEAwAAOegDAAAAAAAIAAAABAMAAF91BAAAAAAACAAAAAQDAADRjgQAAAAAAAgAAAAEAwAAEFF0AgAAAAAIAAAABAMAAJ4W5wIAAAAACAAAAAQDAAA1z+ACAAAAAAgAAAAEAwAANs/gAgAAAAAIAAAABAMAAGRY3QIAAAAAJAAAAAEGAADQAAAA4AAAAPAAAAAAAQAAEAEAACABAAAwAQAAQAEAAFABAAAIAAAAAAQAAEHFWRqkgAAAGAAAAAECAAABAAAAAAAAAA8AAAAAAAAAAAAAAAAAAAAIAAAABAMAAAcAAAAAAAAABAAAAAMDAAD1AQAACAAAAAEJAABmaWxlOi8vLwwAAAABAQAATWFjaW50b3NoIEhECAAAAAQDAAAAkIKW5wAAAAgAAAAABAAAQcYj7JuAAAAkAAAAAQEAADA5QjdFQUJFLTY3OTUtNENERi1BQjI0LTNGRjA4NTY1RDAxNhgAAAABAgAAgQAAAAEAAADvEwAAAQAAAAAAAAAAAAAAAQAAAAEBAAAvAAAAAAAAAAEFAAAJAQAAAQIAADFlNjcwNTE5NTI2NWQzYmUyNzEyMTUzN2RiMTYzNDI3MWEwNTc0MGMxNWYwNDVlM2JjNDNmMDc3ZmFjNTEzZjE7MDA7MDAwMDAwMDA7MDAwMDAwMDA7MDAwMDAwMDA7MDAwMDAwMDAwMDAwMDAyMDtjb20uYXBwbGUuYXBwLXNhbmRib3gucmVhZC13cml0ZTswMTswMTAwMDAxMTswMDAwMDAwMDAyZGQ1ODY0OzAxOy91c2Vycy9tY3Jvd2xleS9kcm9wYm94L2FwcHMvcmVtb3RlbHktc2F2ZS9haXRvcGljcy9hc3NldHMvcGRmLzIwMjMtYXJ4aXYtd3Utc3ByaW5nLnBkZgAAAADMAAAA/v///wEAAAAAAAAAEAAAAAQQAACkAAAAAAAAAAUQAABgAQAAAAAAABAQAACcAQAAAAAAAEAQAACMAQAAAAAAAAIgAABoAgAAAAAAAAUgAADYAQAAAAAAABAgAADoAQAAAAAAABEgAAAcAgAAAAAAABIgAAD8AQAAAAAAABMgAAAMAgAAAAAAACAgAABIAgAAAAAAADAgAAB0AgAAAAAAAAHAAAC8AQAAAAAAABHAAAAUAAAAAAAAABLAAADMAQAAAAAAAIDwAAB8AgAAAAAAAAAIAA0AGgAjAEkAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAE4Q==}}

@inproceedings{chen2021neurips,
	abbr = {DecTransfrmr},
	abstract = {We introduce a framework that abstracts Reinforcement Learning (RL) as a sequence modeling problem. This allows us to draw upon the simplicity and scalability of the Transformer architecture, and associated advances in language modeling such as GPT-x and BERT. In particular, we present Decision Transformer, an architecture that casts the problem of RL as conditional sequence modeling. Unlike prior approaches to RL that fit value functions or compute policy gradients, Decision Transformer simply outputs the optimal actions by leveraging a causally masked Transformer. By conditioning an autoregressive model on the desired return (reward), past states, and actions, our Decision Transformer model can generate future actions that achieve the desired return. Despite its simplicity, Decision Transformer matches or exceeds the performance of state-of-the-art model-free offline RL baselines on Atari, OpenAI Gym, and Key-to-Door tasks.},
	archiveprefix = {arxiv},
	arxiv = {2106.01345},
	author = {Chen, Lili and Lu, Kevin and Rajeswaran, Aravind and Lee, Kimin and Grover, Aditya and Laskin, Misha and Abbeel, Pieter and Srinivas, Aravind and Mordatch, Igor},
	bdsk-color = {6},
	booktitle = {Advances in Neural Information Processing Systems},
	date-added = {2024-02-15 17:44:23 -0500},
	date-modified = {2024-07-26 00:22:39 -0400},
	editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
	eprint = {2106.01345},
	howpublished = {arxiv},
	hypoth = {https://hyp.is/go?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2106.01345.pdf&group=__world__},
	in-website = {1},
	keywords = {rdgrp-ece750T4-f24; machine-learning, reinforcement-learning, decision-transformers, rd-done; rdgrp-f23; rd-later},
	month = {June},
	note = {This is a really neat and clean idea for how to utilize the temporal, predictive structure of transformers to implement Reinforcement Learning. There are other approaches to this, but this one is very elegant.},
	number = {arXiv:2106.01345},
	order = {2},
	pages = {15084--15097},
	pdf = {2021-neurips-chen-decision.pdf},
	primaryclass = {cs},
	shorttitle = {Decision Transformer},
	status = {1},
	title = {Decision Transformer: Reinforcement Learning via Sequence Modeling},
	toread = {1},
	url = {https://proceedings.neurips.cc/paper_files/paper/2021/file/7f489f642a0ddb10272b5c31057f0663-Paper.pdf},
	urldate = {2022-09-27},
	venue-short = {neurips},
	volume = {34},
	year = {2021},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEClhc3NldHMvcGRmLzIwMjEtbmV1cmlwcy1jaGVuLWRlY2lzaW9uLnBkZk8RBKBib29roAQAAAAABBAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACcAwAABQAAAAEBAABVc2VycwAAAAgAAAABAQAAbWNyb3dsZXkHAAAAAQEAAERyb3Bib3gABAAAAAEBAABBcHBzDQAAAAEBAAByZW1vdGVseS1zYXZlAAAACAAAAAEBAABBSVRvcGljcwYAAAABAQAAYXNzZXRzAAADAAAAAQEAAHBkZgAeAAAAAQEAADIwMjEtbmV1cmlwcy1jaGVuLWRlY2lzaW9uLnBkZgAAJAAAAAEGAAAEAAAAFAAAACQAAAA0AAAAQAAAAFgAAABoAAAAeAAAAIQAAAAIAAAABAMAABVdAAAAAAAACAAAAAQDAAA56AMAAAAAAAgAAAAEAwAAX3UEAAAAAAAIAAAABAMAANGOBAAAAAAACAAAAAQDAAAQUXQCAAAAAAgAAAAEAwAAnhbnAgAAAAAIAAAABAMAADXP4AIAAAAACAAAAAQDAAA2z+ACAAAAAAgAAAAEAwAATFjdAgAAAAAkAAAAAQYAANgAAADoAAAA+AAAAAgBAAAYAQAAKAEAADgBAABIAQAAWAEAAAgAAAAABAAAQcVUjr6AAAAYAAAAAQIAAAEAAAAAAAAADwAAAAAAAAAAAAAAAAAAAAgAAAAEAwAABwAAAAAAAAAEAAAAAwMAAPUBAAAIAAAAAQkAAGZpbGU6Ly8vDAAAAAEBAABNYWNpbnRvc2ggSEQIAAAABAMAAACQgpbnAAAACAAAAAAEAABBxiPsm4AAACQAAAABAQAAMDlCN0VBQkUtNjc5NS00Q0RGLUFCMjQtM0ZGMDg1NjVEMDE2GAAAAAECAACBAAAAAQAAAO8TAAABAAAAAAAAAAAAAAABAAAAAQEAAC8AAAAAAAAAAQUAAA8BAAABAgAAOTkxMzExOTc4ZjIxMDYwMGZjMWQ2OTc2YTlhN2ZlZGNlNDRjOWM5NTlhMmM4ZWRmYTdkZWVhOGZmNWU1NGViZjswMDswMDAwMDAwMDswMDAwMDAwMDswMDAwMDAwMDswMDAwMDAwMDAwMDAwMDIwO2NvbS5hcHBsZS5hcHAtc2FuZGJveC5yZWFkLXdyaXRlOzAxOzAxMDAwMDExOzAwMDAwMDAwMDJkZDU4NGM7MDE7L3VzZXJzL21jcm93bGV5L2Ryb3Bib3gvYXBwcy9yZW1vdGVseS1zYXZlL2FpdG9waWNzL2Fzc2V0cy9wZGYvMjAyMS1uZXVyaXBzLWNoZW4tZGVjaXNpb24ucGRmAADMAAAA/v///wEAAAAAAAAAEAAAAAQQAACsAAAAAAAAAAUQAABoAQAAAAAAABAQAACkAQAAAAAAAEAQAACUAQAAAAAAAAIgAABwAgAAAAAAAAUgAADgAQAAAAAAABAgAADwAQAAAAAAABEgAAAkAgAAAAAAABIgAAAEAgAAAAAAABMgAAAUAgAAAAAAACAgAABQAgAAAAAAADAgAAB8AgAAAAAAAAHAAADEAQAAAAAAABHAAAAUAAAAAAAAABLAAADUAQAAAAAAAIDwAACEAgAAAAAAAAAIAA0AGgAjAE8AAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAE8w==},
	bdsk-url-1 = {https://proceedings.neurips.cc/paper_files/paper/2021/file/7f489f642a0ddb10272b5c31057f0663-Paper.pdf}}

@inproceedings{janner2022pmlr,
	abstract = {Model-based reinforcement learning methods often use learning only for the purpose of recovering an approximate dynamics model, offloading the rest of the decision-making work to classical trajectory optimizers. While conceptually simple, this combination has a number of empirical shortcomings, suggesting that learned models may not be well-suited to standard trajectory optimization. In this paper, we consider what it would look like to fold as much of the trajectory optimization pipeline as possible into the modeling problem, such that sampling from the model and planning with it become nearly identical. The core of our technical approach lies in a diffusion probabilistic model that plans by iteratively denoising trajectories. We show how classifier-guided sampling and image inpainting can be reinterpreted as coherent planning strategies, explore the unusual and useful properties of diffusion-based planning methods, and demonstrate the effectiveness of our framework in control settings that emphasize long-horizon decision-making and test-time flexibility.},
	annote = {looks like a very interesting claim },
	author = {Janner, Michael and Du, Yilun and Tenenbaum, Joshua and Levine, Sergey},
	bdsk-color = {6},
	booktitle = {Proceedings of the 39th International Conference on Machine Learning},
	date-added = {2024-02-15 17:44:23 -0500},
	date-modified = {2024-07-26 00:24:21 -0400},
	editor = {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
	hypoth = {https://hyp.is/go?url=https%3A%2F%2Fproceedings.mlr.press%2Fv162%2Fjanner22a%2Fjanner22a.pdf&group=__world__},
	keywords = {reinforcement-learning, transformers, decision-transformers, machine-learning, dcmu, planning, rdgrp-f23},
	month = {17--23 Jul},
	order = {5},
	pages = {9902--9915},
	pdf = {2022-pmlr-janner-planning.pdf},
	publisher = {PMLR},
	series = {Proceedings of Machine Learning Research},
	title = {Planning with Diffusion for Flexible Behavior Synthesis},
	toread = {1},
	url = {https://proceedings.mlr.press/v162/janner22a.html},
	venue-short = {PMLR},
	volume = {162},
	year = {2022},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEChhc3NldHMvcGRmLzIwMjItcG1sci1qYW5uZXItcGxhbm5pbmcucGRmTxEEoGJvb2ugBAAAAAAEEDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJwDAAAFAAAAAQEAAFVzZXJzAAAACAAAAAEBAABtY3Jvd2xleQcAAAABAQAARHJvcGJveAAEAAAAAQEAAEFwcHMNAAAAAQEAAHJlbW90ZWx5LXNhdmUAAAAIAAAAAQEAAEFJVG9waWNzBgAAAAEBAABhc3NldHMAAAMAAAABAQAAcGRmAB0AAAABAQAAMjAyMi1wbWxyLWphbm5lci1wbGFubmluZy5wZGYAAAAkAAAAAQYAAAQAAAAUAAAAJAAAADQAAABAAAAAWAAAAGgAAAB4AAAAhAAAAAgAAAAEAwAAFV0AAAAAAAAIAAAABAMAADnoAwAAAAAACAAAAAQDAABfdQQAAAAAAAgAAAAEAwAA0Y4EAAAAAAAIAAAABAMAABBRdAIAAAAACAAAAAQDAACeFucCAAAAAAgAAAAEAwAANc/gAgAAAAAIAAAABAMAADbP4AIAAAAACAAAAAQDAABfWN0CAAAAACQAAAABBgAA2AAAAOgAAAD4AAAACAEAABgBAAAoAQAAOAEAAEgBAABYAQAACAAAAAAEAABBxYiD6YAAABgAAAABAgAAAQAAAAAAAAAPAAAAAAAAAAAAAAAAAAAACAAAAAQDAAAHAAAAAAAAAAQAAAADAwAA9QEAAAgAAAABCQAAZmlsZTovLy8MAAAAAQEAAE1hY2ludG9zaCBIRAgAAAAEAwAAAJCClucAAAAIAAAAAAQAAEHGI+ybgAAAJAAAAAEBAAAwOUI3RUFCRS02Nzk1LTRDREYtQUIyNC0zRkYwODU2NUQwMTYYAAAAAQIAAIEAAAABAAAA7xMAAAEAAAAAAAAAAAAAAAEAAAABAQAALwAAAAAAAAABBQAADgEAAAECAABhMWM5NDZjNWIxZTdjMzZkOWE2NzI4MzdmNTc3MWZhMTQyZTk1MWZmNGNkYzZiMTIxNmE5YmJiODkwOGY1MmUzOzAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwMDAwMDAwMjA7Y29tLmFwcGxlLmFwcC1zYW5kYm94LnJlYWQtd3JpdGU7MDE7MDEwMDAwMTE7MDAwMDAwMDAwMmRkNTg1ZjswMTsvdXNlcnMvbWNyb3dsZXkvZHJvcGJveC9hcHBzL3JlbW90ZWx5LXNhdmUvYWl0b3BpY3MvYXNzZXRzL3BkZi8yMDIyLXBtbHItamFubmVyLXBsYW5uaW5nLnBkZgAAAMwAAAD+////AQAAAAAAAAAQAAAABBAAAKwAAAAAAAAABRAAAGgBAAAAAAAAEBAAAKQBAAAAAAAAQBAAAJQBAAAAAAAAAiAAAHACAAAAAAAABSAAAOABAAAAAAAAECAAAPABAAAAAAAAESAAACQCAAAAAAAAEiAAAAQCAAAAAAAAEyAAABQCAAAAAAAAICAAAFACAAAAAAAAMCAAAHwCAAAAAAAAAcAAAMQBAAAAAAAAEcAAABQAAAAAAAAAEsAAANQBAAAAAAAAgPAAAIQCAAAAAAAAAAgADQAaACMATgAAAAAAAAIBAAAAAAAAAAUAAAAAAAAAAAAAAAAAAATy},
	bdsk-url-1 = {https://proceedings.mlr.press/v162/janner22a.html}}

@inproceedings{janner2021neurips,
	annote = {An alternative approach to RL via transformers that came out at the same time as Decision Transformers.},
	author = {Janner, Michael and Li, Qiyang and Levine, Sergey},
	bdsk-color = {6},
	booktitle = {Advances in Neural Information Processing Systems},
	date-added = {2024-02-15 17:44:23 -0500},
	date-modified = {2024-07-26 00:25:51 -0400},
	editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
	hypoth = {https://hyp.is/go?url=https%3A%2F%2Fproceedings.neurips.cc%2Fpaper_files%2Fpaper%2F2021%2Ffile%2F099fe6b0b444c23836c4a5d07346082b-Paper.pdf&group=__world__},
	keywords = {reinforcement-learning, transformers, sequenc-modelling, decision-transformers, rdgrp-f23; rdgrp-ece750T4-f24; rd-later},
	order = {5},
	pages = {1273--1286},
	pdf = {2021-neurips-janner-offline.pdf},
	publisher = {Curran Associates, Inc.},
	title = {Offline Reinforcement Learning as One Big Sequence Modeling Problem},
	toread = {1},
	url = {https://proceedings.neurips.cc/paper_files/paper/2021/file/099fe6b0b444c23836c4a5d07346082b-Paper.pdf},
	venue-short = {NeurIPS},
	volume = {34},
	year = {2021},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfECphc3NldHMvcGRmLzIwMjEtbmV1cmlwcy1qYW5uZXItb2ZmbGluZS5wZGZPEQSgYm9va6AEAAAAAAQQMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAnAMAAAUAAAABAQAAVXNlcnMAAAAIAAAAAQEAAG1jcm93bGV5BwAAAAEBAABEcm9wYm94AAQAAAABAQAAQXBwcw0AAAABAQAAcmVtb3RlbHktc2F2ZQAAAAgAAAABAQAAQUlUb3BpY3MGAAAAAQEAAGFzc2V0cwAAAwAAAAEBAABwZGYAHwAAAAEBAAAyMDIxLW5ldXJpcHMtamFubmVyLW9mZmxpbmUucGRmACQAAAABBgAABAAAABQAAAAkAAAANAAAAEAAAABYAAAAaAAAAHgAAACEAAAACAAAAAQDAAAVXQAAAAAAAAgAAAAEAwAAOegDAAAAAAAIAAAABAMAAF91BAAAAAAACAAAAAQDAADRjgQAAAAAAAgAAAAEAwAAEFF0AgAAAAAIAAAABAMAAJ4W5wIAAAAACAAAAAQDAAA1z+ACAAAAAAgAAAAEAwAANs/gAgAAAAAIAAAABAMAAE1Y3QIAAAAAJAAAAAEGAADYAAAA6AAAAPgAAAAIAQAAGAEAACgBAAA4AQAASAEAAFgBAAAIAAAAAAQAAEHFiIVZgAAAGAAAAAECAAABAAAAAAAAAA8AAAAAAAAAAAAAAAAAAAAIAAAABAMAAAcAAAAAAAAABAAAAAMDAAD1AQAACAAAAAEJAABmaWxlOi8vLwwAAAABAQAATWFjaW50b3NoIEhECAAAAAQDAAAAkIKW5wAAAAgAAAAABAAAQcYj7JuAAAAkAAAAAQEAADA5QjdFQUJFLTY3OTUtNENERi1BQjI0LTNGRjA4NTY1RDAxNhgAAAABAgAAgQAAAAEAAADvEwAAAQAAAAAAAAAAAAAAAQAAAAEBAAAvAAAAAAAAAAEFAAAQAQAAAQIAAGFiZTVmMWUyYTNkMmE2YTY4MjgxOTg1ODMxZWI3ZjRhYTJiNjQ4NjQ3YzFkYzVmMjI1ZGEzNTAyYzgzMTU1ZGE7MDA7MDAwMDAwMDA7MDAwMDAwMDA7MDAwMDAwMDA7MDAwMDAwMDAwMDAwMDAyMDtjb20uYXBwbGUuYXBwLXNhbmRib3gucmVhZC13cml0ZTswMTswMTAwMDAxMTswMDAwMDAwMDAyZGQ1ODRkOzAxOy91c2Vycy9tY3Jvd2xleS9kcm9wYm94L2FwcHMvcmVtb3RlbHktc2F2ZS9haXRvcGljcy9hc3NldHMvcGRmLzIwMjEtbmV1cmlwcy1qYW5uZXItb2ZmbGluZS5wZGYAzAAAAP7///8BAAAAAAAAABAAAAAEEAAArAAAAAAAAAAFEAAAaAEAAAAAAAAQEAAApAEAAAAAAABAEAAAlAEAAAAAAAACIAAAcAIAAAAAAAAFIAAA4AEAAAAAAAAQIAAA8AEAAAAAAAARIAAAJAIAAAAAAAASIAAABAIAAAAAAAATIAAAFAIAAAAAAAAgIAAAUAIAAAAAAAAwIAAAfAIAAAAAAAABwAAAxAEAAAAAAAARwAAAFAAAAAAAAAASwAAA1AEAAAAAAACA8AAAhAIAAAAAAAAACAANABoAIwBQAAAAAAAAAgEAAAAAAAAABQAAAAAAAAAAAAAAAAAABPQ=},
	bdsk-url-1 = {https://proceedings.neurips.cc/paper_files/paper/2021/file/099fe6b0b444c23836c4a5d07346082b-Paper.pdf}}

@inproceedings{xiong2023cvpr,
	annote = {Being used for the first attempt for the CSA wildfire project},
	author = {Xiong, Yuwen and Ma, Wei-Chiu and Wang, Jingkang and Urtasun, Raquel},
	booktitle = {Proceedings of the Conference on Computer Vision and Pattern Recognition (CVPR)},
	date-added = {2024-02-14 15:57:21 -0500},
	date-modified = {2024-07-24 11:41:30 -0400},
	hypoth = {https://hyp.is/go?url=https%3A%2F%2Fopenaccess.thecvf.com%2Fcontent%2FCVPR2023%2Fpapers%2FXiong_Learning_Compact_Representations_for_LiDAR_Completion_and_Generation_CVPR_2023_paper.pdf&group=__world__},
	keywords = {rdgrp-s23; proj-firecsalidar, deep-learning, generative-models, autonomous-driving, lidar},
	pages = {1074--1083},
	title = {Learning Compact Representations for LiDAR Completion and Generation},
	venue-short = {cvpr},
	year = {2023}}

@article{mohsenzadeh2023,
	author = {Yalda Mohsenzadeh},
	date-added = {2023-12-06 10:06:16 -0500},
	date-modified = {2023-12-06 10:07:23 -0500},
	journal = {Macleans},
	keywords = {prez-watitis},
	month = {October 12},
	title = {Machines will read our minds},
	year = {2023}}

@article{lambert2022illustrating,
	author = {Lambert, Nathan and Castricato, Louis and von Werra, Leandro and Havrilla, Alex},
	bdsk-color = {4},
	date-added = {2023-12-06 09:34:04 -0500},
	date-modified = {2024-07-26 00:26:05 -0400},
	journal = {Hugging Face Blog},
	keywords = {prez-watitis; reinforcement-learning; large-language-models; gpt; rlhf; rdgrp-ece750T4-f24; rd-middle},
	note = {https://huggingface.co/blog/rlhf},
	order = {2},
	temp = {0},
	title = {Illustrating Reinforcement Learning from Human Feedback (RLHF)},
	year = {2022}}

@article{knight2017dark,
	author = {Knight, Will},
	date-added = {2023-12-06 09:22:11 -0500},
	date-modified = {2023-12-06 09:25:29 -0500},
	journal = {MIT Technology review},
	keywords = {prez-watitis},
	number = {3},
	pages = {54--65},
	publisher = {Massachusetts Institute of Technology Cambridge, MA},
	temp = {1},
	title = {The dark secret at the heart of AI},
	volume = {120},
	year = {2017}}

@article{yang2023arxiv,
	annote = {I'm wary of some of their intro, "BERT models started to disappear" it's only been a year or two. They have a very nice overview figure. This recent review paper gives content on what tasks GPT style decoder-only LLMs are good for and which they are not (most tasks in fact).},
	archiveprefix = {arXiv},
	author = {Jingfeng Yang and Hongye Jin and Ruixiang Tang and Xiaotian Han and Qizhang Feng and Haoming Jiang and Bing Yin and Xia Hu},
	date-added = {2023-12-06 09:19:51 -0500},
	date-modified = {2024-07-26 00:19:48 -0400},
	eprint = {2304.13712},
	in-website = {1},
	journal = {Arxiv Preprint},
	keywords = {rd-done, transformer, BERT, gpt, survey, prez-watitis; rdgrp-s23},
	order = 8,
	pdf = {2023-arxiv-yang-harnessing.pdf},
	primaryclass = {cs.CL},
	temp = {0},
	title = {Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond},
	toread = {1},
	venue-short = {arxiv},
	year = {2023},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEBxhc3NldHMvcGRmL3lhbmcyMDIzYXJ4aXYucGRmTxEEiGJvb2uIBAAAAAAEEDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIQDAAAFAAAAAQEAAFVzZXJzAAAACAAAAAEBAABtY3Jvd2xleQcAAAABAQAARHJvcGJveAAEAAAAAQEAAEFwcHMNAAAAAQEAAHJlbW90ZWx5LXNhdmUAAAAIAAAAAQEAAEFJVG9waWNzBgAAAAEBAABhc3NldHMAAAMAAAABAQAAcGRmABEAAAABAQAAeWFuZzIwMjNhcnhpdi5wZGYAAAAkAAAAAQYAAAQAAAAUAAAAJAAAADQAAABAAAAAWAAAAGgAAAB4AAAAhAAAAAgAAAAEAwAAFV0AAAAAAAAIAAAABAMAADnoAwAAAAAACAAAAAQDAABfdQQAAAAAAAgAAAAEAwAA0Y4EAAAAAAAIAAAABAMAABBRdAIAAAAACAAAAAQDAACeFucCAAAAAAgAAAAEAwAANc/gAgAAAAAIAAAABAMAADbP4AIAAAAACAAAAAQDAABlWN0CAAAAACQAAAABBgAAzAAAANwAAADsAAAA/AAAAAwBAAAcAQAALAEAADwBAABMAQAACAAAAAAEAABBxZB1TYAAABgAAAABAgAAAQAAAAAAAAAPAAAAAAAAAAAAAAAAAAAACAAAAAQDAAAHAAAAAAAAAAQAAAADAwAA9QEAAAgAAAABCQAAZmlsZTovLy8MAAAAAQEAAE1hY2ludG9zaCBIRAgAAAAEAwAAAJCClucAAAAIAAAAAAQAAEHGI+ybgAAAJAAAAAEBAAAwOUI3RUFCRS02Nzk1LTRDREYtQUIyNC0zRkYwODU2NUQwMTYYAAAAAQIAAIEAAAABAAAA7xMAAAEAAAAAAAAAAAAAAAEAAAABAQAALwAAAAAAAAABBQAAAgEAAAECAABlMWQ2YWVhZjllYTVmZWM3Yzc3NjVhZmIxMTk5OGZkZWYxYmNhMjc5ZTEwODI5MTZhNGNlMTE5YjE4ZmNmNzg5OzAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwMDAwMDAwMjA7Y29tLmFwcGxlLmFwcC1zYW5kYm94LnJlYWQtd3JpdGU7MDE7MDEwMDAwMTE7MDAwMDAwMDAwMmRkNTg2NTswMTsvdXNlcnMvbWNyb3dsZXkvZHJvcGJveC9hcHBzL3JlbW90ZWx5LXNhdmUvYWl0b3BpY3MvYXNzZXRzL3BkZi95YW5nMjAyM2FyeGl2LnBkZgAAAMwAAAD+////AQAAAAAAAAAQAAAABBAAAKAAAAAAAAAABRAAAFwBAAAAAAAAEBAAAJgBAAAAAAAAQBAAAIgBAAAAAAAAAiAAAGQCAAAAAAAABSAAANQBAAAAAAAAECAAAOQBAAAAAAAAESAAABgCAAAAAAAAEiAAAPgBAAAAAAAAEyAAAAgCAAAAAAAAICAAAEQCAAAAAAAAMCAAAHACAAAAAAAAAcAAALgBAAAAAAAAEcAAABQAAAAAAAAAEsAAAMgBAAAAAAAAgPAAAHgCAAAAAAAAAAgADQAaACMAQgAAAAAAAAIBAAAAAAAAAAUAAAAAAAAAAAAAAAAAAATO}}

@inproceedings{devlin2019naaclhlt,
	annote = {The original paper for the BERT transformer model for NLP tasks.},
	author = {Jacob Devlin and Ming-Wei Chang and Kenten Lee and Kristina Toutanova},
	booktitle = {Proceedings of NAACL-HLT},
	date-added = {2023-12-06 09:19:51 -0500},
	date-discussed = {2023-06-14 14 led by Josh Sun},
	date-modified = {2024-07-26 00:19:48 -0400},
	in-website = {1},
	keywords = {rd-done, machine-learning, transformers, nlp, BERT, large-language-models; rdgrp-s23},
	order = {4},
	pages = {4171--4186},
	paperdesc = {The original paper for the BERT transformer model for NLP tasks.},
	pdf = {2019-naaclhlt-kenton-bert pre-training of deep bidirectional transformers for language understanding},
	status = {1},
	temp = {0},
	title = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
	toread = {1},
	venue-short = {naaclhlt},
	year = {2019},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfECFhc3NldHMvcGRmL2RldmxpbjIwMTluYWFjbGhsdC5wZGZPEQSQYm9va5AEAAAAAAQQMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAjAMAAAUAAAABAQAAVXNlcnMAAAAIAAAAAQEAAG1jcm93bGV5BwAAAAEBAABEcm9wYm94AAQAAAABAQAAQXBwcw0AAAABAQAAcmVtb3RlbHktc2F2ZQAAAAgAAAABAQAAQUlUb3BpY3MGAAAAAQEAAGFzc2V0cwAAAwAAAAEBAABwZGYAFgAAAAEBAABkZXZsaW4yMDE5bmFhY2xobHQucGRmAAAkAAAAAQYAAAQAAAAUAAAAJAAAADQAAABAAAAAWAAAAGgAAAB4AAAAhAAAAAgAAAAEAwAAFV0AAAAAAAAIAAAABAMAADnoAwAAAAAACAAAAAQDAABfdQQAAAAAAAgAAAAEAwAA0Y4EAAAAAAAIAAAABAMAABBRdAIAAAAACAAAAAQDAACeFucCAAAAAAgAAAAEAwAANc/gAgAAAAAIAAAABAMAADbP4AIAAAAACAAAAAQDAAAtWN0CAAAAACQAAAABBgAA0AAAAOAAAADwAAAAAAEAABABAAAgAQAAMAEAAEABAABQAQAACAAAAAAEAABBxVSOvoAAABgAAAABAgAAAQAAAAAAAAAPAAAAAAAAAAAAAAAAAAAACAAAAAQDAAAHAAAAAAAAAAQAAAADAwAA9QEAAAgAAAABCQAAZmlsZTovLy8MAAAAAQEAAE1hY2ludG9zaCBIRAgAAAAEAwAAAJCClucAAAAIAAAAAAQAAEHGI+ybgAAAJAAAAAEBAAAwOUI3RUFCRS02Nzk1LTRDREYtQUIyNC0zRkYwODU2NUQwMTYYAAAAAQIAAIEAAAABAAAA7xMAAAEAAAAAAAAAAAAAAAEAAAABAQAALwAAAAAAAAABBQAABwEAAAECAAAwM2Q1MjBmMTlkZWY1MGUwYzFlODQ4YjUwNGMzYjAzYmI2NzkzZmYwMWFiZDljNDNmMzVjOTVmNzQyOGE3NTJkOzAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwMDAwMDAwMjA7Y29tLmFwcGxlLmFwcC1zYW5kYm94LnJlYWQtd3JpdGU7MDE7MDEwMDAwMTE7MDAwMDAwMDAwMmRkNTgyZDswMTsvdXNlcnMvbWNyb3dsZXkvZHJvcGJveC9hcHBzL3JlbW90ZWx5LXNhdmUvYWl0b3BpY3MvYXNzZXRzL3BkZi9kZXZsaW4yMDE5bmFhY2xobHQucGRmAADMAAAA/v///wEAAAAAAAAAEAAAAAQQAACkAAAAAAAAAAUQAABgAQAAAAAAABAQAACcAQAAAAAAAEAQAACMAQAAAAAAAAIgAABoAgAAAAAAAAUgAADYAQAAAAAAABAgAADoAQAAAAAAABEgAAAcAgAAAAAAABIgAAD8AQAAAAAAABMgAAAMAgAAAAAAACAgAABIAgAAAAAAADAgAAB0AgAAAAAAAAHAAAC8AQAAAAAAABHAAAAUAAAAAAAAABLAAADMAQAAAAAAAIDwAAB8AgAAAAAAAAAIAA0AGgAjAEcAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAE2w==}}

@inproceedings{goodfellow2014neurips,
	abstract = {We propose a new framework for estimating generative models via adversarial nets, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitatively evaluation of the generated samples.},
	annote = {Seminal paper introducing the GAN framework which provided a huge advance in generative learning for images using novel metaphors from adversarial game theory to guide optimization.},
	author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
	booktitle = {Advances in Neural Information Processing Systems},
	date-added = {2023-11-17 08:48:30 -0500},
	date-modified = {2023-11-17 08:50:28 -0500},
	editor = {Z. Ghahramani and M. Welling and C. Cortes and N. Lawrence and K.Q. Weinberger},
	keywords = {deep-learning, generative-models, image-processing, game-theory; grant-csa-fire-2023},
	publisher = {Curran Associates, Inc.},
	rating = {5},
	seminal = {1},
	title = {Generative Adversarial Nets},
	url = {https://proceedings.neurips.cc/paper_files/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf},
	venue-short = {NeurIPS},
	volume = {27},
	year = {2014},
	bdsk-url-1 = {https://proceedings.neurips.cc/paper_files/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf}}

@inproceedings{gpt3,
	abstract = {We demonstrate that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even becoming competitive with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks. We also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora.},
	address = {Virtual.},
	annote = {Introduction of the GPT-3 model.},
	arxiv = {2005.14165},
	author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
	booktitle = {Advances in Neural Information Processing Systems},
	date-added = {2023-11-17 08:44:49 -0500},
	date-discussed = {2023-06-28 led by Felix},
	date-modified = {2024-07-26 00:19:48 -0400},
	editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
	hypoth = {https://hyp.is/go?url=https%3A%2F%2Fpapers.nips.cc%2Fpaper_files%2Fpaper%2F2020%2Ffile%2F1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf&group=__world__},
	keywords = {large-language-models, gpt, transformers; rd-done; grant-csa-fire-2023; prez-watitis; rdgrp-s23},
	note = {Introduction of the GPT-3 model.},
	order = {5},
	pages = {1877--1901},
	pdf = {2020-neurips-brown-language.pdf},
	temp = {0},
	title = {Language Models are Few-Shot Learners},
	toread = {1},
	url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf},
	venue-short = {neurips},
	volume = {33},
	year = {2020},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEB9hc3NldHMvcGRmL2Jyb3duMjAyMG5ldXJpcHMucGRmTxEEjGJvb2uMBAAAAAAEEDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIgDAAAFAAAAAQEAAFVzZXJzAAAACAAAAAEBAABtY3Jvd2xleQcAAAABAQAARHJvcGJveAAEAAAAAQEAAEFwcHMNAAAAAQEAAHJlbW90ZWx5LXNhdmUAAAAIAAAAAQEAAEFJVG9waWNzBgAAAAEBAABhc3NldHMAAAMAAAABAQAAcGRmABQAAAABAQAAYnJvd24yMDIwbmV1cmlwcy5wZGYkAAAAAQYAAAQAAAAUAAAAJAAAADQAAABAAAAAWAAAAGgAAAB4AAAAhAAAAAgAAAAEAwAAFV0AAAAAAAAIAAAABAMAADnoAwAAAAAACAAAAAQDAABfdQQAAAAAAAgAAAAEAwAA0Y4EAAAAAAAIAAAABAMAABBRdAIAAAAACAAAAAQDAACeFucCAAAAAAgAAAAEAwAANc/gAgAAAAAIAAAABAMAADbP4AIAAAAACAAAAAQDAAAzWN0CAAAAACQAAAABBgAAzAAAANwAAADsAAAA/AAAAAwBAAAcAQAALAEAADwBAABMAQAACAAAAAAEAABBxVSOvoAAABgAAAABAgAAAQAAAAAAAAAPAAAAAAAAAAAAAAAAAAAACAAAAAQDAAAHAAAAAAAAAAQAAAADAwAA9QEAAAgAAAABCQAAZmlsZTovLy8MAAAAAQEAAE1hY2ludG9zaCBIRAgAAAAEAwAAAJCClucAAAAIAAAAAAQAAEHGI+ybgAAAJAAAAAEBAAAwOUI3RUFCRS02Nzk1LTRDREYtQUIyNC0zRkYwODU2NUQwMTYYAAAAAQIAAIEAAAABAAAA7xMAAAEAAAAAAAAAAAAAAAEAAAABAQAALwAAAAAAAAABBQAABQEAAAECAAA2YjI3NGE4ZjE3NjY2OTdiOTRiYzNiMDFjZjBlNzE2OWJjNmRkYWIwZjhiNWVkZTlhNDI0OGI2NWE1MjdlYjVmOzAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwMDAwMDAwMjA7Y29tLmFwcGxlLmFwcC1zYW5kYm94LnJlYWQtd3JpdGU7MDE7MDEwMDAwMTE7MDAwMDAwMDAwMmRkNTgzMzswMTsvdXNlcnMvbWNyb3dsZXkvZHJvcGJveC9hcHBzL3JlbW90ZWx5LXNhdmUvYWl0b3BpY3MvYXNzZXRzL3BkZi9icm93bjIwMjBuZXVyaXBzLnBkZgAAAADMAAAA/v///wEAAAAAAAAAEAAAAAQQAACgAAAAAAAAAAUQAABcAQAAAAAAABAQAACYAQAAAAAAAEAQAACIAQAAAAAAAAIgAABkAgAAAAAAAAUgAADUAQAAAAAAABAgAADkAQAAAAAAABEgAAAYAgAAAAAAABIgAAD4AQAAAAAAABMgAAAIAgAAAAAAACAgAABEAgAAAAAAADAgAABwAgAAAAAAAAHAAAC4AQAAAAAAABHAAAAUAAAAAAAAABLAAADIAQAAAAAAAIDwAAB4AgAAAAAAAAAIAA0AGgAjAEUAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAE1Q==},
	bdsk-url-1 = {https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf}}

@inproceedings{vaswani2017neurips,
	abbr = {Trnsfrmr},
	abstract = {The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms. We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.},
	address = {Long Beach California, USA},
	annote = {The original paper that introduced the Transformers architecture.  The stack of modules of the original transformer are quite similar to multiple subsequent layers of a CNN rather than the CNN filters. <br/><b>Questions</b><br/> <ol> <li> Why do they "stack" the modules in the original transformer?  </li> <li> How does the output of one module feed into the next in the stack?  </li> <li>Is there a notion of "sets" and "subsets" somewhere in this definition? Relations being learned amongst sets of non-local symbols?  </li> <li>Multi-head : where is the multi-part? It's not the QKV parts, it's a set of <em>h</em> copies of the attention module. (this is well hidden) </li> <li>"Pair-of-pairs" we discussed that the <em>h</em> copies of the the attention mechanism are considering pairs-of-pairs of symbol outputs or attention outputs, is it really though? Or are they independent filters as in CNNs?  </li> <li><b>The Big Question:</b> why does it work so well? It's not just "more weights is better", the architecture matters.  </li> </ol>},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
	booktitle = {Advances in Neural Information Processing Systems},
	date-added = {2023-11-17 08:44:49 -0500},
	date-discussed = {2023-05-31 led by Mark Crowley},
	date-modified = {2024-07-26 00:19:48 -0400},
	editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
	hypoth = {https://hyp.is/go?url=https%3A%2F%2Farxiv.org%2Fpdf%2F1706.03762.pdf&group=__world__},
	in-website = {1},
	keywords = {rd-done, machine-learning, transformer, recurrent-neural-networks, lstm,nlp; rdgrp-s23},
	month = {December},
	order = {2},
	pdf = {2017-neurips-vaswani-attention.pdf},
	seminal = {1},
	status = {1},
	temp = {0},
	title = {Attention is All you Need},
	toread = {0},
	url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
	venue-short = {neurips},
	volume = {30},
	year = {2017},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfECFhc3NldHMvcGRmL3Zhc3dhbmkyMDE3bmV1cmlwcy5wZGZPEQSQYm9va5AEAAAAAAQQMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAjAMAAAUAAAABAQAAVXNlcnMAAAAIAAAAAQEAAG1jcm93bGV5BwAAAAEBAABEcm9wYm94AAQAAAABAQAAQXBwcw0AAAABAQAAcmVtb3RlbHktc2F2ZQAAAAgAAAABAQAAQUlUb3BpY3MGAAAAAQEAAGFzc2V0cwAAAwAAAAEBAABwZGYAFgAAAAEBAAB2YXN3YW5pMjAxN25ldXJpcHMucGRmAAAkAAAAAQYAAAQAAAAUAAAAJAAAADQAAABAAAAAWAAAAGgAAAB4AAAAhAAAAAgAAAAEAwAAFV0AAAAAAAAIAAAABAMAADnoAwAAAAAACAAAAAQDAABfdQQAAAAAAAgAAAAEAwAA0Y4EAAAAAAAIAAAABAMAABBRdAIAAAAACAAAAAQDAACeFucCAAAAAAgAAAAEAwAANc/gAgAAAAAIAAAABAMAADbP4AIAAAAACAAAAAQDAAAcWN0CAAAAACQAAAABBgAA0AAAAOAAAADwAAAAAAEAABABAAAgAQAAMAEAAEABAABQAQAACAAAAAAEAABBxVSOvoAAABgAAAABAgAAAQAAAAAAAAAPAAAAAAAAAAAAAAAAAAAACAAAAAQDAAAHAAAAAAAAAAQAAAADAwAA9QEAAAgAAAABCQAAZmlsZTovLy8MAAAAAQEAAE1hY2ludG9zaCBIRAgAAAAEAwAAAJCClucAAAAIAAAAAAQAAEHGI+ybgAAAJAAAAAEBAAAwOUI3RUFCRS02Nzk1LTRDREYtQUIyNC0zRkYwODU2NUQwMTYYAAAAAQIAAIEAAAABAAAA7xMAAAEAAAAAAAAAAAAAAAEAAAABAQAALwAAAAAAAAABBQAABwEAAAECAAAyMTZjMmEzNTliYzk2YzAwZGM3NWMzYmQxYzBlZWE4OWMzZmFkNjA3NDE1NzI2ZDExODYyZTZhMmQwZGU2MGY2OzAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwMDAwMDAwMjA7Y29tLmFwcGxlLmFwcC1zYW5kYm94LnJlYWQtd3JpdGU7MDE7MDEwMDAwMTE7MDAwMDAwMDAwMmRkNTgxYzswMTsvdXNlcnMvbWNyb3dsZXkvZHJvcGJveC9hcHBzL3JlbW90ZWx5LXNhdmUvYWl0b3BpY3MvYXNzZXRzL3BkZi92YXN3YW5pMjAxN25ldXJpcHMucGRmAADMAAAA/v///wEAAAAAAAAAEAAAAAQQAACkAAAAAAAAAAUQAABgAQAAAAAAABAQAACcAQAAAAAAAEAQAACMAQAAAAAAAAIgAABoAgAAAAAAAAUgAADYAQAAAAAAABAgAADoAQAAAAAAABEgAAAcAgAAAAAAABIgAAD8AQAAAAAAABMgAAAMAgAAAAAAACAgAABIAgAAAAAAADAgAAB0AgAAAAAAAAHAAAC8AQAAAAAAABHAAAAUAAAAAAAAABLAAADMAQAAAAAAAIDwAAB8AgAAAAAAAAAIAA0AGgAjAEcAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAE2w==},
	bdsk-url-1 = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf}}

@inproceedings{caccia2019,
	author = {Caccia, Lucas and Hoof, Herke van and Courville, Aaron and Pineau, Joelle},
	booktitle = {2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
	date-added = {2023-11-17 08:43:59 -0500},
	date-modified = {2024-02-20 11:36:59 -0500},
	doi = {10.1109/IROS40897.2019.8968535},
	keywords = {grant-csa-fire-2023; lidar; generative-models},
	pages = {5034-5040},
	title = {Deep Generative Modeling of LiDAR Data},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1109/IROS40897.2019.8968535}}

@inproceedings{corso2019itsc,
	abstract = {Determining possible failure scenarios is a critical step in the evaluation of autonomous vehicle systems. Real-world vehicle testing is commonly employed for autonomous vehicle validation, but the costs and time requirements are high. Consequently, simulation-driven methods such as Adaptive Stress Testing (AST) have been proposed to aid in validation. AST formulates the problem of finding the most likely failure scenarios as a Markov decision process, which can be solved using reinforcement learning. In practice, AST tends to find scenarios where failure is unavoidable and tends to repeatedly discover the same types of failures of a system. This work addresses these issues by encoding domain relevant information into the search procedure. With this modification, the AST method discovers a larger and more expressive subset of the failure space when compared to the original AST formulation. We show that our approach is able to identify useful failure scenarios of an autonomous vehicle policy.},
	annote = {Mentioned during Xiaoliang Zhou's MASc seminar that they have done more recently to learn realism scores from traffic data.},
	arxiv = {1908.01046},
	author = {Corso, Anthony and Du, Peter and Driggs-Campbell, Katherine and Kochenderfer, Mykel J.},
	booktitle = {2019 IEEE Intelligent Transportation Systems Conference (ITSC)},
	date-added = {2023-09-15 12:23:20 -0400},
	date-modified = {2024-03-24 23:20:25 -0400},
	doi = {10.1109/ITSC.2019.8917242},
	hypoth = {https://hyp.is/go?url=https%3A%2F%2Farxiv.org%2Fpdf%2F1908.01046.pdf&group=__world__},
	keywords = {proj-black-box-testing, multi-agent learning, autonomous-driving, toread, xiaoliangzhou, oleksandra},
	pages = {163-168},
	rating = {4},
	title = {Adaptive Stress Testing with Reward Augmentation for Autonomous Vehicle Validatio},
	toread = {1},
	venue-short = {itsc},
	year = {2019},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEBxhc3NldHMvcGRmL2NvcnNvMjAxOWl0c2MucGRmTxEEiGJvb2uIBAAAAAAEEDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIQDAAAFAAAAAQEAAFVzZXJzAAAACAAAAAEBAABtY3Jvd2xleQcAAAABAQAARHJvcGJveAAEAAAAAQEAAEFwcHMNAAAAAQEAAHJlbW90ZWx5LXNhdmUAAAAIAAAAAQEAAEFJVG9waWNzBgAAAAEBAABhc3NldHMAAAMAAAABAQAAcGRmABEAAAABAQAAY29yc28yMDE5aXRzYy5wZGYAAAAkAAAAAQYAAAQAAAAUAAAAJAAAADQAAABAAAAAWAAAAGgAAAB4AAAAhAAAAAgAAAAEAwAAFV0AAAAAAAAIAAAABAMAADnoAwAAAAAACAAAAAQDAABfdQQAAAAAAAgAAAAEAwAA0Y4EAAAAAAAIAAAABAMAABBRdAIAAAAACAAAAAQDAACeFucCAAAAAAgAAAAEAwAANc/gAgAAAAAIAAAABAMAADbP4AIAAAAACAAAAAQDAAD6KdgBAAAAACQAAAABBgAAzAAAANwAAADsAAAA/AAAAAwBAAAcAQAALAEAADwBAABMAQAACAAAAAAEAABBxVpekwzaoxgAAAABAgAAAQAAAAAAAAAPAAAAAAAAAAAAAAAAAAAACAAAAAQDAAAHAAAAAAAAAAQAAAADAwAA9QEAAAgAAAABCQAAZmlsZTovLy8MAAAAAQEAAE1hY2ludG9zaCBIRAgAAAAEAwAAAJCClucAAAAIAAAAAAQAAEHGI+ybgAAAJAAAAAEBAAAwOUI3RUFCRS02Nzk1LTRDREYtQUIyNC0zRkYwODU2NUQwMTYYAAAAAQIAAIEAAAABAAAA7xMAAAEAAAAAAAAAAAAAAAEAAAABAQAALwAAAAAAAAABBQAAAgEAAAECAABmNjQ5NjlmMmJmYTJiZmFjYjgzZjRhM2JjZGRjNDIzYTk1NmIwZTE4MjE3ZThiNWMyMDQ1MTBjNTM1MzUwYjNjOzAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwMDAwMDAwMjA7Y29tLmFwcGxlLmFwcC1zYW5kYm94LnJlYWQtd3JpdGU7MDE7MDEwMDAwMTE7MDAwMDAwMDAwMWQ4MjlmYTswMTsvdXNlcnMvbWNyb3dsZXkvZHJvcGJveC9hcHBzL3JlbW90ZWx5LXNhdmUvYWl0b3BpY3MvYXNzZXRzL3BkZi9jb3JzbzIwMTlpdHNjLnBkZgAAAMwAAAD+////AQAAAAAAAAAQAAAABBAAAKAAAAAAAAAABRAAAFwBAAAAAAAAEBAAAJgBAAAAAAAAQBAAAIgBAAAAAAAAAiAAAGQCAAAAAAAABSAAANQBAAAAAAAAECAAAOQBAAAAAAAAESAAABgCAAAAAAAAEiAAAPgBAAAAAAAAEyAAAAgCAAAAAAAAICAAAEQCAAAAAAAAMCAAAHACAAAAAAAAAcAAALgBAAAAAAAAEcAAABQAAAAAAAAAEsAAAMgBAAAAAAAAgPAAAHgCAAAAAAAAAAgADQAaACMAQgAAAAAAAAIBAAAAAAAAAAUAAAAAAAAAAAAAAAAAAATO},
	bdsk-url-1 = {https://doi.org/10.1109/ITSC.2019.8917242}}

@comment{BibDesk Static Groups{
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<array>
	<dict>
		<key>group name</key>
		<string>RLConf2024</string>
		<key>keys</key>
		<string>abel2016aaaiaies,ayars2016jourcognition,badea2022sgai,christopoulos2017jourbusethics,haas2022dnhni,herlau2022icccr,hadfield-menell2017neurips,peschl2022aamas</string>
	</dict>
</array>
</plist>
}}

@comment{BibDesk Smart Groups{
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<array>
	<dict>
		<key>conditions</key>
		<array>
			<dict>
				<key>comparison</key>
				<integer>2</integer>
				<key>key</key>
				<string>Keywords</string>
				<key>value</key>
				<string>rdgrp-ece750T4-f24</string>
				<key>version</key>
				<string>1</string>
			</dict>
		</array>
		<key>conjunction</key>
		<integer>0</integer>
		<key>group name</key>
		<string>rdgrp-ece750T4-f24</string>
	</dict>
	<dict>
		<key>conditions</key>
		<array>
			<dict>
				<key>comparison</key>
				<integer>2</integer>
				<key>key</key>
				<string>Keywords</string>
				<key>value</key>
				<string>rdgrp-f23</string>
				<key>version</key>
				<string>1</string>
			</dict>
		</array>
		<key>conjunction</key>
		<integer>0</integer>
		<key>group name</key>
		<string>rdgrp-f23</string>
	</dict>
	<dict>
		<key>conditions</key>
		<array>
			<dict>
				<key>comparison</key>
				<integer>2</integer>
				<key>key</key>
				<string>Keywords</string>
				<key>value</key>
				<string>rdgrp-s23</string>
				<key>version</key>
				<string>1</string>
			</dict>
		</array>
		<key>conjunction</key>
		<integer>0</integer>
		<key>group name</key>
		<string>rdgrp-s23</string>
	</dict>
</array>
</plist>
}}

%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Mark at 2024-07-24 15:29:08 -0400 


%% Saved with string encoding Unicode (UTF-8) 



@book{hu2023artofrl,
	author = {Hu, Michael},
	date-added = {2024-07-03 14:12:07 -0400},
	date-modified = {2024-07-24 15:25:50 -0400},
	doi = {https://doi.org/10.1007/978-1-4842-9606-6},
	edition = {1},
	isbn = {978-1-4842-9605-9},
	keywords = {reference; reinforcement-learning, artificial-intellgience, python, machine-learning; rdgrp-ece750T4-f24},
	order = {3},
	publisher = {Apress Berkeley, CA},
	title = {The Art of Reinforcement Learning: Fundamentals, Mathematics, and Implementations with Python},
	url = {https://books.google.ca/books?id=1ijwzwEACAAJ},
	venue-short = {TextBook},
	year = {2023},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEEsuLi8uLi8uLi9Ecm9wYm94L0FwcHMvcmVtb3RlbHktc2F2ZS9hc3NldHMvcGRmLzIwMjMtdGV4dGJvb2staHUtdGhlLWFydC5wZGZPEQRoYm9va2gEAAAAAAQQMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAZAMAAAUAAAABAQAAVXNlcnMAAAAIAAAAAQEAAG1jcm93bGV5BwAAAAEBAABEcm9wYm94AAQAAAABAQAAQXBwcw0AAAABAQAAcmVtb3RlbHktc2F2ZQAAAAYAAAABAQAAYXNzZXRzAAADAAAAAQEAAHBkZgAcAAAAAQEAADIwMjMtdGV4dGJvb2staHUtdGhlLWFydC5wZGYgAAAAAQYAAAQAAAAUAAAAJAAAADQAAABAAAAAWAAAAGgAAAB0AAAACAAAAAQDAAAVXQAAAAAAAAgAAAAEAwAAOegDAAAAAAAIAAAABAMAAF91BAAAAAAACAAAAAQDAADRjgQAAAAAAAgAAAAEAwAAEFF0AgAAAAAIAAAABAMAACh9RgMAAAAACAAAAAQDAAApfUYDAAAAAAgAAAAEAwAAx3ZGAwAAAAAgAAAAAQYAAMAAAADQAAAA4AAAAPAAAAAAAQAAEAEAACABAAAwAQAACAAAAAAEAABBxhrlHlMyXxgAAAABAgAAAQAAAAAAAAAPAAAAAAAAAAAAAAAAAAAACAAAAAQDAAAGAAAAAAAAAAQAAAADAwAA9QEAAAgAAAABCQAAZmlsZTovLy8MAAAAAQEAAE1hY2ludG9zaCBIRAgAAAAEAwAAAJCClucAAAAIAAAAAAQAAEHF8csqAAAAJAAAAAEBAAAwOUI3RUFCRS02Nzk1LTRDREYtQUIyNC0zRkYwODU2NUQwMTYYAAAAAQIAAIEAAAABAAAA7xMAAAEAAAAAAAAAAAAAAAEAAAABAQAALwAAAAAAAAABBQAABAEAAAECAABiMDk0NDAzOTFlYWIzZDc3OTMzYjBhMmQ3NGE2NWJiOTJiMDI0ZWQwMGQ5MjdiOTE4MDU0MGUyMjgxYmZmMDA5OzAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwMDAwMDAwMjA7Y29tLmFwcGxlLmFwcC1zYW5kYm94LnJlYWQtd3JpdGU7MDE7MDEwMDAwMTA7MDAwMDAwMDAwMzQ2NzZjNzswMTsvdXNlcnMvbWNyb3dsZXkvZHJvcGJveC9hcHBzL3JlbW90ZWx5LXNhdmUvYXNzZXRzL3BkZi8yMDIzLXRleHRib29rLWh1LXRoZS1hcnQucGRmAMwAAAD+////AQAAAAAAAAAQAAAABBAAAJgAAAAAAAAABRAAAEABAAAAAAAAEBAAAHgBAAAAAAAAQBAAAGgBAAAAAAAAAiAAAEQCAAAAAAAABSAAALQBAAAAAAAAECAAAMQBAAAAAAAAESAAAPgBAAAAAAAAEiAAANgBAAAAAAAAEyAAAOgBAAAAAAAAICAAACQCAAAAAAAAMCAAAFACAAAAAAAAAcAAAJgBAAAAAAAAEcAAABQAAAAAAAAAEsAAAKgBAAAAAAAAgPAAAFgCAAAAAAAAAAgADQAaACMAcQAAAAAAAAIBAAAAAAAAAAUAAAAAAAAAAAAAAAAAAATd},
	bdsk-url-1 = {https://books.google.ca/books?id=1ijwzwEACAAJ}}

@article{Subramanian2017a,
	abstract = {Machine learning algorithms have increased tremendously in power in recent years but have yet to be fully utilized in many ecology and sustainable resource management domains such as wildlife reserve design, forest fire management and invasive species spread. One thing these domains have in common is that they contain dynamics that can be characterized as a Spatially Spreading Process (SSP) which requires many parameters to be set precisely to model the dynamics, spread rates and directional biases of the elements which are spreading. We present related work in Artificial Intelligence and Machine Learning for SSP sustainability domains including forest wildfire prediction. We then introduce a novel approach for learning in SSP domains using Reinforcement Learning (RL) where fire is the agent at any cell in the landscape and the set of actions the fire can take from a location at any point in time includes spreading North, South, East, West or not spreading. This approach inverts the usual RL setup since the dynamics of the corresponding Markov Decision Process (MDP) is a known function for immediate wildfire spread. Meanwhile, we learn an agent policy for a predictive model of the dynamics of a complex spatially-spreading process. Rewards are provided for correctly classifying which cells are on fire or not compared to satellite and other related data. We examine the behaviour of five RL algorithms on this problem: Value Iteration, Policy Iteration, Q-Learning, Monte Carlo Tree Search and Asynchronous Advantage Actor-Critic (A3C). We compare to a Gaussian process based supervised learning approach and discuss the relation of our approach to manually constructed, state-of-the-art methods from forest wildfire modelling. We also discuss the relation of our approach to manually constructed, state-of-the-art methods from forest wildfire modelling. We validate our approach with satellite image data of two massive wildfire events in Northern Alberta, Canada; the Fort McMurray fire of 2016 and the Richardson fire of 2011. The results show that we can learn predictive, agent-based policies as models of spatial dynamics using RL on readily available satellite images that other methods and have many additional advantages in terms of generalizability and interpretability.},
	author = {{Ganapathi Subramanian}, Sriram and Crowley, Mark},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-07-24 15:08:40 -0400},
	doi = {10.3389/FICT.2018.00006},
	file = {:Users/mcrowley/Dropbox/MendeleyDesktop/fict-05-00006.pdf:pdf},
	issn = {2297-198X},
	journal = {Frontiers in ICT},
	keywords = {A3C,deep learning,forest-management,machine-learning,spatially spreading processes,sustainabtility; forest-management; forest-wildfire; reinforcement-learning},
	pages = {6},
	publisher = {Frontiers},
	title = {{Using Spatial Reinforcement Learning to Build Forest Wildfire Dynamics Models from Satellite Images}},
	url = {https://www.frontiersin.org/articles/10.3389/fict.2018.00006/abstract},
	volume = {5},
	year = {2018},
	bdsk-url-1 = {https://www.frontiersin.org/articles/10.3389/fict.2018.00006/abstract},
	bdsk-url-2 = {https://doi.org/10.3389/FICT.2018.00006}}

@article{Hanes2018,
	abstract = {Contemporary fire regimes of Canadian forests have been well documented based on forest fire records between the late 1950s to 1990s. Due to known limitations of fire datasets, an analysis of changes in fire-regime characteristics could not be easily undertaken. This paper presents fire regime trends nationally and within two zonation systems, the homogeneous fire regime zones and ecozones, for two time periods: 1959-2015 and 1980-2015. Nationally, trends in both area burned and number of large fires (â‰¥ 200 ha) have increased significantly since 1959, which might be due to increases in lightning-caused fires. Human-caused fires, in contrast, have shown a decline. Results suggest that large fires have been getting larger over the last 57 years, and that the fire season has been starting approximately one week earlier and ending one week later. At the regional level, trends in fire regimes are variable across the country, with fewer significant trends. Area burned, number of large fires, and lightning-cause...},
	author = {Hanes, Chelene and Wang, Xianli and Jain, Piyush and Parisien, Marc-Andr{\'{e}} and Little, John and Flannigan, Mike},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-06-27 16:46:20 -0400},
	doi = {10.1139/cjfr-2018-0293},
	file = {:Users/mcrowley/Dropbox/MendeleyDesktop/FireRegimeChange.pdf:pdf},
	issn = {0045-5067},
	journal = {Canadian Journal of Forest Research},
	keywords = {forest-management; forest-wildfire},
	pages = {cjfr--2018--0293},
	title = {{Fire regime changes in Canada over the last half century}},
	url = {http://www.nrcresearchpress.com/doi/10.1139/cjfr-2018-0293},
	year = {2018},
	bdsk-url-1 = {http://www.nrcresearchpress.com/doi/10.1139/cjfr-2018-0293},
	bdsk-url-2 = {https://doi.org/10.1139/cjfr-2018-0293}}

@article{Jain2017,
	abstract = {We have constructed a fire weather climatology over North America from 1979 to 2015 using the North American Regional Reanalysis dataset and the Canadian Fire Weather Index (FWI) System. We tested for the presence of trends in potential fire season length, based on a meteorological definition, and extreme fire weather using the non-parametric Theil--Sen slope estimator and Mann--Kendall test. Applying field significance testing (i.e. joint significance of multiple tests) allowed the identification of the locations of significant trends, taking into account spatial correlations. Fire season length was found to be increasing over large areas of North America, especially in eastern Canada and the south-western US, which is consistent with a later fire season end and an earlier fire season start. Both positive and negative trends in potential fire spread days and the 99th percentile of FWI occurred in Canada and the contiguous United States, although the trends of largest magnitude and statistical significance were mostly positive. In contrast, the proportion of trends with significant decreases in these variables were much lower, indicating an overall increase in extreme fire weather. The smaller proportion of significant positive trends found over Canada reflects the truncation of the time series, necessary because assimilation of precipitation observations over Canada ceased in the reanalysis post-2002.},
	author = {Jain, Piyush and Wang, Xianli and Flannigan, Mike D.},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-06-27 16:46:20 -0400},
	doi = {10.1071/WF17008},
	file = {:Users/mcrowley/Dropbox/MendeleyDesktop/Jain, Wang, Flannigan - 2017 - Trend analysis of fire season length and extreme fire weather in North America between 1979 and 2015.pdf:pdf},
	issn = {1049-8001},
	journal = {International Journal of Wildland Fire},
	keywords = {climate-change,fire-weather,reanalysis,time series.; forest-management; forest-wildfire},
	month = {jan},
	number = {12},
	pages = {1009},
	publisher = {CSIRO PUBLISHING},
	title = {{Trend analysis of fire season length and extreme fire weather in North America between 1979 and 2015}},
	url = {http://www.publish.csiro.au/?paper=WF17008},
	volume = {26},
	year = {2017},
	bdsk-url-1 = {http://www.publish.csiro.au/?paper=WF17008},
	bdsk-url-2 = {https://doi.org/10.1071/WF17008}}

@article{Kirchmeier-Young2017,
	abstract = {{\textcopyright} 2017, The Author(s). Canada is expected to see an increase in fire risk under future climate projections. Large fires, such as that near Fort McMurray, Alberta in 2016, can be devastating to the communities affected. Understanding the role of human emissions in the occurrence of such extreme fire events can lend insight into how these events might change in the future. An event attribution framework is used to quantify the influence of anthropogenic forcings on extreme fire risk in the current climate of a western Canada region. Fourteen metrics from the Canadian Forest Fire Danger Rating System are used to define the extreme fire seasons. For the majority of these metrics and during the current decade, the combined effect of anthropogenic and natural forcing is estimated to have made extreme fire risk events in the region 1.5 to 6 times as likely compared to a climate that would have been with natural forcings alone.},
	author = {Kirchmeier-Young, Megan C. and Zwiers, Francis W. and Gillett, Nathan P. and Cannon, Alex J.},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-06-27 16:46:20 -0400},
	doi = {10.1007/s10584-017-2030-0},
	file = {:Users/mcrowley/Dropbox/MendeleyDesktop/Kirchmeier-Young et al. - 2017 - Attributing extreme fire risk in Western Canada to human emissions.pdf:pdf},
	isbn = {9788362936571},
	issn = {15731480},
	journal = {Climatic Change},
	keywords = {Event attribution,Extremes,fire-weather; forest-management; forest-wildfire},
	month = {sep},
	number = {2},
	pages = {365--379},
	publisher = {Springer Netherlands},
	title = {{Attributing extreme fire risk in Western Canada to human emissions}},
	url = {http://link.springer.com/10.1007/s10584-017-2030-0},
	volume = {144},
	year = {2017},
	bdsk-url-1 = {http://link.springer.com/10.1007/s10584-017-2030-0},
	bdsk-url-2 = {https://doi.org/10.1007/s10584-017-2030-0}}

@article{Lagerquist2017,
	abstract = {Wildfires burn an average of 2 million hectares per year in Canada, most of which can be attributed to only a few days of severe fire weather. These " spread days " are often associated with large-scale weather systems. We used extreme threshold values of three Canadian Fire Weather Index System (CFWIS) variables --- the fine fuel moisture code (FFMC), initial spread index (ISI), and fire weather index (FWI) --- as a proxy for spread days. Then we used self-organizing maps (SOMs) to predict spread days, with sea-level pressure and 500 hPa geopotential height as predictors. SOMs require many input parameters, and we performed an experiment to optimize six key parameters. For each month of the fire season (May--August), we also tested whether SOMs performed better when trained with only one month or with neighbouring months as well. Good performance (AUC of 0.8) was achieved for FFMC and ISI, while nearly good performance was achieved for FWI. To our knowledge, this is the first study to develop a machine-learning model for extreme fire weather that could be deployed in real time. R{\'{e}}sum{\'{e}} : Les feux, dont la plupart peuvent {\^{e}}tre imput{\'{e}}s {\`{a}} seulement quelques jours durant lesquels les conditions m{\'{e}}t{\'{e}}orologiques sont propices aux incendies forestiers s{\'{e}}v{\`{e}}res, d{\'{e}}truisent en moyenne deux millions d'hectares de for{\^{e}}t par ann{\'{e}}e au Canada. Ces jours propices {\`{a}} la propagation des feux sont souvent associ{\'{e}}s {\`{a}} de vastes syst{\`{e}}mes m{\'{e}}t{\'{e}}orologiques. Nous avons utilis{\'{e}} des valeurs seuils extr{\^{e}}mes pour trois variables de la m{\'{e}}thode canadienne de l'indice for{\^{e}}t-m{\'{e}}t{\'{e}}o (MCIFM) : l'indice du combustible l{\'{e}}ger (ICL), l'indice de propagation initiale (IPI) et l'indice for{\^{e}}t-m{\'{e}}t{\'{e}}o (IFM) en tant que substituts pour les jours propices {\`{a}} la propagation des feux. Ensuite, nous avons utilis{\'{e}} des cartes autoorganisables (SOM) pour pr{\'{e}}dire les jours propices {\`{a}} la propagation des feux avec comme pr{\'{e}}dicteurs la pression au niveau de la mer et une hauteur du g{\'{e}}opotentiel de 500 hPa. Les SOM exigent plusieurs param{\`{e}}tres d'entr{\'{e}}e et nous avons effectu{\'{e}} une exp{\'{e}}rience pour optimiser six param{\`{e}}tres cl{\'{e}}s. Pour chaque mois de la saison des feux (mai--ao{\^{u}}t), nous avons aussi test{\'{e}} si les SOM {\'{e}}taient plus performantes lorsqu'elles {\'{e}}taient entra{\^{i}}n{\'{e}}es avec seulement un mois ou en incluant aussi les mois voisins. Une bonne performance (AUC de 0,8) a {\'{e}}t{\'{e}} obtenue pour ICL et IPI, alors qu'une performance satisfaisante a {\'{e}}t{\'{e}} obtenue pour IFM. {\`{A}} notre connaissance, il s'agit de la premi{\`{e}}re {\'{e}}tude qui {\'{e}}labore un mod{\`{e}}le d'apprentissage automatique pour des conditions m{\'{e}}t{\'{e}}orologiques extr{\^{e}}mes propices aux incendies forest-iers qui peut {\^{e}}tre d{\'{e}}ploy{\'{e}} en temps r{\'{e}}el. [Traduit par la R{\'{e}}daction] Mots-cl{\'{e}}s : feux de for{\^{e}}t, danger d'incendie, r{\'{e}}gime des feux, cartes autoorganisables (SOM), conditions m{\'{e}}t{\'{e}}orologiques.},
	author = {Lagerquist, Ryan and Flannigan, Mike D and Wang, Xianli and Marshall, Ginny A},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-06-27 16:46:20 -0400},
	doi = {10.1139/cjfr-2017-0063},
	file = {:Users/mcrowley/Dropbox/MendeleyDesktop/Lagerquist et al. - 2017 - Automated prediction of extreme fire weather from synoptic(2).pdf:pdf},
	issn = {12086037},
	journal = {Canadian Journal of Forest Research},
	keywords = {wildfire-management; forest-management; forest-wildfire},
	number = {August},
	pages = {1175--1183},
	title = {{Automated prediction of extreme fire weather from synoptic}},
	url = {http://www.nrcresearchpress.com/doi/pdf/10.1139/cjfr-2017-0063},
	volume = {1183},
	year = {2017},
	bdsk-url-1 = {http://www.nrcresearchpress.com/doi/pdf/10.1139/cjfr-2017-0063},
	bdsk-url-2 = {https://doi.org/10.1139/cjfr-2017-0063}}

@article{Mann2017,
	abstract = {Influence of Anthropogenic Climate Change on Planetary Wave Resonance and Extreme Weather Events},
	author = {Mann, Michael E. and Rahmstorf, Stefan and Kornhuber, Kai and Steinman, Byron A. and Miller, Sonya K. and Coumou, Dim},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-06-27 16:46:20 -0400},
	doi = {10.1038/srep45242},
	issn = {2045-2322},
	journal = {Scientific Reports},
	keywords = {Atmospheric science,climate-change; forest-management; forest-wildfire},
	month = {dec},
	number = {1},
	pages = {45242},
	publisher = {Nature Publishing Group},
	title = {{Influence of Anthropogenic Climate Change on Planetary Wave Resonance and Extreme Weather Events}},
	url = {http://www.nature.com/articles/srep45242},
	volume = {7},
	year = {2017},
	bdsk-url-1 = {http://www.nature.com/articles/srep45242},
	bdsk-url-2 = {https://doi.org/10.1038/srep45242}}

@inproceedings{Subramanian2018,
	address = {Toronto, Ontario, Canada},
	author = {Subramanian, Sriram Ganapathi and Crowley, Mark},
	booktitle = {Canadian Conference on Artificial Intelligence},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-07-24 15:08:40 -0400},
	file = {:Users/mcrowley/Dropbox/MendeleyDesktop/Subramanian, Crowley - 2018 - Combining MCTS and A3C for Prediction of Spatially Spreading Processes in Forest Wildfire Settings.pdf:pdf;:Users/mcrowley/Dropbox/MendeleyDesktop/Canadian{\_}AI{\_}forestfire{\_}2.pdf:pdf},
	keywords = {a3c,computational-sustainability,forest-wildfire,forest-wildfire,monte-carlo tree search,forest-management; forest-wildfire; reinforcement-learning},
	title = {{Combining MCTS and A3C for Prediction of Spatially Spreading Processes in Forest Wildfire Settings}},
	year = {2018}}

@article{Taleghan2015,
	abstract = {In a simulator-defined MDP, the Markovian dynamics and rewards are provided in the form of a simulator from which samples can be drawn. This paper studies MDP planning algorithms that attempt to minimize the number of simulator calls before terminating and outputting a policy that is approximately optimal with high probability. The paper introduces two heuristics for efficient exploration and an improved confidence interval that enables earlier termination with probabilis- tic guarantees. We prove that the heuristics and the confidence interval are sound and produce with high probability an approximately optimal policy in polynomial time. Experiments on two benchmark problems and two instances of an invasive species management problem show that the improved confidence intervals and the new search heuristics yield reductions of between 8{\%} and 47{\%} in the number of simulator calls required to reach near-optimal policies.},
	author = {Taleghan, Majid Alkaee and Dietterich, Thomas G. and Crowley, Mark and Hall, Kim and Albers, H. Jo},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-07-24 15:08:40 -0400},
	file = {:Users/mcrowley/Dropbox/MendeleyDesktop/Taleghan et al. - 2015 - PAC Optimal MDP Planning with Application to Invasive Species Management.pdf:pdf},
	issn = {15337928},
	journal = {Journal of Machine Learning Research},
	keywords = {Good- Turing estimate,MDP planning,Markov decision processes,computational-sustainability,grant-wici16,invasive species management,machine-learning,mdp planning,optimization,forest-management; forest-wildfire; reinforcement-learning},
	mendeley-tags = {computational sustainability,grant-wici16,machine learning,mdp planning,optimization},
	pages = {3877--3903},
	title = {{PAC Optimal MDP Planning with Application to Invasive Species Management}},
	url = {http://jmlr.org/papers/v16/taleghan15a.html},
	volume = {16},
	year = {2015},
	bdsk-url-1 = {http://jmlr.org/papers/v16/taleghan15a.html}}

@inproceedings{Tsang-AAAI-2013,
	author = {Tsang, Alan and Larson, Kate and Mcalpine, Rob},
	booktitle = {Proceedings of the Twenty-Seventh AAAI Conference on Artificial Intelligence Resource},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-06-27 16:46:20 -0400},
	file = {:Users/mcrowley/Dropbox/MendeleyDesktop/6404-30900-1-PB.pdf:pdf;:Users/mcrowley/Dropbox/MendeleyDesktop/CS-2012-11.pdf:pdf},
	isbn = {9781577356158},
	keywords = {Special Track on Computational Sustainability and; forest-management; forest-wildfire},
	pages = {1355--1361},
	title = {{Resource Sharing for Control of Wildland Fires}},
	url = {http://www.aaai.org/ocs/index.php/AAAI/AAAI13/paper/view/6404},
	year = {2013},
	bdsk-url-1 = {http://www.aaai.org/ocs/index.php/AAAI/AAAI13/paper/view/6404}}

@article{Wang2017,
	author = {Wang, Xianli and Wotton, B. Mike and Cantin, Alan S. and Parisien, Marc-Andr{\'{e}} and Anderson, Kerry and Moore, Brett and Flannigan, Mike D.},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-06-27 16:46:20 -0400},
	doi = {10.1186/s13717-017-0070-z},
	file = {:Users/mcrowley/Dropbox/MendeleyDesktop/Wang et al. - 2017 - cffdrs an R package for the Canadian Forest Fire Danger Rating System.pdf:pdf},
	issn = {2192-1709},
	journal = {Ecological Processes},
	keywords = {forest-management; forest-wildfire},
	month = {dec},
	number = {1},
	pages = {5},
	publisher = {Springer Berlin Heidelberg},
	title = {{cffdrs: an R package for the Canadian Forest Fire Danger Rating System}},
	url = {http://ecologicalprocesses.springeropen.com/articles/10.1186/s13717-017-0070-z},
	volume = {6},
	year = {2017},
	bdsk-url-1 = {http://ecologicalprocesses.springeropen.com/articles/10.1186/s13717-017-0070-z},
	bdsk-url-2 = {https://doi.org/10.1186/s13717-017-0070-z}}

@article{Wang-ERL-2017,
	abstract = {In the face of climate change, predicting and understanding future fire regimes across Canada is a high priority for wildland fire research and management. Due in large part to the difficulties in obtaining future daily fire weather projections, one of the major challenges in predicting future fire activity is to estimate how much of the change in weather potential could translate into on-the-ground fire spread. As a result, past studies have used monthly, annual, or multi-decadal weather projections to predict future fires, thereby sacrificing information relevant to day-to-day fire spread. Using climate projections from the fifth phase of the Coupled Model Intercomparison Project (CMIP5), historical weather observations, MODIS fire detection data, and the national fire database of Canada, this study investigated potential changes in the number of active burning days of wildfires by relating `spread days' to patterns of daily fire-conducive weather. Results suggest that climate change over the next century may have significant impacts on fire spread days in almost all parts of Canada's forested landmass; the number of fire spread days could experience a 2-to-3-fold increase under a high CO 2 forcing scenario in eastern Canada, and a greater than 50{\%} increase in western Canada, where the fire potential is already high. The change in future fire spread is critical in understanding fire regime changes, but is also imminently relevant to fire management operations and in fire risk mitigation.},
	author = {Wang, Xianli and Parisien, Marc Andr{\'{e}} and Taylor, Steve W. and Candau, Jean No{\"{e}}l and Stralberg, Diana and Marshall, Ginny A. and Little, John M. and Flannigan, Mike D.},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-06-27 16:46:20 -0400},
	doi = {10.1088/1748-9326/aa5835},
	file = {:Users/mcrowley/Dropbox/MendeleyDesktop/FireRegimeChange(2).pdf:pdf},
	issn = {17489326},
	journal = {Environmental Research Letters},
	keywords = {Canadian forests,climate-change,fire-weather,wildfire-spread-day; forest-management; forest-wildfire},
	month = {feb},
	number = {2},
	pages = {025005},
	pmid = {23110131},
	title = {{Projected changes in daily fire spread across Canada over the next century}},
	url = {http://stacks.iop.org/1748-9326/12/i=2/a=025005?key=crossref.8043842fba0f06f383dbb079aeb2f59d},
	volume = {12},
	year = {2017},
	bdsk-url-1 = {http://stacks.iop.org/1748-9326/12/i=2/a=025005?key=crossref.8043842fba0f06f383dbb079aeb2f59d},
	bdsk-url-2 = {https://doi.org/10.1088/1748-9326/aa5835}}

@inproceedings{ronneberger2015miccai,
	author = {O. Ronneberger and P.Fischer and T. Brox},
	booktitle = {Medical Image Computing and Computer-Assisted Intervention (MICCAI)},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-06-27 16:46:20 -0400},
	keywords = {forest-management; forest-wildfire; fund-waii-nexus-seed-2024-wildfire},
	note = {(available on arXiv:1505.04597 [cs.CV])},
	pages = {234--241},
	publisher = {Springer},
	series = {LNCS},
	title = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
	url = {http://lmb.informatik.uni-freiburg.de/Publications/2015/RFB15a},
	venue-short = {miccai},
	volume = {9351},
	year = {2015},
	bdsk-url-1 = {http://lmb.informatik.uni-freiburg.de/Publications/2015/RFB15a}}

@article{parks2019ecosphere,
	abstract = {Abstract Forests are an incredibly important resource across the globe, yet they are threatened by climate change through stressors such as drought, insect outbreaks, and wildfire. Trailing edge forests---those areas expected to experience range contractions under a changing climate---are of particular concern because of the potential for abrupt conversion to non-forest. However, due to plant-climate disequilibrium, broad-scale forest die-off and range contraction in trailing edge forests are unlikely to occur over short timeframes (<~25--50 yr) without a disturbance catalyst (e.g., wildfire). This underscores that explicit attention to both climate and disturbance is necessary to understand how the distribution of forests will respond to climate change. As such, we first identify the expected location of trailing edge forests in the intermountain western United States by mid-21st century. We then identify those trailing edge forests that have a high probability of stand-replacing fire and consider such sites to have an elevated risk of fire-facilitated transition to non-forest. Results show that 18\% of trailing edge forest and 6.6\% of all forest are at elevated risk of fire-facilitated conversion to non-forest in the intermountain western United States by mid-21st century. This estimate, however, assumes that fire burns under average weather conditions. For a subset of the study area (the southwestern United States), we were able to incorporate expected fire severity under extreme weather conditions. For this spatial subset, we found that 61\% of trailing edge forest and 30\% of all forest are at elevated risk of fire-facilitated conversion to non-forest under extreme burning conditions. However, due to compounding error in our process that results in unknowable uncertainty, we urge caution in a strict interpretation of these estimates. Nevertheless, our findings suggest the potential for transformed landscapes in the intermountain western United States that will affect ecosystem services such as watershed integrity, wildlife habitat, wood production, and recreation.},
	author = {Parks, Sean A. and Dobrowski, Solomon Z. and Shaw, John D. and Miller, Carol},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-06-27 16:46:20 -0400},
	doi = {https://doi.org/10.1002/ecs2.2651},
	eprint = {https://esajournals.onlinelibrary.wiley.com/doi/pdf/10.1002/ecs2.2651},
	journal = {Ecosphere},
	keywords = {climate analog model, climate-change, climatic debt, disequilibrium, disturbance, trailing edge forest, type conversion, forest-wildfire, wildland fire; forest-management; forest-wildfire; fund-waii-nexus-seed-2024-wildfire},
	number = {3},
	pages = {e02651},
	title = {Living on the edge: trailing edge forests at risk of fire-facilitated conversion to non-forest},
	url = {https://esajournals.onlinelibrary.wiley.com/doi/abs/10.1002/ecs2.2651},
	venue-short = {ecosphere},
	volume = {10},
	year = {2019},
	bdsk-url-1 = {https://esajournals.onlinelibrary.wiley.com/doi/abs/10.1002/ecs2.2651},
	bdsk-url-2 = {https://doi.org/10.1002/ecs2.2651}}

@webpage{flannigan2020canadawildfire,
	author = {Flannigan, Mike and others},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-06-27 16:46:20 -0400},
	doi = {https://www.canadawildfire.org/nsercnetwork},
	institution = {{Canada Wildfire}},
	keywords = {canadawildfire, forest-wildfire, forest-wildfire; forest-management; forest-wildfire; fund-waii-nexus-seed-2024-wildfire},
	title = {{Canada Wildfire NSERC Strategic Network}},
	url = {https://www.canadawildfire.org/nsercnetwork},
	venue-short = {canadawildfire},
	year = {2020 (https://www.canadawildfire.org/nsercnetwork)},
	bdsk-url-1 = {https://www.canadawildfire.org/nsercnetwork}}

@article{wang2023scitotenviro,
	abstract = {A spread day is defined as a day in which fires grow a substantial amount of area; such days usually occur during high or extreme fire weather conditions. The identification and prediction of a spread day based on fire weather conditions could help both our understanding of fire regimes as well as forecasting and managing fires operationally. This study explores the relationships between fire weather and spread days in the forested areas of Canada by spatially and temporally matching a daily fire growth database to a daily gridded fire weather database that spans from 2001 to 2019. By examining the correlations between spread day fire weather conditions and location, conifer coverage (%), and elevation, we found that a spread day happens under less severe fire weather conditions as latitude increases for the entire study area and as conifer coverage increases within non-mountainous study areas. In the western mountain areas, however, with increasing conifer coverage more severe fire weather conditions are required for a spread day to occur. Using two modeling approaches, we were able to identify spread day indicators (generalized additive model) and to predict the occurrence of spread days (semi-binomial regression model) by Canadian Ecozones both annually and seasonally. Overall, Fine Fuel Moisture Code (FFMC), Initial Spread Index (ISI), and Fire Weather Index (FWI) performed the best in all models built for spread day identification and prediction but varied depending on the conditions mentioned above. FFMC was the most consistent across all spatial and temporal scales.},
	author = {Xianli Wang and Jacqueline Oliver and Tom Swystun and Chelene C. Hanes and Sandy Erni and Mike D. Flannigan},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-06-27 16:46:20 -0400},
	doi = {https://doi.org/10.1016/j.scitotenv.2023.161831},
	issn = {0048-9697},
	journal = {Science of The Total Environment},
	keywords = {fire-weather, wildfire-spread-day, Thresholds, Area burned, Canada; forest-management; forest-wildfire; fund-waii-nexus-seed-2024-wildfire},
	pages = {161831},
	title = {Critical fire weather conditions during active fire spread days in Canada},
	url = {https://www.sciencedirect.com/science/article/pii/S0048969723004461},
	venue-short = {scitotenviro},
	volume = {869},
	year = {2023},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0048969723004461},
	bdsk-url-2 = {https://doi.org/10.1016/j.scitotenv.2023.161831}}

@article{gincheva2024scidata,
	author = {Gincheva, Andrina and Pausas, Juli G and Edwards, Andrew and Provenzale, Antonello and Cerd{\`a}, Artemi and Hanes, Chelene and Roy{\'e}, Dominic and Chuvieco, Emilio and Mouillot, Florent and Vissio, Gabriele and others},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-06-27 16:46:20 -0400},
	journal = {Scientific data},
	keywords = {forest-management; forest-wildfire; fund-waii-nexus-seed-2024-wildfire},
	number = {1},
	pages = {352},
	publisher = {Nature Publishing Group UK London},
	title = {A monthly gridded burned area database of national wildland fire data},
	venue-short = {scidata},
	volume = {11},
	year = {2024}}

@techreport{tymstra2010nrcan,
	address = {Edmonton, Alberta},
	author = {Tymstra, C.; Bryce, R.W.; Wotton, B.M.; Taylor, S.W.; Armitage, O.B.},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-06-27 16:46:20 -0400},
	institution = {Natural Resources Canada, Canadian Forest Service, Northern Forestry Centre},
	keywords = {prometheus, forest-wildfire, simulation; forest-management; forest-wildfire; fund-waii-nexus-seed-2024-wildfire},
	number = {Information Report NOR-X-417.},
	pages = {102},
	title = {Development and structure of Prometheus: the Canadian Wildland Fire Growth Simulation Model.},
	venue-short = {nrcan},
	year = {2010}}

@article{zheng2017forest,
	author = {Zheng, Zhong and Huang, Wei and Li, Songnian and Zeng, Yongnian},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-06-27 16:46:20 -0400},
	journal = {Ecological Modelling},
	keywords = {forest-management; forest-wildfire; fund-waii-nexus-seed-2024-wildfire},
	pages = {33--43},
	publisher = {Elsevier},
	title = {Forest fire spread simulating model using cellular automaton with extreme learning machine},
	volume = {348},
	year = {2017}}

@article{crowley2014ieeetoc,
	abstract = {Spatiotemporal planning involves making choices at multiple locations in space over some planning horizon to maximize utility and satisfy various constraints. In Forest Ecosystem Management, the problem is to choose actions for thousands of locations each year including harvesting, treating trees for fire or pests, or doing nothing. The utility models could place value on sale of lumber, ecosystem sustainability or employment levels and incorporate legal and logistical constraints on actions such as avoiding large contiguous areas of clearcutting. Simulators developed by forestry researchers provide detailed dynamics but are generally inaccesible black boxes. We model spatiotemporal planning as a factored Markov decision process and present a policy gradient planning algorithm to optimize a stochastic spatial policy using simulated dynamics. It is common in environmental and resource planning to have actions at different locations be spatially interelated, this makes representation and planning challenging. We define a global spatial policy in terms of interacting local policies defining distributions over actions at each location conditioned on actions at nearby locations. Markov chain Monte Carlo simulation is used to sample landscape policies and estimate their gradients. Evaluation is carried out on a forestry planning problem with 1,880 locations using a variety of value models and constraints. Index},
	author = {Crowley, Mark},
	citations = {7},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-06-27 16:46:20 -0400},
	doi = {10.1109/TC.2013.113},
	file = {:Users/mcrowley/Dropbox/MendeleyDesktop/Crowley - 2014 - Using equilibrium policy gradients for spatiotemporal planning in forest ecosystem management(2).pdf:pdf},
	in-cv = {1},
	issn = {00189340},
	journal = {IEEE Transactions on Computers},
	keywords = {computational-sustainability,Ecosystem management,forest-management,machine-learning,mdp,Optimization,policy-gradient,Reinforcement-Learning,grant-wici16,proj-spatiallyspreadingprocess,spatiotemporal-planning, showcase; forest-wildfire; fund-waii-nexus-seed-2024-wildfire},
	mendeley-tags = {grant-wici16,proj-spatiallyspreadingprocess,spatiotemporal planning},
	number = {1},
	pages = {142--154},
	publisher = {IEEE computer Society Digital Library. IEEE Computer Society.},
	self = {1},
	self-citations = {2},
	seminal = {0},
	status = {1},
	tempflag = {0},
	title = {{Using equilibrium policy gradients for spatiotemporal planning in forest ecosystem management}},
	url = {http://www.computer.org/csdl/trans/tc/preprint/06514032-abs.html},
	venue-short = {IEEEToC},
	volume = {63},
	year = {2014},
	bdsk-url-1 = {http://www.computer.org/csdl/trans/tc/preprint/06514032-abs.html},
	bdsk-url-2 = {https://doi.org/10.1109/TC.2013.113}}

@inproceedings{Crowley2009,
	abstract = {We introduce a challenging real world planning problem where actions must be taken at each location in a spatial area at each point in time. We use forestry planning as the motivating application. In Large Scale Spatial-Temporal (LSST) planning problems, the state and action spaces are defined as the cross-products of many local state and action spaces spread over a large spatial area such as a city or forest. These problems possess state uncertainty, have complex utility functions involving spatial constraints and we generally must rely on simulations rather than an explicit transition model. We define LSST problems as reinforcement learning prob- lems and present a solution using policy gradients. We compare two different policy formulations: an explicit policy that identifies each location in space and the action to take there, and an abstract policy that defines the proportion of actions to take across all locations in space. We show that the abstract policy is more robust and achieves higher rewards with far fewer parameters than the elementary policy. This abstract policy is also a better fit to the properties that practitioners in LSST problem domains require for such methods to be widely useful},
	address = {Montreal, Canada},
	author = {Crowley, Mark and Nelson, John and Poole, David},
	booktitle = {Conference on Uncertainty in Artificial Intelligence (UAI09)},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-06-27 16:46:20 -0400},
	file = {:Users/mcrowley/Dropbox/MendeleyDesktop/Crowley, Nelson, Poole - 2009 - Seeing the Forest Despite the Trees Large Scale Spatial-Temporal Decision Making.pdf:pdf},
	in-cv = {1},
	keywords = {mdp,computational-sustainability,forest-management,probabilistic-inference,planning,spatiotemporal-planning; showcase; forest-wildfire; fund-waii-nexus-seed-2024-wildfire},
	pages = {126--134},
	self = {1},
	status = {1},
	tempflag = {0},
	title = {{Seeing the Forest Despite the Trees : Large Scale Spatial-Temporal Decision Making}},
	url = {http://www.cs.ubc.ca/{~}crowley/papers/uai09-mark-crowley.pdf},
	venue-short = {UAI},
	year = {2009},
	bdsk-url-1 = {http://www.cs.ubc.ca/%7B~%7Dcrowley/papers/uai09-mark-crowley.pdf}}

@inproceedings{ganapathisubramanian2021aamas,
	abbr = {PO-MFRL},
	abstract = {Traditional multi-agent reinforcement learning algorithms are not scalable to environments with more than a few agents, since these algorithms are exponential in the number of agents. Recent research has introduced successful methods to scale multi-agent reinforcement learning algorithms to many agent scenarios using mean field theory. Previous work in this field assumes that an agent has access to exact cumulative metrics regarding the mean field behaviour of the system, which it can then use to take its actions. In this paper, we relax this assumption and maintain a distribution to model the uncertainty regarding the mean field of the system. We consider two different settings for this problem. In the first setting, only agents in a fixed neighbourhood are visible, while in the second setting, the visibility of agents is determined at random based on distances. For each of these settings, we introduce a Q-learning based algorithm that can learn effectively. We prove that this Q-learning estimate stays very close to the Nash Q-value (under a common set of assumptions) for the first setting. We also empirically show our algorithms outperform multiple baselines in three different games in the MAgents framework, which supports large environments with many agents learning simultaneously to achieve possibly distinct goals.},
	address = {London, United Kingdom},
	arxiv = {2012.15791},
	author = {Ganapathi Subramanian, Sriram and Taylor, Matthew and Crowley, Mark and Poupart, Pascal},
	booktitle = {Proceedings of the 20th International Conference on Autonomous Agents and MultiAgent Systems (AAMAS)},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-06-27 16:46:20 -0400},
	editor = {U. Endriss, A. Now{\'e}, F. Dignu and A. Lomuscio},
	in-cv = {1},
	isbn = {9781450383073},
	keywords = {game-theory, multi-agent-reinforcement-learning, reinforcement-learning, mean-field-theory, incomplete-information, partially-observable-problems, showcase; year-in-review-2021; forest-wildfire; forest-management; fund-waii-nexus-seed-2024-wildfire},
	location = {Virtual Event, United Kingdom},
	month = {May},
	numpages = {9},
	pages = {537-545},
	pdf = {2021-aamas-ganapathi subramanian-partially.pdf},
	publicationstatus = {published},
	publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
	self = {1},
	series = {AAMAS '21},
	status = {1},
	tempflag = {0},
	title = {Partially Observable Mean Field Reinforcement Learning},
	venue-short = {AAMAS},
	year = {2021},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEDwuLi9hc3NldHMvcGRmLzIwMjEtYWFtYXMtZ2FuYXBhdGhpIHN1YnJhbWFuaWFuLXBhcnRpYWxseS5wZGZPEQRkYm9va2QEAAAAAAQQMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYAMAAAUAAAABAQAAVXNlcnMAAAAIAAAAAQEAAG1jcm93bGV5BQAAAAEBAAByZXBvcwAAAA4AAAABAQAAbWFya2Nyb3dsZXktY2EAAAYAAAABAQAAYXNzZXRzAAADAAAAAQEAAHBkZgAuAAAAAQEAADIwMjEtYWFtYXMtZ2FuYXBhdGhpIHN1YnJhbWFuaWFuLXBhcnRpYWxseS5wZGYAABwAAAABBgAABAAAABQAAAAkAAAANAAAAEwAAABcAAAAaAAAAAgAAAAEAwAAFV0AAAAAAAAIAAAABAMAADnoAwAAAAAACAAAAAQDAABokgoAAAAAAAgAAAAEAwAAh9YQAAAAAAAIAAAABAMAADF1XAMAAAAACAAAAAQDAACidVwDAAAAAAgAAAAEAwAAt3VcAwAAAAAcAAAAAQYAAMQAAADUAAAA5AAAAPQAAAAEAQAAFAEAACQBAAAIAAAAAAQAAEHDfHhyAAAAGAAAAAECAAABAAAAAAAAAA8AAAAAAAAAAAAAAAAAAAAIAAAABAMAAAUAAAAAAAAABAAAAAMDAAD1AQAACAAAAAEJAABmaWxlOi8vLwwAAAABAQAATWFjaW50b3NoIEhECAAAAAQDAAAAkIKW5wAAAAgAAAAABAAAQcXxyyoAAAAkAAAAAQEAADA5QjdFQUJFLTY3OTUtNENERi1BQjI0LTNGRjA4NTY1RDAxNhgAAAABAgAAgQAAAAEAAADvEwAAAQAAAAAAAAAAAAAAAQAAAAEBAAAvAAAAAAAAAAEFAAAQAQAAAQIAADI5ZDNmMmViOWVlYzZlYmJlNGM0NDk2ZDJkN2Q5YjI4ZDQ5ZjhjZWM5OGYyZjIzNGYwZWUwNGE1NWNkZWZjMDc7MDA7MDAwMDAwMDA7MDAwMDAwMDA7MDAwMDAwMDA7MDAwMDAwMDAwMDAwMDAyMDtjb20uYXBwbGUuYXBwLXNhbmRib3gucmVhZC13cml0ZTswMTswMTAwMDAxMDswMDAwMDAwMDAzNWM3NWI3OzAxOy91c2Vycy9tY3Jvd2xleS9yZXBvcy9tYXJrY3Jvd2xleS1jYS9hc3NldHMvcGRmLzIwMjEtYWFtYXMtZ2FuYXBhdGhpIHN1YnJhbWFuaWFuLXBhcnRpYWxseS5wZGYAzAAAAP7///8BAAAAAAAAABAAAAAEEAAAoAAAAAAAAAAFEAAANAEAAAAAAAAQEAAAaAEAAAAAAABAEAAAWAEAAAAAAAACIAAANAIAAAAAAAAFIAAApAEAAAAAAAAQIAAAtAEAAAAAAAARIAAA6AEAAAAAAAASIAAAyAEAAAAAAAATIAAA2AEAAAAAAAAgIAAAFAIAAAAAAAAwIAAAQAIAAAAAAAABwAAAiAEAAAAAAAARwAAAFAAAAAAAAAASwAAAmAEAAAAAAACA8AAASAIAAAAAAAAACAANABoAIwBiAAAAAAAAAgEAAAAAAAAABQAAAAAAAAAAAAAAAAAABMo=}}

@article{houtman2013ijwf,
	abstract = {Where a legacy of aggressive wildland fire suppression has left forests in need of fuel reduction, allowing wildland fire to burn may provide fuel treatment benefits, thereby reducing suppression costs from subsequent fires. The least-cost-plus-net-value-change model of wildland fire economics includes benefits of wildfire in a framework for evaluating suppression options. In this study, we estimated one component of that benefit -- the expected present value of the reduction in suppression costs for subsequent fires arising from the fuel treatment effect of a current fire. To that end, we employed Monte Carlo methods to generate a set of scenarios for subsequent fire ignition and weather events, which are referred to as sample paths, for a study area in central Oregon. We simulated fire on the landscape over a 100-year time horizon using existing models of fire behaviour, vegetation and fuels development, and suppression effectiveness, and we estimated suppression costs using an existing suppression cost model. Our estimates suggest that the potential cost savings may be substantial. Further research is needed to estimate the full least-cost-plus-net-value-change model. This line of research will extend the set of tools available for developing wildfire management plans for forested landscapes.},
	annote = {NULL},
	author = {Houtman, Rachel M. and Montgomery, Claire A. and Gagnon, Aaron R. and Calkin, David E. and Dietterich, Thomas G. and McGregor, Sean and Crowley, Mark},
	citations = {108},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-06-27 16:48:05 -0400},
	doi = {10.1071/WF12157},
	file = {:Users/mcrowley/Dropbox/MendeleyDesktop/Houtman et al. - 2013 - Allowing a wildfire to burn Estimating the effect on future fire suppression costs(2).pdf:pdf},
	in-cv = {1},
	in-website = {0},
	issn = {10498001},
	journal = {International Journal of Wildland Fire},
	keywords = {bio-economic modelling,forest-wildfire,forest-wildfire,grant-wici16,proj-spatiallyspreadingprocess,spatial simulation,forest-wildfire, showcase; forest-management; fund-waii-nexus-seed-2024-wildfire},
	mendeley-tags = {grant-wici16,proj-spatiallyspreadingprocess,spatial simulation},
	number = {7},
	pages = {871--882},
	pdf = {2013-ijwf-houtman-allowing.pdf},
	rating = {5},
	self = {1},
	self-citations = {3},
	seminal = {1},
	status = {1},
	tempflag = {0},
	title = {Allowing a wildfire to burn: Estimating the effect on future fire suppression costs},
	url = {https://www.publish.csiro.au/wf/WF12157},
	venue-short = {IJWF},
	volume = {22},
	year = {2013},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfECwuLi9hc3NldHMvcGRmLzIwMTMtaWp3Zi1ob3V0bWFuLWFsbG93aW5nLnBkZk8RBERib29rRAQAAAAABBAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAAwAABQAAAAEBAABVc2VycwAAAAgAAAABAQAAbWNyb3dsZXkFAAAAAQEAAHJlcG9zAAAADgAAAAEBAABtYXJrY3Jvd2xleS1jYQAABgAAAAEBAABhc3NldHMAAAMAAAABAQAAcGRmAB4AAAABAQAAMjAxMy1pandmLWhvdXRtYW4tYWxsb3dpbmcucGRmAAAcAAAAAQYAAAQAAAAUAAAAJAAAADQAAABMAAAAXAAAAGgAAAAIAAAABAMAABVdAAAAAAAACAAAAAQDAAA56AMAAAAAAAgAAAAEAwAAaJIKAAAAAAAIAAAABAMAAIfWEAAAAAAACAAAAAQDAAAxdVwDAAAAAAgAAAAEAwAAonVcAwAAAAAIAAAABAMAAKV1XAMAAAAAHAAAAAEGAAC0AAAAxAAAANQAAADkAAAA9AAAAAQBAAAUAQAACAAAAAAEAABBw4yVbYAAABgAAAABAgAAAQAAAAAAAAAPAAAAAAAAAAAAAAAAAAAACAAAAAQDAAAFAAAAAAAAAAQAAAADAwAA9QEAAAgAAAABCQAAZmlsZTovLy8MAAAAAQEAAE1hY2ludG9zaCBIRAgAAAAEAwAAAJCClucAAAAIAAAAAAQAAEHF8csqAAAAJAAAAAEBAAAwOUI3RUFCRS02Nzk1LTRDREYtQUIyNC0zRkYwODU2NUQwMTYYAAAAAQIAAIEAAAABAAAA7xMAAAEAAAAAAAAAAAAAAAEAAAABAQAALwAAAAAAAAABBQAAAAEAAAECAABiYTk5ZDE4MDQ0MWM1OWI4NDZkMGU2M2U2YmM3YTJjMzA5NDY5NmY2ZGViMzIzOWNiYzAzOTE5ZmMxNzRjN2RhOzAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwMDAwMDAwMjA7Y29tLmFwcGxlLmFwcC1zYW5kYm94LnJlYWQtd3JpdGU7MDE7MDEwMDAwMTA7MDAwMDAwMDAwMzVjNzVhNTswMTsvdXNlcnMvbWNyb3dsZXkvcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi8yMDEzLWlqd2YtaG91dG1hbi1hbGxvd2luZy5wZGYAzAAAAP7///8BAAAAAAAAABAAAAAEEAAAkAAAAAAAAAAFEAAAJAEAAAAAAAAQEAAAWAEAAAAAAABAEAAASAEAAAAAAAACIAAAJAIAAAAAAAAFIAAAlAEAAAAAAAAQIAAApAEAAAAAAAARIAAA2AEAAAAAAAASIAAAuAEAAAAAAAATIAAAyAEAAAAAAAAgIAAABAIAAAAAAAAwIAAAMAIAAAAAAAABwAAAeAEAAAAAAAARwAAAFAAAAAAAAAASwAAAiAEAAAAAAACA8AAAOAIAAAAAAAAACAANABoAIwBSAAAAAAAAAgEAAAAAAAAABQAAAAAAAAAAAAAAAAAABJo=},
	bdsk-url-1 = {https://doi.org/10.1071/WF12157}}

@inproceedings{subramanian2018neurips-ai4sg,
	address = {NeurIPS},
	author = {Subramanian, Sriram Ganapathi and Crowley, Mark},
	booktitle = {Neural Information Processing Systems (AI for social good workshop)},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-06-27 16:46:20 -0400},
	in-cv = {1},
	keywords = {reinforcement-learning; machine-learning; mcts; forest-wildfire; forest-management; computational-sustainability; fund-waii-nexus-seed-2024-wildfire},
	pdf = {2018-neurips-ai-subramanian-a complementary.pdf},
	self = {1},
	status = {1},
	tempflag = {0},
	title = {A Complementary Approach to Improve WildFire Prediction Systems.},
	url = {https://aiforsocialgood.github.io/2018/acceptedpapers.htm},
	venue-short = {neurips-ai4sg},
	year = {2018},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfED0uLi9hc3NldHMvcGRmLzIwMTgtbmV1cmlwcy1haS1zdWJyYW1hbmlhbi1hIGNvbXBsZW1lbnRhcnkucGRmTxEEaGJvb2toBAAAAAAEEDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGQDAAAFAAAAAQEAAFVzZXJzAAAACAAAAAEBAABtY3Jvd2xleQUAAAABAQAAcmVwb3MAAAAOAAAAAQEAAG1hcmtjcm93bGV5LWNhAAAGAAAAAQEAAGFzc2V0cwAAAwAAAAEBAABwZGYALwAAAAEBAAAyMDE4LW5ldXJpcHMtYWktc3VicmFtYW5pYW4tYSBjb21wbGVtZW50YXJ5LnBkZgAcAAAAAQYAAAQAAAAUAAAAJAAAADQAAABMAAAAXAAAAGgAAAAIAAAABAMAABVdAAAAAAAACAAAAAQDAAA56AMAAAAAAAgAAAAEAwAAaJIKAAAAAAAIAAAABAMAAIfWEAAAAAAACAAAAAQDAAAxdVwDAAAAAAgAAAAEAwAAonVcAwAAAAAIAAAABAMAAKp1XAMAAAAAHAAAAAEGAADEAAAA1AAAAOQAAAD0AAAABAEAABQBAAAkAQAACAAAAAAEAABBw6yoU4AAABgAAAABAgAAAQAAAAAAAAAPAAAAAAAAAAAAAAAAAAAACAAAAAQDAAAFAAAAAAAAAAQAAAADAwAA9QEAAAgAAAABCQAAZmlsZTovLy8MAAAAAQEAAE1hY2ludG9zaCBIRAgAAAAEAwAAAJCClucAAAAIAAAAAAQAAEHF8csqAAAAJAAAAAEBAAAwOUI3RUFCRS02Nzk1LTRDREYtQUIyNC0zRkYwODU2NUQwMTYYAAAAAQIAAIEAAAABAAAA7xMAAAEAAAAAAAAAAAAAAAEAAAABAQAALwAAAAAAAAABBQAAEQEAAAECAAA5MzI4ZDQ0ZTNlZWJiNjA4N2VhY2E5MDRhNzM0Njc5NmYzMzMzYWQ0NjQ5OTVkYTFiZDU2MjJlYWJhMjE4ZWY5OzAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwMDAwMDAwMjA7Y29tLmFwcGxlLmFwcC1zYW5kYm94LnJlYWQtd3JpdGU7MDE7MDEwMDAwMTA7MDAwMDAwMDAwMzVjNzVhYTswMTsvdXNlcnMvbWNyb3dsZXkvcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi8yMDE4LW5ldXJpcHMtYWktc3VicmFtYW5pYW4tYSBjb21wbGVtZW50YXJ5LnBkZgAAAADMAAAA/v///wEAAAAAAAAAEAAAAAQQAACgAAAAAAAAAAUQAAA0AQAAAAAAABAQAABoAQAAAAAAAEAQAABYAQAAAAAAAAIgAAA0AgAAAAAAAAUgAACkAQAAAAAAABAgAAC0AQAAAAAAABEgAADoAQAAAAAAABIgAADIAQAAAAAAABMgAADYAQAAAAAAACAgAAAUAgAAAAAAADAgAABAAgAAAAAAAAHAAACIAQAAAAAAABHAAAAUAAAAAAAAABLAAACYAQAAAAAAAIDwAABIAgAAAAAAAAAIAA0AGgAjAGMAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAEzw==},
	bdsk-url-1 = {https://aiforsocialgood.github.io/2018/acceptedpapers.htm}}

@inproceedings{subramanian2017rldm,
	address = {Ann Arbor, MI, USA.},
	author = {Subramanian, Sriram Ganapathi and Crowley, Mark},
	booktitle = {Conference on Reinforcement Learning and Decision Making},
	citations = {15},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-06-27 16:46:20 -0400},
	in-cv = {1},
	keywords = {A2C, reinforcement-learning, forest-wildfire, showcase; forest-management; image-processing; fund-waii-nexus-seed-2024-wildfire},
	note = {1},
	pages = {244-248},
	self = {1},
	self-citations = {5},
	status = {1},
	tempflag = {0},
	title = {{Learning Forest Wildfire Dynamics from Satellite Images Using Reinforcement Learning}},
	venue-short = {RLDM},
	year = {2017},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEDAuLi9hc3NldHMvcGRmLzIwMTctcmxkbS1zdWJyYW1hbmlhbi1sZWFybmluZy5wZGZPEQRMYm9va0wEAAAAAAQQMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAASAMAAAUAAAABAQAAVXNlcnMAAAAIAAAAAQEAAG1jcm93bGV5BQAAAAEBAAByZXBvcwAAAA4AAAABAQAAbWFya2Nyb3dsZXktY2EAAAYAAAABAQAAYXNzZXRzAAADAAAAAQEAAHBkZgAiAAAAAQEAADIwMTctcmxkbS1zdWJyYW1hbmlhbi1sZWFybmluZy5wZGYAABwAAAABBgAABAAAABQAAAAkAAAANAAAAEwAAABcAAAAaAAAAAgAAAAEAwAAFV0AAAAAAAAIAAAABAMAADnoAwAAAAAACAAAAAQDAABokgoAAAAAAAgAAAAEAwAAh9YQAAAAAAAIAAAABAMAADF1XAMAAAAACAAAAAQDAACidVwDAAAAAAgAAAAEAwAAp3VcAwAAAAAcAAAAAQYAALgAAADIAAAA2AAAAOgAAAD4AAAACAEAABgBAAAIAAAAAAQAAEHDfHhxgAAAGAAAAAECAAABAAAAAAAAAA8AAAAAAAAAAAAAAAAAAAAIAAAABAMAAAUAAAAAAAAABAAAAAMDAAD1AQAACAAAAAEJAABmaWxlOi8vLwwAAAABAQAATWFjaW50b3NoIEhECAAAAAQDAAAAkIKW5wAAAAgAAAAABAAAQcXxyyoAAAAkAAAAAQEAADA5QjdFQUJFLTY3OTUtNENERi1BQjI0LTNGRjA4NTY1RDAxNhgAAAABAgAAgQAAAAEAAADvEwAAAQAAAAAAAAAAAAAAAQAAAAEBAAAvAAAAAAAAAAEFAAAEAQAAAQIAADJhZjNjZTFmYjBjNTkxNTIxY2Y2MWNkMTQ3ZGFkNzI1ODE2YzMzMDMzOTMwMzUxYWJmMTMxODUzNWIzMWEwOTg7MDA7MDAwMDAwMDA7MDAwMDAwMDA7MDAwMDAwMDA7MDAwMDAwMDAwMDAwMDAyMDtjb20uYXBwbGUuYXBwLXNhbmRib3gucmVhZC13cml0ZTswMTswMTAwMDAxMDswMDAwMDAwMDAzNWM3NWE3OzAxOy91c2Vycy9tY3Jvd2xleS9yZXBvcy9tYXJrY3Jvd2xleS1jYS9hc3NldHMvcGRmLzIwMTctcmxkbS1zdWJyYW1hbmlhbi1sZWFybmluZy5wZGYAzAAAAP7///8BAAAAAAAAABAAAAAEEAAAlAAAAAAAAAAFEAAAKAEAAAAAAAAQEAAAXAEAAAAAAABAEAAATAEAAAAAAAACIAAAKAIAAAAAAAAFIAAAmAEAAAAAAAAQIAAAqAEAAAAAAAARIAAA3AEAAAAAAAASIAAAvAEAAAAAAAATIAAAzAEAAAAAAAAgIAAACAIAAAAAAAAwIAAANAIAAAAAAAABwAAAfAEAAAAAAAARwAAAFAAAAAAAAAASwAAAjAEAAAAAAACA8AAAPAIAAAAAAAAACAANABoAIwBWAAAAAAAAAgEAAAAAAAAABQAAAAAAAAAAAAAAAAAABKY=}}

@article{jain2020review,
	abbr = {WildfireMLRev},
	abstract = {
Artificial intelligence has been applied in wildfire science and management since the 1990s, with early applications including neural networks and expert systems. Since then the field has rapidly progressed congruently with the wide adoption of machine learning (ML) methods in the environmental sciences. Here, we present a scoping review of ML applications in wildfire science and management. Our overall objective is to improve awareness of ML methods among wildfire researchers and managers, as well as illustrate the diverse and challenging range of problems in wildfire science available to ML data scientists. To that end, we first present an overview of popular ML approaches used in wildfire science to date, and then review the use of ML in wildfire science as broadly categorized into six problem domains, including: 1) fuels characterization, fire detection, and mapping; 2) fire weather and climate change; 3) fire occurrence, susceptibility, and risk; 4) fire behavior prediction; 5) fire effects; and 6) fire management. Furthermore, we discuss the advantages and limitations of various ML approaches relating to data size, computational requirements, generalizability, and interpretability, as well as identify opportunities for future advances in the science and management of wildfires within a data science context. In total, we identified 298 relevant publications, where the most frequently used ML methods across problem domains included random forests, MaxEnt, artificial neural networks, decision trees, support vector machines, and genetic algorithms. As such, there exists opportunities to apply more current ML methods --- including deep learning and agent based learning --- in the wildfire sciences, especially in instances involving very large multivariate datasets. We must recognize, however, that despite the ability of ML models to learn on their own, expertise in wildfire science is necessary to ensure realistic modelling of fire processes across multiple scales, while the complexity of some ML methods, such as deep learning, requires a dedicated and sophisticated knowledge of their application. Finally, we stress that the wildfire research and management communities play an active role in providing relevant, high quality, and freely available wildfire data for use by practitioners of ML methods.},
	arxiv = {2003.00646},
	author = {Jain, Piyush and Coogan, Sean CP and Ganapathi Subramanian, Sriram and Crowley, Mark and Taylor, Steve and Flannigan, Mike D},
	citations = {474},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-06-27 16:48:06 -0400},
	doi = {https://doi.org/10.1139/er-2020-0019},
	in-cv = {1},
	in-website = {0},
	journal = {Environmental Reviews},
	keywords = {showcase; year-in-review-2021; forest-management; machine-learning; forest-wildfire; tree-based-ensembles; fund-waii-nexus-seed-2024-wildfire},
	month = {July},
	number = {3},
	paperdesc = {This review paper arose from my visit to BC to speak on the use of AI for Forest Fire management and led to a collaboration amongst these senior researchers, myself and my PhD student Sriram. We collaborated on every part of the paper, I especially wrote the general AI/ML background and checked that each specific Forest Fire domain was connected correctly to the ML literature. It will serve as a much-needed resource for researches in my field as well as applied Forest Fire Management and Science fields. Note, that for the tutorials there is some self-citation included.},
	pdf = {2020-envrevjrnl-jain-review.pdf},
	publisher = {Canadian Science Publishing},
	rating = {4},
	self = {1},
	slides = {https://www.dropbox.com/scl/fi/5236qksp44pp96tll8egl/2020-envrevjrnl-jain-review1.pdf?rlkey=1ycxvh8tyfxi8cxlzcctxch2y&raw=1},
	status = {1},
	tempflag = {0},
	title = {A review of machine learning applications in wildfire science and management},
	url = {https://cdnsciencepub.com/doi/10.1139/er-2020-0019},
	venue-short = {EnvRevJrnl},
	volume = {28},
	year = {2020},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEC0uLi9hc3NldHMvcGRmLzIwMjAtZW52cmV2anJubC1qYWluLXJldmlldy5wZGZPEQRIYm9va0gEAAAAAAQQMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAARAMAAAUAAAABAQAAVXNlcnMAAAAIAAAAAQEAAG1jcm93bGV5BQAAAAEBAAByZXBvcwAAAA4AAAABAQAAbWFya2Nyb3dsZXktY2EAAAYAAAABAQAAYXNzZXRzAAADAAAAAQEAAHBkZgAfAAAAAQEAADIwMjAtZW52cmV2anJubC1qYWluLXJldmlldy5wZGYAHAAAAAEGAAAEAAAAFAAAACQAAAA0AAAATAAAAFwAAABoAAAACAAAAAQDAAAVXQAAAAAAAAgAAAAEAwAAOegDAAAAAAAIAAAABAMAAGiSCgAAAAAACAAAAAQDAACH1hAAAAAAAAgAAAAEAwAAMXVcAwAAAAAIAAAABAMAAKJ1XAMAAAAACAAAAAQDAACxdVwDAAAAABwAAAABBgAAtAAAAMQAAADUAAAA5AAAAPQAAAAEAQAAFAEAAAgAAAAABAAAQcYUQv6AAAAYAAAAAQIAAAEAAAAAAAAADwAAAAAAAAAAAAAAAAAAAAgAAAAEAwAABQAAAAAAAAAEAAAAAwMAAPUBAAAIAAAAAQkAAGZpbGU6Ly8vDAAAAAEBAABNYWNpbnRvc2ggSEQIAAAABAMAAACQgpbnAAAACAAAAAAEAABBxfHLKgAAACQAAAABAQAAMDlCN0VBQkUtNjc5NS00Q0RGLUFCMjQtM0ZGMDg1NjVEMDE2GAAAAAECAACBAAAAAQAAAO8TAAABAAAAAAAAAAAAAAABAAAAAQEAAC8AAAAAAAAAAQUAAAEBAAABAgAANThhZjQ2MTJmYmIxMjM5ODBkZTJhYWMzMzA0ZGVlMDJhNjliNWFiOGU0Zjc0NWM2MGQ3NDhlYTgyNmY5MWQ3ZTswMDswMDAwMDAwMDswMDAwMDAwMDswMDAwMDAwMDswMDAwMDAwMDAwMDAwMDIwO2NvbS5hcHBsZS5hcHAtc2FuZGJveC5yZWFkLXdyaXRlOzAxOzAxMDAwMDEwOzAwMDAwMDAwMDM1Yzc1YjE7MDE7L3VzZXJzL21jcm93bGV5L3JlcG9zL21hcmtjcm93bGV5LWNhL2Fzc2V0cy9wZGYvMjAyMC1lbnZyZXZqcm5sLWphaW4tcmV2aWV3LnBkZgAAAADMAAAA/v///wEAAAAAAAAAEAAAAAQQAACQAAAAAAAAAAUQAAAkAQAAAAAAABAQAABYAQAAAAAAAEAQAABIAQAAAAAAAAIgAAAkAgAAAAAAAAUgAACUAQAAAAAAABAgAACkAQAAAAAAABEgAADYAQAAAAAAABIgAAC4AQAAAAAAABMgAADIAQAAAAAAACAgAAAEAgAAAAAAADAgAAAwAgAAAAAAAAHAAAB4AQAAAAAAABHAAAAUAAAAAAAAABLAAACIAQAAAAAAAIDwAAA4AgAAAAAAAAAIAA0AGgAjAFMAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAEnw==},
	bdsk-file-2 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxAuLi4vYXNzZXRzL3BkZi8yMDIwLWVudnJldmpybmwtamFpbi1yZXZpZXcxLnBkZk8RAbwAAAAAAbwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAAAAAABCRAAB/////x8yMDIwLWVudnJldmpybmwtamEjRkZGRkZGRkYucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/////AAAAAAAAAAAAAAAAAAEAAwAACiBjdQAAAAAAAAAAAAAAAAADcGRmAAACAFEvOlVzZXJzOm1jcm93bGV5OnJlcG9zOm1hcmtjcm93bGV5LWNhOmFzc2V0czpwZGY6MjAyMC1lbnZyZXZqcm5sLWphaW4tcmV2aWV3MS5wZGYAAA4AQgAgADIAMAAyADAALQBlAG4AdgByAGUAdgBqAHIAbgBsAC0AagBhAGkAbgAtAHIAZQB2AGkAZQB3ADEALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAE9Vc2Vycy9tY3Jvd2xleS9yZXBvcy9tYXJrY3Jvd2xleS1jYS9hc3NldHMvcGRmLzIwMjAtZW52cmV2anJubC1qYWluLXJldmlldzEucGRmAAATAAEvAAAVAAIAD///AAAACAANABoAJABVAAAAAAAAAgEAAAAAAAAABQAAAAAAAAAAAAAAAAAAAhU=}}

@article{ghali2023fire,
	abstract = {Wildland fires are one of the most dangerous natural risks, causing significant economic damage and loss of lives worldwide. Every year, millions of hectares are lost, and experts warn that the frequency and severity of wildfires will increase in the coming years due to climate change. To mitigate these hazards, numerous deep learning models were developed to detect and map wildland fires, estimate their severity, and predict their spread. In this paper, we provide a comprehensive review of recent deep learning techniques for detecting, mapping, and predicting wildland fires using satellite remote sensing data. We begin by introducing remote sensing satellite systems and their use in wildfire monitoring. Next, we review the deep learning methods employed for these tasks, including fire detection and mapping, severity estimation, and spread prediction. We further present the popular datasets used in these studies. Finally, we address the challenges faced by these models to accurately predict wildfire behaviors, and suggest future directions for developing reliable and robust wildland fire models.},
	article-number = {192},
	author = {Ghali, Rafik and Akhloufi, Moulay A.},
	date-added = {2024-06-27 16:46:20 -0400},
	date-modified = {2024-06-27 16:46:20 -0400},
	doi = {10.3390/fire6050192},
	issn = {2571-6255},
	journal = {Fire},
	keywords = {forest-management; forest-wildfire; fund-waii-nexus-seed-2024-wildfire},
	number = {5},
	title = {Deep Learning Approaches for Wildland Fires Using Satellite Remote Sensing Data: Detection, Mapping, and Prediction},
	url = {https://www.mdpi.com/2571-6255/6/5/192},
	venue-short = {fire},
	volume = {6},
	year = {2023},
	bdsk-url-1 = {https://www.mdpi.com/2571-6255/6/5/192},
	bdsk-url-2 = {https://doi.org/10.3390/fire6050192}}

@inproceedings{pmlr-v81-buolamwini18a,
	abstract = {Recent studies demonstrate that machine learning algorithms can discriminate based on classes like race and gender. In this work, we present an approach to evaluate bias present in automated facial analysis algorithms and datasets with respect to phenotypic subgroups. Using the dermatologist  approved Fitzpatrick Skin Type classification system, we characterize the gender and skin type distribution of two facial analysis benchmarks, IJB-A and Adience. We find that these datasets are overwhelmingly composed of lighter-skinned subjects (79.6% for IJB-A and 86.2% for Adience) and introduce a new facial analysis dataset which is balanced by gender and skin type. We evaluate 3 commercial gender classification systems using our dataset and show that darker-skinned females are the most misclassified group (with error rates of up to 34.7%). The maximum error rate for lighter-skinned males is 0.8%. The substantial disparities in the accuracy of classifying darker females, lighter females, darker males, and lighter males in gender classification systems require urgent attention if commercial companies are to build genuinely fair, transparent and accountable facial analysis algorithms.},
	author = {Buolamwini, Joy and Gebru, Timnit},
	booktitle = {Proceedings of the 1st Conference on Fairness, Accountability and Transparency},
	date-added = {2024-06-06 16:58:23 -0400},
	date-modified = {2024-06-06 17:01:03 -0400},
	editor = {Friedler, Sorelle A. and Wilson, Christo},
	keywords = {course-watspeed-ai, ethical-ai, bias, fairness, deep-learning, racism, value-alignment},
	month = {23--24 Feb},
	pages = {77--91},
	pdf = {http://proceedings.mlr.press/v81/buolamwini18a/buolamwini18a.pdf},
	publisher = {PMLR},
	series = {Proceedings of Machine Learning Research},
	title = {Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification},
	url = {https://proceedings.mlr.press/v81/buolamwini18a.html},
	venue-short = {pmlr},
	volume = {81},
	year = {2018},
	bdsk-url-1 = {https://proceedings.mlr.press/v81/buolamwini18a.html}}

@book{ghojogh2022springerbook,
	abbr = {Textbook},
	abstract = {Dimensionality reduction, also known as manifold learning, is an area of machine learning used for extracting informative features from data, for better representation of data or separation between classes. This book presents a cohesive review of linear and nonlinear dimensionality reduction and manifold learning. Three main aspects of dimensionality reduction are covered -- spectral dimensionality reduction, probabilistic dimensionality reduction, and neural network-based dimensionality reduction, which have geometric, probabilistic, and information-theoretic points of view to dimensionality reduction, respectively. This book delves into basic concepts and recent developments in the field of dimensionality reduction and manifold learning, providing the reader with a comprehensive understanding. The necessary background and preliminaries, on linear algebra, optimization, and kernels, are also explained in the book to ensure a comprehensive understanding of the algorithms.

The tools this book introduces are applied to various applications involving feature extraction, image processing, computer vision, and signal processing. This book is applicable to a wide audience who would like to acquire a deep understanding of the various ways to extract, transform, and understand the structure of data. The intended audiences are academics, students, and industry professionals. Academic researchers and students can use this book as a textbook for machine learning and dimensionality reduction. Data scientists, machine learning scientists, computer vision scientists, computer scientists, statisticians, and mathematicians in the fields of applied mathematics, statistical learning, Riemannian manifolds, subspace analysis, linear algebra, and optimization can use this book as a reference book for both technical and applied concepts. Industry professionals, including applied engineers, data engineers, and engineers in various fields of science dealing with machine learning, can use this book as a guidebook for feature extraction from their data as the raw data in industry often requires pre-processing. Data feature extraction is useful in various fields of science including engineering, physics, chemistry, biometrics, biomedical signals and images, etc.

This book is structured as a reference textbook, so that it can be used for advanced courses, as an in-depth supplementary resource or for researchers or practitioners who want to learn about dimensionality reduction and manifold learning. The book is grounded in theory, but provides thorough explanations and diverse examples to improve the readers comprehension of the advanced topics. Advanced methods are explained in a step-by-step manner so that readers of all levels can follow the reasoning and come to a deep understanding of the concepts. This book does not assume the reader has an advanced theoretical background in machine learning and provides necessary background, though an undergraduate-level background in linear algebra and calculus is recommended.},
	annote = {My former PhD student Ghojogh (grad S21) led completion of our textbook on the subject of his thesis Dimensionality Reduction and Manifold Learning.  He created the primary content for the book with significant contributions from the coauthors. In the Spring 2022 we hired a copy-editor to improve the text flow, and the draft book was submitted to Springer Nature in the early Fall of 2022. The publisher now has our final copy edits and the book is expected to be published in early 2023.},
	author = {Benyamin Ghojogh and Mark Crowley and Fakhri Karray and Ali Ghodsi},
	citations = {11},
	date-added = {2024-04-22 20:04:33 -0400},
	date-modified = {2024-04-22 20:04:33 -0400},
	in-cv = {1},
	in-website = {1},
	isbn-10 = {3031106016},
	isbn-13 = {978-3031106016},
	keywords = {manifold-learning, dimensionality-reduction, machine-learning, metric-learning, showcase},
	month = {February},
	pages = {363},
	publicationstatus = {published},
	publisher = {Springer Nature},
	rating = {5},
	self = {1},
	self-citation = {4},
	status = {1},
	title = {Elements of Dimensionality Reduction and Manifold Learning},
	url = {https://link.springer.com/book/10.1007/978-3-031-10602-6},
	venue-short = {SpringerBook},
	year = {2023},
	bdsk-file-1 = {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},
	bdsk-url-1 = {https://www.amazon.ca/Elements-Dimensionality-Reduction-Manifold-Learning/dp/3031106016/ref=sr_1_1?keywords=9783031106019&linkCode=qs&qid=1659572815&returnFromLogin=1&s=books&sr=1-1},
	bdsk-url-2 = {https://link.springer.com/book/10.1007/978-3-031-10602-6}}

@inproceedings{2024-submission142-canai-gpu-job,
	booktitle = {(under review) The 37th Canadian Conference on Artificial Intelligence},
	date-added = {2024-03-25 00:48:06 -0400},
	date-modified = {2024-03-25 00:49:00 -0400},
	keywords = {reinforcement-learning, gpu-scheduling, systems, scheduling, optimization, heuristics},
	title = {GPU Job Scheduler with Deep Reinforcement Learning},
	year = {2024},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEFwuLi8uLi8uLi9Ecm9wYm94L0FwcHMvcmVtb3RlbHktc2F2ZS9BSVRvcGljcy9hc3NldHMvcGRmLzIwMjQtc3VibWlzc2lvbjE0Mi1jYW5haS1ncHUtam9iLnBkZk8RBKxib29rrAQAAAAABBAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACoAwAABQAAAAEBAABVc2VycwAAAAgAAAABAQAAbWNyb3dsZXkHAAAAAQEAAERyb3Bib3gABAAAAAEBAABBcHBzDQAAAAEBAAByZW1vdGVseS1zYXZlAAAACAAAAAEBAABBSVRvcGljcwYAAAABAQAAYXNzZXRzAAADAAAAAQEAAHBkZgAkAAAAAQEAADIwMjQtc3VibWlzc2lvbjE0Mi1jYW5haS1ncHUtam9iLnBkZiQAAAABBgAABAAAABQAAAAkAAAANAAAAEAAAABYAAAAaAAAAHgAAACEAAAACAAAAAQDAAAVXQAAAAAAAAgAAAAEAwAAOegDAAAAAAAIAAAABAMAAF91BAAAAAAACAAAAAQDAADRjgQAAAAAAAgAAAAEAwAAEFF0AgAAAAAIAAAABAMAAJ4W5wIAAAAACAAAAAQDAAA1z+ACAAAAAAgAAAAEAwAANs/gAgAAAAAIAAAABAMAAPti6QIAAAAAJAAAAAEGAADcAAAA7AAAAPwAAAAMAQAAHAEAACwBAAA8AQAATAEAAFwBAAAIAAAAAAQAAEHF2JunJ7C5GAAAAAECAAABAAAAAAAAAA8AAAAAAAAAAAAAAAAAAAAIAAAABAMAAAcAAAAAAAAABAAAAAMDAAD1AQAACAAAAAEJAABmaWxlOi8vLwwAAAABAQAATWFjaW50b3NoIEhECAAAAAQDAAAAkIKW5wAAAAgAAAAABAAAQcXxyyoAAAAkAAAAAQEAADA5QjdFQUJFLTY3OTUtNENERi1BQjI0LTNGRjA4NTY1RDAxNhgAAAABAgAAgQAAAAEAAADvEwAAAQAAAAAAAAAAAAAAAQAAAAEBAAAvAAAAAAAAAAEFAAAVAQAAAQIAAGIyZWZhZTljZDI1MWZlMjE3YzljYzQ2MjZlODc1NGRhODIyYmQ1NzAwZWZmNTk1MjQwOTU1YjBiMzY5MThhOTM7MDA7MDAwMDAwMDA7MDAwMDAwMDA7MDAwMDAwMDA7MDAwMDAwMDAwMDAwMDAyMDtjb20uYXBwbGUuYXBwLXNhbmRib3gucmVhZC13cml0ZTswMTswMTAwMDAxMDswMDAwMDAwMDAyZTk2MmZiOzAxOy91c2Vycy9tY3Jvd2xleS9kcm9wYm94L2FwcHMvcmVtb3RlbHktc2F2ZS9haXRvcGljcy9hc3NldHMvcGRmLzIwMjQtc3VibWlzc2lvbjE0Mi1jYW5haS1ncHUtam9iLnBkZgAAAADMAAAA/v///wEAAAAAAAAAEAAAAAQQAACwAAAAAAAAAAUQAABsAQAAAAAAABAQAACoAQAAAAAAAEAQAACYAQAAAAAAAAIgAAB0AgAAAAAAAAUgAADkAQAAAAAAABAgAAD0AQAAAAAAABEgAAAoAgAAAAAAABIgAAAIAgAAAAAAABMgAAAYAgAAAAAAACAgAABUAgAAAAAAADAgAACAAgAAAAAAAAHAAADIAQAAAAAAABHAAAAUAAAAAAAAABLAAADYAQAAAAAAAIDwAACIAgAAAAAAAAAIAA0AGgAjAIIAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAFMg==}}

@inproceedings{2024-submission73-canai-deep-hedging,
	booktitle = {(under review) The 37th Canadian Conference on Artificial Intelligence},
	date-added = {2024-03-25 00:46:03 -0400},
	date-modified = {2024-03-25 00:47:43 -0400},
	keywords = {reinforcement-learning, finance, quantitative-analysis, hedging},
	title = {Deep Hedging with Market Impact},
	year = {2024},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEGAuLi8uLi8uLi9Ecm9wYm94L0FwcHMvcmVtb3RlbHktc2F2ZS9BSVRvcGljcy9hc3NldHMvcGRmLzIwMjQtc3VibWlzc2lvbjczLWNhbmFpLWRlZXAtaGVkZ2luZy5wZGZPEQS0Ym9va7QEAAAAAAQQMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsAMAAAUAAAABAQAAVXNlcnMAAAAIAAAAAQEAAG1jcm93bGV5BwAAAAEBAABEcm9wYm94AAQAAAABAQAAQXBwcw0AAAABAQAAcmVtb3RlbHktc2F2ZQAAAAgAAAABAQAAQUlUb3BpY3MGAAAAAQEAAGFzc2V0cwAAAwAAAAEBAABwZGYAKAAAAAEBAAAyMDI0LXN1Ym1pc3Npb243My1jYW5haS1kZWVwLWhlZGdpbmcucGRmJAAAAAEGAAAEAAAAFAAAACQAAAA0AAAAQAAAAFgAAABoAAAAeAAAAIQAAAAIAAAABAMAABVdAAAAAAAACAAAAAQDAAA56AMAAAAAAAgAAAAEAwAAX3UEAAAAAAAIAAAABAMAANGOBAAAAAAACAAAAAQDAAAQUXQCAAAAAAgAAAAEAwAAnhbnAgAAAAAIAAAABAMAADXP4AIAAAAACAAAAAQDAAA2z+ACAAAAAAgAAAAEAwAAagLhAgAAAAAkAAAAAQYAAOAAAADwAAAAAAEAABABAAAgAQAAMAEAAEABAABQAQAAYAEAAAgAAAAABAAAQcXYm57yrBgYAAAAAQIAAAEAAAAAAAAADwAAAAAAAAAAAAAAAAAAAAgAAAAEAwAABwAAAAAAAAAEAAAAAwMAAPUBAAAIAAAAAQkAAGZpbGU6Ly8vDAAAAAEBAABNYWNpbnRvc2ggSEQIAAAABAMAAACQgpbnAAAACAAAAAAEAABBxfHLKgAAACQAAAABAQAAMDlCN0VBQkUtNjc5NS00Q0RGLUFCMjQtM0ZGMDg1NjVEMDE2GAAAAAECAACBAAAAAQAAAO8TAAABAAAAAAAAAAAAAAABAAAAAQEAAC8AAAAAAAAAAQUAABkBAAABAgAAYjQ4NjI4OTI4YmQ5N2IwOTZjOGMzZDk4NWMzYmEwM2Q5ZGZiNmY0ZWQ2NjE2NDJjZTRhNGIwYmIxOWI4YmZmMTswMDswMDAwMDAwMDswMDAwMDAwMDswMDAwMDAwMDswMDAwMDAwMDAwMDAwMDIwO2NvbS5hcHBsZS5hcHAtc2FuZGJveC5yZWFkLXdyaXRlOzAxOzAxMDAwMDEwOzAwMDAwMDAwMDJlMTAyNmE7MDE7L3VzZXJzL21jcm93bGV5L2Ryb3Bib3gvYXBwcy9yZW1vdGVseS1zYXZlL2FpdG9waWNzL2Fzc2V0cy9wZGYvMjAyNC1zdWJtaXNzaW9uNzMtY2FuYWktZGVlcC1oZWRnaW5nLnBkZgAAAADMAAAA/v///wEAAAAAAAAAEAAAAAQQAAC0AAAAAAAAAAUQAABwAQAAAAAAABAQAACsAQAAAAAAAEAQAACcAQAAAAAAAAIgAAB4AgAAAAAAAAUgAADoAQAAAAAAABAgAAD4AQAAAAAAABEgAAAsAgAAAAAAABIgAAAMAgAAAAAAABMgAAAcAgAAAAAAACAgAABYAgAAAAAAADAgAACEAgAAAAAAAAHAAADMAQAAAAAAABHAAAAUAAAAAAAAABLAAADcAQAAAAAAAIDwAACMAgAAAAAAAAAIAA0AGgAjAIYAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAFPg==}}

@incollection{rodriguezsoto2021ijcai-Multi-Objective-Reinforcement,
	date-added = {2024-03-25 00:16:29 -0400},
	date-modified = {2024-03-25 00:17:21 -0400},
	keywords = {ai-morality},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEHAuLi8uLi8uLi9Ecm9wYm94L0FwcHMvcmVtb3RlbHktc2F2ZS9BSVRvcGljcy9hc3NldHMvcGRmL3JvZHJpZ3VlenNvdG8yMDIxaWpjYWktTXVsdGktT2JqZWN0aXZlLVJlaW5mb3JjZW1lbnQucGRmTxEE1GJvb2vUBAAAAAAEEDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANADAAAFAAAAAQEAAFVzZXJzAAAACAAAAAEBAABtY3Jvd2xleQcAAAABAQAARHJvcGJveAAEAAAAAQEAAEFwcHMNAAAAAQEAAHJlbW90ZWx5LXNhdmUAAAAIAAAAAQEAAEFJVG9waWNzBgAAAAEBAABhc3NldHMAAAMAAAABAQAAcGRmADgAAAABAQAAcm9kcmlndWV6c290bzIwMjFpamNhaS1NdWx0aS1PYmplY3RpdmUtUmVpbmZvcmNlbWVudC5wZGYkAAAAAQYAAAQAAAAUAAAAJAAAADQAAABAAAAAWAAAAGgAAAB4AAAAhAAAAAgAAAAEAwAAFV0AAAAAAAAIAAAABAMAADnoAwAAAAAACAAAAAQDAABfdQQAAAAAAAgAAAAEAwAA0Y4EAAAAAAAIAAAABAMAABBRdAIAAAAACAAAAAQDAACeFucCAAAAAAgAAAAEAwAANc/gAgAAAAAIAAAABAMAADbP4AIAAAAACAAAAAQDAADc9eACAAAAACQAAAABBgAA8AAAAAABAAAQAQAAIAEAADABAABAAQAAUAEAAGABAABwAQAACAAAAAAEAABBxdiXVo1siRgAAAABAgAAAQAAAAAAAAAPAAAAAAAAAAAAAAAAAAAACAAAAAQDAAAHAAAAAAAAAAQAAAADAwAA9QEAAAgAAAABCQAAZmlsZTovLy8MAAAAAQEAAE1hY2ludG9zaCBIRAgAAAAEAwAAAJCClucAAAAIAAAAAAQAAEHF8csqAAAAJAAAAAEBAAAwOUI3RUFCRS02Nzk1LTRDREYtQUIyNC0zRkYwODU2NUQwMTYYAAAAAQIAAIEAAAABAAAA7xMAAAEAAAAAAAAAAAAAAAEAAAABAQAALwAAAAAAAAABBQAAKQEAAAECAABmZTA2ZDUyNzBiMDRkODI5NWRiYmQzM2Q5MGQwOWRmODFiN2I3ODFjMzg5Y2ZlM2RkNGY1MGM1Y2E2ZDU2Mzg2OzAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwMDAwMDAwMjA7Y29tLmFwcGxlLmFwcC1zYW5kYm94LnJlYWQtd3JpdGU7MDE7MDEwMDAwMTA7MDAwMDAwMDAwMmUwZjVkYzswMTsvdXNlcnMvbWNyb3dsZXkvZHJvcGJveC9hcHBzL3JlbW90ZWx5LXNhdmUvYWl0b3BpY3MvYXNzZXRzL3BkZi9yb2RyaWd1ZXpzb3RvMjAyMWlqY2FpLW11bHRpLW9iamVjdGl2ZS1yZWluZm9yY2VtZW50LnBkZgAAAADMAAAA/v///wEAAAAAAAAAEAAAAAQQAADEAAAAAAAAAAUQAACAAQAAAAAAABAQAAC8AQAAAAAAAEAQAACsAQAAAAAAAAIgAACIAgAAAAAAAAUgAAD4AQAAAAAAABAgAAAIAgAAAAAAABEgAAA8AgAAAAAAABIgAAAcAgAAAAAAABMgAAAsAgAAAAAAACAgAABoAgAAAAAAADAgAACUAgAAAAAAAAHAAADcAQAAAAAAABHAAAAUAAAAAAAAABLAAADsAQAAAAAAAIDwAACcAgAAAAAAAAAIAA0AGgAjAJYAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAFbg==}}

@incollection{peschl2021arxiv-MORAL-Aligning,
	date-added = {2024-03-25 00:10:55 -0400},
	date-modified = {2024-03-25 00:17:21 -0400},
	keywords = {ai-morality},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEFouLi8uLi8uLi9Ecm9wYm94L0FwcHMvcmVtb3RlbHktc2F2ZS9BSVRvcGljcy9hc3NldHMvcGRmL3Blc2NobDIwMjFhcnhpdi1NT1JBTC1BbGlnbmluZy5wZGZPEQSoYm9va6gEAAAAAAQQMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAApAMAAAUAAAABAQAAVXNlcnMAAAAIAAAAAQEAAG1jcm93bGV5BwAAAAEBAABEcm9wYm94AAQAAAABAQAAQXBwcw0AAAABAQAAcmVtb3RlbHktc2F2ZQAAAAgAAAABAQAAQUlUb3BpY3MGAAAAAQEAAGFzc2V0cwAAAwAAAAEBAABwZGYAIgAAAAEBAABwZXNjaGwyMDIxYXJ4aXYtTU9SQUwtQWxpZ25pbmcucGRmAAAkAAAAAQYAAAQAAAAUAAAAJAAAADQAAABAAAAAWAAAAGgAAAB4AAAAhAAAAAgAAAAEAwAAFV0AAAAAAAAIAAAABAMAADnoAwAAAAAACAAAAAQDAABfdQQAAAAAAAgAAAAEAwAA0Y4EAAAAAAAIAAAABAMAABBRdAIAAAAACAAAAAQDAACeFucCAAAAAAgAAAAEAwAANc/gAgAAAAAIAAAABAMAADbP4AIAAAAACAAAAAQDAAD19eACAAAAACQAAAABBgAA3AAAAOwAAAD8AAAADAEAABwBAAAsAQAAPAEAAEwBAABcAQAACAAAAAAEAABBxdiXV6/82xgAAAABAgAAAQAAAAAAAAAPAAAAAAAAAAAAAAAAAAAACAAAAAQDAAAHAAAAAAAAAAQAAAADAwAA9QEAAAgAAAABCQAAZmlsZTovLy8MAAAAAQEAAE1hY2ludG9zaCBIRAgAAAAEAwAAAJCClucAAAAIAAAAAAQAAEHF8csqAAAAJAAAAAEBAAAwOUI3RUFCRS02Nzk1LTRDREYtQUIyNC0zRkYwODU2NUQwMTYYAAAAAQIAAIEAAAABAAAA7xMAAAEAAAAAAAAAAAAAAAEAAAABAQAALwAAAAAAAAABBQAAEwEAAAECAABiZTQ3ZDgyNzJiMTU1NzFlMWViMTViNGY3Y2QwOGZmYzczNWE1NzQ5MjY3OWE2YWZlMjVjYmQyYmNiNTk1N2RiOzAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwMDAwMDAwMjA7Y29tLmFwcGxlLmFwcC1zYW5kYm94LnJlYWQtd3JpdGU7MDE7MDEwMDAwMTA7MDAwMDAwMDAwMmUwZjVmNTswMTsvdXNlcnMvbWNyb3dsZXkvZHJvcGJveC9hcHBzL3JlbW90ZWx5LXNhdmUvYWl0b3BpY3MvYXNzZXRzL3BkZi9wZXNjaGwyMDIxYXJ4aXYtbW9yYWwtYWxpZ25pbmcucGRmAADMAAAA/v///wEAAAAAAAAAEAAAAAQQAACwAAAAAAAAAAUQAABsAQAAAAAAABAQAACoAQAAAAAAAEAQAACYAQAAAAAAAAIgAAB0AgAAAAAAAAUgAADkAQAAAAAAABAgAAD0AQAAAAAAABEgAAAoAgAAAAAAABIgAAAIAgAAAAAAABMgAAAYAgAAAAAAACAgAABUAgAAAAAAADAgAACAAgAAAAAAAAHAAADIAQAAAAAAABHAAAAUAAAAAAAAABLAAADYAQAAAAAAAIDwAACIAgAAAAAAAAAIAA0AGgAjAIAAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAFLA==}}

@incollection{rodriguezsoto2023nca-Multi-objective,
	date-added = {2024-03-25 00:10:29 -0400},
	date-modified = {2024-03-25 00:17:21 -0400},
	keywords = {ai-morality},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEGAuLi8uLi8uLi9Ecm9wYm94L0FwcHMvcmVtb3RlbHktc2F2ZS9BSVRvcGljcy9hc3NldHMvcGRmL3JvZHJpZ3VlenNvdG8yMDIzbmNhLU11bHRpLW9iamVjdGl2ZS5wZGZPEQS0Ym9va7QEAAAAAAQQMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsAMAAAUAAAABAQAAVXNlcnMAAAAIAAAAAQEAAG1jcm93bGV5BwAAAAEBAABEcm9wYm94AAQAAAABAQAAQXBwcw0AAAABAQAAcmVtb3RlbHktc2F2ZQAAAAgAAAABAQAAQUlUb3BpY3MGAAAAAQEAAGFzc2V0cwAAAwAAAAEBAABwZGYAKAAAAAEBAAByb2RyaWd1ZXpzb3RvMjAyM25jYS1NdWx0aS1vYmplY3RpdmUucGRmJAAAAAEGAAAEAAAAFAAAACQAAAA0AAAAQAAAAFgAAABoAAAAeAAAAIQAAAAIAAAABAMAABVdAAAAAAAACAAAAAQDAAA56AMAAAAAAAgAAAAEAwAAX3UEAAAAAAAIAAAABAMAANGOBAAAAAAACAAAAAQDAAAQUXQCAAAAAAgAAAAEAwAAnhbnAgAAAAAIAAAABAMAADXP4AIAAAAACAAAAAQDAAA2z+ACAAAAAAgAAAAEAwAA3/XgAgAAAAAkAAAAAQYAAOAAAADwAAAAAAEAABABAAAgAQAAMAEAAEABAABQAQAAYAEAAAgAAAAABAAAQcXYl1aOuWkYAAAAAQIAAAEAAAAAAAAADwAAAAAAAAAAAAAAAAAAAAgAAAAEAwAABwAAAAAAAAAEAAAAAwMAAPUBAAAIAAAAAQkAAGZpbGU6Ly8vDAAAAAEBAABNYWNpbnRvc2ggSEQIAAAABAMAAACQgpbnAAAACAAAAAAEAABBxfHLKgAAACQAAAABAQAAMDlCN0VBQkUtNjc5NS00Q0RGLUFCMjQtM0ZGMDg1NjVEMDE2GAAAAAECAACBAAAAAQAAAO8TAAABAAAAAAAAAAAAAAABAAAAAQEAAC8AAAAAAAAAAQUAABkBAAABAgAAMGY0NmU5OTFhN2RiNDhlZTYxMjJjY2QyMjhjMjg2YmZiNGYyNjNhZDQzMWQ3ZTMyZjg0ZWMzYzczMGMxNDRhZTswMDswMDAwMDAwMDswMDAwMDAwMDswMDAwMDAwMDswMDAwMDAwMDAwMDAwMDIwO2NvbS5hcHBsZS5hcHAtc2FuZGJveC5yZWFkLXdyaXRlOzAxOzAxMDAwMDEwOzAwMDAwMDAwMDJlMGY1ZGY7MDE7L3VzZXJzL21jcm93bGV5L2Ryb3Bib3gvYXBwcy9yZW1vdGVseS1zYXZlL2FpdG9waWNzL2Fzc2V0cy9wZGYvcm9kcmlndWV6c290bzIwMjNuY2EtbXVsdGktb2JqZWN0aXZlLnBkZgAAAADMAAAA/v///wEAAAAAAAAAEAAAAAQQAAC0AAAAAAAAAAUQAABwAQAAAAAAABAQAACsAQAAAAAAAEAQAACcAQAAAAAAAAIgAAB4AgAAAAAAAAUgAADoAQAAAAAAABAgAAD4AQAAAAAAABEgAAAsAgAAAAAAABIgAAAMAgAAAAAAABMgAAAcAgAAAAAAACAgAABYAgAAAAAAADAgAACEAgAAAAAAAAHAAADMAQAAAAAAABHAAAAUAAAAAAAAABLAAADcAQAAAAAAAIDwAACMAgAAAAAAAAAIAA0AGgAjAIYAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAFPg==}}

@incollection{bai2022arxiv-constitutional-ai,
	date-added = {2024-03-25 00:09:40 -0400},
	date-modified = {2024-03-25 00:17:21 -0400},
	keywords = {ai-morality},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEFouLi8uLi8uLi9Ecm9wYm94L0FwcHMvcmVtb3RlbHktc2F2ZS9BSVRvcGljcy9hc3NldHMvcGRmL2JhaTIwMjJhcnhpdi1jb25zdGl0dXRpb25hbC1haS5wZGZPEQSoYm9va6gEAAAAAAQQMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAApAMAAAUAAAABAQAAVXNlcnMAAAAIAAAAAQEAAG1jcm93bGV5BwAAAAEBAABEcm9wYm94AAQAAAABAQAAQXBwcw0AAAABAQAAcmVtb3RlbHktc2F2ZQAAAAgAAAABAQAAQUlUb3BpY3MGAAAAAQEAAGFzc2V0cwAAAwAAAAEBAABwZGYAIgAAAAEBAABiYWkyMDIyYXJ4aXYtY29uc3RpdHV0aW9uYWwtYWkucGRmAAAkAAAAAQYAAAQAAAAUAAAAJAAAADQAAABAAAAAWAAAAGgAAAB4AAAAhAAAAAgAAAAEAwAAFV0AAAAAAAAIAAAABAMAADnoAwAAAAAACAAAAAQDAABfdQQAAAAAAAgAAAAEAwAA0Y4EAAAAAAAIAAAABAMAABBRdAIAAAAACAAAAAQDAACeFucCAAAAAAgAAAAEAwAANc/gAgAAAAAIAAAABAMAADbP4AIAAAAACAAAAAQDAADe9eACAAAAACQAAAABBgAA3AAAAOwAAAD8AAAADAEAABwBAAAsAQAAPAEAAEwBAABcAQAACAAAAAAEAABBxdiXVo6fZRgAAAABAgAAAQAAAAAAAAAPAAAAAAAAAAAAAAAAAAAACAAAAAQDAAAHAAAAAAAAAAQAAAADAwAA9QEAAAgAAAABCQAAZmlsZTovLy8MAAAAAQEAAE1hY2ludG9zaCBIRAgAAAAEAwAAAJCClucAAAAIAAAAAAQAAEHF8csqAAAAJAAAAAEBAAAwOUI3RUFCRS02Nzk1LTRDREYtQUIyNC0zRkYwODU2NUQwMTYYAAAAAQIAAIEAAAABAAAA7xMAAAEAAAAAAAAAAAAAAAEAAAABAQAALwAAAAAAAAABBQAAEwEAAAECAAA3MGExMTE4ZTk1YWRmZjg5ODA2MTI3ZTZjOGE0NjA1NWEwZTQyZmY5MTAwNWQ0ZmEwMzYyNWRiYzczZmQwYmQ3OzAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwMDAwMDAwMjA7Y29tLmFwcGxlLmFwcC1zYW5kYm94LnJlYWQtd3JpdGU7MDE7MDEwMDAwMTA7MDAwMDAwMDAwMmUwZjVkZTswMTsvdXNlcnMvbWNyb3dsZXkvZHJvcGJveC9hcHBzL3JlbW90ZWx5LXNhdmUvYWl0b3BpY3MvYXNzZXRzL3BkZi9iYWkyMDIyYXJ4aXYtY29uc3RpdHV0aW9uYWwtYWkucGRmAADMAAAA/v///wEAAAAAAAAAEAAAAAQQAACwAAAAAAAAAAUQAABsAQAAAAAAABAQAACoAQAAAAAAAEAQAACYAQAAAAAAAAIgAAB0AgAAAAAAAAUgAADkAQAAAAAAABAgAAD0AQAAAAAAABEgAAAoAgAAAAAAABIgAAAIAgAAAAAAABMgAAAYAgAAAAAAACAgAABUAgAAAAAAADAgAACAAgAAAAAAAAHAAADIAQAAAAAAABHAAAAUAAAAAAAAABLAAADYAQAAAAAAAIDwAACIAgAAAAAAAAAIAA0AGgAjAIAAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAFLA==}}

@incollection{tomasik2014-artificial-reinforcement,
	date-added = {2024-03-25 00:09:29 -0400},
	date-modified = {2024-03-25 00:17:21 -0400},
	keywords = {ai-morality},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEGAuLi8uLi8uLi9Ecm9wYm94L0FwcHMvcmVtb3RlbHktc2F2ZS9BSVRvcGljcy9hc3NldHMvcGRmL3RvbWFzaWsyMDE0LWFydGlmaWNpYWwtcmVpbmZvcmNlbWVudC5wZGZPEQS0Ym9va7QEAAAAAAQQMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsAMAAAUAAAABAQAAVXNlcnMAAAAIAAAAAQEAAG1jcm93bGV5BwAAAAEBAABEcm9wYm94AAQAAAABAQAAQXBwcw0AAAABAQAAcmVtb3RlbHktc2F2ZQAAAAgAAAABAQAAQUlUb3BpY3MGAAAAAQEAAGFzc2V0cwAAAwAAAAEBAABwZGYAKAAAAAEBAAB0b21hc2lrMjAxNC1hcnRpZmljaWFsLXJlaW5mb3JjZW1lbnQucGRmJAAAAAEGAAAEAAAAFAAAACQAAAA0AAAAQAAAAFgAAABoAAAAeAAAAIQAAAAIAAAABAMAABVdAAAAAAAACAAAAAQDAAA56AMAAAAAAAgAAAAEAwAAX3UEAAAAAAAIAAAABAMAANGOBAAAAAAACAAAAAQDAAAQUXQCAAAAAAgAAAAEAwAAnhbnAgAAAAAIAAAABAMAADXP4AIAAAAACAAAAAQDAAA2z+ACAAAAAAgAAAAEAwAA2fXgAgAAAAAkAAAAAQYAAOAAAADwAAAAAAEAABABAAAgAQAAMAEAAEABAABQAQAAYAEAAAgAAAAABAAAQcXYl1aMfVQYAAAAAQIAAAEAAAAAAAAADwAAAAAAAAAAAAAAAAAAAAgAAAAEAwAABwAAAAAAAAAEAAAAAwMAAPUBAAAIAAAAAQkAAGZpbGU6Ly8vDAAAAAEBAABNYWNpbnRvc2ggSEQIAAAABAMAAACQgpbnAAAACAAAAAAEAABBxfHLKgAAACQAAAABAQAAMDlCN0VBQkUtNjc5NS00Q0RGLUFCMjQtM0ZGMDg1NjVEMDE2GAAAAAECAACBAAAAAQAAAO8TAAABAAAAAAAAAAAAAAABAAAAAQEAAC8AAAAAAAAAAQUAABkBAAABAgAANDQzY2JjOTA0ODI5ZjBkNGE4OGZjMThmODBiZGExM2FjOGZiZDc3ZGVjMDM1NWI4MDExNjQwNDMyZjlkNmNkMDswMDswMDAwMDAwMDswMDAwMDAwMDswMDAwMDAwMDswMDAwMDAwMDAwMDAwMDIwO2NvbS5hcHBsZS5hcHAtc2FuZGJveC5yZWFkLXdyaXRlOzAxOzAxMDAwMDEwOzAwMDAwMDAwMDJlMGY1ZDk7MDE7L3VzZXJzL21jcm93bGV5L2Ryb3Bib3gvYXBwcy9yZW1vdGVseS1zYXZlL2FpdG9waWNzL2Fzc2V0cy9wZGYvdG9tYXNpazIwMTQtYXJ0aWZpY2lhbC1yZWluZm9yY2VtZW50LnBkZgAAAADMAAAA/v///wEAAAAAAAAAEAAAAAQQAAC0AAAAAAAAAAUQAABwAQAAAAAAABAQAACsAQAAAAAAAEAQAACcAQAAAAAAAAIgAAB4AgAAAAAAAAUgAADoAQAAAAAAABAgAAD4AQAAAAAAABEgAAAsAgAAAAAAABIgAAAMAgAAAAAAABMgAAAcAgAAAAAAACAgAABYAgAAAAAAADAgAACEAgAAAAAAAAHAAADMAQAAAAAAABHAAAAUAAAAAAAAABLAAADcAQAAAAAAAIDwAACMAgAAAAAAAAAIAA0AGgAjAIYAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAFPg==}}

@incollection{haas2022dnhni_pdf,
	date-added = {2024-03-25 00:09:07 -0400},
	date-modified = {2024-03-25 00:17:21 -0400},
	keywords = {ai-morality},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEEkuLi8uLi8uLi9Ecm9wYm94L0FwcHMvcmVtb3RlbHktc2F2ZS9BSVRvcGljcy9hc3NldHMvcGRmL2hhYXMyMDIyZG5obmkucGRmTxEEiGJvb2uIBAAAAAAEEDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIQDAAAFAAAAAQEAAFVzZXJzAAAACAAAAAEBAABtY3Jvd2xleQcAAAABAQAARHJvcGJveAAEAAAAAQEAAEFwcHMNAAAAAQEAAHJlbW90ZWx5LXNhdmUAAAAIAAAAAQEAAEFJVG9waWNzBgAAAAEBAABhc3NldHMAAAMAAAABAQAAcGRmABEAAAABAQAAaGFhczIwMjJkbmhuaS5wZGYAAAAkAAAAAQYAAAQAAAAUAAAAJAAAADQAAABAAAAAWAAAAGgAAAB4AAAAhAAAAAgAAAAEAwAAFV0AAAAAAAAIAAAABAMAADnoAwAAAAAACAAAAAQDAABfdQQAAAAAAAgAAAAEAwAA0Y4EAAAAAAAIAAAABAMAABBRdAIAAAAACAAAAAQDAACeFucCAAAAAAgAAAAEAwAANc/gAgAAAAAIAAAABAMAADbP4AIAAAAACAAAAAQDAADh9eACAAAAACQAAAABBgAAzAAAANwAAADsAAAA/AAAAAwBAAAcAQAALAEAADwBAABMAQAACAAAAAAEAABBxdiXVo7VlBgAAAABAgAAAQAAAAAAAAAPAAAAAAAAAAAAAAAAAAAACAAAAAQDAAAHAAAAAAAAAAQAAAADAwAA9QEAAAgAAAABCQAAZmlsZTovLy8MAAAAAQEAAE1hY2ludG9zaCBIRAgAAAAEAwAAAJCClucAAAAIAAAAAAQAAEHF8csqAAAAJAAAAAEBAAAwOUI3RUFCRS02Nzk1LTRDREYtQUIyNC0zRkYwODU2NUQwMTYYAAAAAQIAAIEAAAABAAAA7xMAAAEAAAAAAAAAAAAAAAEAAAABAQAALwAAAAAAAAABBQAAAgEAAAECAAAzMTYxZDMzMzNiZjc1ZDhjYWY2OTQyNDc3NDdhNDE3Mzk3YjZmMjY1MGFjOTdiMWY5NTM5N2MwMWJjMzc5YzE1OzAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwMDAwMDAwMjA7Y29tLmFwcGxlLmFwcC1zYW5kYm94LnJlYWQtd3JpdGU7MDE7MDEwMDAwMTA7MDAwMDAwMDAwMmUwZjVlMTswMTsvdXNlcnMvbWNyb3dsZXkvZHJvcGJveC9hcHBzL3JlbW90ZWx5LXNhdmUvYWl0b3BpY3MvYXNzZXRzL3BkZi9oYWFzMjAyMmRuaG5pLnBkZgAAAMwAAAD+////AQAAAAAAAAAQAAAABBAAAKAAAAAAAAAABRAAAFwBAAAAAAAAEBAAAJgBAAAAAAAAQBAAAIgBAAAAAAAAAiAAAGQCAAAAAAAABSAAANQBAAAAAAAAECAAAOQBAAAAAAAAESAAABgCAAAAAAAAEiAAAPgBAAAAAAAAEyAAAAgCAAAAAAAAICAAAEQCAAAAAAAAMCAAAHACAAAAAAAAAcAAALgBAAAAAAAAEcAAABQAAAAAAAAAEsAAAMgBAAAAAAAAgPAAAHgCAAAAAAAAAAgADQAaACMAbwAAAAAAAAIBAAAAAAAAAAUAAAAAAAAAAAAAAAAAAAT7}}

@unpublished{ghojogh2020osfpreprint,
	abstract = {This is a tutorial and survey paper on the attention mechanism, transformers, BERT, and GPT. We first explain attention mechanism, sequence-to-sequence model without and with attention, self-attention, and attention in different areas such as natural language processing and computer vision. Then, we explain transformers which do not use any recurrence. We explain all the parts of encoder and decoder in the transformer, including positional encoding, multihead self-attention and cross-attention, and masked multihead attention. Thereafter, we introduce the Bidirectional Encoder Representations from Transformers (BERT) and Generative Pre-trained Transformer (GPT) as the stacks of encoders and decoders of transformer, respectively. We explain their characteristics and how they work.},
	author = {Benyamin Ghojogh and Ali Ghodsi},
	cited-by = {https://paperswithcode.com/paper/attention-mechanism-transformers-bert-and-gpt},
	date-added = {2024-03-24 23:37:59 -0400},
	date-discussed = {2023-05-24 led by Benyamin Ghojogh},
	date-modified = {2024-07-24 11:43:47 -0400},
	doi = {https://osf.io/m6gcn},
	howpublished = {preprint},
	in-website = {1},
	keywords = {done, machine-learning, transformer, nlp, recurrent-neural-networks, lstm; rdgrp-s23},
	month = {December},
	order = {1},
	pdf = {2020-osfpreprin-ghojogh-attention},
	status = {1},
	title = {Attention Mechanism, Transformers, BERT, and GPT: Tutorial and Survey},
	toread = {1},
	url = {https://osf.io/m6gcn},
	venue-short = {osfpreprint},
	year = {2020},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEFIuLi8uLi8uLi9Ecm9wYm94L0FwcHMvcmVtb3RlbHktc2F2ZS9BSVRvcGljcy9hc3NldHMvcGRmL2dob2pvZ2gyMDIwb3NmcHJlcHJpbnQucGRmTxEEmGJvb2uYBAAAAAAEEDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJQDAAAFAAAAAQEAAFVzZXJzAAAACAAAAAEBAABtY3Jvd2xleQcAAAABAQAARHJvcGJveAAEAAAAAQEAAEFwcHMNAAAAAQEAAHJlbW90ZWx5LXNhdmUAAAAIAAAAAQEAAEFJVG9waWNzBgAAAAEBAABhc3NldHMAAAMAAAABAQAAcGRmABoAAAABAQAAZ2hvam9naDIwMjBvc2ZwcmVwcmludC5wZGYAACQAAAABBgAABAAAABQAAAAkAAAANAAAAEAAAABYAAAAaAAAAHgAAACEAAAACAAAAAQDAAAVXQAAAAAAAAgAAAAEAwAAOegDAAAAAAAIAAAABAMAAF91BAAAAAAACAAAAAQDAADRjgQAAAAAAAgAAAAEAwAAEFF0AgAAAAAIAAAABAMAAJ4W5wIAAAAACAAAAAQDAAA1z+ACAAAAAAgAAAAEAwAANs/gAgAAAAAIAAAABAMAADRY3QIAAAAAJAAAAAEGAADUAAAA5AAAAPQAAAAEAQAAFAEAACQBAAA0AQAARAEAAFQBAAAIAAAAAAQAAEHF06TRgAAAGAAAAAECAAABAAAAAAAAAA8AAAAAAAAAAAAAAAAAAAAIAAAABAMAAAcAAAAAAAAABAAAAAMDAAD1AQAACAAAAAEJAABmaWxlOi8vLwwAAAABAQAATWFjaW50b3NoIEhECAAAAAQDAAAAkIKW5wAAAAgAAAAABAAAQcXxyyoAAAAkAAAAAQEAADA5QjdFQUJFLTY3OTUtNENERi1BQjI0LTNGRjA4NTY1RDAxNhgAAAABAgAAgQAAAAEAAADvEwAAAQAAAAAAAAAAAAAAAQAAAAEBAAAvAAAAAAAAAAEFAAALAQAAAQIAAGZiZWQyOWExNGYyODdlZDE1MmUyZGQ0NTI4MzAyY2NlMWJkZWVlMmE2NzI3OWU5MWE2YzIwNjgyNDMwYWE5MjQ7MDA7MDAwMDAwMDA7MDAwMDAwMDA7MDAwMDAwMDA7MDAwMDAwMDAwMDAwMDAyMDtjb20uYXBwbGUuYXBwLXNhbmRib3gucmVhZC13cml0ZTswMTswMTAwMDAxMDswMDAwMDAwMDAyZGQ1ODM0OzAxOy91c2Vycy9tY3Jvd2xleS9kcm9wYm94L2FwcHMvcmVtb3RlbHktc2F2ZS9haXRvcGljcy9hc3NldHMvcGRmL2dob2pvZ2gyMDIwb3NmcHJlcHJpbnQucGRmAADMAAAA/v///wEAAAAAAAAAEAAAAAQQAACoAAAAAAAAAAUQAABkAQAAAAAAABAQAACgAQAAAAAAAEAQAACQAQAAAAAAAAIgAABsAgAAAAAAAAUgAADcAQAAAAAAABAgAADsAQAAAAAAABEgAAAgAgAAAAAAABIgAAAAAgAAAAAAABMgAAAQAgAAAAAAACAgAABMAgAAAAAAADAgAAB4AgAAAAAAAAHAAADAAQAAAAAAABHAAAAUAAAAAAAAABLAAADQAQAAAAAAAIDwAACAAgAAAAAAAAAIAA0AGgAjAHgAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAFFA==}}

@inproceedings{yang2020acmikm,
	address = {{Virtual Event Ireland}},
	annotation = {ACM-IKM},
	annote = {We did not get to this paper in the Spring 2023 reading group.},
	author = {Yang, Liu and Zhang, Mingyang and Li, Cheng and Bendersky, Michael and Najork, Marc},
	booktitle = {Proceedings of the 29th {{ACM International Conference}} on {{Information}} \& {{Knowledge Management}}},
	date-added = {2024-03-24 23:37:48 -0400},
	date-modified = {2024-03-24 23:37:48 -0400},
	doi = {10.1145/3340531.3411908},
	in-website = {1},
	isbn = {978-1-4503-6859-9},
	keywords = {NLP,siamese,transformers; potential},
	langid = {english},
	month = oct,
	pages = {1725--1734},
	publisher = {{ACM}},
	status = {1},
	title = {Beyond 512 {{Tokens}}: {{Siamese Multi-depth Transformer-based Hierarchical Encoder}} for {{Long-Form Document Matching}}},
	toread = {1},
	urldate = {2021-02-25},
	venue-short = {acmikm},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1145/3340531.3411908}}

@inproceedings{igl2022icra,
	annote = {We did not get to this paper in the Spring 2023 reading group.},
	author = {Igl, Maximilian and Kim, Daewoo and Kuefler, Alex and Mougin, Paul and Shah, Punit and Shiarlis, Kyriacos and Anguelov, Dragomir and Palatucci, Mark and White, Brandyn and Whiteson, Shimon},
	booktitle = {International Conference on Robotics and Automation (ICRA)},
	date-added = {2024-03-24 23:36:46 -0400},
	date-modified = {2024-03-25 01:51:46 -0400},
	doi = {https://ieeexplore.ieee.org/document/9811990},
	event = {ICRA},
	in-website = {1},
	keywords = {autonomous-driving, machine-learning; potential},
	pages = {2445-2451},
	status = {1},
	title = {Symphony: Learning Realistic and Diverse Agents for Autonomous Driving Simulation},
	titleshort = {Symphony},
	toread = {1},
	venue-short = {ICRA},
	year = {2022},
	bdsk-url-1 = {https://doi.org/10.1109/ICRA46639.2022.9811990},
	bdsk-url-2 = {https://arxiv.org/abs/2205.03195}}

@inproceedings{theile2020ieeersj,
	annotation = {IROS},
	annote = {We did not get to this paper in the Spring 2023 reading group.},
	author = {Theile, Mirco and Bayerlein, Harald and Nai, Richard and Gesbert, David and Caccamo, Marco},
	booktitle = {2020 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
	date-added = {2024-03-24 23:36:46 -0400},
	date-modified = {2024-03-24 23:36:46 -0400},
	in-website = {1},
	keywords = {potential},
	pages = {1444--1449},
	publisher = {{IEEE}},
	status = {1},
	title = {{{UAV}} Coverage Path Planning under Varying Power Constraints Using Deep Reinforcement Learning},
	toread = {1},
	venue-short = {IEEERSJ},
	year = {2020}}

@article{thoppilan2022arxiv,
	annote = {Facebook enters the ring...},
	archiveprefix = {arXiv},
	author = {Romal Thoppilan and Daniel De Freitas and Jamie Hall and Noam Shazeer and Apoorv Kulshreshtha and Heng-Tze Cheng and Alicia Jin and Taylor Bos and Leslie Baker and Yu Du and YaGuang Li and Hongrae Lee and Huaixiu Steven Zheng and Amin Ghafouri and Marcelo Menegali and Yanping Huang and Maxim Krikun and Dmitry Lepikhin and James Qin and Dehao Chen and Yuanzhong Xu and Zhifeng Chen and Adam Roberts and Maarten Bosma and Vincent Zhao and Yanqi Zhou and Chung-Ching Chang and Igor Krivokon and Will Rusch and Marc Pickett and Pranesh Srinivasan and Laichee Man and Kathleen Meier-Hellstern and Meredith Ringel Morris and Tulsee Doshi and Renelito Delos Santos and Toju Duke and Johnny Soraker and Ben Zevenbergen and Vinodkumar Prabhakaran and Mark Diaz and Ben Hutchinson and Kristen Olson and Alejandra Molina and Erin Hoffman-John and Josh Lee and Lora Aroyo and Ravi Rajakumar and Alena Butryna and Matthew Lamm and Viktoriya Kuzmina and Joe Fenton and Aaron Cohen and Rachel Bernstein and Ray Kurzweil and Blaise Aguera-Arcas and Claire Cui and Marian Croak and Ed Chi and Quoc Le},
	date-added = {2024-03-24 23:36:46 -0400},
	date-discussed = {2023-7-12 led by Delin},
	date-modified = {2024-07-24 11:43:47 -0400},
	eprint = {2201.08239},
	in-website = {1},
	journal = {Arxiv Preprint},
	keywords = {done; transformers; large-language-models; gpt; rdgrp-s23},
	order = {6},
	pdf = {2022-arxiv-thoppilan-lamda},
	primaryclass = {cs.CL},
	title = {LaMDA: Language Models for Dialog Applications},
	toread = {1},
	venue-short = {arxiv},
	year = {2022},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxBKLi4vLi4vLi4vLi4vcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi8yMDIyLWFyeGl2LXRob3BwaWxhbi1sYW1kYS5wZGZPEQG0AAAAAAG0AAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAAAAAAAAQkQAAf////8eMjAyMi1hcnhpdi10aG9wcGlsYW4tbGFtZGEucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/////wAAAAAAAAAAAAAAAAAEAAUAAAogY3UAAAAAAAAAAAAAAAAAA3BkZgAAAgBPLzpVc2VyczptY3Jvd2xleTpyZXBvczptYXJrY3Jvd2xleS1jYTphc3NldHM6cGRmOjIwMjItYXJ4aXYtdGhvcHBpbGFuLWxhbWRhLnBkZgAADgA+AB4AMgAwADIAMgAtAGEAcgB4AGkAdgAtAHQAaABvAHAAcABpAGwAYQBuAC0AbABhAG0AZABhAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBNVXNlcnMvbWNyb3dsZXkvcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi8yMDIyLWFyeGl2LXRob3BwaWxhbi1sYW1kYS5wZGYAABMAAS8AABUAAgAP//8AAAAIAA0AGgAkAHEAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAACKQ==}}

@inproceedings{gpt2,
	abstract = {Natural language processing tasks, such as question answering, machine translation, reading comprehension, and summarization, are typically approached with supervised learning on taskspecific datasets. We demonstrate that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of millions of webpages called WebText. When conditioned on a document plus questions, the answers generated by the language model reach 55 F1 on the CoQA dataset matching or exceeding the performance of 3 out of 4 baseline systems without using the 127,000+ training examples. The capacity of the language model is essential to the success of zero-shot task transfer and increasing it improves performance in a log-linear fashion across tasks. Our largest model, GPT-2, is a 1.5B parameter Transformer that achieves state of the art results on 7 out of 8 tested language modeling datasets in a zero-shot setting but still underfits WebText. Samples from the model reflect these improvements and contain coherent paragraphs of text. These findings suggest a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations. },
	author = {Alec Radford and Jeff Wu and Rewon Child and David Luan and Dario Amodei and Ilya Sutskever},
	date-added = {2024-03-24 23:35:53 -0400},
	date-discussed = {2023-06-28 led by Felix},
	date-modified = {2024-07-24 11:43:47 -0400},
	hypoth = {https://hyp.is/go?url=https%3A%2F%2Fd4mucfpksywv.cloudfront.net%2Fbetter-language-models%2Flanguage-models.pdf&group=__world__},
	keywords = {done; transformers; large-language-models; gpt; rdgrp-s23},
	order = {5},
	pdf = {2019-arxiv-radford-language},
	title = {Language Models are Unsupervised Multitask Learners},
	url = {https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf},
	venue-short = {arxiv},
	year = {2019},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxBLLi4vLi4vLi4vLi4vcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi8yMDE5LWFyeGl2LXJhZGZvcmQtbGFuZ3VhZ2UucGRmTxEBtgAAAAABtgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAAAAAAEJEAAH/////HzIwMTktYXJ4aXYtcmFkZm9yZC1sYW5ndWFnZS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP////8AAAAAAAAAAAAAAAAABAAFAAAKIGN1AAAAAAAAAAAAAAAAAANwZGYAAAIAUC86VXNlcnM6bWNyb3dsZXk6cmVwb3M6bWFya2Nyb3dsZXktY2E6YXNzZXRzOnBkZjoyMDE5LWFyeGl2LXJhZGZvcmQtbGFuZ3VhZ2UucGRmAA4AQAAfADIAMAAxADkALQBhAHIAeABpAHYALQByAGEAZABmAG8AcgBkAC0AbABhAG4AZwB1AGEAZwBlAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBOVXNlcnMvbWNyb3dsZXkvcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi8yMDE5LWFyeGl2LXJhZGZvcmQtbGFuZ3VhZ2UucGRmABMAAS8AABUAAgAP//8AAAAIAA0AGgAkAHIAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAACLA==},
	bdsk-url-1 = {https://paperswithcode.com/paper/language-models-are-unsupervised-multitask},
	bdsk-url-2 = {https://www.semanticscholar.org/paper/Language-Models-are-Unsupervised-Multitask-Learners-Radford-Wu/9405cc0d6169988371b2755e573cc28650d14dfe}}

@article{lewis2019arxiv,
	annote = {This paper builds on the success of BERT but maintaining full encoder-decoder framework.},
	author = {Lewis, Mike and Liu, Yinhan and Goyal, Naman and Ghazvininejad, Marjan and Mohamed, Abdelrahman and Levy, Omer and Stoyanov, Ves and Zettlemoyer, Luke},
	date-added = {2024-03-24 23:35:53 -0400},
	date-modified = {2024-07-24 11:43:47 -0400},
	in-website = {1},
	journal = {arXiv preprint arXiv:1910.13461},
	keywords = {done; transformers; large-language-models; BERT; rdgrp-s23},
	order = {5},
	pdf = {2019-arxiv-lewis-bart},
	title = {Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension},
	toread = {1},
	venue-short = {arxiv},
	year = {2019},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxBFLi4vLi4vLi4vLi4vcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi8yMDE5LWFyeGl2LWxld2lzLWJhcnQucGRmTxEBngAAAAABngACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAAAAAAEJEAAH/////GTIwMTktYXJ4aXYtbGV3aXMtYmFydC5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP////8AAAAAAAAAAAAAAAAABAAFAAAKIGN1AAAAAAAAAAAAAAAAAANwZGYAAAIASi86VXNlcnM6bWNyb3dsZXk6cmVwb3M6bWFya2Nyb3dsZXktY2E6YXNzZXRzOnBkZjoyMDE5LWFyeGl2LWxld2lzLWJhcnQucGRmAA4ANAAZADIAMAAxADkALQBhAHIAeABpAHYALQBsAGUAdwBpAHMALQBiAGEAcgB0AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBIVXNlcnMvbWNyb3dsZXkvcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi8yMDE5LWFyeGl2LWxld2lzLWJhcnQucGRmABMAAS8AABUAAgAP//8AAAAIAA0AGgAkAGwAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAACDg==}}

@article{liu2019,
	abstract = {Language model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes, and, as we will show, hyperparameter choices have significant impact on the final results. We present a replication study of BERT pretraining (Devlin et al., 2019) that carefully measures the impact of many key hyperparameters and training data size. We find that BERT was significantly undertrained, and can match or exceed the performance of every model published after it. Our best model achieves state-of-the-art results on GLUE, RACE and SQuAD. These results highlight the importance of previously overlooked design choices, and raise questions about the source of recently reported improvements. We release our models and code.},
	annote = {Where does the annotation show up? anywhere?},
	author = {Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and Mike Lewis and Luke Zettlemoyer and Veselin Stoyanov},
	date-added = {2024-03-24 23:35:53 -0400},
	date-discussed = {2023-06-21 led by Mark Crowley},
	date-modified = {2024-07-24 11:43:47 -0400},
	eprint = {1907.11692},
	hypothesis = {https://hyp.is/go?url=https%3A%2F%2Farxiv.org%2Fpdf%2F1907.11692.pdf&group=__world__},
	in-website = {1},
	keywords = {done, transformers, BERT, large-language-models; rdgrp-s23},
	month = {07},
	order = {3},
	pdf = {2019-arxiv-liu-roberta.pdf},
	seminal = {1},
	status = {1},
	title = {RoBERTa: A Robustly Optimized BERT Pretraining Approach},
	toread = {1},
	url = {https://arxiv.org/pdf/1907.11692.pdf},
	venue-short = {arxiv},
	year = {2019},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxBGLi4vLi4vLi4vLi4vcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi8yMDE5LWFyeGl2LWxpdS1yb2JlcnRhLnBkZk8RAaQAAAAAAaQAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAAAAAABCRAAB/////xoyMDE5LWFyeGl2LWxpdS1yb2JlcnRhLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/////AAAAAAAAAAAAAAAAAAQABQAACiBjdQAAAAAAAAAAAAAAAAADcGRmAAACAEsvOlVzZXJzOm1jcm93bGV5OnJlcG9zOm1hcmtjcm93bGV5LWNhOmFzc2V0czpwZGY6MjAxOS1hcnhpdi1saXUtcm9iZXJ0YS5wZGYAAA4ANgAaADIAMAAxADkALQBhAHIAeABpAHYALQBsAGkAdQAtAHIAbwBiAGUAcgB0AGEALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAElVc2Vycy9tY3Jvd2xleS9yZXBvcy9tYXJrY3Jvd2xleS1jYS9hc3NldHMvcGRmLzIwMTktYXJ4aXYtbGl1LXJvYmVydGEucGRmAAATAAEvAAAVAAIAD///AAAACAANABoAJABtAAAAAAAAAgEAAAAAAAAABQAAAAAAAAAAAAAAAAAAAhU=},
	bdsk-url-1 = {https://arxiv.org/pdf/1907.11692.pdf},
	bdsk-url-2 = {https://arxiv.org/abs/1907.11692},
	bdsk-url-3 = {https://openreview.net/forum?id=SyxS0T4tvS}}

@inproceedings{mahendran2022acmwww,
	abstract = {Extracting information regarding novel chemicals and chemical reactions from chemical patents plays a vital role in the chemical and pharmaceutical industry. Due to the increasing volume of chemical patents, there is an urgent need for automated solutions to extract relations between chemical compounds. Several studies have used models that apply attention mechanisms such as Bidirectional Encoder Representations from Transformers (BERT) to capture the contextual information within a text. However, these models do not capture the global information about a specific vocabulary. On the other hand, Graph Convolutional Networks (GCNs) capture global dependencies between terms within a corpus but not the local contextual information. In this work, we propose two novel approaches, GCN-Vanilla and GCN-BERT, for chemical relation extraction. GCN-Vanilla approach builds a single graph for the whole corpus based on word co-occurrence and sentence-word relations. Then, we model the graph with GCN to capture the global information and classify the sentence nodes. GCN-BERT approach combines GCN and BERT to capture both global and local information, and build together a final representation for relation extraction. We evaluate our approaches on the CLEF-2020 dataset. Our results show the combined GCN-BERT approach outperforms standalone BERT and GCN models, and achieves a higher F1 than that reported in our previous studies.},
	address = {{New York, NY, USA}},
	annote = {We did not get to this paper in the Spring 2023 reading group.},
	author = {Mahendran, Darshini and Tang, Christina and McInnes, Bridget T.},
	booktitle = {Companion {{Proceedings}} of the {{Web Conference}} 2022},
	date-added = {2024-03-24 23:35:53 -0400},
	date-modified = {2024-03-24 23:35:53 -0400},
	doi = {10.1145/3487553.3524702},
	in-website = {1},
	isbn = {978-1-4503-9130-6},
	keywords = {BERT,chemical natural language processing,graph convolutional neural networks,relation extraction, potential},
	month = apr,
	pages = {833--842},
	publisher = {{Association for Computing Machinery}},
	series = {{{WWW}} '22},
	status = {1},
	title = {Graph {{Convolutional Networks}} for {{Chemical Relation Extraction}}},
	toread = {1},
	urldate = {2022-09-26},
	venue-short = {ACMWWW},
	year = {2022},
	bdsk-url-1 = {https://doi.org/10.1145/3487553.3524702}}

@article{radfordopenai,
	annote = {The founding paper for GPT 1.0 posted online as a preprint.},
	author = {Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
	date-added = {2024-03-24 23:35:53 -0400},
	date-discussed = {2023-06-14 led by Hao Pu},
	date-modified = {2024-07-24 11:43:47 -0400},
	in-website = {1},
	journal = {Preprint},
	keywords = {transformers, gpt, openai, nlp, large-language-models, done; rdgrp-s23},
	local-url = {2018-openai-radford-improving},
	order = {3},
	paperdesc = {The original paper for the GPT 1.0 model.},
	pdf = {2018-openai-radford-improving},
	read = {1},
	title = {Improving Language Understanding by Generative Pre-Training},
	toread = {0},
	venue-short = {openai},
	year = {2018},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxBNLi4vLi4vLi4vLi4vcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi8yMDE4LW9wZW5haS1yYWRmb3JkLWltcHJvdmluZy5wZGZPEQG+AAAAAAG+AAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAAAAAAAAQkQAAf////8fMjAxOC1vcGVuYWktcmFkZm9yI0ZGRkZGRkZGLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/////wAAAAAAAAAAAAAAAAAEAAUAAAogY3UAAAAAAAAAAAAAAAAAA3BkZgAAAgBSLzpVc2VyczptY3Jvd2xleTpyZXBvczptYXJrY3Jvd2xleS1jYTphc3NldHM6cGRmOjIwMTgtb3BlbmFpLXJhZGZvcmQtaW1wcm92aW5nLnBkZgAOAEQAIQAyADAAMQA4AC0AbwBwAGUAbgBhAGkALQByAGEAZABmAG8AcgBkAC0AaQBtAHAAcgBvAHYAaQBuAGcALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAFBVc2Vycy9tY3Jvd2xleS9yZXBvcy9tYXJrY3Jvd2xleS1jYS9hc3NldHMvcGRmLzIwMTgtb3BlbmFpLXJhZGZvcmQtaW1wcm92aW5nLnBkZgATAAEvAAAVAAIAD///AAAACAANABoAJAB0AAAAAAAAAgEAAAAAAAAABQAAAAAAAAAAAAAAAAAAAjY=},
	bdsk-file-2 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxBXLi4vLi4vLi4vLi4vcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi8yMDE4LW9wZW5haS1yYWRmb3JkLWltcHJvdmluZy1hbm5vdGF0ZWQucGRmTxEB5gAAAAAB5gACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAAAAAAEJEAAH/////HzIwMTgtb3BlbmFpLXJhZGZvciNGRkZGRkZGRi5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP////8AAAAAAAAAAAAAAAAABAAFAAAKIGN1AAAAAAAAAAAAAAAAAANwZGYAAAIAXC86VXNlcnM6bWNyb3dsZXk6cmVwb3M6bWFya2Nyb3dsZXktY2E6YXNzZXRzOnBkZjoyMDE4LW9wZW5haS1yYWRmb3JkLWltcHJvdmluZy1hbm5vdGF0ZWQucGRmAA4AWAArADIAMAAxADgALQBvAHAAZQBuAGEAaQAtAHIAYQBkAGYAbwByAGQALQBpAG0AcAByAG8AdgBpAG4AZwAtAGEAbgBuAG8AdABhAHQAZQBkAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBaVXNlcnMvbWNyb3dsZXkvcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi8yMDE4LW9wZW5haS1yYWRmb3JkLWltcHJvdmluZy1hbm5vdGF0ZWQucGRmABMAAS8AABUAAgAP//8AAAAIAA0AGgAkAH4AAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAACaA==},
	bdsk-file-3 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxBeLi4vLi4vLi4vLi4vcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi8yMDE4LW9wZW5haS1yYWRmb3JkLWltcHJvdmluZy1hbm5vdGF0ZWQtZXhwb3J0LnBkZk8RAgQAAAAAAgQAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAAAAAABCRAAB/////x8yMDE4LW9wZW5haS1yYWRmb3IjRkZGRkZGRkYucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/////AAAAAAAAAAAAAAAAAAQABQAACiBjdQAAAAAAAAAAAAAAAAADcGRmAAACAGMvOlVzZXJzOm1jcm93bGV5OnJlcG9zOm1hcmtjcm93bGV5LWNhOmFzc2V0czpwZGY6MjAxOC1vcGVuYWktcmFkZm9yZC1pbXByb3ZpbmctYW5ub3RhdGVkLWV4cG9ydC5wZGYAAA4AZgAyADIAMAAxADgALQBvAHAAZQBuAGEAaQAtAHIAYQBkAGYAbwByAGQALQBpAG0AcAByAG8AdgBpAG4AZwAtAGEAbgBuAG8AdABhAHQAZQBkAC0AZQB4AHAAbwByAHQALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAGFVc2Vycy9tY3Jvd2xleS9yZXBvcy9tYXJrY3Jvd2xleS1jYS9hc3NldHMvcGRmLzIwMTgtb3BlbmFpLXJhZGZvcmQtaW1wcm92aW5nLWFubm90YXRlZC1leHBvcnQucGRmAAATAAEvAAAVAAIAD///AAAACAANABoAJACFAAAAAAAAAgEAAAAAAAAABQAAAAAAAAAAAAAAAAAAAo0=}}

@article{shanahan2022arxiv,
	abstract = {Thanks to rapid progress in artificial intelligence, we have entered an era when technology and philosophy intersect in interesting ways. Sitting squarely at the centre of this intersection are large language models (LLMs). The more adept LLMs become at mimicking human language, the more vulnerable we become to anthropomorphism, to seeing the systems in which they are embedded as more human-like than they really are. This trend is amplified by the natural tendency to use philosophically loaded terms, such as "knows", "believes", and "thinks", when describing these systems. To mitigate this trend, this paper advocates the practice of repeatedly stepping back to remind ourselves of how LLMs, and the systems of which they form a part, actually work. The hope is that increased scientific precision will encourage more philosophical nuance in the discourse around artificial intelligence, both within the field and in the public sphere.},
	arxiv = {2212.03551},
	author = {Murray Shanahan},
	date-added = {2024-03-24 23:35:53 -0400},
	date-modified = {2024-07-24 11:43:47 -0400},
	eprint = {2212.03551},
	in-website = {1},
	journal = {Arxiv Preprint},
	keywords = {potential; rdgrp-s23},
	month = {12},
	order = {9},
	pdf = {2022-arxiv-shanahan-talking},
	title = {Talking About Large Language Models},
	toread = {1},
	url = {https://arxiv.org/pdf/2212.03551.pdf},
	venue-short = {arxiv},
	year = {2022},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxBLLi4vLi4vLi4vLi4vcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi8yMDIyLWFyeGl2LXNoYW5haGFuLXRhbGtpbmcucGRmTxEBtgAAAAABtgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAAAAAAEJEAAH/////HzIwMjItYXJ4aXYtc2hhbmFoYW4tdGFsa2luZy5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP////8AAAAAAAAAAAAAAAAABAAFAAAKIGN1AAAAAAAAAAAAAAAAAANwZGYAAAIAUC86VXNlcnM6bWNyb3dsZXk6cmVwb3M6bWFya2Nyb3dsZXktY2E6YXNzZXRzOnBkZjoyMDIyLWFyeGl2LXNoYW5haGFuLXRhbGtpbmcucGRmAA4AQAAfADIAMAAyADIALQBhAHIAeABpAHYALQBzAGgAYQBuAGEAaABhAG4ALQB0AGEAbABrAGkAbgBnAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBOVXNlcnMvbWNyb3dsZXkvcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi8yMDIyLWFyeGl2LXNoYW5haGFuLXRhbGtpbmcucGRmABMAAS8AABUAAgAP//8AAAAIAA0AGgAkAHIAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAACLA==},
	bdsk-file-2 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxBdLi4vLi4vLi4vLi4vcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi8yMDIyLWFyeGl2LXNoYW5haGFuLXRhbGtpbmctYW5ub3RhdGVkMjAyMzA2MTIucGRmTxEB/gAAAAAB/gACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAAAAAAEJEAAH/////HzIwMjItYXJ4aXYtc2hhbmFoYSNGRkZGRkZGRi5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP////8AAAAAAAAAAAAAAAAABAAFAAAKIGN1AAAAAAAAAAAAAAAAAANwZGYAAAIAYi86VXNlcnM6bWNyb3dsZXk6cmVwb3M6bWFya2Nyb3dsZXktY2E6YXNzZXRzOnBkZjoyMDIyLWFyeGl2LXNoYW5haGFuLXRhbGtpbmctYW5ub3RhdGVkMjAyMzA2MTIucGRmAA4AZAAxADIAMAAyADIALQBhAHIAeABpAHYALQBzAGgAYQBuAGEAaABhAG4ALQB0AGEAbABrAGkAbgBnAC0AYQBuAG4AbwB0AGEAdABlAGQAMgAwADIAMwAwADYAMQAyAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBgVXNlcnMvbWNyb3dsZXkvcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi8yMDIyLWFyeGl2LXNoYW5haGFuLXRhbGtpbmctYW5ub3RhdGVkMjAyMzA2MTIucGRmABMAAS8AABUAAgAP//8AAAAIAA0AGgAkAIQAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAChg==},
	bdsk-url-1 = {https://arxiv.org/pdf/2212.03551.pdf},
	bdsk-url-2 = {https://arxiv.org/abs/2212.03551}}

@inproceedings{tay2021acl,
	abstract = {In the era of pre-trained language models, Transformers are the de facto choice of model architectures. While recent research has shown promise in entirely convolutional, or CNN, architectures, they have not been explored using the pre-train-fine-tune paradigm. In the context of language models, are convolutional models competitive to Transformers when pre-trained? This paper investigates this research question and presents several interesting findings. Across an extensive set of experiments on 8 datasets/tasks, we find that CNN-based pre-trained models are competitive and outperform their Transformer counterpart in certain scenarios, albeit with caveats. Overall, the findings outlined in this paper suggest that conflating pre-training and architectural advances is misguided and that both advances should be considered independently. We believe our research paves the way for a healthy amount of optimism in alternative architectures.},
	address = {Online.},
	author = {Tay, Yi and Dehghani, Mostafa and Gupta, Jai Prakash and Aribandi, Vamsi and Bahri, Dara and Qin, Zhen and Metzler, Donald},
	booktitle = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
	date-added = {2024-03-24 23:35:53 -0400},
	date-discussed = {2023-07-05 led by Mark Crowley},
	date-modified = {2024-07-24 11:43:47 -0400},
	doi = {10.18653/v1/2021.acl-long.335},
	eprint = {2105.03322},
	hypoth = {https://hyp.is/go?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2105.03322.pdf&group=__world__},
	keywords = {done; transformers; deep-learning; rdgrp-s23},
	month = August,
	order = {7},
	pages = {4349--4359},
	pdf = {2021-acl-tay-are pretrained},
	publisher = {Association for Computational Linguistics},
	title = {Are Pretrained Convolutions Better than Pretrained Transformers?},
	url = {https://aclanthology.org/2021.acl-long.335},
	venue-short = {ACL},
	year = {2021},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxBLLi4vLi4vLi4vLi4vcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi8yMDIxLWFjbC10YXktYXJlIHByZXRyYWluZWQucGRmTxEBtgAAAAABtgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAAAAAAEJEAAH/////HzIwMjEtYWNsLXRheS1hcmUgcHJldHJhaW5lZC5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP////8AAAAAAAAAAAAAAAAABAAFAAAKIGN1AAAAAAAAAAAAAAAAAANwZGYAAAIAUC86VXNlcnM6bWNyb3dsZXk6cmVwb3M6bWFya2Nyb3dsZXktY2E6YXNzZXRzOnBkZjoyMDIxLWFjbC10YXktYXJlIHByZXRyYWluZWQucGRmAA4AQAAfADIAMAAyADEALQBhAGMAbAAtAHQAYQB5AC0AYQByAGUAIABwAHIAZQB0AHIAYQBpAG4AZQBkAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBOVXNlcnMvbWNyb3dsZXkvcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi8yMDIxLWFjbC10YXktYXJlIHByZXRyYWluZWQucGRmABMAAS8AABUAAgAP//8AAAAIAA0AGgAkAHIAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAACLA==},
	bdsk-url-1 = {https://aclanthology.org/2021.acl-long.335},
	bdsk-url-2 = {https://doi.org/10.18653/v1/2021.acl-long.335}}

@article{taylor2022arxiv,
	annote = {A promising approach to scientific reasoning with LLMs.},
	archiveprefix = {arXiv},
	author = {Ross Taylor and Marcin Kardas and Guillem Cucurull and Thomas Scialom and Anthony Hartshorn and Elvis Saravia and Andrew Poulton and Viktor Kerkez and Robert Stojnic},
	date-added = {2024-03-24 23:35:53 -0400},
	date-modified = {2024-07-24 11:42:59 -0400},
	eprint = {2211.09085},
	in-website = {1},
	journal = {Arxiv Preprint},
	keywords = {rdgrp-s23; potential; large-language-models; transformers; NLP},
	order = {?},
	pdf = {2022-arxiv-taylor-galactica},
	primaryclass = {cs.CL},
	title = {Galactica: A Large Language Model for Science},
	toread = {1},
	venue-short = {arxiv},
	year = {2022},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxBLLi4vLi4vLi4vLi4vcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi8yMDIyLWFyeGl2LXRheWxvci1nYWxhY3RpY2EucGRmTxEBtgAAAAABtgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAAAAAAEJEAAH/////HzIwMjItYXJ4aXYtdGF5bG9yLWdhbGFjdGljYS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP////8AAAAAAAAAAAAAAAAABAAFAAAKIGN1AAAAAAAAAAAAAAAAAANwZGYAAAIAUC86VXNlcnM6bWNyb3dsZXk6cmVwb3M6bWFya2Nyb3dsZXktY2E6YXNzZXRzOnBkZjoyMDIyLWFyeGl2LXRheWxvci1nYWxhY3RpY2EucGRmAA4AQAAfADIAMAAyADIALQBhAHIAeABpAHYALQB0AGEAeQBsAG8AcgAtAGcAYQBsAGEAYwB0AGkAYwBhAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBOVXNlcnMvbWNyb3dsZXkvcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi8yMDIyLWFyeGl2LXRheWxvci1nYWxhY3RpY2EucGRmABMAAS8AABUAAgAP//8AAAAIAA0AGgAkAHIAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAACLA==}}

@inproceedings{peschl2022aamas,
	abstract = {Inferring reward functions from demonstrations and pairwise preferences are auspicious approaches for aligning Reinforcement Learning (RL) agents with human intentions. However, state-of-the art methods typically focus on learning a single reward model, thus rendering it difficult to trade off different reward functions from multiple experts. We propose Multi-Objective Reinforced Active Learning (MORAL), a novel method for combining diverse demonstrations of social norms into a Pareto-optimal policy. Through maintaining a distribution over scalarization weights, our approach is able to interactively tune a deep RL agent towards a variety of preferences, while eliminating the need for computing multiple policies. We empirically demonstrate the effectiveness of MORAL in two scenarios, which model a delivery and an emergency task that require an agent to act in the presence of normative conflicts. Overall, we consider our research a step towards multi-objective RL with learned rewards, bridging the gap between current reward learning and machine ethics literature.},
	address = {Richland, SC},
	author = {Peschl, Markus and Zgonnikov, Arkady and Oliehoek, Frans A. and Siebert, Luciano C.},
	booktitle = {Proceedings of the 21st International Conference on Autonomous Agents and Multiagent Systems},
	date-added = {2024-03-08 22:18:51 -0500},
	date-modified = {2024-03-25 00:20:20 -0400},
	isbn = {9781450392136},
	keywords = {active learning, inverse reinforcement learning, multi-objective decision-making, value alignment; ai-morality},
	location = {Virtual Event, New Zealand},
	numpages = {9},
	pages = {1038--1046},
	publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
	series = {AAMAS '22},
	title = {MORAL: Aligning AI with Human Norms through Multi-Objective Reinforced Active Learning},
	toread = {1},
	venue-short = {AAMAS},
	year = {2022},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxA/Li4vLi4vLi4vLi4vcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi9wZXNjaGwyMDIyYWFtYXMucGRmTxEBhgAAAAABhgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAAAAAAEJEAAH/////E3Blc2NobDIwMjJhYW1hcy5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP////8AAAAAAAAAAAAAAAAABAAFAAAKIGN1AAAAAAAAAAAAAAAAAANwZGYAAAIARC86VXNlcnM6bWNyb3dsZXk6cmVwb3M6bWFya2Nyb3dsZXktY2E6YXNzZXRzOnBkZjpwZXNjaGwyMDIyYWFtYXMucGRmAA4AKAATAHAAZQBzAGMAaABsADIAMAAyADIAYQBhAG0AYQBzAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBCVXNlcnMvbWNyb3dsZXkvcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi9wZXNjaGwyMDIyYWFtYXMucGRmABMAAS8AABUAAgAP//8AAAAIAA0AGgAkAGYAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAB8A==}}

@inproceedings{hadfield-menell2017neurips,
	author = {Hadfield-Menell, Dylan and Milli, Smitha and Abbeel, Pieter and Russell, Stuart J and Dragan, Anca},
	booktitle = {Advances in Neural Information Processing Systems},
	date-added = {2024-03-08 20:21:03 -0500},
	date-modified = {2024-03-25 00:20:06 -0400},
	editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
	keywords = {ai-morality; value alignment},
	publisher = {Curran Associates, Inc.},
	title = {Inverse Reward Design},
	url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/32fdab6559cdfa4f167f8c31b9199643-Paper.pdf},
	venue-short = {neurips},
	volume = {30},
	year = {2017},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxBKLi4vLi4vLi4vLi4vcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi9oYWRmaWVsZC1tZW5lbGwyMDE3bmV1cmlwcy5wZGZPEQG0AAAAAAG0AAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAAAAAAAAQkQAAf////8eaGFkZmllbGQtbWVuZWxsMjAxN25ldXJpcHMucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/////wAAAAAAAAAAAAAAAAAEAAUAAAogY3UAAAAAAAAAAAAAAAAAA3BkZgAAAgBPLzpVc2VyczptY3Jvd2xleTpyZXBvczptYXJrY3Jvd2xleS1jYTphc3NldHM6cGRmOmhhZGZpZWxkLW1lbmVsbDIwMTduZXVyaXBzLnBkZgAADgA+AB4AaABhAGQAZgBpAGUAbABkAC0AbQBlAG4AZQBsAGwAMgAwADEANwBuAGUAdQByAGkAcABzAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBNVXNlcnMvbWNyb3dsZXkvcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi9oYWRmaWVsZC1tZW5lbGwyMDE3bmV1cmlwcy5wZGYAABMAAS8AABUAAgAP//8AAAAIAA0AGgAkAHEAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAACKQ==},
	bdsk-url-1 = {https://proceedings.neurips.cc/paper_files/paper/2017/file/32fdab6559cdfa4f167f8c31b9199643-Paper.pdf}}

@inproceedings{abel2016aaaiaies,
	author = {David Abel and James MacGlashan and Michael L. Littman},
	booktitle = {AAAI Workshop: AI, Ethics, and Society},
	date-added = {2024-02-24 15:31:30 -0500},
	date-modified = {2024-07-24 15:27:22 -0400},
	keywords = {middle, ai-morality, ai-ethics, reinforcement-learning, pomdp; rdgrp-ece750T4-f24},
	order = {2},
	title = {Reinforcement Learning as a Framework for Ethical Decision Making},
	url = {https://api.semanticscholar.org/CorpusID:14717578},
	venue-short = {aaaiaies},
	year = {2016},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEGUuLi8uLi8uLi9Ecm9wYm94L0FwcHMvcmVtb3RlbHktc2F2ZS9BSVRvcGljcy9hc3NldHMvcGRmLzIwMTYtYWFhaWFpZXMtYWJlbC1yZWluZm9yY2VtZW50LWxlYXJuaW5nLnBkZk8RBMBib29rwAQAAAAABBAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC8AwAABQAAAAEBAABVc2VycwAAAAgAAAABAQAAbWNyb3dsZXkHAAAAAQEAAERyb3Bib3gABAAAAAEBAABBcHBzDQAAAAEBAAByZW1vdGVseS1zYXZlAAAACAAAAAEBAABBSVRvcGljcwYAAAABAQAAYXNzZXRzAAADAAAAAQEAAHBkZgAtAAAAAQEAADIwMTYtYWFhaWFpZXMtYWJlbC1yZWluZm9yY2VtZW50LWxlYXJuaW5nLnBkZgAAACQAAAABBgAABAAAABQAAAAkAAAANAAAAEAAAABYAAAAaAAAAHgAAACEAAAACAAAAAQDAAAVXQAAAAAAAAgAAAAEAwAAOegDAAAAAAAIAAAABAMAAF91BAAAAAAACAAAAAQDAADRjgQAAAAAAAgAAAAEAwAAEFF0AgAAAAAIAAAABAMAAJ4W5wIAAAAACAAAAAQDAAA1z+ACAAAAAAgAAAAEAwAANs/gAgAAAAAIAAAABAMAAKD04AIAAAAAJAAAAAEGAADoAAAA+AAAAAgBAAAYAQAAKAEAADgBAABIAQAAWAEAAGgBAAAIAAAAAAQAAEHF2JcFfvlmGAAAAAECAAABAAAAAAAAAA8AAAAAAAAAAAAAAAAAAAAIAAAABAMAAAcAAAAAAAAABAAAAAMDAAD1AQAACAAAAAEJAABmaWxlOi8vLwwAAAABAQAATWFjaW50b3NoIEhECAAAAAQDAAAAkIKW5wAAAAgAAAAABAAAQcXxyyoAAAAkAAAAAQEAADA5QjdFQUJFLTY3OTUtNENERi1BQjI0LTNGRjA4NTY1RDAxNhgAAAABAgAAgQAAAAEAAADvEwAAAQAAAAAAAAAAAAAAAQAAAAEBAAAvAAAAAAAAAAEFAAAeAQAAAQIAADA5ZGYxNzRmMzc1Zjg0YjYxODgxN2MzYWNiMmRjZGUwZWI0OTg5MzQwOGEyYmE4MTY2NTY0MGNjYzVmNzMwYjQ7MDA7MDAwMDAwMDA7MDAwMDAwMDA7MDAwMDAwMDA7MDAwMDAwMDAwMDAwMDAyMDtjb20uYXBwbGUuYXBwLXNhbmRib3gucmVhZC13cml0ZTswMTswMTAwMDAxMDswMDAwMDAwMDAyZTBmNGEwOzAxOy91c2Vycy9tY3Jvd2xleS9kcm9wYm94L2FwcHMvcmVtb3RlbHktc2F2ZS9haXRvcGljcy9hc3NldHMvcGRmLzIwMTYtYWFhaWFpZXMtYWJlbC1yZWluZm9yY2VtZW50LWxlYXJuaW5nLnBkZgAAAMwAAAD+////AQAAAAAAAAAQAAAABBAAALwAAAAAAAAABRAAAHgBAAAAAAAAEBAAALQBAAAAAAAAQBAAAKQBAAAAAAAAAiAAAIACAAAAAAAABSAAAPABAAAAAAAAECAAAAACAAAAAAAAESAAADQCAAAAAAAAEiAAABQCAAAAAAAAEyAAACQCAAAAAAAAICAAAGACAAAAAAAAMCAAAIwCAAAAAAAAAcAAANQBAAAAAAAAEcAAABQAAAAAAAAAEsAAAOQBAAAAAAAAgPAAAJQCAAAAAAAAAAgADQAaACMAiwAAAAAAAAIBAAAAAAAAAAUAAAAAAAAAAAAAAAAAAAVP},
	bdsk-url-1 = {https://api.semanticscholar.org/CorpusID:14717578}}

@incollection{haas2022dnhni,
	author = {Haas, Julia},
	booktitle = {Does Neuroscience Have Normative Implications?},
	date-added = {2024-02-24 15:22:44 -0500},
	date-modified = {2024-03-25 00:19:51 -0400},
	editor = {Geoffrey Holtzman and Elisabeth Hildt.},
	keywords = {ai-morality},
	publisher = {Cham: Springer International Publishing AG},
	title = {Revising and Expanding Cushman's Learning-Based Model of Moral Cognition.},
	venue-short = {dnhni},
	year = {2022},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxA9Li4vLi4vLi4vLi4vcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi9oYWFzMjAyMmRuaG5pLnBkZk8RAX4AAAAAAX4AAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAAAAAABCRAAB/////xFoYWFzMjAyMmRuaG5pLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/////AAAAAAAAAAAAAAAAAAQABQAACiBjdQAAAAAAAAAAAAAAAAADcGRmAAACAEIvOlVzZXJzOm1jcm93bGV5OnJlcG9zOm1hcmtjcm93bGV5LWNhOmFzc2V0czpwZGY6aGFhczIwMjJkbmhuaS5wZGYADgAkABEAaABhAGEAcwAyADAAMgAyAGQAbgBoAG4AaQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAQFVzZXJzL21jcm93bGV5L3JlcG9zL21hcmtjcm93bGV5LWNhL2Fzc2V0cy9wZGYvaGFhczIwMjJkbmhuaS5wZGYAEwABLwAAFQACAA///wAAAAgADQAaACQAZAAAAAAAAAIBAAAAAAAAAAUAAAAAAAAAAAAAAAAAAAHm}}

@article{haas2020mindsmachines,
	abstract = {I describe a suite of reinforcement learning environments in which artificial agents learn to value and respond to moral content and contexts. I illustrate the core principles of the framework by characterizing one such environment, or ``gridworld,''in which an agent learns to trade-off between monetary profit and fair dealing, as applied in a standard behavioral economic paradigm. I then highlight the core technical and philosophical advantages of the learning approach for modeling moral cognition, and for addressing the so-called value alignment problem in AI.},
	author = {Haas, Julia},
	date = {2020/06/01},
	date-added = {2024-02-24 15:12:56 -0500},
	date-modified = {2024-07-24 15:27:34 -0400},
	doi = {10.1007/s11023-020-09524-9},
	id = {Haas2020},
	isbn = {1572-8641},
	journal = {Minds and Machines},
	keywords = {middle, ai-morality, ai-ethics, philosophy, reinforcement-learning; rdgrp-ece750T4-f24},
	number = {2},
	order = {4},
	pages = {219--246},
	title = {Moral Gridworlds: A Theoretical Proposal for Modeling Artificial Moral Cognition},
	url = {https://doi.org/10.1007/s11023-020-09524-9},
	venue-short = {mindsmachines},
	volume = {30},
	year = {2020},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEGQuLi8uLi8uLi9Ecm9wYm94L0FwcHMvcmVtb3RlbHktc2F2ZS9BSVRvcGljcy9hc3NldHMvcGRmLzIwMjAtbWluZHNtYWNoaW5lcy1oYWFzLW1vcmFsLWdyaWR3b3JsZHMucGRmTxEEvGJvb2u8BAAAAAAEEDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALgDAAAFAAAAAQEAAFVzZXJzAAAACAAAAAEBAABtY3Jvd2xleQcAAAABAQAARHJvcGJveAAEAAAAAQEAAEFwcHMNAAAAAQEAAHJlbW90ZWx5LXNhdmUAAAAIAAAAAQEAAEFJVG9waWNzBgAAAAEBAABhc3NldHMAAAMAAAABAQAAcGRmACwAAAABAQAAMjAyMC1taW5kc21hY2hpbmVzLWhhYXMtbW9yYWwtZ3JpZHdvcmxkcy5wZGYkAAAAAQYAAAQAAAAUAAAAJAAAADQAAABAAAAAWAAAAGgAAAB4AAAAhAAAAAgAAAAEAwAAFV0AAAAAAAAIAAAABAMAADnoAwAAAAAACAAAAAQDAABfdQQAAAAAAAgAAAAEAwAA0Y4EAAAAAAAIAAAABAMAABBRdAIAAAAACAAAAAQDAACeFucCAAAAAAgAAAAEAwAANc/gAgAAAAAIAAAABAMAADbP4AIAAAAACAAAAAQDAADy9eACAAAAACQAAAABBgAA5AAAAPQAAAAEAQAAFAEAACQBAAA0AQAARAEAAFQBAABkAQAACAAAAAAEAABBxdiXV5xp4hgAAAABAgAAAQAAAAAAAAAPAAAAAAAAAAAAAAAAAAAACAAAAAQDAAAHAAAAAAAAAAQAAAADAwAA9QEAAAgAAAABCQAAZmlsZTovLy8MAAAAAQEAAE1hY2ludG9zaCBIRAgAAAAEAwAAAJCClucAAAAIAAAAAAQAAEHF8csqAAAAJAAAAAEBAAAwOUI3RUFCRS02Nzk1LTRDREYtQUIyNC0zRkYwODU2NUQwMTYYAAAAAQIAAIEAAAABAAAA7xMAAAEAAAAAAAAAAAAAAAEAAAABAQAALwAAAAAAAAABBQAAHQEAAAECAAA5ZmI1ZjVmNzFjMGRhOTQ1ODA1YjVlMWFhOTBhYjNjZDk3YmIwYjdiNmEyYzc5MjMzNTIyMzkyYTI3NTBiODU5OzAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwMDAwMDAwMjA7Y29tLmFwcGxlLmFwcC1zYW5kYm94LnJlYWQtd3JpdGU7MDE7MDEwMDAwMTA7MDAwMDAwMDAwMmUwZjVmMjswMTsvdXNlcnMvbWNyb3dsZXkvZHJvcGJveC9hcHBzL3JlbW90ZWx5LXNhdmUvYWl0b3BpY3MvYXNzZXRzL3BkZi8yMDIwLW1pbmRzbWFjaGluZXMtaGFhcy1tb3JhbC1ncmlkd29ybGRzLnBkZgAAAADMAAAA/v///wEAAAAAAAAAEAAAAAQQAAC4AAAAAAAAAAUQAAB0AQAAAAAAABAQAACwAQAAAAAAAEAQAACgAQAAAAAAAAIgAAB8AgAAAAAAAAUgAADsAQAAAAAAABAgAAD8AQAAAAAAABEgAAAwAgAAAAAAABIgAAAQAgAAAAAAABMgAAAgAgAAAAAAACAgAABcAgAAAAAAADAgAACIAgAAAAAAAAHAAADQAQAAAAAAABHAAAAUAAAAAAAAABLAAADgAQAAAAAAAIDwAACQAgAAAAAAAAAIAA0AGgAjAIoAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAFSg==},
	bdsk-url-1 = {https://doi.org/10.1007/s11023-020-09524-9}}

@article{christopoulos2017jourbusethics,
	abstract = {In business settings, decision makers facing moral issues often experience the challenges of continuous changes. This dynamic process has been less examined in previous literature on moral decision making. We borrow theories on learning strategies and computational models from decision neuroscience to explain the updating and learning mechanisms underlying moral decision processes. Specifically, we present two main learning strategies: model-free learning, wherein the values of choices are updated in a trial-and-error fashion sustaining the formation of habits and model-based learning, wherein the brain updates more general cognitive maps and associations, thus sustaining flexible and state-dependent behaviors. We then summarize studies explaining the neuro-computational processes of both learning strategies---the calculation of prediction errors and valuation. We conclude by emphasizing how the incorporation of dynamic aspects in moral decision making could open new avenues for understanding moral behaviors in a changing world.},
	author = {Christopoulos, George I. and Liu, Xiao-Xiao and Hong, Ying-yi},
	date = {2017/09/01},
	date-added = {2024-02-24 14:41:39 -0500},
	date-modified = {2024-02-24 14:42:28 -0500},
	doi = {10.1007/s10551-016-3058-1},
	id = {Christopoulos2017},
	isbn = {1573-0697},
	journal = {Journal of Business Ethics},
	keywords = {ai-ethics, ai-morality, decision-making, philosophy},
	number = {4},
	pages = {699--715},
	title = {Toward an Understanding of Dynamic Moral Decision Making: Model-Free and Model-Based Learning},
	url = {https://doi.org/10.1007/s10551-016-3058-1},
	venue-short = {JourBusEthics},
	volume = {144},
	year = {2017},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEGYuLi8uLi8uLi9Ecm9wYm94L0FwcHMvcmVtb3RlbHktc2F2ZS9BSVRvcGljcy9hc3NldHMvcGRmLzIwMTctam91cmJ1c2V0aGljcy1jaHJpc3RvcG91bG9zLXRvd2FyZC1hbi5wZGZPEQTAYm9va8AEAAAAAAQQMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAvAMAAAUAAAABAQAAVXNlcnMAAAAIAAAAAQEAAG1jcm93bGV5BwAAAAEBAABEcm9wYm94AAQAAAABAQAAQXBwcw0AAAABAQAAcmVtb3RlbHktc2F2ZQAAAAgAAAABAQAAQUlUb3BpY3MGAAAAAQEAAGFzc2V0cwAAAwAAAAEBAABwZGYALgAAAAEBAAAyMDE3LWpvdXJidXNldGhpY3MtY2hyaXN0b3BvdWxvcy10b3dhcmQtYW4ucGRmAAAkAAAAAQYAAAQAAAAUAAAAJAAAADQAAABAAAAAWAAAAGgAAAB4AAAAhAAAAAgAAAAEAwAAFV0AAAAAAAAIAAAABAMAADnoAwAAAAAACAAAAAQDAABfdQQAAAAAAAgAAAAEAwAA0Y4EAAAAAAAIAAAABAMAABBRdAIAAAAACAAAAAQDAACeFucCAAAAAAgAAAAEAwAANc/gAgAAAAAIAAAABAMAADbP4AIAAAAACAAAAAQDAADa9eACAAAAACQAAAABBgAA6AAAAPgAAAAIAQAAGAEAACgBAAA4AQAASAEAAFgBAABoAQAACAAAAAAEAABBxdiXVo1OCRgAAAABAgAAAQAAAAAAAAAPAAAAAAAAAAAAAAAAAAAACAAAAAQDAAAHAAAAAAAAAAQAAAADAwAA9QEAAAgAAAABCQAAZmlsZTovLy8MAAAAAQEAAE1hY2ludG9zaCBIRAgAAAAEAwAAAJCClucAAAAIAAAAAAQAAEHF8csqAAAAJAAAAAEBAAAwOUI3RUFCRS02Nzk1LTRDREYtQUIyNC0zRkYwODU2NUQwMTYYAAAAAQIAAIEAAAABAAAA7xMAAAEAAAAAAAAAAAAAAAEAAAABAQAALwAAAAAAAAABBQAAHwEAAAECAAA3NTY4YTJlOWU0ZDU1ZmU5NGFmZGVlM2Q3ZmQ2MDYwOGQ2NzcyYmVkNzY4MzI1NzViMTZmOWZkYzJjMGRjYWQwOzAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwMDAwMDAwMjA7Y29tLmFwcGxlLmFwcC1zYW5kYm94LnJlYWQtd3JpdGU7MDE7MDEwMDAwMTA7MDAwMDAwMDAwMmUwZjVkYTswMTsvdXNlcnMvbWNyb3dsZXkvZHJvcGJveC9hcHBzL3JlbW90ZWx5LXNhdmUvYWl0b3BpY3MvYXNzZXRzL3BkZi8yMDE3LWpvdXJidXNldGhpY3MtY2hyaXN0b3BvdWxvcy10b3dhcmQtYW4ucGRmAADMAAAA/v///wEAAAAAAAAAEAAAAAQQAAC8AAAAAAAAAAUQAAB4AQAAAAAAABAQAAC0AQAAAAAAAEAQAACkAQAAAAAAAAIgAACAAgAAAAAAAAUgAADwAQAAAAAAABAgAAAAAgAAAAAAABEgAAA0AgAAAAAAABIgAAAUAgAAAAAAABMgAAAkAgAAAAAAACAgAABgAgAAAAAAADAgAACMAgAAAAAAAAHAAADUAQAAAAAAABHAAAAUAAAAAAAAABLAAADkAQAAAAAAAIDwAACUAgAAAAAAAAAIAA0AGgAjAIwAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAFUA==},
	bdsk-url-1 = {https://doi.org/10.1007/s10551-016-3058-1}}

@inproceedings{badea2022sgai,
	abstract = {We present what we call the Interpretation Problem, whereby any rule in symbolic form is open to infinite interpretation in ways that we might disapprove of and argue that any attempt to build morality into machines is subject to it. We show how the Interpretation Problem in Artificial Intelligence is an illustration of Wittgenstein's general claim that no rule can contain the criteria for its own application, and that the risks created by this problem escalates in proportion to the degree to which a machine is causally connected to the world, in what we call the Law of Interpretative Exposure. Using games as an illustration, we attempt to define the structure of normative spaces and argue that any rule-following within a normative space is guided by values that are external to that space and which cannot themselves be represented as rules. In light of this, we categorise the types of mistakes an artificial moral agent could make into Mistakes of Intention and Instrumental Mistakes, and we propose ways of building morality into machines by getting them to interpret the rules we give in accordance with these external values, through explicit moral reasoning, the ``Show, not Tell'' paradigm, the adjustment of causal power and structure of the agent, and relational values, with the ultimate aim that the machine develop a virtuous character and that the impact of the Interpretation Problem is minimised.},
	address = {Cham},
	author = {Badea, Cosmin and Artus, Gregory},
	booktitle = {Artificial Intelligence XXXIX},
	date-added = {2024-02-23 12:03:27 -0500},
	date-modified = {2024-07-24 15:28:36 -0400},
	editor = {Bramer, Max and Stahl, Frederic},
	isbn = {978-3-031-21441-7},
	keywords = {middle; ai-morality, ai-ethics, philosophy, wittgenstein, reinforcement-learning; rdgrp-ece750T4-f24},
	order = {3},
	pages = {124--137},
	publisher = {Springer International Publishing},
	title = {Morality, Machines, and the Interpretation Problem: A Value-based, Wittgensteinian Approach to Building Moral Agents},
	toread = {0},
	venue-short = {sgai},
	year = {2022},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEF0uLi8uLi8uLi9Ecm9wYm94L0FwcHMvcmVtb3RlbHktc2F2ZS9BSVRvcGljcy9hc3NldHMvcGRmLzIwMjItc2dhaS1iYWRlYS1tb3JhbGl0eS1tYWNoaW5lcy5wZGZPEQSwYm9va7AEAAAAAAQQMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAArAMAAAUAAAABAQAAVXNlcnMAAAAIAAAAAQEAAG1jcm93bGV5BwAAAAEBAABEcm9wYm94AAQAAAABAQAAQXBwcw0AAAABAQAAcmVtb3RlbHktc2F2ZQAAAAgAAAABAQAAQUlUb3BpY3MGAAAAAQEAAGFzc2V0cwAAAwAAAAEBAABwZGYAJQAAAAEBAAAyMDIyLXNnYWktYmFkZWEtbW9yYWxpdHktbWFjaGluZXMucGRmAAAAJAAAAAEGAAAEAAAAFAAAACQAAAA0AAAAQAAAAFgAAABoAAAAeAAAAIQAAAAIAAAABAMAABVdAAAAAAAACAAAAAQDAAA56AMAAAAAAAgAAAAEAwAAX3UEAAAAAAAIAAAABAMAANGOBAAAAAAACAAAAAQDAAAQUXQCAAAAAAgAAAAEAwAAnhbnAgAAAAAIAAAABAMAADXP4AIAAAAACAAAAAQDAAA2z+ACAAAAAAgAAAAEAwAA2uXgAgAAAAAkAAAAAQYAAOAAAADwAAAAAAEAABABAAAgAQAAMAEAAEABAABQAQAAYAEAAAgAAAAABAAAQcXYkpjaAHQYAAAAAQIAAAEAAAAAAAAADwAAAAAAAAAAAAAAAAAAAAgAAAAEAwAABwAAAAAAAAAEAAAAAwMAAPUBAAAIAAAAAQkAAGZpbGU6Ly8vDAAAAAEBAABNYWNpbnRvc2ggSEQIAAAABAMAAACQgpbnAAAACAAAAAAEAABBxfHLKgAAACQAAAABAQAAMDlCN0VBQkUtNjc5NS00Q0RGLUFCMjQtM0ZGMDg1NjVEMDE2GAAAAAECAACBAAAAAQAAAO8TAAABAAAAAAAAAAAAAAABAAAAAQEAAC8AAAAAAAAAAQUAABYBAAABAgAAMjg1MzBhMmYwOWFhYTgxYzM4ZDkxMzA1YjU3ZDhlMmJiMDE5MDk0ZWRjN2U1MWRjMTFhZjhmOTFhMjMxZmEzNjswMDswMDAwMDAwMDswMDAwMDAwMDswMDAwMDAwMDswMDAwMDAwMDAwMDAwMDIwO2NvbS5hcHBsZS5hcHAtc2FuZGJveC5yZWFkLXdyaXRlOzAxOzAxMDAwMDEwOzAwMDAwMDAwMDJlMGU1ZGE7MDE7L3VzZXJzL21jcm93bGV5L2Ryb3Bib3gvYXBwcy9yZW1vdGVseS1zYXZlL2FpdG9waWNzL2Fzc2V0cy9wZGYvMjAyMi1zZ2FpLWJhZGVhLW1vcmFsaXR5LW1hY2hpbmVzLnBkZgAAAMwAAAD+////AQAAAAAAAAAQAAAABBAAALQAAAAAAAAABRAAAHABAAAAAAAAEBAAAKwBAAAAAAAAQBAAAJwBAAAAAAAAAiAAAHgCAAAAAAAABSAAAOgBAAAAAAAAECAAAPgBAAAAAAAAESAAACwCAAAAAAAAEiAAAAwCAAAAAAAAEyAAABwCAAAAAAAAICAAAFgCAAAAAAAAMCAAAIQCAAAAAAAAAcAAAMwBAAAAAAAAEcAAABQAAAAAAAAAEsAAANwBAAAAAAAAgPAAAIwCAAAAAAAAAAgADQAaACMAgwAAAAAAAAIBAAAAAAAAAAUAAAAAAAAAAAAAAAAAAAU3}}

@inproceedings{herlau2022icccr,
	author = {Herlau, Tue},
	booktitle = {2022 2nd International Conference on Computer, Control and Robotics (ICCCR)},
	date-added = {2024-02-18 12:13:32 -0500},
	date-modified = {2024-07-24 15:08:40 -0400},
	doi = {10.1109/ICCCR54399.2022.9790262},
	hypoth = {https://hyp.is/go?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2205.08192.pdf&group=__world__},
	keywords = {Digital control;Costs;Toy manufacturing industry;Forestry;Causality;Actual Causation;ai-ethics; ai-morality; reinforcement-learning},
	pages = {179-185},
	title = {Moral Reinforcement Learning Using Actual Causation},
	toread = {1},
	venue-short = {icccr},
	year = {2022},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEGEuLi8uLi8uLi9Ecm9wYm94L0FwcHMvcmVtb3RlbHktc2F2ZS9BSVRvcGljcy9hc3NldHMvcGRmLzIwMjItaWNjY3ItaGVybGF1LW1vcmFsLXJlaW5mb3JjZW1lbnQucGRmTxEEuGJvb2u4BAAAAAAEEDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALQDAAAFAAAAAQEAAFVzZXJzAAAACAAAAAEBAABtY3Jvd2xleQcAAAABAQAARHJvcGJveAAEAAAAAQEAAEFwcHMNAAAAAQEAAHJlbW90ZWx5LXNhdmUAAAAIAAAAAQEAAEFJVG9waWNzBgAAAAEBAABhc3NldHMAAAMAAAABAQAAcGRmACkAAAABAQAAMjAyMi1pY2Njci1oZXJsYXUtbW9yYWwtcmVpbmZvcmNlbWVudC5wZGYAAAAkAAAAAQYAAAQAAAAUAAAAJAAAADQAAABAAAAAWAAAAGgAAAB4AAAAhAAAAAgAAAAEAwAAFV0AAAAAAAAIAAAABAMAADnoAwAAAAAACAAAAAQDAABfdQQAAAAAAAgAAAAEAwAA0Y4EAAAAAAAIAAAABAMAABBRdAIAAAAACAAAAAQDAACeFucCAAAAAAgAAAAEAwAANc/gAgAAAAAIAAAABAMAADbP4AIAAAAACAAAAAQDAADb9eACAAAAACQAAAABBgAA5AAAAPQAAAAEAQAAFAEAACQBAAA0AQAARAEAAFQBAABkAQAACAAAAAAEAABBxdiXVo1cdxgAAAABAgAAAQAAAAAAAAAPAAAAAAAAAAAAAAAAAAAACAAAAAQDAAAHAAAAAAAAAAQAAAADAwAA9QEAAAgAAAABCQAAZmlsZTovLy8MAAAAAQEAAE1hY2ludG9zaCBIRAgAAAAEAwAAAJCClucAAAAIAAAAAAQAAEHF8csqAAAAJAAAAAEBAAAwOUI3RUFCRS02Nzk1LTRDREYtQUIyNC0zRkYwODU2NUQwMTYYAAAAAQIAAIEAAAABAAAA7xMAAAEAAAAAAAAAAAAAAAEAAAABAQAALwAAAAAAAAABBQAAGgEAAAECAAA5NjkwZTgyN2NkNzdjNjkzODgzZjhkMjk1YzM0Y2M3M2M5MTMxOWY5ZTRmOGY4ZWVmZTgyYjYwMTdlOWJiZDdjOzAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwMDAwMDAwMjA7Y29tLmFwcGxlLmFwcC1zYW5kYm94LnJlYWQtd3JpdGU7MDE7MDEwMDAwMTA7MDAwMDAwMDAwMmUwZjVkYjswMTsvdXNlcnMvbWNyb3dsZXkvZHJvcGJveC9hcHBzL3JlbW90ZWx5LXNhdmUvYWl0b3BpY3MvYXNzZXRzL3BkZi8yMDIyLWljY2NyLWhlcmxhdS1tb3JhbC1yZWluZm9yY2VtZW50LnBkZgAAAMwAAAD+////AQAAAAAAAAAQAAAABBAAALgAAAAAAAAABRAAAHQBAAAAAAAAEBAAALABAAAAAAAAQBAAAKABAAAAAAAAAiAAAHwCAAAAAAAABSAAAOwBAAAAAAAAECAAAPwBAAAAAAAAESAAADACAAAAAAAAEiAAABACAAAAAAAAEyAAACACAAAAAAAAICAAAFwCAAAAAAAAMCAAAIgCAAAAAAAAAcAAANABAAAAAAAAEcAAABQAAAAAAAAAEsAAAOABAAAAAAAAgPAAAJACAAAAAAAAAAgADQAaACMAhwAAAAAAAAIBAAAAAAAAAAUAAAAAAAAAAAAAAAAAAAVD},
	bdsk-url-1 = {https://doi.org/10.1109/ICCCR54399.2022.9790262}}

@article{ayars2016jourcognition,
	abstract = {Dual-systems frameworks propose that moral judgments are derived from both an immediate emotional response, and controlled/rational cognition. Recently Cushman (2013) proposed a new dual-system theory based on model-free and model-based reinforcement learning. Model-free learning attaches values to actions based on their history of reward and punishment, and explains some deontological, non-utilitarian judgments. Model-based learning involves the construction of a causal model of the world and allows for far-sighted planning; this form of learning fits well with utilitarian considerations that seek to maximize certain kinds of outcomes. I present three concerns regarding the use of model-free reinforcement learning to explain deontological moral judgment. First, many actions that humans find aversive from model-free learning are not judged to be morally wrong. Moral judgment must require something in addition to model-free learning. Second, there is a dearth of evidence for central predictions of the reinforcement account---e.g., that people with different reinforcement histories will, all else equal, make different moral judgments. Finally, to account for the effect of intention within the framework requires certain assumptions which lack support. These challenges are reasonable foci for future empirical/theoretical work on the model-free/model-based framework.},
	author = {Alisabeth Ayars},
	date-added = {2024-02-18 11:50:18 -0500},
	date-modified = {2024-07-24 15:08:40 -0400},
	doi = {https://doi.org/10.1016/j.cognition.2016.02.002},
	hypoth = {https://hyp.is/go?url=https%3A%2F%2Fpdf.sciencedirectassets.com%2F271061%2F1-s2.0-S0010027716X00030%2F1-s2.0-S0010027716300300%2Fam.pdf%3FX-Amz-Security-Token%3DIQoJb3JpZ2luX2VjEBkaCXVzLWVhc3QtMSJIMEYCIQDSrlQ2%252FwMRUQYLXcyJsvA%252FD78LcAoEOqzKeA3VRyhFFAIhAOoj2FmqkF1ap10phRf3285JCN9%252Fgc%252B63iZoHyVcHcvEKrsFCPH%252F%252F%252F%252F%252F%252F%252F%252F%252F%252FwEQBRoMMDU5MDAzNTQ2ODY1IgxHtaeR%252BdxL1Gryc40qjwVZhRrguJCGp82jIJrPl7ATnmlb1nAG0ArISExDhEmAsakcaVnyQsiPF7iW%252FAd7ZtFUsbDDfDXK8nME9sxyTLXQcZoN3IAqTu4%252BpqCpnHQCtuVec1V4JqzvXjCCirEPO134eYfx5wn8lyPUdUSl4Kl3crcLPt6LpKwmaiE4jURhWltY2xOTF6PGeFftCwRAQN91yIfKPMYFGtgpwnGXO8trg1GddYz9QcOFND%252F5zdPrKLgZOdJpPKyU4nDTkbh%252FezcAgqkdfeXY%252FyWus8HP%252BpSZ50BwdA6VMnQwgmcSKG4%252FtzMNMIcE0wX1eVbAPC8JPt17Wb861shHacE3PWcSlPPci1gY0bhUTKp1LRZtdYRKVglwAq%252FIwUGTAH2%252FXU7gUE2qX2okzXl7jqzoRAw4zRsYxRsu1VHZu1tGQVVwYQe%252BGuk8IGzFtCR5jqTd5cMLNpPG5LY1fScwraKL%252Ft0v8jU7EkeXZwzRGstGVlu7jN7lgJn1hJgE%252B86%252BhF5h3HsfOvfaUt794s7kRxX9%252BS3Gam6USuHlv38lx50Oo%252B1h1goDp%252BZdj4At8LeP2tNSSVtYCBILUJKYTT3NCoXt%252FyTQLwQxNEZukx5BXNA3uxAJLl3ZdOddJhaAyGQAyd%252FWJ37XOYhJs5v7qxvXDVRacW8C90m6UNR5Zm%252BvDbOPbfLEWVy5dopLsikosHCWRkk%252F%252Fx%252BH4t71UwYUSMoIajVYBKmevJsn4ZWdVlyRI9f1PzUURVlslen81vJX%252BOGqoDrpUdiSrj4T3Oo0sU2kixy0o3rn%252BvDIKq5NC80mSWcd8rRrM9As%252FZYG15rPcwJDMU7hVZxlHpbssMuh9w2U3OXuS9EE%252FnKOS6KE1hvBWd0bRHCFb1VKMNzayK4GOrABAWcW7lsKo%252BjGoFJsqYTqtR1C3s%252Fz7MVHG1qHhOR4yZwDGQRcJpGB4vZgqjekEWOAAnfs1WanAS7TH6QaXsBBYqCPU4TcGyI4%252B%252BChmnKd7C3g6JpNCzINPKe55PXtdodH3Bh%252BEC8JNQuNH7mEkuIWcSpQkyVJirsJYLQ%252BPeqHAHSME2PhW9yC1ngxsztcT0%252BcOV0QP9fC%252BZN%252FHWT7qE%252FFy9mmPM%252Bc5ScPaGRp8pPhiTI%253D%26X-Amz-Algorithm%3DAWS4-HMAC-SHA256%26X-Amz-Date%3D20240218T164230Z%26X-Amz-SignedHeaders%3Dhost%26X-Amz-Expires%3D300%26X-Amz-Credential%3DASIAQ3PHCVTYQEPLVETU%252F20240218%252Fus-east-1%252Fs3%252Faws4_request%26X-Amz-Signature%3Dfc9a2aa4f6990030ce0552b2b0810521ca08b9d9e83ce60e6d70b19c8f4d923d%26hash%3D5edaf95f4c6380a596fa370e2a9aca696b0e21361b739d4ac6a10be02d8d539e%26host%3D68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61%26pii%3DS0010027716300300%26tid%3Dpdf-557cb268-9fe2-4c31-ad63-bfa5525003e8%26sid%3D4cb73e9469cc5247698a38d863c0e12aebdagxrqa%26type%3Dclient&group=__world__},
	issn = {0010-0277},
	journal = {Cognition},
	keywords = {Moral judgment, Model-free, Model-based, Dual-system, ai-morality, ai-ethics; reinforcement-learning},
	pages = {232-242},
	title = {Can model-free reinforcement learning explain deontological moral judgments?},
	toread = {0},
	url = {https://www.sciencedirect.com/science/article/pii/S0010027716300300},
	venue-short = {JourCognition},
	volume = {150},
	year = {2016},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEF4uLi8uLi8uLi9Ecm9wYm94L0FwcHMvcmVtb3RlbHktc2F2ZS9BSVRvcGljcy9hc3NldHMvcGRmLzIwMTYtam91cmNvZ25pdGlvbi1heWFycy1jYW4tbW9kZWwucGRmTxEEsGJvb2uwBAAAAAAEEDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKwDAAAFAAAAAQEAAFVzZXJzAAAACAAAAAEBAABtY3Jvd2xleQcAAAABAQAARHJvcGJveAAEAAAAAQEAAEFwcHMNAAAAAQEAAHJlbW90ZWx5LXNhdmUAAAAIAAAAAQEAAEFJVG9waWNzBgAAAAEBAABhc3NldHMAAAMAAAABAQAAcGRmACYAAAABAQAAMjAxNi1qb3VyY29nbml0aW9uLWF5YXJzLWNhbi1tb2RlbC5wZGYAACQAAAABBgAABAAAABQAAAAkAAAANAAAAEAAAABYAAAAaAAAAHgAAACEAAAACAAAAAQDAAAVXQAAAAAAAAgAAAAEAwAAOegDAAAAAAAIAAAABAMAAF91BAAAAAAACAAAAAQDAADRjgQAAAAAAAgAAAAEAwAAEFF0AgAAAAAIAAAABAMAAJ4W5wIAAAAACAAAAAQDAAA1z+ACAAAAAAgAAAAEAwAANs/gAgAAAAAIAAAABAMAAOf14AIAAAAAJAAAAAEGAADgAAAA8AAAAAABAAAQAQAAIAEAADABAABAAQAAUAEAAGABAAAIAAAAAAQAAEHF2JdWlQbLGAAAAAECAAABAAAAAAAAAA8AAAAAAAAAAAAAAAAAAAAIAAAABAMAAAcAAAAAAAAABAAAAAMDAAD1AQAACAAAAAEJAABmaWxlOi8vLwwAAAABAQAATWFjaW50b3NoIEhECAAAAAQDAAAAkIKW5wAAAAgAAAAABAAAQcXxyyoAAAAkAAAAAQEAADA5QjdFQUJFLTY3OTUtNENERi1BQjI0LTNGRjA4NTY1RDAxNhgAAAABAgAAgQAAAAEAAADvEwAAAQAAAAAAAAAAAAAAAQAAAAEBAAAvAAAAAAAAAAEFAAAXAQAAAQIAADljNjZjMTliM2ZmNmJjMTNiZGRhYWZmYzIzNTE5MDY1NmE0N2IzZmZmYjE2Y2ExZjc5YTM0MzBhNWRmMDdkY2U7MDA7MDAwMDAwMDA7MDAwMDAwMDA7MDAwMDAwMDA7MDAwMDAwMDAwMDAwMDAyMDtjb20uYXBwbGUuYXBwLXNhbmRib3gucmVhZC13cml0ZTswMTswMTAwMDAxMDswMDAwMDAwMDAyZTBmNWU3OzAxOy91c2Vycy9tY3Jvd2xleS9kcm9wYm94L2FwcHMvcmVtb3RlbHktc2F2ZS9haXRvcGljcy9hc3NldHMvcGRmLzIwMTYtam91cmNvZ25pdGlvbi1heWFycy1jYW4tbW9kZWwucGRmAADMAAAA/v///wEAAAAAAAAAEAAAAAQQAAC0AAAAAAAAAAUQAABwAQAAAAAAABAQAACsAQAAAAAAAEAQAACcAQAAAAAAAAIgAAB4AgAAAAAAAAUgAADoAQAAAAAAABAgAAD4AQAAAAAAABEgAAAsAgAAAAAAABIgAAAMAgAAAAAAABMgAAAcAgAAAAAAACAgAABYAgAAAAAAADAgAACEAgAAAAAAAAHAAADMAQAAAAAAABHAAAAUAAAAAAAAABLAAADcAQAAAAAAAIDwAACMAgAAAAAAAAAIAA0AGgAjAIQAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAFOA==},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0010027716300300},
	bdsk-url-2 = {https://doi.org/10.1016/j.cognition.2016.02.002}}

@article{wang2023nature,
	abbr = {AI4Science},
	abstract = {Artificial intelligence (AI) is being increasingly integrated into scientific discovery to augment and accelerate research, helping scientists to generate hypotheses, design experiments, collect and interpret large datasets, and gain insights that might not have been possible using traditional scientific methods alone. Here we examine breakthroughs over the past decade that include self-supervised learning, which allows models to be trained on vast amounts of unlabelled data, and geometric deep learning, which leverages knowledge about the structure of scientific data to enhance model accuracy and efficiency. Generative AI methods can create designs, such as small-molecule drugs and proteins, by analysing diverse data modalities, including images and sequences. We discuss how these methods can help scientists throughout the scientific process and the central issues that remain despite such advances. Both developers and users of AI tools need a better understanding of when such approaches need improvement, and challenges posed by poor data quality and stewardship remain. These issues cut across scientific disciplines and require developing foundational algorithmic approaches that can contribute to scientific understanding or acquire it autonomously, making them critical areas of focus for AI innovation.},
	annote = {This is a great paper to look at for an update on the many ways AI/ML/RL are being used for science. It is written by the organizers of the regular [AI for Science workshop](https://ai4sciencecommunity.github.io/) held at multiple major conferences. There are extensive notes in the hypothesis link of the webpage version of the paper, click the hypothesis link to see the notes.},
	author = {Wang, Hanchen and Fu, Tianfan and Du, Yuanqi and Gao, Wenhao and Huang, Kexin and Liu, Ziming and Chandak, Payal and Liu, Shengchao and Van Katwyk, Peter and Deac, Andreea and Anandkumar, Anima and Bergen, Karianne and Gomes, Carla P. and Ho, Shirley and Kohli, Pushmeet and Lasenby, Joan and Leskovec, Jure and Liu, Tie-Yan and Manrai, Arjun and Marks, Debora and Ramsundar, Bharath and Song, Le and Sun, Jimeng and Tang, Jian and Veli{\v c}kovi{\'c}, Petar and Welling, Max and Zhang, Linfeng and Coley, Connor W. and Bengio, Yoshua and Zitnik, Marinka},
	date = {2023/08/01},
	date-added = {2024-02-15 17:44:23 -0500},
	date-discussed = {2023-10-23 led by Mark Crowley},
	date-modified = {2024-02-15 17:44:23 -0500},
	doi = {10.1038/s41586-023-06221-2},
	hypoth = {https://hyp.is/go?url=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41586-023-06221-2&group=__world__},
	id = {Wang2023},
	in-website = {1},
	isbn = {1476-4687},
	journal = {Nature},
	keywords = {done, ai-for-science, deep-learning, generative-models, large-language-models, nlp, ai-for-physics; rdgrp-f23},
	number = {7972},
	order = {1},
	pages = {47--60},
	title = {Scientific discovery in the age of artificial intelligence},
	toread = {1},
	url = {https://doi.org/10.1038/s41586-023-06221-2},
	venue-short = {Nature},
	volume = {620},
	year = {2023},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEFMuLi8uLi8uLi9Ecm9wYm94L3dlYnNpdGVfYXNzZXRzL21hcmtjcm93bGV5LWNhL3BkZnMvMjAyMy1uYXR1cmUtd2FuZy1zY2llbnRpZmljLnBkZk8RBFhib29rWAQAAAAABBAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABUAwAABQAAAAEBAABVc2VycwAAAAgAAAABAQAAbWNyb3dsZXkHAAAAAQEAAERyb3Bib3gADgAAAAEBAAB3ZWJzaXRlX2Fzc2V0cwAADgAAAAEBAABtYXJrY3Jvd2xleS1jYQAABAAAAAEBAABwZGZzHwAAAAEBAAAyMDIzLW5hdHVyZS13YW5nLXNjaWVudGlmaWMucGRmABwAAAABBgAABAAAABQAAAAkAAAANAAAAEwAAABkAAAAcAAAAAgAAAAEAwAAFV0AAAAAAAAIAAAABAMAADnoAwAAAAAACAAAAAQDAABfdQQAAAAAAAgAAAAEAwAABqPJAQAAAAAIAAAABAMAAIykyQEAAAAACAAAAAQDAACrpMkBAAAAAAgAAAAEAwAAnmvPAQAAAAAcAAAAAQYAALwAAADMAAAA3AAAAOwAAAD8AAAADAEAABwBAAAIAAAAAAQAAEHFV8DX33noGAAAAAECAAABAAAAAAAAAA8AAAAAAAAAAAAAAAAAAAAIAAAABAMAAAUAAAAAAAAABAAAAAMDAAD1AQAACAAAAAEJAABmaWxlOi8vLwwAAAABAQAATWFjaW50b3NoIEhECAAAAAQDAAAAkIKW5wAAAAgAAAAABAAAQcXxyyoAAAAkAAAAAQEAADA5QjdFQUJFLTY3OTUtNENERi1BQjI0LTNGRjA4NTY1RDAxNhgAAAABAgAAgQAAAAEAAADvEwAAAQAAAAAAAAAAAAAAAQAAAAEBAAAvAAAAAAAAAAEFAAAMAQAAAQIAADI3OWExYzZiMGYzNDg0MWM5MDNkMWI2NTkxZWM5ZjFmODdmNTIwMGJjN2UzN2YzOTM3M2E2NjQ3ZGNjZDRmMjY7MDA7MDAwMDAwMDA7MDAwMDAwMDA7MDAwMDAwMDA7MDAwMDAwMDAwMDAwMDAyMDtjb20uYXBwbGUuYXBwLXNhbmRib3gucmVhZC13cml0ZTswMTswMTAwMDAxMDswMDAwMDAwMDAxY2Y2YjllOzAxOy91c2Vycy9tY3Jvd2xleS9kcm9wYm94L3dlYnNpdGVfYXNzZXRzL21hcmtjcm93bGV5LWNhL3BkZnMvMjAyMy1uYXR1cmUtd2FuZy1zY2llbnRpZmljLnBkZgDMAAAA/v///wEAAAAAAAAAEAAAAAQQAACYAAAAAAAAAAUQAAAsAQAAAAAAABAQAABgAQAAAAAAAEAQAABQAQAAAAAAAAIgAAAsAgAAAAAAAAUgAACcAQAAAAAAABAgAACsAQAAAAAAABEgAADgAQAAAAAAABIgAADAAQAAAAAAABMgAADQAQAAAAAAACAgAAAMAgAAAAAAADAgAAA4AgAAAAAAAAHAAACAAQAAAAAAABHAAAAUAAAAAAAAABLAAACQAQAAAAAAAIDwAABAAgAAAAAAAAAIAA0AGgAjAHkAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAE1Q==},
	bdsk-url-1 = {https://doi.org/10.1038/s41586-023-06221-2}}

@article{zecevic2023tmlr,
	abstract = {Some argue scale is all what is needed to achieve AI, covering even causal models. We make it clear that large language models (LLMs) cannot be causal and give reason onto why sometimes we might feel otherwise. To this end, we define and exemplify a new subgroup of Structural Causal Model (SCM) that we call meta SCM which encode causal facts about other SCM within their variables. We conjecture that in the cases where LLM succeed in doing causal inference, underlying was a respective meta SCM that exposed correlations between causal facts in natural language on whose data the LLM was ultimately trained. If our hypothesis holds true, then this would imply that LLMs are like parrots in that they simply recite the causal knowledge embedded in the data. Our empirical analysis provides favoring evidence that current LLMs are even weak `causal parrots.'},
	annote = {This paper has a very bold premise to show clearly what causality and conceptual reasoning means in terms of Large Language Models. They define it clearly int terms of evidence existing in the training set and argue that LLMs can only learn causal relations in those cases. These authors are organizing a workshop on this very topic for NeurIPS 2023.},
	arxiv = {2308.13067},
	author = {Matej Ze{\v{c}}evi{\'c} and Moritz Willig and Devendra Singh Dhami and Kristian Kersting},
	date-added = {2024-02-15 17:44:23 -0500},
	date-discussed = {2023-10-30 led by Shayan},
	date-modified = {2024-02-15 17:44:23 -0500},
	hypoth = {https://hyp.is/go?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2308.13067.pdf&group=__world__},
	in-website = {1},
	issn = {2835-8856},
	journal = {Transactions on Machine Learning Research},
	keywords = {large-language-models, causality, done; rdgrp-f23},
	month = {August},
	order = {2},
	pdf = {2023-tmlr-zecevic-causal.pdf},
	rating = {4},
	title = {Causal Parrots: Large Language Models May Talk Causality But Are Not Causal},
	toread = {1},
	url = {https://openreview.net/forum?id=tv46tCzs83},
	venue-short = {TMLR},
	year = {2023},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxBQLi4vLi4vLi4vRHJvcGJveC93ZWJzaXRlX2Fzc2V0cy9tYXJrY3Jvd2xleS1jYS9wZGZzLzIwMjMtdG1sci16ZWNldmljLWNhdXNhbC5wZGZPEQHAAAAAAAHAAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAAAAAAAAQkQAAf////8cMjAyMy10bWxyLXplY2V2aWMtY2F1c2FsLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/////wAAAAAAAAAAAAAAAAADAAUAAAogY3UAAAAAAAAAAAAAAAAABHBkZnMAAgBYLzpVc2VyczptY3Jvd2xleTpEcm9wYm94OndlYnNpdGVfYXNzZXRzOm1hcmtjcm93bGV5LWNhOnBkZnM6MjAyMy10bWxyLXplY2V2aWMtY2F1c2FsLnBkZgAOADoAHAAyADAAMgAzAC0AdABtAGwAcgAtAHoAZQBjAGUAdgBpAGMALQBjAGEAdQBzAGEAbAAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAVlVzZXJzL21jcm93bGV5L0Ryb3Bib3gvd2Vic2l0ZV9hc3NldHMvbWFya2Nyb3dsZXktY2EvcGRmcy8yMDIzLXRtbHItemVjZXZpYy1jYXVzYWwucGRmABMAAS8AABUAAgAP//8AAAAIAA0AGgAkAHcAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAACOw==}}

@misc{wu2023arxiv,
	abbr = {SPRING},
	arxiv = {2305.15486},
	author = {Yue Wu and Shrimai Prabhumoye and So Yeon Min and Yonatan Bisk and Ruslan Salakhutdinov and Amos Azaria and Tom Mitchell and Yuanzhi Li},
	date-added = {2024-02-15 17:44:23 -0500},
	date-modified = {2024-07-24 15:26:53 -0400},
	howpublished = {arxiv},
	hypoth = {https://hyp.is/go?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2305.15486.pdf&group=__world__},
	in-website = {1},
	keywords = {later, large-language-models, reinforcement-learning; rdgrp-f23; rdgrp-ece750T4-f24},
	order = {3},
	pdf = {2023-arxiv-wu-spring.pdf},
	title = {SPRING: GPT-4 Out-performs RL Algorithms by Studying Papers and Reasoning},
	toread = {1},
	venue-short = {arxiv},
	year = {2023},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEFAuLi8uLi8uLi9Ecm9wYm94L0FwcHMvcmVtb3RlbHktc2F2ZS9BSVRvcGljcy9hc3NldHMvcGRmLzIwMjMtYXJ4aXYtd3Utc3ByaW5nLnBkZk8RBJRib29rlAQAAAAABBAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACQAwAABQAAAAEBAABVc2VycwAAAAgAAAABAQAAbWNyb3dsZXkHAAAAAQEAAERyb3Bib3gABAAAAAEBAABBcHBzDQAAAAEBAAByZW1vdGVseS1zYXZlAAAACAAAAAEBAABBSVRvcGljcwYAAAABAQAAYXNzZXRzAAADAAAAAQEAAHBkZgAYAAAAAQEAADIwMjMtYXJ4aXYtd3Utc3ByaW5nLnBkZiQAAAABBgAABAAAABQAAAAkAAAANAAAAEAAAABYAAAAaAAAAHgAAACEAAAACAAAAAQDAAAVXQAAAAAAAAgAAAAEAwAAOegDAAAAAAAIAAAABAMAAF91BAAAAAAACAAAAAQDAADRjgQAAAAAAAgAAAAEAwAAEFF0AgAAAAAIAAAABAMAAJ4W5wIAAAAACAAAAAQDAAA1z+ACAAAAAAgAAAAEAwAANs/gAgAAAAAIAAAABAMAAGRY3QIAAAAAJAAAAAEGAADQAAAA4AAAAPAAAAAAAQAAEAEAACABAAAwAQAAQAEAAFABAAAIAAAAAAQAAEHFWRqkgAAAGAAAAAECAAABAAAAAAAAAA8AAAAAAAAAAAAAAAAAAAAIAAAABAMAAAcAAAAAAAAABAAAAAMDAAD1AQAACAAAAAEJAABmaWxlOi8vLwwAAAABAQAATWFjaW50b3NoIEhECAAAAAQDAAAAkIKW5wAAAAgAAAAABAAAQcXxyyoAAAAkAAAAAQEAADA5QjdFQUJFLTY3OTUtNENERi1BQjI0LTNGRjA4NTY1RDAxNhgAAAABAgAAgQAAAAEAAADvEwAAAQAAAAAAAAAAAAAAAQAAAAEBAAAvAAAAAAAAAAEFAAAJAQAAAQIAADMwYWUxYTA4NGQ4MjNiNzBjMTVkOWQ4MjUyNDk4N2ZiN2U4YzRmNTJlZGQ3MDdhMGYxNjYyOTkwMDA3MTdhZWU7MDA7MDAwMDAwMDA7MDAwMDAwMDA7MDAwMDAwMDA7MDAwMDAwMDAwMDAwMDAyMDtjb20uYXBwbGUuYXBwLXNhbmRib3gucmVhZC13cml0ZTswMTswMTAwMDAxMDswMDAwMDAwMDAyZGQ1ODY0OzAxOy91c2Vycy9tY3Jvd2xleS9kcm9wYm94L2FwcHMvcmVtb3RlbHktc2F2ZS9haXRvcGljcy9hc3NldHMvcGRmLzIwMjMtYXJ4aXYtd3Utc3ByaW5nLnBkZgAAAADMAAAA/v///wEAAAAAAAAAEAAAAAQQAACkAAAAAAAAAAUQAABgAQAAAAAAABAQAACcAQAAAAAAAEAQAACMAQAAAAAAAAIgAABoAgAAAAAAAAUgAADYAQAAAAAAABAgAADoAQAAAAAAABEgAAAcAgAAAAAAABIgAAD8AQAAAAAAABMgAAAMAgAAAAAAACAgAABIAgAAAAAAADAgAAB0AgAAAAAAAAHAAAC8AQAAAAAAABHAAAAUAAAAAAAAABLAAADMAQAAAAAAAIDwAAB8AgAAAAAAAAAIAA0AGgAjAHYAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAFDg==}}

@inproceedings{chen2021neurips,
	abbr = {DecTransfrmr},
	abstract = {We introduce a framework that abstracts Reinforcement Learning (RL) as a sequence modeling problem. This allows us to draw upon the simplicity and scalability of the Transformer architecture, and associated advances in language modeling such as GPT-x and BERT. In particular, we present Decision Transformer, an architecture that casts the problem of RL as conditional sequence modeling. Unlike prior approaches to RL that fit value functions or compute policy gradients, Decision Transformer simply outputs the optimal actions by leveraging a causally masked Transformer. By conditioning an autoregressive model on the desired return (reward), past states, and actions, our Decision Transformer model can generate future actions that achieve the desired return. Despite its simplicity, Decision Transformer matches or exceeds the performance of state-of-the-art model-free offline RL baselines on Atari, OpenAI Gym, and Key-to-Door tasks.},
	archiveprefix = {arxiv},
	arxiv = {2106.01345},
	author = {Chen, Lili and Lu, Kevin and Rajeswaran, Aravind and Lee, Kimin and Grover, Aditya and Laskin, Misha and Abbeel, Pieter and Srinivas, Aravind and Mordatch, Igor},
	booktitle = {Advances in Neural Information Processing Systems},
	date-added = {2024-02-15 17:44:23 -0500},
	date-modified = {2024-07-24 15:27:59 -0400},
	editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
	eprint = {2106.01345},
	howpublished = {arxiv},
	hypoth = {https://hyp.is/go?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2106.01345.pdf&group=__world__},
	in-website = {1},
	keywords = {early; rdgrp-ece750T4-f24; machine-learning, reinforcement-learning, decision-transformers, done; rdgrp-f23},
	month = {June},
	note = {This is a really neat and clean idea for how to utilize the temporal, predictive structure of transformers to implement Reinforcement Learning. There are other approaches to this, but this one is very elegant.},
	number = {arXiv:2106.01345},
	order = {2},
	pages = {15084--15097},
	pdf = {2021-neurips-chen-decision.pdf},
	primaryclass = {cs},
	shorttitle = {Decision Transformer},
	status = {1},
	title = {Decision Transformer: Reinforcement Learning via Sequence Modeling},
	toread = {1},
	url = {https://proceedings.neurips.cc/paper_files/paper/2021/file/7f489f642a0ddb10272b5c31057f0663-Paper.pdf},
	urldate = {2022-09-27},
	venue-short = {neurips},
	volume = {34},
	year = {2021},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEFYuLi8uLi8uLi9Ecm9wYm94L0FwcHMvcmVtb3RlbHktc2F2ZS9BSVRvcGljcy9hc3NldHMvcGRmLzIwMjEtbmV1cmlwcy1jaGVuLWRlY2lzaW9uLnBkZk8RBKBib29roAQAAAAABBAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACcAwAABQAAAAEBAABVc2VycwAAAAgAAAABAQAAbWNyb3dsZXkHAAAAAQEAAERyb3Bib3gABAAAAAEBAABBcHBzDQAAAAEBAAByZW1vdGVseS1zYXZlAAAACAAAAAEBAABBSVRvcGljcwYAAAABAQAAYXNzZXRzAAADAAAAAQEAAHBkZgAeAAAAAQEAADIwMjEtbmV1cmlwcy1jaGVuLWRlY2lzaW9uLnBkZgAAJAAAAAEGAAAEAAAAFAAAACQAAAA0AAAAQAAAAFgAAABoAAAAeAAAAIQAAAAIAAAABAMAABVdAAAAAAAACAAAAAQDAAA56AMAAAAAAAgAAAAEAwAAX3UEAAAAAAAIAAAABAMAANGOBAAAAAAACAAAAAQDAAAQUXQCAAAAAAgAAAAEAwAAnhbnAgAAAAAIAAAABAMAADXP4AIAAAAACAAAAAQDAAA2z+ACAAAAAAgAAAAEAwAATFjdAgAAAAAkAAAAAQYAANgAAADoAAAA+AAAAAgBAAAYAQAAKAEAADgBAABIAQAAWAEAAAgAAAAABAAAQcVUjr6AAAAYAAAAAQIAAAEAAAAAAAAADwAAAAAAAAAAAAAAAAAAAAgAAAAEAwAABwAAAAAAAAAEAAAAAwMAAPUBAAAIAAAAAQkAAGZpbGU6Ly8vDAAAAAEBAABNYWNpbnRvc2ggSEQIAAAABAMAAACQgpbnAAAACAAAAAAEAABBxfHLKgAAACQAAAABAQAAMDlCN0VBQkUtNjc5NS00Q0RGLUFCMjQtM0ZGMDg1NjVEMDE2GAAAAAECAACBAAAAAQAAAO8TAAABAAAAAAAAAAAAAAABAAAAAQEAAC8AAAAAAAAAAQUAAA8BAAABAgAAMzY2NDNhZGFiZDBkZmMwYTY1M2QwN2JmOGQ5OTE0NTg1MGI1YWIxYTU3YWEyNmRmMjNkMWQzNWM0OTIxZTJjNzswMDswMDAwMDAwMDswMDAwMDAwMDswMDAwMDAwMDswMDAwMDAwMDAwMDAwMDIwO2NvbS5hcHBsZS5hcHAtc2FuZGJveC5yZWFkLXdyaXRlOzAxOzAxMDAwMDEwOzAwMDAwMDAwMDJkZDU4NGM7MDE7L3VzZXJzL21jcm93bGV5L2Ryb3Bib3gvYXBwcy9yZW1vdGVseS1zYXZlL2FpdG9waWNzL2Fzc2V0cy9wZGYvMjAyMS1uZXVyaXBzLWNoZW4tZGVjaXNpb24ucGRmAADMAAAA/v///wEAAAAAAAAAEAAAAAQQAACsAAAAAAAAAAUQAABoAQAAAAAAABAQAACkAQAAAAAAAEAQAACUAQAAAAAAAAIgAABwAgAAAAAAAAUgAADgAQAAAAAAABAgAADwAQAAAAAAABEgAAAkAgAAAAAAABIgAAAEAgAAAAAAABMgAAAUAgAAAAAAACAgAABQAgAAAAAAADAgAAB8AgAAAAAAAAHAAADEAQAAAAAAABHAAAAUAAAAAAAAABLAAADUAQAAAAAAAIDwAACEAgAAAAAAAAAIAA0AGgAjAHwAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAFIA==},
	bdsk-url-1 = {https://proceedings.neurips.cc/paper_files/paper/2021/file/7f489f642a0ddb10272b5c31057f0663-Paper.pdf}}

@inproceedings{janner2022pmlr,
	abstract = {Model-based reinforcement learning methods often use learning only for the purpose of recovering an approximate dynamics model, offloading the rest of the decision-making work to classical trajectory optimizers. While conceptually simple, this combination has a number of empirical shortcomings, suggesting that learned models may not be well-suited to standard trajectory optimization. In this paper, we consider what it would look like to fold as much of the trajectory optimization pipeline as possible into the modeling problem, such that sampling from the model and planning with it become nearly identical. The core of our technical approach lies in a diffusion probabilistic model that plans by iteratively denoising trajectories. We show how classifier-guided sampling and image inpainting can be reinterpreted as coherent planning strategies, explore the unusual and useful properties of diffusion-based planning methods, and demonstrate the effectiveness of our framework in control settings that emphasize long-horizon decision-making and test-time flexibility.},
	annote = {looks like a very interesting claim },
	author = {Janner, Michael and Du, Yilun and Tenenbaum, Joshua and Levine, Sergey},
	booktitle = {Proceedings of the 39th International Conference on Machine Learning},
	date-added = {2024-02-15 17:44:23 -0500},
	date-modified = {2024-07-24 15:17:31 -0400},
	editor = {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
	hypoth = {https://hyp.is/go?url=https%3A%2F%2Fproceedings.mlr.press%2Fv162%2Fjanner22a%2Fjanner22a.pdf&group=__world__},
	keywords = {reinforcement-learning, transformers, decision-transformers, machine-learning, dcmu, planning, next; rdgrp-f23},
	month = {17--23 Jul},
	order = {5},
	pages = {9902--9915},
	pdf = {2022-pmlr-janner-planning.pdf},
	publisher = {PMLR},
	series = {Proceedings of Machine Learning Research},
	title = {Planning with Diffusion for Flexible Behavior Synthesis},
	toread = {1},
	url = {https://proceedings.mlr.press/v162/janner22a.html},
	venue-short = {PMLR},
	volume = {162},
	year = {2022},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEFUuLi8uLi8uLi9Ecm9wYm94L0FwcHMvcmVtb3RlbHktc2F2ZS9BSVRvcGljcy9hc3NldHMvcGRmLzIwMjItcG1sci1qYW5uZXItcGxhbm5pbmcucGRmTxEEoGJvb2ugBAAAAAAEEDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJwDAAAFAAAAAQEAAFVzZXJzAAAACAAAAAEBAABtY3Jvd2xleQcAAAABAQAARHJvcGJveAAEAAAAAQEAAEFwcHMNAAAAAQEAAHJlbW90ZWx5LXNhdmUAAAAIAAAAAQEAAEFJVG9waWNzBgAAAAEBAABhc3NldHMAAAMAAAABAQAAcGRmAB0AAAABAQAAMjAyMi1wbWxyLWphbm5lci1wbGFubmluZy5wZGYAAAAkAAAAAQYAAAQAAAAUAAAAJAAAADQAAABAAAAAWAAAAGgAAAB4AAAAhAAAAAgAAAAEAwAAFV0AAAAAAAAIAAAABAMAADnoAwAAAAAACAAAAAQDAABfdQQAAAAAAAgAAAAEAwAA0Y4EAAAAAAAIAAAABAMAABBRdAIAAAAACAAAAAQDAACeFucCAAAAAAgAAAAEAwAANc/gAgAAAAAIAAAABAMAADbP4AIAAAAACAAAAAQDAABfWN0CAAAAACQAAAABBgAA2AAAAOgAAAD4AAAACAEAABgBAAAoAQAAOAEAAEgBAABYAQAACAAAAAAEAABBxYiD6YAAABgAAAABAgAAAQAAAAAAAAAPAAAAAAAAAAAAAAAAAAAACAAAAAQDAAAHAAAAAAAAAAQAAAADAwAA9QEAAAgAAAABCQAAZmlsZTovLy8MAAAAAQEAAE1hY2ludG9zaCBIRAgAAAAEAwAAAJCClucAAAAIAAAAAAQAAEHF8csqAAAAJAAAAAEBAAAwOUI3RUFCRS02Nzk1LTRDREYtQUIyNC0zRkYwODU2NUQwMTYYAAAAAQIAAIEAAAABAAAA7xMAAAEAAAAAAAAAAAAAAAEAAAABAQAALwAAAAAAAAABBQAADgEAAAECAABjYzU2NTgwZDdhZDJmOGI5MzUzODIwMTFkNGY0ODkzMjM3ZTBjNzEyYTVlZjRiMTkyN2U5ZjJiYTE1NDI1NGYzOzAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwMDAwMDAwMjA7Y29tLmFwcGxlLmFwcC1zYW5kYm94LnJlYWQtd3JpdGU7MDE7MDEwMDAwMTA7MDAwMDAwMDAwMmRkNTg1ZjswMTsvdXNlcnMvbWNyb3dsZXkvZHJvcGJveC9hcHBzL3JlbW90ZWx5LXNhdmUvYWl0b3BpY3MvYXNzZXRzL3BkZi8yMDIyLXBtbHItamFubmVyLXBsYW5uaW5nLnBkZgAAAMwAAAD+////AQAAAAAAAAAQAAAABBAAAKwAAAAAAAAABRAAAGgBAAAAAAAAEBAAAKQBAAAAAAAAQBAAAJQBAAAAAAAAAiAAAHACAAAAAAAABSAAAOABAAAAAAAAECAAAPABAAAAAAAAESAAACQCAAAAAAAAEiAAAAQCAAAAAAAAEyAAABQCAAAAAAAAICAAAFACAAAAAAAAMCAAAHwCAAAAAAAAAcAAAMQBAAAAAAAAEcAAABQAAAAAAAAAEsAAANQBAAAAAAAAgPAAAIQCAAAAAAAAAAgADQAaACMAewAAAAAAAAIBAAAAAAAAAAUAAAAAAAAAAAAAAAAAAAUf},
	bdsk-url-1 = {https://proceedings.mlr.press/v162/janner22a.html}}

@inproceedings{janner2021neurips,
	annote = {An alternative approach to RL via transformers that came out at the same time as Decision Transformers.},
	author = {Janner, Michael and Li, Qiyang and Levine, Sergey},
	booktitle = {Advances in Neural Information Processing Systems},
	date-added = {2024-02-15 17:44:23 -0500},
	date-modified = {2024-07-24 15:27:43 -0400},
	editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
	hypoth = {https://hyp.is/go?url=https%3A%2F%2Fproceedings.neurips.cc%2Fpaper_files%2Fpaper%2F2021%2Ffile%2F099fe6b0b444c23836c4a5d07346082b-Paper.pdf&group=__world__},
	keywords = {early, reinforcement-learning, transformers, sequenc-modelling, decision-transformers, next, rdgrp-f23; rdgrp-ece750T4-f24},
	order = {5},
	pages = {1273--1286},
	pdf = {2021-neurips-janner-offline.pdf},
	publisher = {Curran Associates, Inc.},
	title = {Offline Reinforcement Learning as One Big Sequence Modeling Problem},
	toread = {1},
	url = {https://proceedings.neurips.cc/paper_files/paper/2021/file/099fe6b0b444c23836c4a5d07346082b-Paper.pdf},
	venue-short = {NeurIPS},
	volume = {34},
	year = {2021},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEFcuLi8uLi8uLi9Ecm9wYm94L0FwcHMvcmVtb3RlbHktc2F2ZS9BSVRvcGljcy9hc3NldHMvcGRmLzIwMjEtbmV1cmlwcy1qYW5uZXItb2ZmbGluZS5wZGZPEQSgYm9va6AEAAAAAAQQMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAnAMAAAUAAAABAQAAVXNlcnMAAAAIAAAAAQEAAG1jcm93bGV5BwAAAAEBAABEcm9wYm94AAQAAAABAQAAQXBwcw0AAAABAQAAcmVtb3RlbHktc2F2ZQAAAAgAAAABAQAAQUlUb3BpY3MGAAAAAQEAAGFzc2V0cwAAAwAAAAEBAABwZGYAHwAAAAEBAAAyMDIxLW5ldXJpcHMtamFubmVyLW9mZmxpbmUucGRmACQAAAABBgAABAAAABQAAAAkAAAANAAAAEAAAABYAAAAaAAAAHgAAACEAAAACAAAAAQDAAAVXQAAAAAAAAgAAAAEAwAAOegDAAAAAAAIAAAABAMAAF91BAAAAAAACAAAAAQDAADRjgQAAAAAAAgAAAAEAwAAEFF0AgAAAAAIAAAABAMAAJ4W5wIAAAAACAAAAAQDAAA1z+ACAAAAAAgAAAAEAwAANs/gAgAAAAAIAAAABAMAAE1Y3QIAAAAAJAAAAAEGAADYAAAA6AAAAPgAAAAIAQAAGAEAACgBAAA4AQAASAEAAFgBAAAIAAAAAAQAAEHFiIVZgAAAGAAAAAECAAABAAAAAAAAAA8AAAAAAAAAAAAAAAAAAAAIAAAABAMAAAcAAAAAAAAABAAAAAMDAAD1AQAACAAAAAEJAABmaWxlOi8vLwwAAAABAQAATWFjaW50b3NoIEhECAAAAAQDAAAAkIKW5wAAAAgAAAAABAAAQcXxyyoAAAAkAAAAAQEAADA5QjdFQUJFLTY3OTUtNENERi1BQjI0LTNGRjA4NTY1RDAxNhgAAAABAgAAgQAAAAEAAADvEwAAAQAAAAAAAAAAAAAAAQAAAAEBAAAvAAAAAAAAAAEFAAAQAQAAAQIAAGY1MjEzODkyODUyNjI3N2FjMjI2OTAyM2I3YmY4Mjg4N2VhN2IzNTE3MDg4ZjhiZDM1ZDY1NDY1MGRjNDRmNGM7MDA7MDAwMDAwMDA7MDAwMDAwMDA7MDAwMDAwMDA7MDAwMDAwMDAwMDAwMDAyMDtjb20uYXBwbGUuYXBwLXNhbmRib3gucmVhZC13cml0ZTswMTswMTAwMDAxMDswMDAwMDAwMDAyZGQ1ODRkOzAxOy91c2Vycy9tY3Jvd2xleS9kcm9wYm94L2FwcHMvcmVtb3RlbHktc2F2ZS9haXRvcGljcy9hc3NldHMvcGRmLzIwMjEtbmV1cmlwcy1qYW5uZXItb2ZmbGluZS5wZGYAzAAAAP7///8BAAAAAAAAABAAAAAEEAAArAAAAAAAAAAFEAAAaAEAAAAAAAAQEAAApAEAAAAAAABAEAAAlAEAAAAAAAACIAAAcAIAAAAAAAAFIAAA4AEAAAAAAAAQIAAA8AEAAAAAAAARIAAAJAIAAAAAAAASIAAABAIAAAAAAAATIAAAFAIAAAAAAAAgIAAAUAIAAAAAAAAwIAAAfAIAAAAAAAABwAAAxAEAAAAAAAARwAAAFAAAAAAAAAASwAAA1AEAAAAAAACA8AAAhAIAAAAAAAAACAANABoAIwB9AAAAAAAAAgEAAAAAAAAABQAAAAAAAAAAAAAAAAAABSE=},
	bdsk-url-1 = {https://proceedings.neurips.cc/paper_files/paper/2021/file/099fe6b0b444c23836c4a5d07346082b-Paper.pdf}}

@inproceedings{xiong2023cvpr,
	annote = {Being used for the first attempt for the CSA wildfire project},
	author = {Xiong, Yuwen and Ma, Wei-Chiu and Wang, Jingkang and Urtasun, Raquel},
	booktitle = {Proceedings of the Conference on Computer Vision and Pattern Recognition (CVPR)},
	date-added = {2024-02-14 15:57:21 -0500},
	date-modified = {2024-07-24 11:41:30 -0400},
	hypoth = {https://hyp.is/go?url=https%3A%2F%2Fopenaccess.thecvf.com%2Fcontent%2FCVPR2023%2Fpapers%2FXiong_Learning_Compact_Representations_for_LiDAR_Completion_and_Generation_CVPR_2023_paper.pdf&group=__world__},
	keywords = {rdgrp-s23; proj-firecsalidar, deep-learning, generative-models, autonomous-driving, lidar},
	pages = {1074--1083},
	title = {Learning Compact Representations for LiDAR Completion and Generation},
	venue-short = {cvpr},
	year = {2023}}

@article{mohsenzadeh2023,
	author = {Yalda Mohsenzadeh},
	date-added = {2023-12-06 10:06:16 -0500},
	date-modified = {2023-12-06 10:07:23 -0500},
	journal = {Macleans},
	keywords = {prez-watitis},
	month = {October 12},
	title = {Machines will read our minds},
	year = {2023}}

@article{lambert2022illustrating,
	author = {Lambert, Nathan and Castricato, Louis and von Werra, Leandro and Havrilla, Alex},
	date-added = {2023-12-06 09:34:04 -0500},
	date-modified = {2024-07-24 15:28:22 -0400},
	journal = {Hugging Face Blog},
	keywords = {early; prez-watitis; reinforcement-learning; large-language-models; gpt; rlhf; rdgrp-ece750T4-f24},
	note = {https://huggingface.co/blog/rlhf},
	order = {2},
	temp = {0},
	title = {Illustrating Reinforcement Learning from Human Feedback (RLHF)},
	year = {2022}}

@article{knight2017dark,
	author = {Knight, Will},
	date-added = {2023-12-06 09:22:11 -0500},
	date-modified = {2023-12-06 09:25:29 -0500},
	journal = {MIT Technology review},
	keywords = {prez-watitis},
	number = {3},
	pages = {54--65},
	publisher = {Massachusetts Institute of Technology Cambridge, MA},
	temp = {1},
	title = {The dark secret at the heart of AI},
	volume = {120},
	year = {2017}}

@article{yang2023arxiv,
	annote = {I'm wary of some of their intro, "BERT models started to disappear" it's only been a year or two. They have a very nice overview figure. This recent review paper gives content on what tasks GPT style decoder-only LLMs are good for and which they are not (most tasks in fact).},
	archiveprefix = {arXiv},
	author = {Jingfeng Yang and Hongye Jin and Ruixiang Tang and Xiaotian Han and Qizhang Feng and Haoming Jiang and Bing Yin and Xia Hu},
	date-added = {2023-12-06 09:19:51 -0500},
	date-modified = {2024-07-24 11:43:47 -0400},
	eprint = {2304.13712},
	in-website = {1},
	journal = {Arxiv Preprint},
	keywords = {done, transformer, BERT, gpt, survey, prez-watitis; rdgrp-s23},
	order = 8,
	pdf = {2023-arxiv-yang-harnessing.pdf},
	primaryclass = {cs.CL},
	temp = {0},
	title = {Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond},
	toread = {1},
	venue-short = {arxiv},
	year = {2023},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEEkuLi8uLi8uLi9Ecm9wYm94L0FwcHMvcmVtb3RlbHktc2F2ZS9BSVRvcGljcy9hc3NldHMvcGRmL3lhbmcyMDIzYXJ4aXYucGRmTxEEiGJvb2uIBAAAAAAEEDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIQDAAAFAAAAAQEAAFVzZXJzAAAACAAAAAEBAABtY3Jvd2xleQcAAAABAQAARHJvcGJveAAEAAAAAQEAAEFwcHMNAAAAAQEAAHJlbW90ZWx5LXNhdmUAAAAIAAAAAQEAAEFJVG9waWNzBgAAAAEBAABhc3NldHMAAAMAAAABAQAAcGRmABEAAAABAQAAeWFuZzIwMjNhcnhpdi5wZGYAAAAkAAAAAQYAAAQAAAAUAAAAJAAAADQAAABAAAAAWAAAAGgAAAB4AAAAhAAAAAgAAAAEAwAAFV0AAAAAAAAIAAAABAMAADnoAwAAAAAACAAAAAQDAABfdQQAAAAAAAgAAAAEAwAA0Y4EAAAAAAAIAAAABAMAABBRdAIAAAAACAAAAAQDAACeFucCAAAAAAgAAAAEAwAANc/gAgAAAAAIAAAABAMAADbP4AIAAAAACAAAAAQDAABlWN0CAAAAACQAAAABBgAAzAAAANwAAADsAAAA/AAAAAwBAAAcAQAALAEAADwBAABMAQAACAAAAAAEAABBxZB1TYAAABgAAAABAgAAAQAAAAAAAAAPAAAAAAAAAAAAAAAAAAAACAAAAAQDAAAHAAAAAAAAAAQAAAADAwAA9QEAAAgAAAABCQAAZmlsZTovLy8MAAAAAQEAAE1hY2ludG9zaCBIRAgAAAAEAwAAAJCClucAAAAIAAAAAAQAAEHF8csqAAAAJAAAAAEBAAAwOUI3RUFCRS02Nzk1LTRDREYtQUIyNC0zRkYwODU2NUQwMTYYAAAAAQIAAIEAAAABAAAA7xMAAAEAAAAAAAAAAAAAAAEAAAABAQAALwAAAAAAAAABBQAAAgEAAAECAABhZTBlZGUwOWY1OTI1YjZmYWQ4ZTc4NTQ2NGJmMDE3MzU0OWVkMDY1ZGNhMDQ1ZjhiZjg0MmMxZmRkNTgyY2EzOzAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwMDAwMDAwMjA7Y29tLmFwcGxlLmFwcC1zYW5kYm94LnJlYWQtd3JpdGU7MDE7MDEwMDAwMTA7MDAwMDAwMDAwMmRkNTg2NTswMTsvdXNlcnMvbWNyb3dsZXkvZHJvcGJveC9hcHBzL3JlbW90ZWx5LXNhdmUvYWl0b3BpY3MvYXNzZXRzL3BkZi95YW5nMjAyM2FyeGl2LnBkZgAAAMwAAAD+////AQAAAAAAAAAQAAAABBAAAKAAAAAAAAAABRAAAFwBAAAAAAAAEBAAAJgBAAAAAAAAQBAAAIgBAAAAAAAAAiAAAGQCAAAAAAAABSAAANQBAAAAAAAAECAAAOQBAAAAAAAAESAAABgCAAAAAAAAEiAAAPgBAAAAAAAAEyAAAAgCAAAAAAAAICAAAEQCAAAAAAAAMCAAAHACAAAAAAAAAcAAALgBAAAAAAAAEcAAABQAAAAAAAAAEsAAAMgBAAAAAAAAgPAAAHgCAAAAAAAAAAgADQAaACMAbwAAAAAAAAIBAAAAAAAAAAUAAAAAAAAAAAAAAAAAAAT7}}

@inproceedings{devlin2019naaclhlt,
	annote = {The original paper for the BERT transformer model for NLP tasks.},
	author = {Jacob Devlin and Ming-Wei Chang and Kenten Lee and Kristina Toutanova},
	booktitle = {Proceedings of NAACL-HLT},
	date-added = {2023-12-06 09:19:51 -0500},
	date-discussed = {2023-06-14 14 led by Josh Sun},
	date-modified = {2024-07-24 11:43:47 -0400},
	in-website = {1},
	keywords = {done, machine-learning, transformers, nlp, BERT, large-language-models; rdgrp-s23},
	order = {4},
	pages = {4171--4186},
	paperdesc = {The original paper for the BERT transformer model for NLP tasks.},
	pdf = {2019-naaclhlt-kenton-bert pre-training of deep bidirectional transformers for language understanding},
	status = {1},
	temp = {0},
	title = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
	toread = {1},
	venue-short = {naaclhlt},
	year = {2019},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEE4uLi8uLi8uLi9Ecm9wYm94L0FwcHMvcmVtb3RlbHktc2F2ZS9BSVRvcGljcy9hc3NldHMvcGRmL2RldmxpbjIwMTluYWFjbGhsdC5wZGZPEQSQYm9va5AEAAAAAAQQMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAjAMAAAUAAAABAQAAVXNlcnMAAAAIAAAAAQEAAG1jcm93bGV5BwAAAAEBAABEcm9wYm94AAQAAAABAQAAQXBwcw0AAAABAQAAcmVtb3RlbHktc2F2ZQAAAAgAAAABAQAAQUlUb3BpY3MGAAAAAQEAAGFzc2V0cwAAAwAAAAEBAABwZGYAFgAAAAEBAABkZXZsaW4yMDE5bmFhY2xobHQucGRmAAAkAAAAAQYAAAQAAAAUAAAAJAAAADQAAABAAAAAWAAAAGgAAAB4AAAAhAAAAAgAAAAEAwAAFV0AAAAAAAAIAAAABAMAADnoAwAAAAAACAAAAAQDAABfdQQAAAAAAAgAAAAEAwAA0Y4EAAAAAAAIAAAABAMAABBRdAIAAAAACAAAAAQDAACeFucCAAAAAAgAAAAEAwAANc/gAgAAAAAIAAAABAMAADbP4AIAAAAACAAAAAQDAAAtWN0CAAAAACQAAAABBgAA0AAAAOAAAADwAAAAAAEAABABAAAgAQAAMAEAAEABAABQAQAACAAAAAAEAABBxVSOvoAAABgAAAABAgAAAQAAAAAAAAAPAAAAAAAAAAAAAAAAAAAACAAAAAQDAAAHAAAAAAAAAAQAAAADAwAA9QEAAAgAAAABCQAAZmlsZTovLy8MAAAAAQEAAE1hY2ludG9zaCBIRAgAAAAEAwAAAJCClucAAAAIAAAAAAQAAEHF8csqAAAAJAAAAAEBAAAwOUI3RUFCRS02Nzk1LTRDREYtQUIyNC0zRkYwODU2NUQwMTYYAAAAAQIAAIEAAAABAAAA7xMAAAEAAAAAAAAAAAAAAAEAAAABAQAALwAAAAAAAAABBQAABwEAAAECAAA3ZTEyZGIxNTQyYjQ5NmE5MjAyZGUwOTQ3MGI5YzViYTM5YzkzMDgzMzAwMWMzNTNmMDc3Y2ZhN2FkMGYwZTJlOzAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwMDAwMDAwMjA7Y29tLmFwcGxlLmFwcC1zYW5kYm94LnJlYWQtd3JpdGU7MDE7MDEwMDAwMTA7MDAwMDAwMDAwMmRkNTgyZDswMTsvdXNlcnMvbWNyb3dsZXkvZHJvcGJveC9hcHBzL3JlbW90ZWx5LXNhdmUvYWl0b3BpY3MvYXNzZXRzL3BkZi9kZXZsaW4yMDE5bmFhY2xobHQucGRmAADMAAAA/v///wEAAAAAAAAAEAAAAAQQAACkAAAAAAAAAAUQAABgAQAAAAAAABAQAACcAQAAAAAAAEAQAACMAQAAAAAAAAIgAABoAgAAAAAAAAUgAADYAQAAAAAAABAgAADoAQAAAAAAABEgAAAcAgAAAAAAABIgAAD8AQAAAAAAABMgAAAMAgAAAAAAACAgAABIAgAAAAAAADAgAAB0AgAAAAAAAAHAAAC8AQAAAAAAABHAAAAUAAAAAAAAABLAAADMAQAAAAAAAIDwAAB8AgAAAAAAAAAIAA0AGgAjAHQAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAFCA==}}

@inproceedings{goodfellow2014neurips,
	abstract = {We propose a new framework for estimating generative models via adversarial nets, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitatively evaluation of the generated samples.},
	annote = {Seminal paper introducing the GAN framework which provided a huge advance in generative learning for images using novel metaphors from adversarial game theory to guide optimization.},
	author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
	booktitle = {Advances in Neural Information Processing Systems},
	date-added = {2023-11-17 08:48:30 -0500},
	date-modified = {2023-11-17 08:50:28 -0500},
	editor = {Z. Ghahramani and M. Welling and C. Cortes and N. Lawrence and K.Q. Weinberger},
	keywords = {deep-learning, generative-models, image-processing, game-theory; grant-csa-fire-2023},
	publisher = {Curran Associates, Inc.},
	rating = {5},
	seminal = {1},
	title = {Generative Adversarial Nets},
	url = {https://proceedings.neurips.cc/paper_files/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf},
	venue-short = {NeurIPS},
	volume = {27},
	year = {2014},
	bdsk-url-1 = {https://proceedings.neurips.cc/paper_files/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf}}

@inproceedings{gpt3,
	abstract = {We demonstrate that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even becoming competitive with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks. We also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora.},
	address = {Virtual.},
	annote = {Introduction of the GPT-3 model.},
	arxiv = {2005.14165},
	author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
	booktitle = {Advances in Neural Information Processing Systems},
	date-added = {2023-11-17 08:44:49 -0500},
	date-discussed = {2023-06-28 led by Felix},
	date-modified = {2024-07-24 11:43:47 -0400},
	editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
	hypoth = {https://hyp.is/go?url=https%3A%2F%2Fpapers.nips.cc%2Fpaper_files%2Fpaper%2F2020%2Ffile%2F1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf&group=__world__},
	keywords = {large-language-models, gpt, transformers; done; grant-csa-fire-2023; prez-watitis; rdgrp-s23},
	note = {Introduction of the GPT-3 model.},
	order = {5},
	pages = {1877--1901},
	pdf = {2020-neurips-brown-language.pdf},
	temp = {0},
	title = {Language Models are Few-Shot Learners},
	toread = {1},
	url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf},
	venue-short = {neurips},
	volume = {33},
	year = {2020},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEEwuLi8uLi8uLi9Ecm9wYm94L0FwcHMvcmVtb3RlbHktc2F2ZS9BSVRvcGljcy9hc3NldHMvcGRmL2Jyb3duMjAyMG5ldXJpcHMucGRmTxEEjGJvb2uMBAAAAAAEEDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIgDAAAFAAAAAQEAAFVzZXJzAAAACAAAAAEBAABtY3Jvd2xleQcAAAABAQAARHJvcGJveAAEAAAAAQEAAEFwcHMNAAAAAQEAAHJlbW90ZWx5LXNhdmUAAAAIAAAAAQEAAEFJVG9waWNzBgAAAAEBAABhc3NldHMAAAMAAAABAQAAcGRmABQAAAABAQAAYnJvd24yMDIwbmV1cmlwcy5wZGYkAAAAAQYAAAQAAAAUAAAAJAAAADQAAABAAAAAWAAAAGgAAAB4AAAAhAAAAAgAAAAEAwAAFV0AAAAAAAAIAAAABAMAADnoAwAAAAAACAAAAAQDAABfdQQAAAAAAAgAAAAEAwAA0Y4EAAAAAAAIAAAABAMAABBRdAIAAAAACAAAAAQDAACeFucCAAAAAAgAAAAEAwAANc/gAgAAAAAIAAAABAMAADbP4AIAAAAACAAAAAQDAAAzWN0CAAAAACQAAAABBgAAzAAAANwAAADsAAAA/AAAAAwBAAAcAQAALAEAADwBAABMAQAACAAAAAAEAABBxVSOvoAAABgAAAABAgAAAQAAAAAAAAAPAAAAAAAAAAAAAAAAAAAACAAAAAQDAAAHAAAAAAAAAAQAAAADAwAA9QEAAAgAAAABCQAAZmlsZTovLy8MAAAAAQEAAE1hY2ludG9zaCBIRAgAAAAEAwAAAJCClucAAAAIAAAAAAQAAEHF8csqAAAAJAAAAAEBAAAwOUI3RUFCRS02Nzk1LTRDREYtQUIyNC0zRkYwODU2NUQwMTYYAAAAAQIAAIEAAAABAAAA7xMAAAEAAAAAAAAAAAAAAAEAAAABAQAALwAAAAAAAAABBQAABQEAAAECAAA1Yjk3NmMyNzIxZTI1NmZkM2YzMTU4ZTQ0ODIzMDg2MDFmN2VmMzAyMWZkZjg1NmJiOWRhMzg5MGJiYjA0Y2IxOzAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwMDAwMDAwMjA7Y29tLmFwcGxlLmFwcC1zYW5kYm94LnJlYWQtd3JpdGU7MDE7MDEwMDAwMTA7MDAwMDAwMDAwMmRkNTgzMzswMTsvdXNlcnMvbWNyb3dsZXkvZHJvcGJveC9hcHBzL3JlbW90ZWx5LXNhdmUvYWl0b3BpY3MvYXNzZXRzL3BkZi9icm93bjIwMjBuZXVyaXBzLnBkZgAAAADMAAAA/v///wEAAAAAAAAAEAAAAAQQAACgAAAAAAAAAAUQAABcAQAAAAAAABAQAACYAQAAAAAAAEAQAACIAQAAAAAAAAIgAABkAgAAAAAAAAUgAADUAQAAAAAAABAgAADkAQAAAAAAABEgAAAYAgAAAAAAABIgAAD4AQAAAAAAABMgAAAIAgAAAAAAACAgAABEAgAAAAAAADAgAABwAgAAAAAAAAHAAAC4AQAAAAAAABHAAAAUAAAAAAAAABLAAADIAQAAAAAAAIDwAAB4AgAAAAAAAAAIAA0AGgAjAHIAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAFAg==},
	bdsk-url-1 = {https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf}}

@inproceedings{vaswani2017neurips,
	abbr = {Trnsfrmr},
	abstract = {The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms. We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.},
	address = {Long Beach California, USA},
	annote = {The original paper that introduced the Transformers architecture.  The stack of modules of the original transformer are quite similar to multiple subsequent layers of a CNN rather than the CNN filters. <br/><b>Questions</b><br/> <ol> <li> Why do they "stack" the modules in the original transformer?  </li> <li> How does the output of one module feed into the next in the stack?  </li> <li>Is there a notion of "sets" and "subsets" somewhere in this definition? Relations being learned amongst sets of non-local symbols?  </li> <li>Multi-head : where is the multi-part? It's not the QKV parts, it's a set of <em>h</em> copies of the attention module. (this is well hidden) </li> <li>"Pair-of-pairs" we discussed that the <em>h</em> copies of the the attention mechanism are considering pairs-of-pairs of symbol outputs or attention outputs, is it really though? Or are they independent filters as in CNNs?  </li> <li><b>The Big Question:</b> why does it work so well? It's not just "more weights is better", the architecture matters.  </li> </ol>},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
	booktitle = {Advances in Neural Information Processing Systems},
	date-added = {2023-11-17 08:44:49 -0500},
	date-discussed = {2023-05-31 led by Mark Crowley},
	date-modified = {2024-07-24 11:43:47 -0400},
	editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
	hypoth = {https://hyp.is/go?url=https%3A%2F%2Farxiv.org%2Fpdf%2F1706.03762.pdf&group=__world__},
	in-website = {1},
	keywords = {done, machine-learning, transformer, recurrent-neural-networks, lstm,nlp; rdgrp-s23},
	month = {December},
	order = {2},
	pdf = {2017-neurips-vaswani-attention.pdf},
	seminal = {1},
	status = {1},
	temp = {0},
	title = {Attention is All you Need},
	toread = {0},
	url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
	venue-short = {neurips},
	volume = {30},
	year = {2017},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEE4uLi8uLi8uLi9Ecm9wYm94L0FwcHMvcmVtb3RlbHktc2F2ZS9BSVRvcGljcy9hc3NldHMvcGRmL3Zhc3dhbmkyMDE3bmV1cmlwcy5wZGZPEQSQYm9va5AEAAAAAAQQMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAjAMAAAUAAAABAQAAVXNlcnMAAAAIAAAAAQEAAG1jcm93bGV5BwAAAAEBAABEcm9wYm94AAQAAAABAQAAQXBwcw0AAAABAQAAcmVtb3RlbHktc2F2ZQAAAAgAAAABAQAAQUlUb3BpY3MGAAAAAQEAAGFzc2V0cwAAAwAAAAEBAABwZGYAFgAAAAEBAAB2YXN3YW5pMjAxN25ldXJpcHMucGRmAAAkAAAAAQYAAAQAAAAUAAAAJAAAADQAAABAAAAAWAAAAGgAAAB4AAAAhAAAAAgAAAAEAwAAFV0AAAAAAAAIAAAABAMAADnoAwAAAAAACAAAAAQDAABfdQQAAAAAAAgAAAAEAwAA0Y4EAAAAAAAIAAAABAMAABBRdAIAAAAACAAAAAQDAACeFucCAAAAAAgAAAAEAwAANc/gAgAAAAAIAAAABAMAADbP4AIAAAAACAAAAAQDAAAcWN0CAAAAACQAAAABBgAA0AAAAOAAAADwAAAAAAEAABABAAAgAQAAMAEAAEABAABQAQAACAAAAAAEAABBxVSOvoAAABgAAAABAgAAAQAAAAAAAAAPAAAAAAAAAAAAAAAAAAAACAAAAAQDAAAHAAAAAAAAAAQAAAADAwAA9QEAAAgAAAABCQAAZmlsZTovLy8MAAAAAQEAAE1hY2ludG9zaCBIRAgAAAAEAwAAAJCClucAAAAIAAAAAAQAAEHF8csqAAAAJAAAAAEBAAAwOUI3RUFCRS02Nzk1LTRDREYtQUIyNC0zRkYwODU2NUQwMTYYAAAAAQIAAIEAAAABAAAA7xMAAAEAAAAAAAAAAAAAAAEAAAABAQAALwAAAAAAAAABBQAABwEAAAECAABjZDcwZWRiMjg4YzM1ZDA1ZDllYzg1MjM2OTQ1ZGY5MGNkMzY0MTU5YjQxMDY2OWNhM2EwODU4ZGNkZWRkYWIyOzAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwMDAwMDAwMjA7Y29tLmFwcGxlLmFwcC1zYW5kYm94LnJlYWQtd3JpdGU7MDE7MDEwMDAwMTA7MDAwMDAwMDAwMmRkNTgxYzswMTsvdXNlcnMvbWNyb3dsZXkvZHJvcGJveC9hcHBzL3JlbW90ZWx5LXNhdmUvYWl0b3BpY3MvYXNzZXRzL3BkZi92YXN3YW5pMjAxN25ldXJpcHMucGRmAADMAAAA/v///wEAAAAAAAAAEAAAAAQQAACkAAAAAAAAAAUQAABgAQAAAAAAABAQAACcAQAAAAAAAEAQAACMAQAAAAAAAAIgAABoAgAAAAAAAAUgAADYAQAAAAAAABAgAADoAQAAAAAAABEgAAAcAgAAAAAAABIgAAD8AQAAAAAAABMgAAAMAgAAAAAAACAgAABIAgAAAAAAADAgAAB0AgAAAAAAAAHAAAC8AQAAAAAAABHAAAAUAAAAAAAAABLAAADMAQAAAAAAAIDwAAB8AgAAAAAAAAAIAA0AGgAjAHQAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAFCA==},
	bdsk-url-1 = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf}}

@inproceedings{caccia2019,
	author = {Caccia, Lucas and Hoof, Herke van and Courville, Aaron and Pineau, Joelle},
	booktitle = {2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
	date-added = {2023-11-17 08:43:59 -0500},
	date-modified = {2024-02-20 11:36:59 -0500},
	doi = {10.1109/IROS40897.2019.8968535},
	keywords = {grant-csa-fire-2023; lidar; generative-models},
	pages = {5034-5040},
	title = {Deep Generative Modeling of LiDAR Data},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1109/IROS40897.2019.8968535}}

@inproceedings{corso2019itsc,
	abstract = {Determining possible failure scenarios is a critical step in the evaluation of autonomous vehicle systems. Real-world vehicle testing is commonly employed for autonomous vehicle validation, but the costs and time requirements are high. Consequently, simulation-driven methods such as Adaptive Stress Testing (AST) have been proposed to aid in validation. AST formulates the problem of finding the most likely failure scenarios as a Markov decision process, which can be solved using reinforcement learning. In practice, AST tends to find scenarios where failure is unavoidable and tends to repeatedly discover the same types of failures of a system. This work addresses these issues by encoding domain relevant information into the search procedure. With this modification, the AST method discovers a larger and more expressive subset of the failure space when compared to the original AST formulation. We show that our approach is able to identify useful failure scenarios of an autonomous vehicle policy.},
	annote = {Mentioned during Xiaoliang Zhou's MASc seminar that they have done more recently to learn realism scores from traffic data.},
	arxiv = {1908.01046},
	author = {Corso, Anthony and Du, Peter and Driggs-Campbell, Katherine and Kochenderfer, Mykel J.},
	booktitle = {2019 IEEE Intelligent Transportation Systems Conference (ITSC)},
	date-added = {2023-09-15 12:23:20 -0400},
	date-modified = {2024-03-24 23:20:25 -0400},
	doi = {10.1109/ITSC.2019.8917242},
	hypoth = {https://hyp.is/go?url=https%3A%2F%2Farxiv.org%2Fpdf%2F1908.01046.pdf&group=__world__},
	keywords = {proj-black-box-testing, multi-agent learning, autonomous-driving, toread, xiaoliangzhou, oleksandra},
	pages = {163-168},
	rating = {4},
	title = {Adaptive Stress Testing with Reward Augmentation for Autonomous Vehicle Validatio},
	toread = {1},
	venue-short = {itsc},
	year = {2019},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEEkuLi8uLi8uLi9Ecm9wYm94L0FwcHMvcmVtb3RlbHktc2F2ZS9BSVRvcGljcy9hc3NldHMvcGRmL2NvcnNvMjAxOWl0c2MucGRmTxEEiGJvb2uIBAAAAAAEEDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIQDAAAFAAAAAQEAAFVzZXJzAAAACAAAAAEBAABtY3Jvd2xleQcAAAABAQAARHJvcGJveAAEAAAAAQEAAEFwcHMNAAAAAQEAAHJlbW90ZWx5LXNhdmUAAAAIAAAAAQEAAEFJVG9waWNzBgAAAAEBAABhc3NldHMAAAMAAAABAQAAcGRmABEAAAABAQAAY29yc28yMDE5aXRzYy5wZGYAAAAkAAAAAQYAAAQAAAAUAAAAJAAAADQAAABAAAAAWAAAAGgAAAB4AAAAhAAAAAgAAAAEAwAAFV0AAAAAAAAIAAAABAMAADnoAwAAAAAACAAAAAQDAABfdQQAAAAAAAgAAAAEAwAA0Y4EAAAAAAAIAAAABAMAABBRdAIAAAAACAAAAAQDAACeFucCAAAAAAgAAAAEAwAANc/gAgAAAAAIAAAABAMAADbP4AIAAAAACAAAAAQDAAD6KdgBAAAAACQAAAABBgAAzAAAANwAAADsAAAA/AAAAAwBAAAcAQAALAEAADwBAABMAQAACAAAAAAEAABBxVpekwzaoxgAAAABAgAAAQAAAAAAAAAPAAAAAAAAAAAAAAAAAAAACAAAAAQDAAAHAAAAAAAAAAQAAAADAwAA9QEAAAgAAAABCQAAZmlsZTovLy8MAAAAAQEAAE1hY2ludG9zaCBIRAgAAAAEAwAAAJCClucAAAAIAAAAAAQAAEHF8csqAAAAJAAAAAEBAAAwOUI3RUFCRS02Nzk1LTRDREYtQUIyNC0zRkYwODU2NUQwMTYYAAAAAQIAAIEAAAABAAAA7xMAAAEAAAAAAAAAAAAAAAEAAAABAQAALwAAAAAAAAABBQAAAgEAAAECAABiZjlhOWIxMDRlOTViMzhjOTNjYmQ1ZWMyNGM5MjkwYWM1MjNjMzViMGE3NGE4NmMyM2NhMDFjODJiNzRhNzhjOzAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwMDAwMDAwMjA7Y29tLmFwcGxlLmFwcC1zYW5kYm94LnJlYWQtd3JpdGU7MDE7MDEwMDAwMTA7MDAwMDAwMDAwMWQ4MjlmYTswMTsvdXNlcnMvbWNyb3dsZXkvZHJvcGJveC9hcHBzL3JlbW90ZWx5LXNhdmUvYWl0b3BpY3MvYXNzZXRzL3BkZi9jb3JzbzIwMTlpdHNjLnBkZgAAAMwAAAD+////AQAAAAAAAAAQAAAABBAAAKAAAAAAAAAABRAAAFwBAAAAAAAAEBAAAJgBAAAAAAAAQBAAAIgBAAAAAAAAAiAAAGQCAAAAAAAABSAAANQBAAAAAAAAECAAAOQBAAAAAAAAESAAABgCAAAAAAAAEiAAAPgBAAAAAAAAEyAAAAgCAAAAAAAAICAAAEQCAAAAAAAAMCAAAHACAAAAAAAAAcAAALgBAAAAAAAAEcAAABQAAAAAAAAAEsAAAMgBAAAAAAAAgPAAAHgCAAAAAAAAAAgADQAaACMAbwAAAAAAAAIBAAAAAAAAAAUAAAAAAAAAAAAAAAAAAAT7},
	bdsk-url-1 = {https://doi.org/10.1109/ITSC.2019.8917242}}

@comment{BibDesk Static Groups{
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<array>
	<dict>
		<key>group name</key>
		<string>RLConf2024</string>
		<key>keys</key>
		<string>abel2016aaaiaies,ayars2016jourcognition,badea2022sgai,christopoulos2017jourbusethics,haas2022dnhni,herlau2022icccr,hadfield-menell2017neurips,peschl2022aamas</string>
	</dict>
</array>
</plist>
}}

@comment{BibDesk Smart Groups{
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<array>
	<dict>
		<key>conditions</key>
		<array>
			<dict>
				<key>comparison</key>
				<integer>2</integer>
				<key>key</key>
				<string>Keywords</string>
				<key>value</key>
				<string>rdgrp-s23</string>
				<key>version</key>
				<string>1</string>
			</dict>
		</array>
		<key>conjunction</key>
		<integer>0</integer>
		<key>group name</key>
		<string>rdgrp-s23</string>
	</dict>
	<dict>
		<key>conditions</key>
		<array>
			<dict>
				<key>comparison</key>
				<integer>2</integer>
				<key>key</key>
				<string>Keywords</string>
				<key>value</key>
				<string>rdgrp-ece750T4-f24</string>
				<key>version</key>
				<string>1</string>
			</dict>
		</array>
		<key>conjunction</key>
		<integer>0</integer>
		<key>group name</key>
		<string>rdgrp-ece750T4-f24</string>
	</dict>
	<dict>
		<key>conditions</key>
		<array>
			<dict>
				<key>comparison</key>
				<integer>2</integer>
				<key>key</key>
				<string>Keywords</string>
				<key>value</key>
				<string>rdgrp-f23</string>
				<key>version</key>
				<string>1</string>
			</dict>
		</array>
		<key>conjunction</key>
		<integer>0</integer>
		<key>group name</key>
		<string>rdgrp-f23</string>
	</dict>
</array>
</plist>
}}

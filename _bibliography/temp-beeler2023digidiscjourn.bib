%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Mark at 2024-07-26 00:17:14 -0400 


%% Saved with string encoding Unicode (UTF-8) 



@book{bellman:1957,
	address = {New Jersey},
	author = {Bellman, R},
	bdsk-color = {1},
	date-modified = {2024-07-26 00:11:11 -0400},
	keywords = {foundational; paper-beeler2023digidiscjourn; reinforcement-learning},
	publisher = {Princeton University Press},
	temp = {0},
	title = {{Dynamic Programming}},
	year = {1957}}

@article{puterman1978,
	author = {Puterman, Martin L and Shin, Moon Chirl},
	bdsk-color = {1},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {Management Science},
	keywords = {paper-beeler2023digidiscjourn; foundational; reinforcement-learning},
	number = {11},
	pages = {pp. 1127--1137},
	temp = {0},
	title = {{Modified Policy Iteration Algorithms for Discounted Markov Decision Problems}},
	volume = {24},
	year = {1978}}

@phdthesis{watkins1989,
	address = {UK},
	author = {Watkins, C J},
	bdsk-color = {1},
	date-modified = {2024-07-26 00:11:11 -0400},
	keywords = {paper-beeler2023digidiscjourn; foundational; reinforcement-learning},
	note = {Is this Q-Learning?},
	school = {King's College, Cambridge},
	temp = {0},
	title = {{Learning from Delayed Rewards}},
	year = {1989}}

@incollection{Werbos1992,
	author = {Werbos, Paul},
	bdsk-color = {1},
	booktitle = {HANDBOOK OF INTELLIGENT CONTROL},
	date-modified = {2024-07-26 00:11:11 -0400},
	editor = {White, David A and Sorge, Donald A},
	keywords = {paper-beeler2023digidiscjourn; foundational; reinforcement-learning},
	pages = {65--89},
	temp = {0},
	title = {{Neurocontrol and Supervised Learning: An Overview and Evaluation}},
	year = {1992}}

@article{williams1992,
	author = {Williams, Ronald J},
	bdsk-color = {1},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {Machine Learning},
	keywords = {paper-beeler2023digidiscjourn; foundational; reinforcement-learning; reinforce; policy-gradient},
	number = {2},
	pages = {229--256},
	temp = {0},
	title = {{Simple statistical gradient-following algorithms for connectionist reinforcement learning}},
	volume = {8},
	year = {1992}}

@unpublished{singh:1993pg,
	author = {Singh, S and Gullapalli, V},
	date-modified = {2024-07-26 00:11:11 -0400},
	keywords = {paper-beeler2023digidiscjourn; reinforcement-learning},
	title = {{Asynchronous modified policy iteration with single-sided updates}},
	year = {1993}}

@book{bertsekas1996,
	address = {Nashua, NH.},
	author = {Bertsekas, Dimitri P and Tsitsiklis, John N},
	bdsk-color = {1},
	date-modified = {2024-07-26 00:11:11 -0400},
	keywords = {paper-beeler2023digidiscjourn; foundational; reinforcement-learning},
	publisher = {Athena Scientific},
	temp = {0},
	title = {{Neuro-Dymanic Programming}},
	year = {1996}}

@article{amari1998,
	author = {Amari, S},
	bdsk-color = {1},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {Neural Computation},
	keywords = {paper-beeler2023digidiscjourn; foundational; reinforcement-learning; policy-gradient},
	pages = {251--276},
	temp = {0},
	title = {{Natural gradient works efficiently in learning.}},
	volume = {10},
	year = {1998}}

@book{sutton:1998,
	address = {Cambridge, MA},
	author = {Sutton, R.S. and Barto, A.G.},
	bdsk-color = {1},
	date-modified = {2024-07-26 00:11:11 -0400},
	keywords = {paper-beeler2023digidiscjourn; foundational; reference; reinforcement-learning},
	number = {5},
	publisher = {MIT Press},
	temp = {0},
	title = {{Reinforcement Learning: An Introduction}},
	volume = {9},
	year = {1998}}

@inproceedings{Strens2000,
	author = {Strens, Malcolm and Dera, Mjstrens and Uk, G O V},
	booktitle = {Proceeedings of the Seventeenth International Conference on Machine Learning (ICML-2000)},
	date-modified = {2024-07-26 00:11:11 -0400},
	keywords = {paper-beeler2023digidiscjourn; reinforcement-learning},
	title = {{A Bayesian Framework for Reinforcement Learning}},
	year = {2000}}

@article{Diettrich.:2000fk,
	author = {Diettrich., T G},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {Journal of Artificial Intelligence Research},
	keywords = {paper-beeler2023digidiscjourn; reinforcement-learning},
	pages = {227--303},
	title = {{Hierarchical reinforcement learning with the maxq value function decomposition.}},
	volume = {13},
	year = {2000}}

@misc{Mihatsch2002,
	author = {Mihatsch, Oliver and Neuneier, Ralph},
	date-modified = {2024-07-26 00:11:11 -0400},
	keywords = {paper-beeler2023digidiscjourn; reinforcement-learning},
	title = {{Risk-sensitive reinforcement learning}},
	year = {2002}}

@inproceedings{Guestrin02-CRL-sh,
	author = {Guestrin, Carlos and Lagoudakis, Michail and Parr, Ronald},
	booktitle = {ICML},
	date-modified = {2024-07-26 00:11:11 -0400},
	keywords = {paper-beeler2023digidiscjourn; reinforcement-learning},
	pages = {227--234},
	title = {{Coordinated Reinforcement Learning}},
	year = {2002}}

@techreport{u9barto:2003cr,
	author = {Barto, A and Mahadevan, S},
	date-modified = {2024-07-26 00:11:11 -0400},
	institution = {University of Massachusetts},
	keywords = {paper-beeler2023digidiscjourn; reinforcement-learning; hierarchical-reinforcement-learning},
	title = {{Recent advances in hierarchical reinforcement learning}},
	year = {2003}}

@inproceedings{Peters:2005fk,
	author = {Peters, Jan and Vijayakumar, Sethu and Schaal, Stefan},
	bdsk-color = {1},
	booktitle = {European Conference on Machine Learning},
	date-modified = {2024-07-26 00:11:11 -0400},
	editor = {Et. al., J Gama},
	keywords = {paper-beeler2023digidiscjourn; foundational; reinforcement-learning; actor-critic},
	pages = {280--291},
	publisher = {Springer Verlag, Berlin},
	series = {Lecture Notes in Computer Science},
	temp = {0},
	title = {{Natural Actor Critic}},
	volume = {3720},
	year = {2005}}

@article{Strehl2006,
	author = {Strehl, Alexander L and Wiewiora, Eric and Langford, John and Littman, Michael L},
	bdsk-color = {582077695},
	date-modified = {2024-07-26 00:16:50 -0400},
	journal = {Update},
	keywords = {paper-beeler2023digidiscjourn; reinforcement-learning; performance-guarantees; confidence; rd-potential},
	temp = {0},
	title = {{PAC Model-Free Reinforcement Learning}},
	year = {2006}}

@inproceedings{Riedmiller:2007fk,
	author = {Riedmiller, Martin and Peters, Jan and Schaal, Stefan},
	booktitle = {IEEE Symposium on Approximate Dynamic Programming and Reinforcement Learning},
	date-modified = {2024-07-26 00:11:11 -0400},
	keywords = {paper-beeler2023digidiscjourn; reinforcement-learning; policy-gradient},
	pages = {254--261},
	title = {{Evaluation of Policy Gradient Methods and Variants on the Cart-Pole Benchmark}},
	year = {2007}}

@article{Li2008c,
	author = {Li, Lihong and Littman, Michael and Walsh, Thomas J},
	bdsk-color = {582077695},
	date-modified = {2024-07-26 00:17:01 -0400},
	journal = {Proceedings of the 25th International Conference on Machine Learning},
	keywords = {paper-beeler2023digidiscjourn; reinforcement-learning; rd-potential},
	pages = {568--575},
	temp = {0},
	title = {{Knows What It Knows: A Framework For Self-Aware Learning}},
	year = {2008}}

@techreport{Abernethy2008,
	author = {Abernethy, Jacob Duncan and Hazan, Elad and Rakhlin, Alexander},
	date-modified = {2024-07-26 00:11:11 -0400},
	institution = {EECS Department, University of California, Berkeley},
	keywords = {paper-beeler2023digidiscjourn; reinforcement-learning},
	month = {feb},
	number = {UCB/EECS-2008-18},
	title = {{An Efficient Algorithm for Bandit Linear Optimization}},
	year = {2008}}

@inproceedings{hasselt2010,
	author = {Hasselt, Hado Van and Group, Adaptive Computation and Wiskunde, Centrum},
	booktitle = {Advances in Neural Information Processing Systems 23},
	date-modified = {2024-07-26 00:11:11 -0400},
	editor = {Lafferty, J D and Williams, C K I and Shawe-Taylor, J and Zemel, R S and Culotta, A},
	keywords = {paper-beeler2023digidiscjourn; reinforcement-learning; q-learning},
	pages = {1--9},
	publisher = {Curran Associates, Inc.},
	title = {{Double Q-learning}},
	year = {2010}}

@article{Mnih2015,
	author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei a and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
	bdsk-color = {3},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {Nature},
	keywords = {rd-early; paper-beeler2023digidiscjourn; seminal; dqn, deep-learning; deep-reinforcement-learning; atari; reinforcement-learning; rdgrp-ece750T4-f24},
	number = {7540},
	pages = {529--533},
	temp = {0},
	title = {{Human-level control through deep reinforcement learning}},
	volume = {518},
	year = {2015}}

@article{Crawford2016b,
	author = {Crawford, Daniel and Levit, Anna and Ghadermarzy, Navid and Oberoi, Jaspreet S. and Ronagh, Pooya},
	date-modified = {2024-07-26 00:11:11 -0400},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	pages = {1--17},
	title = {{Reinforcement Learning Using Quantum Boltzmann Machines}},
	year = {2016}}

@inproceedings{Mnih2016,
	author = {Mnih, Volodymyr and Badia, Adri{\`{a}} Puigdom{\`{e}}nech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy P. and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
	bdsk-color = {3},
	booktitle = {Proceedings of The 33rd International Conference on Machine Learning (ICML)},
	date-modified = {2024-07-26 00:11:11 -0400},
	keywords = {paper-beeler2023digidiscjourn; actor-critic; deep-reinforcement-learning; reinforcement-learning; rdgrp-ece750T4-f24; rd-early},
	pages = {1928--1937},
	temp = {0},
	title = {{Asynchronous Methods for Deep Reinforcement Learning}},
	year = {2016}}

@article{Young2017,
	author = {Young, Oran R.},
	bdsk-color = {7},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {IEEE SIGNAL PROCESSING MAGAZINE, SPECIAL ISSUE ON DEEP LEARNING FOR IMAGE UNDERSTANDING (ARXIV},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; survey},
	title = {{A Brief Survey of Deep Reinforcement Learning}},
	year = {2017}}

@article{Sutton2017,
	author = {Sutton, Richard S and Barto, Andrew G},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {UCL,Computer Science Department, Reinforcement Learning Lectures},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	pages = {1054},
	title = {{Reinforcement learning: an introduction 2018 complete draft}},
	year = {2017}}

@article{Igl2018,
	author = {Igl, Maximilian and Zintgraf, Luisa and Le, Tuan Anh and Wood, Frank and Whiteson, Shimon},
	date-modified = {2024-07-26 00:11:11 -0400},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	title = {{Deep Variational Reinforcement Learning for POMDPs}},
	year = {2018}}

@book{Kolobov,
	author = {Kolobov, Andrey and Mausam},
	date-modified = {2024-07-26 00:11:11 -0400},
	keywords = {paper-beeler2023digidiscjourn; reinforcement-learning},
	title = {{Planning with MDPs}}}

@book{sutton2018reinforcement,
	author = {Sutton, Richard S and Barto, Andrew G},
	date-modified = {2024-07-26 00:11:11 -0400},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	publisher = {MIT press},
	title = {Reinforcement learning: An introduction},
	year = {2018}}

@article{schulman2017proximal,
	author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {arXiv preprint arXiv:1707.06347},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	title = {Proximal policy optimization algorithms},
	year = {2017}}

@inproceedings{haarnoja2018soft,
	author = {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
	bdsk-color = {5},
	booktitle = {International conference on machine learning},
	date-modified = {2024-07-26 00:11:11 -0400},
	keywords = {rd-middle; paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; policy-gradient; rdgrp-ece750T4-f24},
	organization = {PMLR},
	pages = {1861--1870},
	temp = {0},
	title = {Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
	year = {2018}}

@inproceedings{fujimoto2018addressing,
	author = {Fujimoto, Scott and Hoof, Herke and Meger, David},
	booktitle = {International conference on machine learning},
	date-modified = {2024-07-26 00:11:11 -0400},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; policy-gradient},
	organization = {PMLR},
	pages = {1587--1596},
	title = {Addressing function approximation error in actor-critic methods},
	year = {2018}}

@article{raffin2021stable,
	author = {Raffin, Antonin and Hill, Ashley and Gleave, Adam and Kanervisto, Anssi and Ernestus, Maximilian and Dormann, Noah},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {The Journal of Machine Learning Research},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	number = {1},
	pages = {12348--12355},
	publisher = {JMLRORG},
	title = {Stable-baselines3: Reliable reinforcement learning implementations},
	volume = {22},
	year = {2021}}

@article{jiang2022artificial,
	author = {Jiang, Yibin and Salley, Daniel and Sharma, Abhishek and Keenan, Graham and Mullin, Margaret and Cronin, Leroy},
	bdsk-color = {4247388159},
	date-modified = {2024-07-26 00:11:35 -0400},
	journal = {Science Advances},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; digital-chemistry},
	number = {40},
	pages = {eabo2626},
	publisher = {American Association for the Advancement of Science},
	title = {An artificial intelligence enabled chemical synthesis robot for exploration and optimization of nanomaterials},
	volume = {8},
	year = {2022}}

@article{she2022robotic,
	author = {She, Shan and Bell, Nicola L and Zheng, Dazhong and Mathieson, Jennifer S and Castro, Maria D and Long, De-Liang and Koehnke, Jesko and Cronin, Leroy},
	bdsk-color = {4247388159},
	date-modified = {2024-07-26 00:11:35 -0400},
	journal = {Chem},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; digital-chemistry},
	number = {10},
	pages = {2734--2748},
	publisher = {Elsevier},
	title = {Robotic synthesis of peptides containing metal-oxide-based amino acids},
	volume = {8},
	year = {2022}}

@article{manzano2022autonomous,
	author = {Manzano, J Sebasti{\'a}n and Hou, Wenduan and Zalesskiy, Sergey S and Frei, Przemyslaw and Wang, Hsin and Kitson, Philip J and Cronin, Leroy},
	bdsk-color = {4247388159},
	date-modified = {2024-07-26 00:11:35 -0400},
	journal = {Nature Chemistry},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; digital-chemistry},
	number = {11},
	pages = {1311--1318},
	publisher = {Nature Publishing Group UK London},
	title = {An autonomous portable platform for universal chemical synthesis},
	volume = {14},
	year = {2022}}

@article{m2023digitizing,
	author = {M. Mehr, S Hessam and Caramelli, Dario and Cronin, Leroy},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {Proceedings of the National Academy of Sciences},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	number = {17},
	pages = {e2220045120},
	publisher = {National Acad Sciences},
	title = {Digitizing chemical discovery with a Bayesian explorer for interpreting reactivity data},
	volume = {120},
	year = {2023}}

@article{bubliauskas2022digitizing,
	author = {Bubliauskas, Andrius and Blair, Daniel J and Powell-Davies, Henry and Kitson, Philip J and Burke, Martin D and Cronin, Leroy},
	bdsk-color = {4247388159},
	date-modified = {2024-07-26 00:11:35 -0400},
	journal = {Angewandte Chemie},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; digital-chemistry},
	number = {24},
	pages = {e202116108},
	publisher = {Wiley Online Library},
	title = {Digitizing chemical synthesis in 3D printed reactionware},
	volume = {134},
	year = {2022}}

@article{caramelli2021discovering,
	author = {Caramelli, Dario and Granda, Jaros{\l}aw M and Mehr, S Hessam M and Cambi{\'e}, Dario and Henson, Alon B and Cronin, Leroy},
	bdsk-color = {4247388159},
	date-modified = {2024-07-26 00:11:35 -0400},
	journal = {ACS Central Science},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; digital-chemistry},
	number = {11},
	pages = {1821--1830},
	publisher = {ACS Publications},
	title = {Discovering new chemistry with an autonomous robotic platform driven by a reactivity-seeking neural network},
	volume = {7},
	year = {2021}}

@inproceedings{pizzuto2022solis,
	author = {Pizzuto, Gabriella and De Berardinis, Jacopo and Longley, Louis and Fakhruldeen, Hatem and Cooper, Andrew I},
	bdsk-color = {4247388159},
	booktitle = {2022 International Joint Conference on Neural Networks (IJCNN)},
	date-modified = {2024-07-26 00:11:35 -0400},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; digital-chemistry},
	organization = {IEEE},
	pages = {1--7},
	title = {SOLIS: Autonomous Solubility Screening using Deep Neural Networks},
	year = {2022}}

@inproceedings{fakhruldeen2022archemist,
	author = {Fakhruldeen, Hatem and Pizzuto, Gabriella and Glowacki, Jakub and Cooper, Andrew Ian},
	bdsk-color = {4247388159},
	booktitle = {2022 International Conference on Robotics and Automation (ICRA)},
	date-modified = {2024-07-26 00:11:35 -0400},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; digital-chemistry},
	organization = {IEEE},
	pages = {6013--6019},
	title = {Archemist: Autonomous robotic chemistry system architecture},
	year = {2022}}

@article{pyzer2021accelerating,
	author = {Pyzer-Knapp, Edward O and Chen, Linjiang and Day, Graeme M and Cooper, Andrew I},
	bdsk-color = {4247388159},
	date-modified = {2024-07-26 00:11:35 -0400},
	journal = {Science Advances},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; digital-chemistry},
	number = {33},
	pages = {eabi4763},
	publisher = {American Association for the Advancement of Science},
	title = {Accelerating computational discovery of porous solids through improved navigation of energy-structure-function maps},
	volume = {7},
	year = {2021}}

@article{li2021combining,
	author = {Li, Xiaobo and Maffettone, Phillip M and Che, Yu and Liu, Tao and Chen, Linjiang and Cooper, Andrew I},
	bdsk-color = {4247388159},
	date-modified = {2024-07-26 00:11:35 -0400},
	journal = {Chemical Science},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; digital-chemistry},
	number = {32},
	pages = {10742--10754},
	publisher = {Royal Society of Chemistry},
	title = {Combining machine learning and high-throughput experimentation to discover photocatalytically active organic molecules},
	volume = {12},
	year = {2021}}

@inproceedings{fievez2022machine,
	author = {Fievez, Mathilde and Taherimakhsousi, Nina and MacLeod, Benjamin P and Booker, Edward P and Matheron, Muriel and Manceau, Matthieu and Cros, St{\'e}phane and Berson, Solenn and Berlinguette, Curtis P},
	bdsk-color = {4247388159},
	booktitle = {2022 IEEE 49th Photovoltaics Specialists Conference (PVSC)},
	date-modified = {2024-07-26 00:11:35 -0400},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; digital-chemistry},
	organization = {IEEE},
	pages = {1072--1072},
	title = {A machine vision tool for facilitating the optimization of large-area perovskite photovoltaics},
	year = {2022}}

@article{macleod2022self,
	author = {MacLeod, Benjamin P and Parlane, Fraser GL and Rupnow, Connor C and Dettelbach, Kevan E and Elliott, Michael S and Morrissey, Thomas D and Haley, Ted H and Proskurin, Oleksii and Rooney, Michael B and Taherimakhsousi, Nina and others},
	bdsk-color = {4230545407},
	date-modified = {2024-07-26 00:14:17 -0400},
	journal = {Nature communications},
	keywords = {paper-beeler2023digidiscjourn;  digital-chemistry},
	number = {1},
	pages = {995},
	publisher = {Nature Publishing Group UK London},
	title = {A self-driving laboratory advances the Pareto front for material properties},
	volume = {13},
	year = {2022}}

@incollection{macleod2022flexible,
	author = {MacLeod, Benjamin P and Parlane, Fraser GL and Brown, Amanda K and Hein, Jason E and Berlinguette, Curtis P},
	bdsk-color = {4247388159},
	booktitle = {Accelerated Materials Discovery},
	date-modified = {2024-07-26 00:11:35 -0400},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; digital-chemistry},
	pages = {105--122},
	publisher = {De Gruyter},
	title = {Flexible automation for self-driving laboratories},
	year = {2022}}

@article{rooney2022self,
	author = {Rooney, Michael B and MacLeod, Benjamin P and Oldford, Ryan and Thompson, Zachary J and White, Kolby L and Tungjunyatham, Justin and Stankiewicz, Brian J and Berlinguette, Curtis P},
	bdsk-color = {4247388159},
	date-modified = {2024-07-26 00:11:35 -0400},
	journal = {Digital Discovery},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; digital-chemistry},
	number = {4},
	pages = {382--389},
	publisher = {Royal Society of Chemistry},
	title = {A self-driving laboratory designed to accelerate the discovery of adhesive materials},
	volume = {1},
	year = {2022}}

@article{hickman2023self,
	author = {Hickman, Riley J and Bannigan, Pauric and Bao, Zeqing and Aspuru-Guzik, Al{\'a}n and Allen, Christine},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {Matter},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	number = {4},
	pages = {1071--1081},
	publisher = {Elsevier},
	title = {Self-driving laboratories: A paradigm shift in nanomedicine development},
	volume = {6},
	year = {2023}}

@article{yoshikawa2023digital,
	author = {Yoshikawa, Naruki and Darvish, Kourosh and Garg, Animesh and Aspuru-Guzik, Alan},
	bdsk-color = {4247388159},
	date-modified = {2024-07-26 00:11:35 -0400},
	journal = {ChemRxiv preprint},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; digital-chemistry},
	title = {Digital pipette: Open hardware for liquid transfer in self-driving laboratories},
	year = {2023}}

@article{choubisa2023accelerated,
	author = {Choubisa, Hitarth and Abed, Jehad and Mendoza, Douglas and Matsumura, Hidetoshi and Sugimura, Masahiko and Yao, Zhenpeng and Wang, Ziyun and Sutherland, Brandon R and Aspuru-Guzik, Al{\'a}n and Sargent, Edward H},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {Matter},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	number = {2},
	pages = {605--625},
	publisher = {Elsevier},
	title = {Accelerated chemical space search using a quantum-inspired cluster expansion approach},
	volume = {6},
	year = {2023}}

@article{seifrid2022autonomous,
	author = {Seifrid, Martin and Pollice, Robert and Aguilar-Granda, Andr{\'e}s and Morgan Chan, Zamyla and Hotta, Kazuhiro and Ser, Cher Tian and Vestfrid, Jenya and Wu, Tony C and Aspuru-Guzik, Al{\'a}n},
	bdsk-color = {4247388159},
	date-modified = {2024-07-26 00:11:35 -0400},
	journal = {Accounts of Chemical Research},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; digital-chemistry},
	number = {17},
	pages = {2454--2466},
	publisher = {ACS Publications},
	title = {Autonomous chemical experiments: Challenges and perspectives on establishing a self-driving lab},
	volume = {55},
	year = {2022}}

@article{roch2020chemos,
	author = {Roch, Lo{\"\i}c M and H{\"a}se, Florian and Kreisbeck, Christoph and Tamayo-Mendoza, Teresa and Yunker, Lars PE and Hein, Jason E and Aspuru-Guzik, Al{\'a}n},
	bdsk-color = {4247388159},
	date-modified = {2024-07-26 00:11:35 -0400},
	journal = {PLoS One},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; digital-chemistry},
	number = {4},
	pages = {e0229862},
	publisher = {Public Library of Science San Francisco, CA USA},
	title = {ChemOS: An orchestration software to democratize autonomous discovery},
	volume = {15},
	year = {2020}}

@article{bennett2022autonomous,
	author = {Bennett, Jeffrey A and Abolhasani, Milad},
	bdsk-color = {4247388159},
	date-modified = {2024-07-26 00:11:35 -0400},
	journal = {Current Opinion in Chemical Engineering},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; digital-chemistry},
	pages = {100831},
	publisher = {Elsevier},
	title = {Autonomous chemical science and engineering enabled by self-driving laboratories},
	volume = {36},
	year = {2022}}

@article{flores2020materials,
	author = {Flores-Leonar, Martha M and Mej{\'\i}a-Mendoza, Luis M and Aguilar-Granda, Andr{\'e}s and Sanchez-Lengeling, Benjamin and Tribukait, Hermann and Amador-Bedolla, Carlos and Aspuru-Guzik, Al{\'a}n},
	bdsk-color = {4247388159},
	date-modified = {2024-07-26 00:11:35 -0400},
	journal = {Current Opinion in Green and Sustainable Chemistry},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; digital-chemistry},
	pages = {100370},
	publisher = {Elsevier},
	title = {Materials acceleration platforms: On the way to autonomous experimentation},
	volume = {25},
	year = {2020}}

@article{porwol2020autonomous,
	author = {Porwol, Luzian and Kowalski, Daniel J and Henson, Alon and Long, De-Liang and Bell, Nicola L and Cronin, Leroy},
	bdsk-color = {4247388159},
	date-modified = {2024-07-26 00:11:35 -0400},
	journal = {Angewandte Chemie},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; digital-chemistry},
	number = {28},
	pages = {11352--11357},
	publisher = {Wiley Online Library},
	title = {An autonomous chemical robot discovers the rules of inorganic coordination chemistry without prior knowledge},
	volume = {132},
	year = {2020}}

@article{volk2023alphaflow,
	author = {Volk, Amanda A and Epps, Robert W and Yonemoto, Daniel T and Masters, Benjamin S and Castellano, Felix N and Reyes, Kristofer G and Abolhasani, Milad},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {Nature Communications},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; digital-chemistry},
	number = {1},
	pages = {1403},
	publisher = {Nature Publishing Group UK London},
	title = {AlphaFlow: autonomous discovery and optimization of multi-step chemistry using a self-driven fluidic lab guided by reinforcement learning},
	volume = {14},
	year = {2023}}

@article{zhou2017optimizing,
	author = {Zhou, Zhenpeng and Li, Xiaocheng and Zare, Richard N},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {ACS central science},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	number = {12},
	pages = {1337--1344},
	publisher = {ACS Publications},
	title = {Optimizing chemical reactions with deep reinforcement learning},
	volume = {3},
	year = {2017}}

@inproceedings{gottipati2020learning,
	author = {Gottipati, Sai Krishna and Sattarov, Boris and Niu, Sufeng and Pathak, Yashaswi and Wei, Haoran and Liu, Shengchao and Blackburn, Simon and Thomas, Karam and Coley, Connor and Tang, Jian and others},
	bdsk-color = {4230545407},
	booktitle = {International Conference on Machine Learning},
	date-modified = {2024-07-26 00:15:55 -0400},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; digital-chemistry},
	organization = {PMLR},
	pages = {3668--3679},
	title = {Learning to navigate the synthetically accessible chemical space using reinforcement learning},
	year = {2020}}

@book{hairer1993solving,
	author = {Hairer, Ernst and N{\o}rsett, Syvert P and Wanner, Gerhard},
	date-modified = {2024-07-26 00:11:11 -0400},
	keywords = {paper-beeler2023digidiscjourn; reinforcement-learning},
	publisher = {Springer-Vlg},
	title = {Solving ordinary differential equations. 1, Nonstiff problems},
	year = {1993}}

@article{dulac2021challenges,
	author = {Dulac-Arnold, Gabriel and Levine, Nir and Mankowitz, Daniel J and Li, Jerry and Paduraru, Cosmin and Gowal, Sven and Hester, Todd},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {Machine Learning},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	pages = {1--50},
	publisher = {Springer},
	title = {Challenges of real-world reinforcement learning: {D}efinitions, {B}enchmarks and {A}nalysis},
	volume = {1},
	year = {2021}}

@inproceedings{bellemare2017distributional,
	author = {Bellemare, Marc G and Dabney, Will and Munos, R{\'e}mi},
	bdsk-color = {582077695},
	booktitle = {International conference on machine learning},
	date-modified = {2024-07-26 00:16:53 -0400},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; rd-potential},
	organization = {PMLR},
	pages = {449--458},
	temp = {0},
	title = {A distributional perspective on reinforcement learning},
	year = {2017}}

@inproceedings{liu2021policy,
	author = {Liu, Yongshuai and Halev, Avishai and Liu, Xin},
	bdsk-color = {7},
	booktitle = {The 30th International Joint Conference on Artificial Intelligence (IJCAI)},
	date-modified = {2024-07-26 00:11:11 -0400},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; survey},
	title = {Policy learning with constraints in model-free reinforcement learning: A survey},
	year = {2021}}

@inproceedings{ng2000algorithms,
	address = {Stanford University, Stanford, CA, USA},
	author = {Andrew Y. Ng and Stuart J. Russell},
	booktitle = {ICML, June 29 - July 2, 2000},
	date-modified = {2024-07-26 00:11:11 -0400},
	keywords = {paper-beeler2023digidiscjourn; reinforcement-learning},
	pages = {663--670},
	publisher = {Morgan Kaufmann},
	title = {Algorithms for {I}nverse {R}einforcement {L}earning},
	year = {2000}}

@article{narvekar2020curriculum,
	author = {Narvekar, Sanmit and Peng, Bei and Leonetti, Matteo and Sinapov, Jivko and Taylor, Matthew E and Stone, Peter},
	bdsk-color = {7},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {The Journal of Machine Learning Research},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; survey; curriculum-learning},
	number = {1},
	pages = {7382--7431},
	publisher = {JMLRORG},
	title = {Curriculum learning for reinforcement learning domains: A framework and survey},
	volume = {21},
	year = {2020}}

@article{levine2020offline,
	author = {Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
	bdsk-color = {7},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {arXiv preprint arXiv:2005.01643},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; survey},
	title = {Offline reinforcement learning: Tutorial, review, and perspectives on open problems},
	year = {2020}}

@article{fu2020d4rl,
	author = {Fu, Justin and Kumar, Aviral and Nachum, Ofir and Tucker, George and Levine, Sergey},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {arXiv preprint arXiv:2004.07219},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	title = {D4rl: Datasets for deep data-driven reinforcement learning},
	year = {2020}}

@article{guss2019minerl,
	author = {Guss, William H and Houghton, Brandon and Topin, Nicholay and Wang, Phillip and Codel, Cayden and Veloso, Manuela and Salakhutdinov, Ruslan},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {arXiv preprint arXiv:1907.13440},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; environment},
	title = {Minerl: A large-scale dataset of minecraft demonstrations},
	year = {2019}}

@inproceedings{shoham2021solving,
	author = {Shoham, Yaron and Elidan, Gal},
	booktitle = {Proceedings of the International Symposium on Combinatorial Search},
	date-modified = {2024-07-26 00:11:11 -0400},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	number = {1},
	pages = {191--193},
	title = {Solving sokoban with forward-backward reinforcement learning},
	volume = {12},
	year = {2021}}

@article{moerland2023model,
	author = {Moerland, Thomas M and Broekens, Joost and Plaat, Aske and Jonker, Catholijn M and others},
	bdsk-color = {7},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {Foundations and Trends{\textregistered} in Machine Learning},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; survey; model-based},
	number = {1},
	pages = {1--118},
	publisher = {Now Publishers, Inc.},
	title = {Model-based reinforcement learning: A survey},
	volume = {16},
	year = {2023}}

@article{kurutach2018model,
	author = {Kurutach, Thanard and Clavera, Ignasi and Duan, Yan and Tamar, Aviv and Abbeel, Pieter},
	bdsk-color = {582077695},
	date-modified = {2024-07-26 00:13:01 -0400},
	journal = {arXiv preprint arXiv:1802.10592},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; rd-potential},
	title = {Model-ensemble trust-region policy optimization},
	year = {2018}}

@article{racaniere2017imagination,
	author = {Racani{\`e}re, S{\'e}bastien and Weber, Th{\'e}ophane and Reichert, David and Buesing, Lars and Guez, Arthur and Jimenez Rezende, Danilo and Puigdom{\`e}nech Badia, Adri{\`a} and Vinyals, Oriol and Heess, Nicolas and Li, Yujia and others},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {Advances in neural information processing systems},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	title = {Imagination-augmented agents for deep reinforcement learning},
	volume = {30},
	year = {2017}}

@inproceedings{todorov2012mujoco,
	author = {Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
	booktitle = {2012 IEEE/RSJ international conference on intelligent robots and systems},
	date-modified = {2024-07-26 00:11:11 -0400},
	keywords = {paper-beeler2023digidiscjourn; reinforcement-learning},
	organization = {IEEE},
	pages = {5026--5033},
	title = {Mujoco: A physics engine for model-based control},
	year = {2012}}

@inproceedings{silva2018object,
	author = {Silva, Felipe Leno Da and Costa, Anna Helena Reali},
	booktitle = {Proceedings of the 17th international conference on autonomous agents and multiagent systems},
	date-modified = {2024-07-26 00:11:11 -0400},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	pages = {1026--1034},
	title = {Object-oriented curriculum generation for reinforcement learning},
	year = {2018}}

@inproceedings{hausknecht2016half,
	author = {Hausknecht, Matthew and Mupparaju, Prannoy and Subramanian, Sandeep and Kalyanakrishnan, Shivaram and Stone, Peter},
	booktitle = {AAMAS Adaptive Learning Agents (ALA) Workshop},
	date-modified = {2024-07-26 00:11:11 -0400},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	organization = {sn},
	title = {Half field offense: An environment for multiagent learning and ad hoc teamwork},
	volume = {3},
	year = {2016}}

@article{kim2018screenernet,
	author = {Kim, Tae-Hoon and Choi, Jonghyun},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {arXiv preprint arXiv:1801.00904},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	title = {Screenernet: Learning self-paced curriculum for deep neural networks},
	year = {2018}}

@inproceedings{tessler2017deep,
	author = {Tessler, Chen and Givony, Shahar and Zahavy, Tom and Mankowitz, Daniel and Mannor, Shie},
	booktitle = {Proceedings of the AAAI conference on artificial intelligence},
	date-modified = {2024-07-26 00:11:11 -0400},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	number = {1},
	title = {A deep hierarchical approach to lifelong learning in minecraft},
	volume = {31},
	year = {2017}}

@article{samvelyan2019starcraft,
	author = {Samvelyan, Mikayel and Rashid, Tabish and De Witt, Christian Schroeder and Farquhar, Gregory and Nardelli, Nantas and Rudner, Tim GJ and Hung, Chia-Man and Torr, Philip HS and Foerster, Jakob and Whiteson, Shimon},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {arXiv preprint arXiv:1902.04043},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; rd-middle; environment},
	title = {The starcraft multi-agent challenge},
	year = {2019}}

@article{yang2018cm3,
	author = {Yang, Jiachen and Nakhaei, Alireza and Isele, David and Fujimura, Kikuo and Zha, Hongyuan},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {arXiv preprint arXiv:1809.05188},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	title = {Cm3: Cooperative multi-goal multi-stage multi-agent reinforcement learning},
	year = {2018}}

@inproceedings{lopez2018microscopic,
	author = {Lopez, Pablo Alvarez and Behrisch, Michael and Bieker-Walz, Laura and Erdmann, Jakob and Fl{\"o}tter{\"o}d, Yun-Pang and Hilbrich, Robert and L{\"u}cken, Leonhard and Rummel, Johannes and Wagner, Peter and Wie{\ss}ner, Evamarie},
	booktitle = {2018 21st international conference on intelligent transportation systems (ITSC)},
	date-modified = {2024-07-26 00:11:11 -0400},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	organization = {IEEE},
	pages = {2575--2582},
	title = {Microscopic traffic simulation using sumo},
	year = {2018}}

@inproceedings{grzes2017reward,
	address = {Richland, SC},
	author = {Grzeundefined, Marek},
	booktitle = {Proceedings of the 16th Conference on Autonomous Agents and MultiAgent Systems},
	date-modified = {2024-07-26 00:11:11 -0400},
	keywords = {reinforcement-learning, potential-based reward shaping, multiagent learning, reward structures for learning, reward shaping; paper-beeler2023digidiscjourn; deep-reinforcement-learning},
	location = {S\~{a}o Paulo, Brazil},
	numpages = {9},
	pages = {565--573},
	publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
	series = {AAMAS '17},
	title = {Reward Shaping in Episodic Reinforcement Learning},
	year = {2017}}

@article{tessler2018reward,
	author = {Tessler, Chen and Mankowitz, Daniel J and Mannor, Shie},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {arXiv preprint arXiv:1805.11074},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	title = {Reward constrained policy optimization},
	year = {2018}}

@inproceedings{harutyunyan2015expressing,
	author = {Harutyunyan, Anna and Devlin, Sam and Vrancx, Peter and Now{\'e}, Ann},
	booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
	date-modified = {2024-07-26 00:11:11 -0400},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	number = {1},
	title = {Expressing arbitrary reward functions as potential-based advice},
	volume = {29},
	year = {2015}}

@inproceedings{hausknecht2015deep,
	author = {Hausknecht, Matthew and Stone, Peter},
	booktitle = {2015 aaai fall symposium series},
	date-modified = {2024-07-26 00:11:11 -0400},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	title = {Deep recurrent q-learning for partially observable mdps},
	year = {2015}}

@article{morad2023popgym,
	author = {Morad, Steven and Kortvelesy, Ryan and Bettini, Matteo and Liwicki, Stephan and Prorok, Amanda},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {arXiv preprint arXiv:2303.01859},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	title = {POPGym: Benchmarking Partially Observable Reinforcement Learning},
	year = {2023}}

@article{graves2016hybrid,
	author = {Graves, Alex and Wayne, Greg and Reynolds, Malcolm and Harley, Tim and Danihelka, Ivo and Grabska-Barwi{\'n}ska, Agnieszka and Colmenarejo, Sergio G{\'o}mez and Grefenstette, Edward and Ramalho, Tiago and Agapiou, John and others},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {Nature},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	number = {7626},
	pages = {471--476},
	publisher = {Nature Publishing Group UK London},
	title = {Hybrid computing using a neural network with dynamic external memory},
	volume = {538},
	year = {2016}}

@inproceedings{dabney2018distributional,
	author = {Dabney, Will and Rowland, Mark and Bellemare, Marc and Munos, R{\'e}mi},
	booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
	date-modified = {2024-07-26 00:11:11 -0400},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	number = {1},
	title = {Distributional reinforcement learning with quantile regression},
	volume = {32},
	year = {2018}}

@article{zha2019experience,
	author = {Zha, Daochen and Lai, Kwei-Herng and Zhou, Kaixiong and Hu, Xia},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {arXiv preprint arXiv:1906.08387},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	title = {Experience replay optimization},
	year = {2019}}

@inproceedings{hester2018deep,
	author = {Hester, Todd and Vecerik, Matej and Pietquin, Olivier and Lanctot, Marc and Schaul, Tom and Piot, Bilal and Horgan, Dan and Quan, John and Sendonaris, Andrew and Osband, Ian and others},
	booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
	date-modified = {2024-07-26 00:11:11 -0400},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	number = {1},
	title = {Deep q-learning from demonstrations},
	volume = {32},
	year = {2018}}

@inproceedings{piot2014boosted,
	author = {Piot, Bilal and Geist, Matthieu and Pietquin, Olivier},
	booktitle = {Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2014, Nancy, France, September 15-19, 2014. Proceedings, Part II 14},
	date-modified = {2024-07-26 00:11:11 -0400},
	keywords = {paper-beeler2023digidiscjourn; reinforcement-learning},
	organization = {Springer},
	pages = {549--564},
	title = {Boosted bellman residual minimization handling expert demonstrations},
	year = {2014}}

@article{gao2018reinforcement,
	author = {Gao, Yang and Xu, Huazhe and Lin, Ji and Yu, Fisher and Levine, Sergey and Darrell, Trevor},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {arXiv preprint arXiv:1802.05313},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	title = {Reinforcement learning from imperfect demonstrations},
	year = {2018}}

@article{sutton1999between,
	author = {Sutton, Richard S and Precup, Doina and Singh, Satinder},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {Artificial intelligence},
	keywords = {paper-beeler2023digidiscjourn; reinforcement-learning},
	number = {1-2},
	pages = {181--211},
	publisher = {Elsevier},
	title = {Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning},
	volume = {112},
	year = {1999}}

@inproceedings{bacon2017option,
	author = {Bacon, Pierre-Luc and Harb, Jean and Precup, Doina},
	booktitle = {Proceedings of the AAAI conference on artificial intelligence},
	date-modified = {2024-07-26 00:11:11 -0400},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	number = {1},
	title = {The option-critic architecture},
	volume = {31},
	year = {2017}}

@article{chunduru2022attention,
	author = {Chunduru, Raviteja and Precup, Doina},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {arXiv preprint arXiv:2201.02628},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; rd-later},
	title = {Attention option-critic},
	year = {2022}}

@article{ray2019benchmarking,
	author = {Ray, Alex and Achiam, Joshua and Amodei, Dario},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {arXiv preprint arXiv:1910.01708},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	number = {1},
	pages = {2},
	title = {Benchmarking safe exploration in deep reinforcement learning},
	volume = {7},
	year = {2019}}

@inproceedings{achiam2017constrained,
	author = {Achiam, Joshua and Held, David and Tamar, Aviv and Abbeel, Pieter},
	bdsk-color = {582077695},
	booktitle = {International conference on machine learning},
	date-modified = {2024-07-26 00:17:02 -0400},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; rd-potential},
	organization = {PMLR},
	pages = {22--31},
	temp = {0},
	title = {Constrained policy optimization},
	year = {2017}}

@inproceedings{liu2020ipo,
	author = {Liu, Yongshuai and Ding, Jiaxin and Liu, Xin},
	booktitle = {Proceedings of the AAAI conference on artificial intelligence},
	date-modified = {2024-07-26 00:11:11 -0400},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	number = {04},
	pages = {4940--4947},
	title = {Ipo: Interior-point policy optimization under constraints},
	volume = {34},
	year = {2020}}

@book{russell2010artificial,
	author = {Russell, Stuart J},
	date-modified = {2024-07-26 00:11:11 -0400},
	keywords = {paper-beeler2023digidiscjourn; reference; reinforcement-learning},
	publisher = {Pearson Education, Inc.},
	temp = {0},
	title = {Artificial intelligence a modern approach},
	year = {2010}}

@article{wang2019benchmarking,
	author = {Wang, Tingwu and Bao, Xuchan and Clavera, Ignasi and Hoang, Jerrick and Wen, Yeming and Langlois, Eric and Zhang, Shunshi and Zhang, Guodong and Abbeel, Pieter and Ba, Jimmy},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {arXiv preprint arXiv:1907.02057},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	title = {Benchmarking model-based reinforcement learning},
	year = {2019}}

@book{bellemare2023distributional,
	author = {Bellemare, Marc G and Dabney, Will and Rowland, Mark},
	bdsk-color = {6},
	date-modified = {2024-07-26 00:11:11 -0400},
	keywords = {rd-later; rdgrp-ece750T4-f24; paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	publisher = {MIT Press},
	temp = {0},
	title = {Distributional reinforcement learning},
	year = {2023}}

@article{burda2018exploration,
	author = {Burda, Yuri and Edwards, Harrison and Storkey, Amos and Klimov, Oleg},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {arXiv preprint arXiv:1810.12894},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	title = {Exploration by random network distillation},
	year = {2018}}

@book{laud2004theory,
	author = {Laud, Adam Daniel},
	date-modified = {2024-07-26 00:11:11 -0400},
	keywords = {paper-beeler2023digidiscjourn; reinforcement-learning},
	publisher = {University of Illinois at Urbana-Champaign},
	title = {Theory and application of reward shaping in reinforcement learning},
	year = {2004}}

@inproceedings{ng1999policy,
	author = {Andrew Y. Ng and Daishi Harada and Stuart J. Russell},
	booktitle = {Proceedings of the Sixteenth International Conference on Machine Learning {(ICML} 1999), Bled, Slovenia, June 27 - 30, 1999},
	date-modified = {2024-07-26 00:11:11 -0400},
	keywords = {paper-beeler2023digidiscjourn; reinforcement-learning},
	pages = {278--287},
	publisher = {Morgan Kaufmann},
	title = {Policy {I}nvariance {U}nder {R}eward {T}ransformations: {T}heory and {A}pplication to {R}eward {S}haping},
	year = {1999}}

@inproceedings{wiewiora2003principled,
	author = {Eric Wiewiora and Garrison W. Cottrell and Charles Elkan},
	booktitle = {Proceedings of the Twentieth International Conference of Machine Learning {(ICML} 2003), August 21-24, 2003, Washington, DC, {USA}},
	date-modified = {2024-07-26 00:11:11 -0400},
	keywords = {paper-beeler2023digidiscjourn; reinforcement-learning},
	pages = {792--799},
	publisher = {{AAAI} Press},
	title = {Principled {M}ethods for {A}dvising {R}einforcement {L}earning {A}gents},
	year = {2003}}

@inproceedings{fedus2020revisiting,
	author = {Fedus, William and Ramachandran, Prajit and Agarwal, Rishabh and Bengio, Yoshua and Larochelle, Hugo and Rowland, Mark and Dabney, Will},
	bdsk-color = {6},
	booktitle = {International Conference on Machine Learning},
	date-modified = {2024-07-26 00:11:11 -0400},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; rd-later},
	organization = {PMLR},
	pages = {3061--3071},
	title = {Revisiting fundamentals of experience replay},
	year = {2020}}

@article{lillicrap2015continuous,
	author = {Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
	bdsk-color = {582077695},
	date-modified = {2024-07-26 00:16:59 -0400},
	journal = {arXiv preprint arXiv:1509.02971},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; policy-gradient; rd-potential},
	temp = {0},
	title = {Continuous control with deep reinforcement learning},
	year = {2015}}

@article{garcia2015comprehensive,
	author = {Garc{\i}a, Javier and Fern{\'a}ndez, Fernando},
	bdsk-color = {7},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {Journal of Machine Learning Research},
	keywords = {paper-beeler2023digidiscjourn; reinforcement-learning; survey; confidence; safety; performance-guarantees},
	number = {1},
	pages = {1437--1480},
	title = {A comprehensive survey on safe reinforcement learning},
	volume = {16},
	year = {2015}}

@article{nature2023research,
	author = {Editorial},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {Nature},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	number = {438},
	title = {For chemists, the AI revolution has yet to happen},
	volume = {617},
	year = {2023}}

@article{segler2018planning,
	author = {Segler, Marwin HS and Preuss, Mike and Waller, Mark P},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {Nature},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; digital-chemistry},
	number = {7698},
	pages = {604--610},
	publisher = {Nature Publishing Group UK London},
	title = {Planning chemical syntheses with deep neural networks and symbolic AI},
	volume = {555},
	year = {2018}}

@article{struble2020current,
	author = {Struble, Thomas J and Alvarez, Juan C and Brown, Scott P and Chytil, Milan and Cisar, Justin and DesJarlais, Renee L and Engkvist, Ola and Frank, Scott A and Greve, Daniel R and Griffin, Daniel J and others},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {Journal of medicinal chemistry},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; digital-chemistry},
	number = {16},
	pages = {8667--8682},
	publisher = {ACS Publications},
	title = {Current and future roles of artificial intelligence in medicinal chemistry synthesis},
	volume = {63},
	year = {2020}}

@article{kim2018deep,
	author = {Kim, Kyungdoc and Kang, Seokho and Yoo, Jiho and Kwon, Youngchun and Nam, Youngmin and Lee, Dongseon and Kim, Inkoo and Choi, Youn-Suk and Jung, Yongsik and Kim, Sangmo and others},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {npj Computational Materials},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	number = {1},
	pages = {67},
	publisher = {Nature Publishing Group UK London},
	title = {Deep-learning-based inverse design model for intelligent discovery of organic molecules},
	volume = {4},
	year = {2018}}

@article{yang2019analyzing,
	author = {Yang, Kevin and Swanson, Kyle and Jin, Wengong and Coley, Connor and Eiden, Philipp and Gao, Hua and Guzman-Perez, Angel and Hopper, Timothy and Kelley, Brian and Mathea, Miriam and others},
	bdsk-color = {4230545407},
	date-modified = {2024-07-26 00:16:07 -0400},
	journal = {Journal of chemical information and modeling},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; digital-chemistry},
	number = {8},
	pages = {3370--3388},
	publisher = {ACS Publications},
	title = {Analyzing learned molecular representations for property prediction},
	volume = {59},
	year = {2019}}

@article{jumper2021highly,
	author = {Jumper, John and Evans, Richard and Pritzel, Alexander and Green, Tim and Figurnov, Michael and Ronneberger, Olaf and Tunyasuvunakool, Kathryn and Bates, Russ and {\v{Z}}{\'\i}dek, Augustin and Potapenko, Anna and others},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {Nature},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	number = {7873},
	pages = {583--589},
	publisher = {Nature Publishing Group UK London},
	title = {Highly accurate protein structure prediction with AlphaFold},
	volume = {596},
	year = {2021}}

@article{coley2019robotic,
	author = {Coley, Connor W and Thomas III, Dale A and Lummiss, Justin AM and Jaworski, Jonathan N and Breen, Christopher P and Schultz, Victor and Hart, Travis and Fishman, Joshua S and Rogers, Luke and Gao, Hanyu and others},
	bdsk-color = {4230545407},
	date-modified = {2024-07-26 00:16:07 -0400},
	journal = {Science},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; digital-chemistry},
	number = {6453},
	pages = {eaax1566},
	publisher = {American Association for the Advancement of Science},
	title = {A robotic platform for flow synthesis of organic compounds informed by AI planning},
	volume = {365},
	year = {2019}}

@article{angello2022closed,
	author = {Angello, Nicholas H and Rathore, Vandana and Beker, Wiktor and Wo{\l}os, Agnieszka and Jira, Edward R and Roszak, Rafa{\l} and Wu, Tony C and Schroeder, Charles M and Aspuru-Guzik, Al{\'a}n and Grzybowski, Bartosz A and others},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {Science},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	number = {6618},
	pages = {399--405},
	publisher = {American Association for the Advancement of Science},
	title = {Closed-loop optimization of general reaction conditions for heteroaryl Suzuki-Miyaura coupling},
	volume = {378},
	year = {2022}}

@article{greenman2022multi,
	author = {Greenman, Kevin P and Green, William H and G{\'o}mez-Bombarelli, Rafael},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {Chemical science},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; digital-chemistry},
	number = {4},
	pages = {1152--1162},
	publisher = {Royal Society of Chemistry},
	title = {Multi-fidelity prediction of molecular optical peaks with deep learning},
	volume = {13},
	year = {2022}}

@article{beeler2023chemgymrl,
	author = {Beeler, Chris and Subramanian, Sriram Ganapathi and Sprague, Kyle and Chatti, Nouha and Bellinger, Colin and Shahen, Mitchell and Paquin, Nicholas and Baula, Mark and Dawit, Amanuel and Yang, Zihan and others},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {arXiv preprint arXiv:2305.14177},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; digital-chemistry},
	self = {1},
	title = {ChemGymRL: An Interactive Framework for Reinforcement Learning for Digital Chemistry},
	year = {2023}}

@article{bellinger2023dynamic,
	author = {Bellinger, Colin and Crowley, Mark and Tamblyn, Isaac},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {arXiv preprint arXiv:2307.02620},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	self = {1},
	title = {Dynamic Observation Policies in Observation Cost-Sensitive Reinforcement Learning},
	year = {2023}}

@article{brockman2016openai,
	author = {Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {arXiv preprint arXiv:1606.01540},
	keywords = {paper-beeler2023digidiscjourn; environment; deep-reinforcement-learning; reinforcement-learning},
	title = {Openai gym},
	year = {2016}}

@inproceedings{hasselt2016deep,
	author = {Hado van Hasselt and Arthur Guez and David Silver},
	booktitle = {Proceedings of the Thirtieth {AAAI} Conference on Artificial Intelligence, February 12-17, 2016, Phoenix, Arizona, {USA}},
	date-modified = {2024-07-26 00:11:11 -0400},
	editor = {Dale Schuurmans and Michael P. Wellman},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; q-learning; reinforcement-learning},
	pages = {2094--2100},
	publisher = {{AAAI} Press},
	title = {Deep Reinforcement Learning with Double Q-Learning},
	year = {2016}}

@inproceedings{Lan2020maxmin,
	author = {Qingfeng Lan and Yangchen Pan and Alona Fyshe and Martha White},
	booktitle = {8th International Conference on Learning Representations, {ICLR} 2020, Addis Ababa, Ethiopia, April 26-30, 2020},
	date-modified = {2024-07-26 00:11:11 -0400},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	publisher = {OpenReview.net},
	title = {Maxmin Q-learning: Controlling the Estimation Bias of Q-learning},
	year = {2020}}

@article{Wang2015dueling,
	author = {Ziyu Wang and Nando de Freitas and Marc Lanctot},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {CoRR},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	pages = {1511},
	title = {Dueling Network Architectures for Deep Reinforcement Learning},
	volume = {abs/1511.06581},
	year = {2015}}

@article{zhu2021improved,
	author = {Zhu, Zhengwei and Hu, Can and Zhu, Chenyang and Zhu, Yanping and Sheng, Yu},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {Journal of Marine Science and Engineering},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	number = {11},
	pages = {1267},
	publisher = {MDPI},
	title = {An improved dueling deep double-q network based on prioritized experience replay for path planning of unmanned surface vehicles},
	volume = {9},
	year = {2021}}

@inproceedings{Schaul2016prioritized,
	author = {Tom Schaul and John Quan and Ioannis Antonoglou and David Silver},
	bdsk-color = {3},
	booktitle = {4th International Conference on Learning Representations, {ICLR} 2016, San Juan, Puerto Rico, May 2-4, 2016, Conference Track Proceedings},
	date-modified = {2024-07-26 00:11:11 -0400},
	editor = {Yoshua Bengio and Yann LeCun},
	keywords = {rd-early; paper-beeler2023digidiscjourn; deep-reinforcement-learning; dqn; reinforcement-learning; rdgrp-ece750T4-f24},
	temp = {0},
	title = {Prioritized Experience Replay},
	year = {2016}}

@inproceedings{marcin2017hindsight,
	author = {Marcin Andrychowicz and Dwight Crow and Alex Ray and Jonas Schneider and Rachel Fong and Peter Welinder and Bob McGrew and Josh Tobin and Pieter Abbeel and Wojciech Zaremba},
	bdsk-color = {5},
	booktitle = {Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, {USA}},
	date-modified = {2024-07-26 00:11:11 -0400},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; rdgrp-ece750T4-f24; rd-middle},
	pages = {5048--5058},
	temp = {0},
	title = {Hindsight Experience Replay},
	year = {2017}}

@article{xiong2018parametrized,
	author = {Xiong, Jiechao and Wang, Qing and Yang, Zhuoran and Sun, Peng and Han, Lei and Zheng, Yang and Fu, Haobo and Zhang, Tong and Liu, Ji and Liu, Han},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {arXiv preprint arXiv:1810.06394},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning; q-learning},
	title = {Parametrized deep q-networks learning: Reinforcement learning with discrete-continuous hybrid action space},
	year = {2018}}

@article{ryu2019caql,
	author = {Ryu, Moonkyung and Chow, Yinlam and Anderson, Ross and Tjandraatmadja, Christian and Boutilier, Craig},
	date-modified = {2024-07-26 00:11:11 -0400},
	journal = {arXiv preprint arXiv:1909.12397},
	keywords = {paper-beeler2023digidiscjourn; deep-reinforcement-learning; reinforcement-learning},
	title = {CAQL: Continuous action Q-learning},
	year = {2019}}

@inproceedings{gaskett1999q,
	author = {Gaskett, Chris and Wettergreen, David and Zelinsky, Alexander},
	booktitle = {Australasian joint conference on artificial intelligence},
	date-modified = {2024-07-26 00:11:11 -0400},
	keywords = {paper-beeler2023digidiscjourn; reinforcement-learning},
	organization = {Springer},
	pages = {417--428},
	title = {Q-learning in continuous state and action spaces},
	year = {1999}}

@inproceedings{konda1999actor,
	author = {Konda, Vijay and Tsitsiklis, John},
	bdsk-color = {1},
	booktitle = {Advances in Neural Information Processing Systems},
	date-modified = {2024-07-26 00:11:11 -0400},
	editor = {S. Solla and T. Leen and K. M\"{u}ller},
	keywords = {paper-beeler2023digidiscjourn; foundational; reinforcement-learning; policy-gradient},
	publisher = {MIT Press},
	temp = {0},
	title = {Actor-Critic Algorithms},
	url = {https://proceedings.neurips.cc/paper_files/paper/1999/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf},
	volume = {12},
	year = {1999},
	bdsk-url-1 = {https://proceedings.neurips.cc/paper_files/paper/1999/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf}}

@article{sutton1999policy,
	author = {Sutton, Richard S and McAllester, David and Singh, Satinder and Mansour, Yishay},
	bdsk-color = {1},
	booktitle = {Advances in Neural Information Processing Systems},
	date-modified = {2024-07-26 00:11:11 -0400},
	editor = {S. Solla and T. Leen and K. M\"{u}ller},
	keywords = {paper-beeler2023digidiscjourn; foundational; reinforcement-learning; policy-gradient},
	publisher = {MIT Press},
	temp = {0},
	title = {Policy Gradient Methods for Reinforcement Learning with Function Approximation},
	url = {https://proceedings.neurips.cc/paper_files/paper/1999/file/464d828b85b0bed98e80ade0a5c43b0f-Paper.pdf},
	volume = {12},
	year = {1999},
	bdsk-url-1 = {https://proceedings.neurips.cc/paper_files/paper/1999/file/464d828b85b0bed98e80ade0a5c43b0f-Paper.pdf}}

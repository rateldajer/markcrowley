%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Mark at 2023-11-24 11:56:09 -0500 


%% Saved with string encoding Unicode (UTF-8) 



@inproceedings{janner2021neurips,
	annote = {An alternative approach to RL via transformers that came out at the same time as Decision Transformers.},
	author = {Janner, Michael and Li, Qiyang and Levine, Sergey},
	booktitle = {Advances in Neural Information Processing Systems},
	date-added = {2023-11-24 11:44:28 -0500},
	date-discussed = {2023-11-27 led by Mark Crowley},
	date-modified = {2023-11-24 11:47:12 -0500},
	editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
	keywords = {reinforcement-learning, transformers, sequenc-modelling, decision-transformers},
	order = {5},
	pages = {1273--1286},
	pdf = {2021-neurips-janner-offline.pdf},
	publisher = {Curran Associates, Inc.},
	title = {Offline Reinforcement Learning as One Big Sequence Modeling Problem},
	toread = {1},
	url = {https://proceedings.neurips.cc/paper_files/paper/2021/file/099fe6b0b444c23836c4a5d07346082b-Paper.pdf},
	venue-short = {NeurIPS},
	volume = {34},
	year = {2021},
	bdsk-url-1 = {https://proceedings.neurips.cc/paper_files/paper/2021/file/099fe6b0b444c23836c4a5d07346082b-Paper.pdf},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxAtLi4vYXNzZXRzL3BkZi8yMDIxLW5ldXJpcHMtamFubmVyLW9mZmxpbmUucGRmTxEBtgAAAAABtgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAAAAAAEJEAAH/////HzIwMjEtbmV1cmlwcy1qYW5uZXItb2ZmbGluZS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP////8AAAAAAAAAAAAAAAAAAQADAAAKIGN1AAAAAAAAAAAAAAAAAANwZGYAAAIAUC86VXNlcnM6bWNyb3dsZXk6cmVwb3M6bWFya2Nyb3dsZXktY2E6YXNzZXRzOnBkZjoyMDIxLW5ldXJpcHMtamFubmVyLW9mZmxpbmUucGRmAA4AQAAfADIAMAAyADEALQBuAGUAdQByAGkAcABzAC0AagBhAG4AbgBlAHIALQBvAGYAZgBsAGkAbgBlAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBOVXNlcnMvbWNyb3dsZXkvcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi8yMDIxLW5ldXJpcHMtamFubmVyLW9mZmxpbmUucGRmABMAAS8AABUAAgAP//8AAAAIAA0AGgAkAFQAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAACDg==}}

@inproceedings{janner2022pmlr,
	abstract = {Model-based reinforcement learning methods often use learning only for the purpose of recovering an approximate dynamics model, offloading the rest of the decision-making work to classical trajectory optimizers. While conceptually simple, this combination has a number of empirical shortcomings, suggesting that learned models may not be well-suited to standard trajectory optimization. In this paper, we consider what it would look like to fold as much of the trajectory optimization pipeline as possible into the modeling problem, such that sampling from the model and planning with it become nearly identical. The core of our technical approach lies in a diffusion probabilistic model that plans by iteratively denoising trajectories. We show how classifier-guided sampling and image inpainting can be reinterpreted as coherent planning strategies, explore the unusual and useful properties of diffusion-based planning methods, and demonstrate the effectiveness of our framework in control settings that emphasize long-horizon decision-making and test-time flexibility.},
	annote = {looks like a very interesting claim },
	author = {Janner, Michael and Du, Yilun and Tenenbaum, Joshua and Levine, Sergey},
	booktitle = {Proceedings of the 39th International Conference on Machine Learning},
	date-added = {2023-11-24 11:33:07 -0500},
	date-discussed = {2023-11-27 led by Mark Crowley},
	date-modified = {2023-11-24 11:47:13 -0500},
	editor = {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
	keywords = {reinforcement-learning, transformers, decision-transformers, machine-learning, dcmu, planning},
	month = {17--23 Jul},
	order = {5},
	pages = {9902--9915},
	pdf = {2022-pmlr-janner-planning.pdf},
	publisher = {PMLR},
	series = {Proceedings of Machine Learning Research},
	title = {Planning with Diffusion for Flexible Behavior Synthesis},
	toread = {1},
	url = {https://proceedings.mlr.press/v162/janner22a.html},
	venue-short = {PMLR},
	volume = {162},
	year = {2022},
	bdsk-url-1 = {https://proceedings.mlr.press/v162/janner22a.html},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxArLi4vYXNzZXRzL3BkZi8yMDIyLXBtbHItamFubmVyLXBsYW5uaW5nLnBkZk8RAa4AAAAAAa4AAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAAAAAABCRAAB/////x0yMDIyLXBtbHItamFubmVyLXBsYW5uaW5nLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/////AAAAAAAAAAAAAAAAAAEAAwAACiBjdQAAAAAAAAAAAAAAAAADcGRmAAACAE4vOlVzZXJzOm1jcm93bGV5OnJlcG9zOm1hcmtjcm93bGV5LWNhOmFzc2V0czpwZGY6MjAyMi1wbWxyLWphbm5lci1wbGFubmluZy5wZGYADgA8AB0AMgAwADIAMgAtAHAAbQBsAHIALQBqAGEAbgBuAGUAcgAtAHAAbABhAG4AbgBpAG4AZwAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIATFVzZXJzL21jcm93bGV5L3JlcG9zL21hcmtjcm93bGV5LWNhL2Fzc2V0cy9wZGYvMjAyMi1wbWxyLWphbm5lci1wbGFubmluZy5wZGYAEwABLwAAFQACAA///wAAAAgADQAaACQAUgAAAAAAAAIBAAAAAAAAAAUAAAAAAAAAAAAAAAAAAAIE}}

@misc{wu2023arxiv,
	abbr = {SPRING},
	arxiv = {2305.15486},
	author = {Yue Wu and Shrimai Prabhumoye and So Yeon Min and Yonatan Bisk and Ruslan Salakhutdinov and Amos Azaria and Tom Mitchell and Yuanzhi Li},
	date-added = {2023-09-13 14:20:01 -0400},
	date-discussed = {2023-11-06 led by Nouha Chatti},
	date-modified = {2023-11-07 10:06:32 -0500},
	howpublished = {arxiv},
	hypoth = {https://hyp.is/go?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2305.15486.pdf&group=__world__},
	in-website = {1},
	keywords = {done, large-language-models, reinforcement-learning},
	order = {3},
	pdf = {2023-arxiv-wu-spring.pdf},
	title = {SPRING: GPT-4 Out-performs RL Algorithms by Studying Papers and Reasoning},
	toread = {1},
	venue-short = {arxiv},
	year = {2023},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxAmLi4vYXNzZXRzL3BkZi8yMDIzLWFyeGl2LXd1LXNwcmluZy5wZGZPEQGcAAAAAAGcAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAAAAAAAAQkQAAf////8YMjAyMy1hcnhpdi13dS1zcHJpbmcucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/////wAAAAAAAAAAAAAAAAABAAMAAAogY3UAAAAAAAAAAAAAAAAAA3BkZgAAAgBJLzpVc2VyczptY3Jvd2xleTpyZXBvczptYXJrY3Jvd2xleS1jYTphc3NldHM6cGRmOjIwMjMtYXJ4aXYtd3Utc3ByaW5nLnBkZgAADgAyABgAMgAwADIAMwAtAGEAcgB4AGkAdgAtAHcAdQAtAHMAcAByAGkAbgBnAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBHVXNlcnMvbWNyb3dsZXkvcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi8yMDIzLWFyeGl2LXd1LXNwcmluZy5wZGYAABMAAS8AABUAAgAP//8AAAAIAA0AGgAkAE0AAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAB7Q==}}

@article{wang2023nature,
	abbr = {AI4Science},
	abstract = {Artificial intelligence (AI) is being increasingly integrated into scientific discovery to augment and accelerate research, helping scientists to generate hypotheses, design experiments, collect and interpret large datasets, and gain insights that might not have been possible using traditional scientific methods alone. Here we examine breakthroughs over the past decade that include self-supervised learning, which allows models to be trained on vast amounts of unlabelled data, and geometric deep learning, which leverages knowledge about the structure of scientific data to enhance model accuracy and efficiency. Generative AI methods can create designs, such as small-molecule drugs and proteins, by analysing diverse data modalities, including images and sequences. We discuss how these methods can help scientists throughout the scientific process and the central issues that remain despite such advances. Both developers and users of AI tools need a better understanding of when such approaches need improvement, and challenges posed by poor data quality and stewardship remain. These issues cut across scientific disciplines and require developing foundational algorithmic approaches that can contribute to scientific understanding or acquire it autonomously, making them critical areas of focus for AI innovation.},
	annote = {This is a great paper to look at for an update on the many ways AI/ML/RL are being used for science. It is written by the organizers of the regular [AI for Science workshop](https://ai4sciencecommunity.github.io/) held at multiple major conferences. There are extensive notes in the hypothesis link of the webpage version of the paper, click the hypothesis link to see the notes.},
	author = {Wang, Hanchen and Fu, Tianfan and Du, Yuanqi and Gao, Wenhao and Huang, Kexin and Liu, Ziming and Chandak, Payal and Liu, Shengchao and Van Katwyk, Peter and Deac, Andreea and Anandkumar, Anima and Bergen, Karianne and Gomes, Carla P. and Ho, Shirley and Kohli, Pushmeet and Lasenby, Joan and Leskovec, Jure and Liu, Tie-Yan and Manrai, Arjun and Marks, Debora and Ramsundar, Bharath and Song, Le and Sun, Jimeng and Tang, Jian and Veli{\v c}kovi{\'c}, Petar and Welling, Max and Zhang, Linfeng and Coley, Connor W. and Bengio, Yoshua and Zitnik, Marinka},
	date = {2023/08/01},
	date-added = {2023-09-11 13:13:07 -0400},
	date-discussed = {2023-10-23 led by Mark Crowley},
	date-modified = {2023-10-23 14:29:37 -0400},
	doi = {10.1038/s41586-023-06221-2},
	hypoth = {https://hyp.is/go?url=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41586-023-06221-2&group=__world__},
	id = {Wang2023},
	in-website = {1},
	isbn = {1476-4687},
	journal = {Nature},
	keywords = {done, ai-for-science, deep-learning, generative-models, large-language-models, nlp, ai-for-physics},
	number = {7972},
	order = {1},
	pages = {47--60},
	title = {Scientific discovery in the age of artificial intelligence},
	toread = {1},
	url = {https://doi.org/10.1038/s41586-023-06221-2},
	venue-short = {Nature},
	volume = {620},
	year = {2023},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxBTLi4vLi4vLi4vRHJvcGJveC93ZWJzaXRlX2Fzc2V0cy9tYXJrY3Jvd2xleS1jYS9wZGZzLzIwMjMtbmF0dXJlLXdhbmctc2NpZW50aWZpYy5wZGZPEQHOAAAAAAHOAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAAAAAAAAQkQAAf////8fMjAyMy1uYXR1cmUtd2FuZy1zY2llbnRpZmljLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/////wAAAAAAAAAAAAAAAAADAAUAAAogY3UAAAAAAAAAAAAAAAAABHBkZnMAAgBbLzpVc2VyczptY3Jvd2xleTpEcm9wYm94OndlYnNpdGVfYXNzZXRzOm1hcmtjcm93bGV5LWNhOnBkZnM6MjAyMy1uYXR1cmUtd2FuZy1zY2llbnRpZmljLnBkZgAADgBAAB8AMgAwADIAMwAtAG4AYQB0AHUAcgBlAC0AdwBhAG4AZwAtAHMAYwBpAGUAbgB0AGkAZgBpAGMALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAFlVc2Vycy9tY3Jvd2xleS9Ecm9wYm94L3dlYnNpdGVfYXNzZXRzL21hcmtjcm93bGV5LWNhL3BkZnMvMjAyMy1uYXR1cmUtd2FuZy1zY2llbnRpZmljLnBkZgAAEwABLwAAFQACAA///wAAAAgADQAaACQAegAAAAAAAAIBAAAAAAAAAAUAAAAAAAAAAAAAAAAAAAJM},
	bdsk-url-1 = {https://doi.org/10.1038/s41586-023-06221-2}}

@article{zecevic2023tmlr,
	abstract = {Some argue scale is all what is needed to achieve AI, covering even causal models. We make it clear that large language models (LLMs) cannot be causal and give reason onto why sometimes we might feel otherwise. To this end, we define and exemplify a new subgroup of Structural Causal Model (SCM) that we call meta SCM which encode causal facts about other SCM within their variables. We conjecture that in the cases where LLM succeed in doing causal inference, underlying was a respective meta SCM that exposed correlations between causal facts in natural language on whose data the LLM was ultimately trained. If our hypothesis holds true, then this would imply that LLMs are like parrots in that they simply recite the causal knowledge embedded in the data. Our empirical analysis provides favoring evidence that current LLMs are even weak `causal parrots.'},
	annote = {This paper has a very bold premise to show clearly what causality and conceptual reasoning means in terms of Large Language Models. They define it clearly int terms of evidence existing in the training set and argue that LLMs can only learn causal relations in those cases. These authors are organizing a workshop on this very topic for NeurIPS 2023.},
	arxiv = {2308.13067},
	author = {Matej Ze{\v{c}}evi{\'c} and Moritz Willig and Devendra Singh Dhami and Kristian Kersting},
	date-added = {2023-06-12 21:48:13 -0400},
	date-discussed = {2023-10-30 led by Shayan},
	date-modified = {2023-11-01 11:34:04 -0400},
	hypoth = {https://hyp.is/go?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2308.13067.pdf&group=__world__},
	in-website = {1},
	issn = {2835-8856},
	journal = {Transactions on Machine Learning Research},
	keywords = {large-language-models, causality, done},
	month = {August},
	order = {2},
	pdf = {2023-tmlr-zecevic-causal.pdf},
	rating = {4},
	title = {Causal Parrots: Large Language Models May Talk Causality But Are Not Causal},
	toread = {1},
	url = {https://openreview.net/forum?id=tv46tCzs83},
	venue-short = {TMLR},
	year = {2023},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxBQLi4vLi4vLi4vRHJvcGJveC93ZWJzaXRlX2Fzc2V0cy9tYXJrY3Jvd2xleS1jYS9wZGZzLzIwMjMtdG1sci16ZWNldmljLWNhdXNhbC5wZGZPEQHAAAAAAAHAAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAAAAAAAAQkQAAf////8cMjAyMy10bWxyLXplY2V2aWMtY2F1c2FsLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/////wAAAAAAAAAAAAAAAAADAAUAAAogY3UAAAAAAAAAAAAAAAAABHBkZnMAAgBYLzpVc2VyczptY3Jvd2xleTpEcm9wYm94OndlYnNpdGVfYXNzZXRzOm1hcmtjcm93bGV5LWNhOnBkZnM6MjAyMy10bWxyLXplY2V2aWMtY2F1c2FsLnBkZgAOADoAHAAyADAAMgAzAC0AdABtAGwAcgAtAHoAZQBjAGUAdgBpAGMALQBjAGEAdQBzAGEAbAAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAVlVzZXJzL21jcm93bGV5L0Ryb3Bib3gvd2Vic2l0ZV9hc3NldHMvbWFya2Nyb3dsZXktY2EvcGRmcy8yMDIzLXRtbHItemVjZXZpYy1jYXVzYWwucGRmABMAAS8AABUAAgAP//8AAAAIAA0AGgAkAHcAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAACOw==}}

@inproceedings{chen2021neurips,
	abbr = {DecTransfrmr},
	abstract = {We introduce a framework that abstracts Reinforcement Learning (RL) as a sequence modeling problem. This allows us to draw upon the simplicity and scalability of the Transformer architecture, and associated advances in language modeling such as GPT-x and BERT. In particular, we present Decision Transformer, an architecture that casts the problem of RL as conditional sequence modeling. Unlike prior approaches to RL that fit value functions or compute policy gradients, Decision Transformer simply outputs the optimal actions by leveraging a causally masked Transformer. By conditioning an autoregressive model on the desired return (reward), past states, and actions, our Decision Transformer model can generate future actions that achieve the desired return. Despite its simplicity, Decision Transformer matches or exceeds the performance of state-of-the-art model-free offline RL baselines on Atari, OpenAI Gym, and Key-to-Door tasks.},
	archiveprefix = {arxiv},
	arxiv = {2106.01345},
	author = {Chen, Lili and Lu, Kevin and Rajeswaran, Aravind and Lee, Kimin and Grover, Aditya and Laskin, Misha and Abbeel, Pieter and Srinivas, Aravind and Mordatch, Igor},
	booktitle = {Advances in Neural Information Processing Systems},
	date-added = {2023-05-28 14:42:06 -0400},
	date-discussed = {2023-11-13 led by ???},
	date-modified = {2023-11-07 10:07:13 -0500},
	editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
	hypoth = {https://hyp.is/go?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2106.01345.pdf&group=__world__},
	in-website = {1},
	keywords = {next, machine-learning, reinforcement-learning, decision-transformers},
	month = {June},
	number = {arXiv:2106.01345},
	order = {4},
	pages = {15084--15097},
	pdf = {2021-neurips-chen-decision.pdf},
	primaryclass = {cs},
	shorttitle = {Decision Transformer},
	status = {1},
	title = {Decision Transformer: Reinforcement Learning via Sequence Modeling},
	toread = {1},
	url = {https://proceedings.neurips.cc/paper_files/paper/2021/file/7f489f642a0ddb10272b5c31057f0663-Paper.pdf},
	urldate = {2022-09-27},
	venue-short = {neurips},
	volume = {34},
	year = {2021},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxAsLi4vYXNzZXRzL3BkZi8yMDIxLW5ldXJpcHMtY2hlbi1kZWNpc2lvbi5wZGZPEQG0AAAAAAG0AAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAAAAAAAAQkQAAf////8eMjAyMS1uZXVyaXBzLWNoZW4tZGVjaXNpb24ucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/////wAAAAAAAAAAAAAAAAABAAMAAAogY3UAAAAAAAAAAAAAAAAAA3BkZgAAAgBPLzpVc2VyczptY3Jvd2xleTpyZXBvczptYXJrY3Jvd2xleS1jYTphc3NldHM6cGRmOjIwMjEtbmV1cmlwcy1jaGVuLWRlY2lzaW9uLnBkZgAADgA+AB4AMgAwADIAMQAtAG4AZQB1AHIAaQBwAHMALQBjAGgAZQBuAC0AZABlAGMAaQBzAGkAbwBuAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBNVXNlcnMvbWNyb3dsZXkvcmVwb3MvbWFya2Nyb3dsZXktY2EvYXNzZXRzL3BkZi8yMDIxLW5ldXJpcHMtY2hlbi1kZWNpc2lvbi5wZGYAABMAAS8AABUAAgAP//8AAAAIAA0AGgAkAFMAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAACCw==},
	bdsk-url-1 = {https://proceedings.neurips.cc/paper_files/paper/2021/file/7f489f642a0ddb10272b5c31057f0663-Paper.pdf}}

@comment{BibDesk Smart Groups{
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<array>
	<dict>
		<key>conditions</key>
		<array>
			<dict>
				<key>comparison</key>
				<integer>2</integer>
				<key>key</key>
				<string>Keywords</string>
				<key>value</key>
				<string>next</string>
				<key>version</key>
				<string>1</string>
			</dict>
		</array>
		<key>conjunction</key>
		<integer>0</integer>
		<key>group name</key>
		<string>1 - next</string>
	</dict>
	<dict>
		<key>conditions</key>
		<array>
			<dict>
				<key>comparison</key>
				<integer>2</integer>
				<key>key</key>
				<string>Keywords</string>
				<key>value</key>
				<string>upcoming</string>
				<key>version</key>
				<string>1</string>
			</dict>
		</array>
		<key>conjunction</key>
		<integer>0</integer>
		<key>group name</key>
		<string>2 - upcoming</string>
	</dict>
	<dict>
		<key>conditions</key>
		<array>
			<dict>
				<key>comparison</key>
				<integer>2</integer>
				<key>key</key>
				<string>Keywords</string>
				<key>value</key>
				<string>potential</string>
				<key>version</key>
				<string>1</string>
			</dict>
		</array>
		<key>conjunction</key>
		<integer>0</integer>
		<key>group name</key>
		<string>3 - potential</string>
	</dict>
</array>
</plist>
}}
